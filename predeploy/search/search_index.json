{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Introduction Getting started To browse the source code of neurolib visit out GitHub repository . Read the gentle introduction to neurolib for an overview of the basic functionality and some background information on the science behind whole-brain simulations. What is neurolib? Please read the gentle introduction to neurolib for an overview of the basic functionality and some background information on the science behind whole-brain simulations or read the documentation for getting started. neurolib allows you to build, simulate, and optimize your own state-of-the-art whole-brain models. To simulate the neural activity of each brain area, the main implementation provides an advanced neural mass mean-field model of spiking adaptive exponential integrate-and-fire neurons (AdEx) called ALNModel . Each brain area is represented by two populations of excitatory and inhibitory neurons. An extensive analysis and validation of the ALNModel model can be found in our paper and its associated github page . neurolib provides a simulation and optimization framework which allows you to easily implement your own neural mass model, simulate fMRI BOLD activity, analyse the results and fit your model to empirical data. Please reference the following paper if you use neurolib for your own research: Reference: Cakan, C., Obermayer, K. (2020). Biophysically grounded mean-field models of neural populations under electrical stimulation. PLOS Computational Biology ( Link ). The figure below shows a schematic of how a brain network is constructed: Examples: Single node simulation \u00b7 Whole-brain network \u00b7 Parameter exploration \u00b7 Evolutionary optimization Whole-brain modeling Typically, in whole-brain modeling, diffusion tensor imaging (DTI) is used to infer the structural connectivity (the connection strength) between different brain areas. In a DTI scan, the direction of the diffusion of molecules is measured across the whole brain. Using tractography , this information can yield the distribution of axonal fibers in the brain that connect distant brain areas, called the connectome. Together with an atlas that divides the brain into distinct areas, a matrix can be computed that encodes how many fibers go from one area to another, the so-called structural connectivity (SC) matrix. This matrix defines the coupling strengths between brain areas and acts as an adjacency matrix of the brain network. The fiber length determines the signal transmission delay between all brain areas. Combining the structural data with a computational model of the neuronal activity of each brain area, we can create a dynamical model of the whole brain. The resulting whole-brain model consists of interconnected brain areas, with each brain area having their internal neural dynamics. The neural activity can also be used to simulate hemodynamic BOLD activity using the Balloon-Windkessel model, which can be compared to empirical fMRI data. Often, BOLD activity is used to compute correlations of activity between brain areas, the so called resting state functional connectivity , resulting in a matrix with correlations between each brain area. This matrix can then be fitted to empirical fMRI recordings of the resting-state activity of the brain. Below is an animation of the neuronal activity of a whole-brain model plotted on a brain. Installation The easiest way to get going is to install the pypi package using pip : pip install neurolib Alternatively, you can also clone this repository and install all dependencies with git clone https://github.com/neurolib-dev/neurolib.git cd neurolib/ pip install -r requirements.txt pip install . It is recommended to clone or fork the entire repository since it will also include all examples and tests. Project layout neurolib/ # Main module \u251c\u2500\u2500 models/ # Neural mass models \u251c\u2500\u2500model.py # Base model class \u2514\u2500\u2500 /.../ # Implemented mass models \u251c\u2500\u2500 optimize/ # Optimization submodule \u251c\u2500\u2500 evolution/ # Evolutionary optimization \u2514\u2500\u2500 exploration/ # Parameter exploration \u251c\u2500\u2500 data/ # Empirical datasets (structural, functional) \u251c\u2500\u2500 utils/ # Utility belt \u251c\u2500\u2500 atlases.py # Atlases (Region names, coordinates) \u251c\u2500\u2500 collections.py # Custom data types \u251c\u2500\u2500 functions.py # Useful functions \u251c\u2500\u2500 loadData.py # Dataset loader \u251c\u2500\u2500 parameterSpace.py # Parameter space \u251c\u2500\u2500 saver.py # Save simulation outputs \u251c\u2500\u2500 signal.py # Signal processing functions \u2514\u2500\u2500 stimulus.py # Stimulus construction \u251c\u2500\u2500 examples/ # Example Jupyter notebooks \u251c\u2500\u2500 docs/ # Documentation \u2514\u2500\u2500 tests/ # Automated tests Examples Example IPython Notebooks on how to use the library can be found in the ./examples/ directory, don't forget to check them out! You can run the examples in your browser using Binder by clicking here or one of the following links: Example 0.0 - Basic use of the aln model Example 0.3 - Fitz-Hugh Nagumo model fhn on a brain network Example 0.6 - Minimal example of how to implement your own model in neurolib Example 1.2 - Parameter exploration of a brain network and fitting to BOLD data Example 2.0 - A simple example of the evolutionary optimization framework A basic overview of the functionality of neurolib is also given in the following. Single node This example is available in detail as a IPython Notebook . To create a single aln model with the default parameters, simply run from neurolib.models.aln import ALNModel model = ALNModel () model . params [ 'sigma_ou' ] = 0.1 # add some noise model . run () The results from this small simulation can be plotted easily: import matplotlib.pyplot as plt plt . plot ( model . t , model . output . T ) Whole-brain network A detailed example is available as a IPython Notebook . To simulate a whole-brain network model, first we need to load a DTI and a resting-state fMRI dataset. neurolib already provides some example data for you: from neurolib.utils.loadData import Dataset ds = Dataset ( \"gw\" ) The dataset that we just loaded, looks like this: We initialize a model with the dataset and run it: model = ALNModel ( Cmat = ds . Cmat , Dmat = ds . Dmat ) model . params [ 'duration' ] = 5 * 60 * 1000 # in ms, simulates for 5 minutes model . run ( bold = True ) This can take several minutes to compute, since we are simulating 80 brain regions for 5 minutes realtime. Note that we specified bold=True which simulates the BOLD model in parallel to the neuronal model. The resulting firing rates and BOLD functional connectivity looks like this: The quality of the fit of this simulation can be computed by correlating the simulated functional connectivity matrix above to the empirical resting-state functional connectivity for each subject of the dataset. This gives us an estimate of how well the model reproduces inter-areal BOLD correlations. As a rule of thumb, a value above 0.5 is considered good. We can compute the quality of the fit of the simulated data using func.fc() which calculates a functional connectivity matrix of N ( N = number of brain regions) time series. We use func.matrix_correlation() to compare this matrix to empirical data. scores = [ func . matrix_correlation ( func . fc ( model . BOLD . BOLD [:, 5 :]), fcemp ) for fcemp in ds . FCs ] print ( \"Correlation per subject:\" , [ f \" { s : .2 } \" for s in scores ]) print ( f \"Mean FC/FC correlation: { np . mean ( scores ) : .2 } \" ) Correlation per subject: ['0.34', '0.61', '0.54', '0.7', '0.54', '0.64', '0.69', '0.47', '0.59', '0.72', '0.58'] Mean FC/FC correlation: 0.58 Parameter exploration A detailed example of a single-node exploration is available as a IPython Notebook . For an example of a brain network exploration, see this Notebook . Whenever you work with a model, it is of great importance to know what kind of dynamics it exhibits given a certain set of parameters. It is often useful to get an overview of the state space of a given model of interest. For example in the case of aln , the dynamics depends a lot on the mean inputs to the excitatory and the inhibitory population. neurolib makes it very easy to quickly explore parameter spaces of a given model: # create model model = ALNModel () # define the parameter space to explore parameters = ParameterSpace ({ \"mue_ext_mean\" : np . linspace ( 0 , 3 , 21 ), # input to E \"mui_ext_mean\" : np . linspace ( 0 , 3 , 21 )}) # input to I # define exploration search = BoxSearch ( model , parameters ) search . run () That's it!. You can now use the builtin functions to load the simulation results from disk and perform your analysis: search . loadResults () # calculate maximum firing rate for each parameter for i in search . dfResults . index : search . dfResults . loc [ i , 'max_r' ] = np . max ( search . results [ i ][ 'rates_exc' ][:, - int ( 1000 / model . params [ 'dt' ]):]) We can plot the results to get something close to a bifurcation diagram! Evolutionary optimization A detailed example is available as a IPython Notebook . neurolib also implements evolutionary parameter optimization, which works particularly well with brain networks. In an evolutionary algorithm, each simulation is represented as an individual and the parameters of the simulation, for example coupling strengths or noise level values, are represented as the genes of each individual. An individual is a part of a population. In each generation, individuals are evaluated and ranked according to a fitness criterion. For whole-brain network simulations, this could be the fit of the simulated activity to empirical data. Then, individuals with a high fitness value are selected as parents and mate to create offspring. These offspring undergo random mutations of their genes. After all offspring are evaluated, the best individuals of the population are selected to transition into the next generation. This process goes on for a given amount generations until a stopping criterion is reached. This could be a predefined maximum number of generations or when a large enough population with high fitness values is found. An example genealogy tree is shown below. You can see the evolution starting at the top and individuals reproducing generation by generation. The color indicates the fitness. neurolib makes it very easy to set up your own evolutionary optimization and everything else is handled under the hood. You can chose between two implemented evolutionary algorithms: adaptive is a gaussian mutation and rank selection algorithm with adaptive step size that ensures convergence (a schematic is shown in the image below). nsga2 is an implementation of the popular multi-objective optimization algorithm by Deb et al. 2002. Of course, if you like, you can dig deeper, define your own selection, mutation and mating operators. In the following demonstration, we will simply evaluate the fitness of each individual as the distance to the unit circle. After a couple of generations of mating, mutating and selecting, only individuals who are close to the circle should survive: from neurolib.utils.parameterSpace import ParameterSpace from neurolib.optimize.evolution import Evolution def optimize_me ( traj ): ind = evolution . getIndividualFromTraj ( traj ) # let's make a circle fitness_result = abs (( ind . x ** 2 + ind . y ** 2 ) - 1 ) # gather results fitness_tuple = ( fitness_result ,) result_dict = { \"result\" : [ fitness_result ]} return fitness_tuple , result_dict # we define a parameter space and its boundaries pars = ParameterSpace ([ 'x' , 'y' ], [[ - 5.0 , 5.0 ], [ - 5.0 , 5.0 ]]) # initialize the evolution and go evolution = Evolution ( optimize_me , pars , weightList = [ - 1.0 ], POP_INIT_SIZE = 100 , POP_SIZE = 50 , NGEN = 10 ) evolution . run () That's it! Now we can check the results: evolution . loadResults () evolution . info ( plot = True ) This will gives us a summary of the last generation and plots a distribution of the individuals (and their parameters). Below is an animation of 10 generations of the evolutionary process. Ass you can see, after a couple of generations, all remaining individuals lie very close to the unit circle. More information Built With neurolib is built using other amazing open source projects: pypet - Python parameter exploration toolbox deap - Distributed Evolutionary Algorithms in Python numpy - The fundamental package for scientific computing with Python numba - NumPy aware dynamic Python compiler using LLVM Jupyter - Jupyter Interactive Notebook Get in touch Caglar Cakan (cakan@ni.tu-berlin.de) Department of Software Engineering and Theoretical Computer Science, Technische Universit\u00e4t Berlin, Germany Bernstein Center for Computational Neuroscience Berlin, Germany Acknowledgments This work was supported by the Deutsche Forschungsgemeinschaft (DFG, German Research Foundation) with the project number 327654276 (SFB 1315) and the Research Training Group GRK1589/2.","title":"Introduction"},{"location":"#introduction","text":"","title":"Introduction"},{"location":"#getting-started","text":"To browse the source code of neurolib visit out GitHub repository . Read the gentle introduction to neurolib for an overview of the basic functionality and some background information on the science behind whole-brain simulations.","title":"Getting started"},{"location":"#what-is-neurolib","text":"Please read the gentle introduction to neurolib for an overview of the basic functionality and some background information on the science behind whole-brain simulations or read the documentation for getting started. neurolib allows you to build, simulate, and optimize your own state-of-the-art whole-brain models. To simulate the neural activity of each brain area, the main implementation provides an advanced neural mass mean-field model of spiking adaptive exponential integrate-and-fire neurons (AdEx) called ALNModel . Each brain area is represented by two populations of excitatory and inhibitory neurons. An extensive analysis and validation of the ALNModel model can be found in our paper and its associated github page . neurolib provides a simulation and optimization framework which allows you to easily implement your own neural mass model, simulate fMRI BOLD activity, analyse the results and fit your model to empirical data. Please reference the following paper if you use neurolib for your own research: Reference: Cakan, C., Obermayer, K. (2020). Biophysically grounded mean-field models of neural populations under electrical stimulation. PLOS Computational Biology ( Link ). The figure below shows a schematic of how a brain network is constructed: Examples: Single node simulation \u00b7 Whole-brain network \u00b7 Parameter exploration \u00b7 Evolutionary optimization","title":"What is neurolib?"},{"location":"#whole-brain-modeling","text":"Typically, in whole-brain modeling, diffusion tensor imaging (DTI) is used to infer the structural connectivity (the connection strength) between different brain areas. In a DTI scan, the direction of the diffusion of molecules is measured across the whole brain. Using tractography , this information can yield the distribution of axonal fibers in the brain that connect distant brain areas, called the connectome. Together with an atlas that divides the brain into distinct areas, a matrix can be computed that encodes how many fibers go from one area to another, the so-called structural connectivity (SC) matrix. This matrix defines the coupling strengths between brain areas and acts as an adjacency matrix of the brain network. The fiber length determines the signal transmission delay between all brain areas. Combining the structural data with a computational model of the neuronal activity of each brain area, we can create a dynamical model of the whole brain. The resulting whole-brain model consists of interconnected brain areas, with each brain area having their internal neural dynamics. The neural activity can also be used to simulate hemodynamic BOLD activity using the Balloon-Windkessel model, which can be compared to empirical fMRI data. Often, BOLD activity is used to compute correlations of activity between brain areas, the so called resting state functional connectivity , resulting in a matrix with correlations between each brain area. This matrix can then be fitted to empirical fMRI recordings of the resting-state activity of the brain. Below is an animation of the neuronal activity of a whole-brain model plotted on a brain.","title":"Whole-brain modeling"},{"location":"#installation","text":"The easiest way to get going is to install the pypi package using pip : pip install neurolib Alternatively, you can also clone this repository and install all dependencies with git clone https://github.com/neurolib-dev/neurolib.git cd neurolib/ pip install -r requirements.txt pip install . It is recommended to clone or fork the entire repository since it will also include all examples and tests.","title":"Installation"},{"location":"#project-layout","text":"neurolib/ # Main module \u251c\u2500\u2500 models/ # Neural mass models \u251c\u2500\u2500model.py # Base model class \u2514\u2500\u2500 /.../ # Implemented mass models \u251c\u2500\u2500 optimize/ # Optimization submodule \u251c\u2500\u2500 evolution/ # Evolutionary optimization \u2514\u2500\u2500 exploration/ # Parameter exploration \u251c\u2500\u2500 data/ # Empirical datasets (structural, functional) \u251c\u2500\u2500 utils/ # Utility belt \u251c\u2500\u2500 atlases.py # Atlases (Region names, coordinates) \u251c\u2500\u2500 collections.py # Custom data types \u251c\u2500\u2500 functions.py # Useful functions \u251c\u2500\u2500 loadData.py # Dataset loader \u251c\u2500\u2500 parameterSpace.py # Parameter space \u251c\u2500\u2500 saver.py # Save simulation outputs \u251c\u2500\u2500 signal.py # Signal processing functions \u2514\u2500\u2500 stimulus.py # Stimulus construction \u251c\u2500\u2500 examples/ # Example Jupyter notebooks \u251c\u2500\u2500 docs/ # Documentation \u2514\u2500\u2500 tests/ # Automated tests","title":"Project layout"},{"location":"#examples","text":"Example IPython Notebooks on how to use the library can be found in the ./examples/ directory, don't forget to check them out! You can run the examples in your browser using Binder by clicking here or one of the following links: Example 0.0 - Basic use of the aln model Example 0.3 - Fitz-Hugh Nagumo model fhn on a brain network Example 0.6 - Minimal example of how to implement your own model in neurolib Example 1.2 - Parameter exploration of a brain network and fitting to BOLD data Example 2.0 - A simple example of the evolutionary optimization framework A basic overview of the functionality of neurolib is also given in the following.","title":"Examples"},{"location":"#single-node","text":"This example is available in detail as a IPython Notebook . To create a single aln model with the default parameters, simply run from neurolib.models.aln import ALNModel model = ALNModel () model . params [ 'sigma_ou' ] = 0.1 # add some noise model . run () The results from this small simulation can be plotted easily: import matplotlib.pyplot as plt plt . plot ( model . t , model . output . T )","title":"Single node"},{"location":"#whole-brain-network","text":"A detailed example is available as a IPython Notebook . To simulate a whole-brain network model, first we need to load a DTI and a resting-state fMRI dataset. neurolib already provides some example data for you: from neurolib.utils.loadData import Dataset ds = Dataset ( \"gw\" ) The dataset that we just loaded, looks like this: We initialize a model with the dataset and run it: model = ALNModel ( Cmat = ds . Cmat , Dmat = ds . Dmat ) model . params [ 'duration' ] = 5 * 60 * 1000 # in ms, simulates for 5 minutes model . run ( bold = True ) This can take several minutes to compute, since we are simulating 80 brain regions for 5 minutes realtime. Note that we specified bold=True which simulates the BOLD model in parallel to the neuronal model. The resulting firing rates and BOLD functional connectivity looks like this: The quality of the fit of this simulation can be computed by correlating the simulated functional connectivity matrix above to the empirical resting-state functional connectivity for each subject of the dataset. This gives us an estimate of how well the model reproduces inter-areal BOLD correlations. As a rule of thumb, a value above 0.5 is considered good. We can compute the quality of the fit of the simulated data using func.fc() which calculates a functional connectivity matrix of N ( N = number of brain regions) time series. We use func.matrix_correlation() to compare this matrix to empirical data. scores = [ func . matrix_correlation ( func . fc ( model . BOLD . BOLD [:, 5 :]), fcemp ) for fcemp in ds . FCs ] print ( \"Correlation per subject:\" , [ f \" { s : .2 } \" for s in scores ]) print ( f \"Mean FC/FC correlation: { np . mean ( scores ) : .2 } \" ) Correlation per subject: ['0.34', '0.61', '0.54', '0.7', '0.54', '0.64', '0.69', '0.47', '0.59', '0.72', '0.58'] Mean FC/FC correlation: 0.58","title":"Whole-brain network"},{"location":"#parameter-exploration","text":"A detailed example of a single-node exploration is available as a IPython Notebook . For an example of a brain network exploration, see this Notebook . Whenever you work with a model, it is of great importance to know what kind of dynamics it exhibits given a certain set of parameters. It is often useful to get an overview of the state space of a given model of interest. For example in the case of aln , the dynamics depends a lot on the mean inputs to the excitatory and the inhibitory population. neurolib makes it very easy to quickly explore parameter spaces of a given model: # create model model = ALNModel () # define the parameter space to explore parameters = ParameterSpace ({ \"mue_ext_mean\" : np . linspace ( 0 , 3 , 21 ), # input to E \"mui_ext_mean\" : np . linspace ( 0 , 3 , 21 )}) # input to I # define exploration search = BoxSearch ( model , parameters ) search . run () That's it!. You can now use the builtin functions to load the simulation results from disk and perform your analysis: search . loadResults () # calculate maximum firing rate for each parameter for i in search . dfResults . index : search . dfResults . loc [ i , 'max_r' ] = np . max ( search . results [ i ][ 'rates_exc' ][:, - int ( 1000 / model . params [ 'dt' ]):]) We can plot the results to get something close to a bifurcation diagram!","title":"Parameter exploration"},{"location":"#evolutionary-optimization","text":"A detailed example is available as a IPython Notebook . neurolib also implements evolutionary parameter optimization, which works particularly well with brain networks. In an evolutionary algorithm, each simulation is represented as an individual and the parameters of the simulation, for example coupling strengths or noise level values, are represented as the genes of each individual. An individual is a part of a population. In each generation, individuals are evaluated and ranked according to a fitness criterion. For whole-brain network simulations, this could be the fit of the simulated activity to empirical data. Then, individuals with a high fitness value are selected as parents and mate to create offspring. These offspring undergo random mutations of their genes. After all offspring are evaluated, the best individuals of the population are selected to transition into the next generation. This process goes on for a given amount generations until a stopping criterion is reached. This could be a predefined maximum number of generations or when a large enough population with high fitness values is found. An example genealogy tree is shown below. You can see the evolution starting at the top and individuals reproducing generation by generation. The color indicates the fitness. neurolib makes it very easy to set up your own evolutionary optimization and everything else is handled under the hood. You can chose between two implemented evolutionary algorithms: adaptive is a gaussian mutation and rank selection algorithm with adaptive step size that ensures convergence (a schematic is shown in the image below). nsga2 is an implementation of the popular multi-objective optimization algorithm by Deb et al. 2002. Of course, if you like, you can dig deeper, define your own selection, mutation and mating operators. In the following demonstration, we will simply evaluate the fitness of each individual as the distance to the unit circle. After a couple of generations of mating, mutating and selecting, only individuals who are close to the circle should survive: from neurolib.utils.parameterSpace import ParameterSpace from neurolib.optimize.evolution import Evolution def optimize_me ( traj ): ind = evolution . getIndividualFromTraj ( traj ) # let's make a circle fitness_result = abs (( ind . x ** 2 + ind . y ** 2 ) - 1 ) # gather results fitness_tuple = ( fitness_result ,) result_dict = { \"result\" : [ fitness_result ]} return fitness_tuple , result_dict # we define a parameter space and its boundaries pars = ParameterSpace ([ 'x' , 'y' ], [[ - 5.0 , 5.0 ], [ - 5.0 , 5.0 ]]) # initialize the evolution and go evolution = Evolution ( optimize_me , pars , weightList = [ - 1.0 ], POP_INIT_SIZE = 100 , POP_SIZE = 50 , NGEN = 10 ) evolution . run () That's it! Now we can check the results: evolution . loadResults () evolution . info ( plot = True ) This will gives us a summary of the last generation and plots a distribution of the individuals (and their parameters). Below is an animation of 10 generations of the evolutionary process. Ass you can see, after a couple of generations, all remaining individuals lie very close to the unit circle.","title":"Evolutionary optimization"},{"location":"#more-information","text":"","title":"More information"},{"location":"#built-with","text":"neurolib is built using other amazing open source projects: pypet - Python parameter exploration toolbox deap - Distributed Evolutionary Algorithms in Python numpy - The fundamental package for scientific computing with Python numba - NumPy aware dynamic Python compiler using LLVM Jupyter - Jupyter Interactive Notebook","title":"Built With"},{"location":"#get-in-touch","text":"Caglar Cakan (cakan@ni.tu-berlin.de) Department of Software Engineering and Theoretical Computer Science, Technische Universit\u00e4t Berlin, Germany Bernstein Center for Computational Neuroscience Berlin, Germany","title":"Get in touch"},{"location":"#acknowledgments","text":"This work was supported by the Deutsche Forschungsgemeinschaft (DFG, German Research Foundation) with the project number 327654276 (SFB 1315) and the Research Training Group GRK1589/2.","title":"Acknowledgments"},{"location":"contributing/","text":"Contributing to neurolib Thank you for your interest in contributing to neurolib . We welcome bug reports through the issues tab and pull requests for fixes or improvements. You are warlmy invited to join our development efforts and make brain network modeling easier and more useful for all researchers. Pull requests To propose a change to neurolib 's code, you should first clone the repository to your own Github account. Then, create a branch and make some changes. You can then send a pull request to neurolib's own repository and we will review and discuss your proposed changes. More information on how to make pull requests can be found in the Github help pages. Maintaining code Please be aware that we have a conservative policy for implementing new functionality. All new features need to be maintained, sometimes forever. We are a small team of developers and can only maintain a limited amount of code. Therefore, ideally, you should also feel responsible for the changes you have proposed and maintain it after it becomes part of neurolib . Code style We are using the black code formatter with the additional argument --line-length=120 . It's called the \"uncompromising formatter\" because it is completely deterministic and you have literally no control over how your code will look like. We like that! We recommend using black directly in your IDE, for example in VSCode . Commenting Code We are using the sphinx format for commenting code. Comments are incredibly important to us since neurolib is supposed to be a library of user-facing code. It's encouraged to read the code, change it and build something on top of it. Our users are coders. Please write as many comments as you can, including a description of each function and method and its arguments but also single-line comments for the code itself. Implementing a neural mass model You are very welcome to implement your favorite neural mass model and contribute it to neurolib . The easiest way of implementing a model is to copy a model directory and adapt the relevant parts of it to your own model. Please have a look of how other models are implemented. We recommend having a look at the HopfModel which is a fairly simple model. All models inherit from the Model base class which can be found in neurolib/models/model.py . You can also check out the model implementation example to find out how a model is implemented. All models need to pass tests. Tests are located in the tests/ directory of the project. A model should be added to the test files tests/test_models.py and tests/test_autochunk.py . However, you should also make sure that your model supports as many neurolib features as possible, such as exploration and optimization. If you did everything right, this should be the case. As of now, models consist of three parts: The model.py file which contains the class of the model. Here the model specifies attributes like its name, its state variables, its initial value parameters. Additionally, in the constructor (the __init__() method), the model loads its default parameters. The loadDefaultParams.py file contains a function ( loadDefaultParams() ) which has the arguments Cmat for the structural connectivity matrix, Dmat for the delay matrix and seed for the seed of the random number generator. This function returns a dictionary (or dotdict , see neurolib/utils/collections.py ) with all parrameters inside. The timeIntegration.py file which contains a timeIntegration() function which has the argument params coming from the previous step. Here, we need to prepare the numerical integration. We load all relevant parameters from the params dictionary and pass it to the main integration loop. The integration loop is written such that it can be accelerated by numba ( numba's page ) which speeds up the integration by a factor of around 1000. Contributing examples We very much welcome example contributions since they help new users to learn how to make use of neurolib . They can include basic usage examples or tutorials of neurolib 's features, or a demonstration of how to solve a specific scientific task using neural mass models or whole-brain networks. Examples are provided as Jupyter Notebooks in the /examples/ directory of the project repository. Notebooks should have a brief description of what they are trying to accomplish at the beginning. It is recommended to change the working directory to the root directory at the very beginning of the notebook ( os.chdir('..') ). Notebooks should be structured with different subheadings (Markdown style). Please also describe in words what you are doing in code. Contributing brain data We have a few small datasets already in neurolib so everyone can start simulating right away. If you'd like to contribute more data to the project, please feel invited to do so. We're looking for more structural connectivity matrices and fiber length matrices in the MATLAB matrix .mat format (which can be loaded by scipy.loadmat ). We also appreciate BOLD data, EEG data, or MEG data. Other modalities could be useful as well. Please be aware that the data has to be in a parcellated form, i.e., the brain areas need to be organized according to an atlas like the AAL2 atlas (or others).","title":"Contributing to neurolib"},{"location":"contributing/#contributing-to-neurolib","text":"Thank you for your interest in contributing to neurolib . We welcome bug reports through the issues tab and pull requests for fixes or improvements. You are warlmy invited to join our development efforts and make brain network modeling easier and more useful for all researchers.","title":"Contributing to neurolib"},{"location":"contributing/#pull-requests","text":"To propose a change to neurolib 's code, you should first clone the repository to your own Github account. Then, create a branch and make some changes. You can then send a pull request to neurolib's own repository and we will review and discuss your proposed changes. More information on how to make pull requests can be found in the Github help pages.","title":"Pull requests"},{"location":"contributing/#maintaining-code","text":"Please be aware that we have a conservative policy for implementing new functionality. All new features need to be maintained, sometimes forever. We are a small team of developers and can only maintain a limited amount of code. Therefore, ideally, you should also feel responsible for the changes you have proposed and maintain it after it becomes part of neurolib .","title":"Maintaining code"},{"location":"contributing/#code-style","text":"We are using the black code formatter with the additional argument --line-length=120 . It's called the \"uncompromising formatter\" because it is completely deterministic and you have literally no control over how your code will look like. We like that! We recommend using black directly in your IDE, for example in VSCode .","title":"Code style"},{"location":"contributing/#commenting-code","text":"We are using the sphinx format for commenting code. Comments are incredibly important to us since neurolib is supposed to be a library of user-facing code. It's encouraged to read the code, change it and build something on top of it. Our users are coders. Please write as many comments as you can, including a description of each function and method and its arguments but also single-line comments for the code itself.","title":"Commenting Code"},{"location":"contributing/#implementing-a-neural-mass-model","text":"You are very welcome to implement your favorite neural mass model and contribute it to neurolib . The easiest way of implementing a model is to copy a model directory and adapt the relevant parts of it to your own model. Please have a look of how other models are implemented. We recommend having a look at the HopfModel which is a fairly simple model. All models inherit from the Model base class which can be found in neurolib/models/model.py . You can also check out the model implementation example to find out how a model is implemented. All models need to pass tests. Tests are located in the tests/ directory of the project. A model should be added to the test files tests/test_models.py and tests/test_autochunk.py . However, you should also make sure that your model supports as many neurolib features as possible, such as exploration and optimization. If you did everything right, this should be the case. As of now, models consist of three parts: The model.py file which contains the class of the model. Here the model specifies attributes like its name, its state variables, its initial value parameters. Additionally, in the constructor (the __init__() method), the model loads its default parameters. The loadDefaultParams.py file contains a function ( loadDefaultParams() ) which has the arguments Cmat for the structural connectivity matrix, Dmat for the delay matrix and seed for the seed of the random number generator. This function returns a dictionary (or dotdict , see neurolib/utils/collections.py ) with all parrameters inside. The timeIntegration.py file which contains a timeIntegration() function which has the argument params coming from the previous step. Here, we need to prepare the numerical integration. We load all relevant parameters from the params dictionary and pass it to the main integration loop. The integration loop is written such that it can be accelerated by numba ( numba's page ) which speeds up the integration by a factor of around 1000.","title":"Implementing a neural mass model"},{"location":"contributing/#contributing-examples","text":"We very much welcome example contributions since they help new users to learn how to make use of neurolib . They can include basic usage examples or tutorials of neurolib 's features, or a demonstration of how to solve a specific scientific task using neural mass models or whole-brain networks. Examples are provided as Jupyter Notebooks in the /examples/ directory of the project repository. Notebooks should have a brief description of what they are trying to accomplish at the beginning. It is recommended to change the working directory to the root directory at the very beginning of the notebook ( os.chdir('..') ). Notebooks should be structured with different subheadings (Markdown style). Please also describe in words what you are doing in code.","title":"Contributing examples"},{"location":"contributing/#contributing-brain-data","text":"We have a few small datasets already in neurolib so everyone can start simulating right away. If you'd like to contribute more data to the project, please feel invited to do so. We're looking for more structural connectivity matrices and fiber length matrices in the MATLAB matrix .mat format (which can be loaded by scipy.loadmat ). We also appreciate BOLD data, EEG data, or MEG data. Other modalities could be useful as well. Please be aware that the data has to be in a parcellated form, i.e., the brain areas need to be organized according to an atlas like the AAL2 atlas (or others).","title":"Contributing brain data"},{"location":"examples/example-0-aln-minimal/","text":"(function() { function addWidgetsRenderer() { var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var scriptElement = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} scriptElement.src = widgetRendererSrc; document.body.appendChild(scriptElement); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); The neural mass model In this example, we will learn about the basic of neurolib . We will create a two-population mean-field model of exponential integrate-and-fire neurons called the aln model. We will learn how to create a Model , set some parameters and run a simulation. We will also see how we can easily access the output of each simulation. aln - the adaptive linear-nonlinear cascade model The adaptive linear-nonlinear ( aln ) cascade model is a low-dimensional population model of spiking neural networks. Mathematically, it is a dynamical system of non-linear ODEs. The dynamical variables of the system simulated in the aln model describe the average firing rate and other macroscopic variables of a randomly connected, delay-coupled network of excitatory and inhibitory adative exponential integrate-and-fire neurons (AdEx) with non-linear synaptic currents. Ultimately, the model is a result of various steps of model reduction starting from the Fokker-Planck equation of the AdEx neuron subject to white noise input at many steps of input means \\(\\mu\\) and variances \\(\\sigma\\) . The resulting mean firing rates and mean membrane potentials are then stored in a lookup table and serve as the nonlinear firing rate transfer function, \\(r = \\Phi(\\mu, \\sigma)\\) . Basic use # change to the root directory of the project import os if os . getcwd () . split ( \"/\" )[ - 1 ] == \"examples\" : os . chdir ( '..' ) # This will reload all imports as soon as the code changes % load_ext autoreload % autoreload 2 try : import matplotlib.pyplot as plt except ImportError : import sys ! { sys . executable } - m pip install matplotlib import matplotlib.pyplot as plt import numpy as np import scipy # Let's import the aln model from neurolib.models.aln import ALNModel # Some useful functions are provided here import neurolib.utils.functions as func # a nice color map plt . rcParams [ 'image.cmap' ] = 'plasma' Simulating a single aln node To create a single node, we simply instanciate the model without any arguments. # Create the model aln = ALNModel () # Each model comes with a set of default parameters which are are a dictionary. # Let's change the parameter that controls the duration of a simulation to 10s. aln . params [ 'duration' ] = 10.0 * 1000 # For convenience, we could also use: aln . params . duration = 10.0 * 1000 # In the aln model an Ornstein-Uhlenbeck process is simulated in parallel # as the source of input noise fluctuations. Here we can set the variance # of the process. # For more info: https://en.wikipedia.org/wiki/Ornstein%E2%80%93Uhlenbeck_process # Let's add some noise. aln . params [ 'sigma_ou' ] = 0.1 # Finally, we run the model aln . run () Accessing the outputs Accessing the outputs is straight-forward. Every model's outputs are stored in the model.outputs attribute. According to the specific name of each of the model's outputs, they can also be accessed as a key of the Model object, i.e. aln['rates_exc'] . plt . plot ( aln [ 't' ], aln [ 'rates_exc' ] . T , lw = 2 , c = 'k' ) plt . xlabel ( \"t [ms]\" ) plt . ylabel ( \"Rate [Hz]\" ) plt . xlim ( 1000 , 2000 ); # Outputs are also available as an xr DataArray xr = aln . xr () print ( xr . dims ) # outputs can also be accessed via attributes in dot.notation print ( \"rates_exc\" , aln . rates_exc ) ('output', 'space', 'time') rates_exc [[0.54644307 0.48676051 0.43664265 ... 0.06910043 0.06969732 0.07031085]] Bifurcation diagram Bifurcation diagrams can give us an overview of how different parameters of the model affect its dynamics. The simplest method for drawing a bifurcation diagram is to simply change relevant parameters step by step and record the model's behavior in response to these changes. In this example, we want to see how the model's dynamics changes with respect to the external input currents to the excitatory population. These input currents could be due to couplings with other nodes in a brain network or we could model other factors like external electrical stimulation. Below, you can see a schematic of the aln model. As you can see, a single node consists of one excitatory (red) and one inhibitory population (blue). The parameter that controls the mean input to the excitatory population is \\(\\mu_{E}\\) or aln.params[\"mue_ext_mean\"] . Let's first decrease the duration of a single run so we can scan the parameter space a bit faster and let's also disable the noisy input. aln . params [ 'duration' ] = 2.0 * 1000 aln . params [ 'sigma_ou' ] = 0.0 Let's fix the input to the inhibitory population: aln . params [ 'mui_ext_mean' ] = 0.5 We draw a one-dimensional bifurcation diagram, so it is enough to loop through different values of mue_ext_mean and record the minimum and maximum of the rate for each parameter. max_rate_e = [] min_rate_e = [] # these are the different input values that we want to scan mue_inputs = np . linspace ( 0 , 2 , 50 ) for mue in mue_inputs : # Note: this has to be a vector since it is input for all nodes # (but we have only one node in this example) aln . params [ 'mue_ext_mean' ] = mue aln . run () # we add the maximum and the minimum of the last second of the # simulation to a list max_rate_e . append ( np . max ( aln . output [ 0 , - int ( 1000 / aln . params [ 'dt' ]):])) min_rate_e . append ( np . min ( aln . output [ 0 , - int ( 1000 / aln . params [ 'dt' ]):])) Let's plot the results! plt . plot ( mue_inputs , max_rate_e , c = 'k' , lw = 2 ) plt . plot ( mue_inputs , min_rate_e , c = 'k' , lw = 2 ) plt . title ( \"Bifurcation diagram of the aln model\" ) plt . xlabel ( \"Input to excitatory population\" ) plt . ylabel ( \"Min / max firing rate\" ) Text(0, 0.5, 'Min / max firing rate') Whole-brain model neurolib comes with some example datasets for exploring its functionality. Please be aware that these datasets are not tested and should not be used for your research, only for experimentation with the software. A dataset for whole-brain modeling can consists of the following parts: A structural connectivity matrix capturing the synaptic connection strengths between brain areas, often derived from DTI tractography of the whole brain. The connectome is then typically parcellated in a preferred atlas (for exapmle the AAL2 atlas) and the number of axonal fibers connecting each brain area with every other area is counted. This number serves as a indication of the synaptic coupling strengths between the areas of the brain. A delay matrix which can be calculated from the average length of the axonal fibers connecting each brain area with another. A set of functional data that can act as a target for model optimization. Resting-state fMRI offers an easy and fairly unbiased way for calibrating whole-brain models. EEG data could be used as well. We can load a Dataset by passing the name of it in the constructor. from neurolib.utils.loadData import Dataset ds = Dataset ( \"gw\" ) We now create the aln model with a structural connectivity matrix and a delay matrix. In order to achieve a good fit of the BOLD activity to the empirical data, the model has to run for quite a while. A a rule of thumb, a simulation of resting-state BOLD activity should not be shorter than 3 minutes and preferrably longer than 5 minutes real time. If the empirical recordings are for example 10 minues long, ideally, a simulation of 10 minutes would be used to compare the output of the model to the resting state recording. aln = ALNModel ( Cmat = ds . Cmat , Dmat = ds . Dmat ) aln . params [ 'duration' ] = 0.2 * 60 * 1000 # Info: value 0.2*60*1000 is low for testing # use 5*60*1000 for real simulation After some optimization to the resting-state fMRI data of the dataset, we found a set of parameters that creates interesting whole-brain dynamics. We set the mean input of the excitatory and the inhibitory population to be close to the E-I limit cycle. aln . params [ 'mue_ext_mean' ] = 1.57 aln . params [ 'mui_ext_mean' ] = 1.6 # We set an appropriate level of noise aln . params [ 'sigma_ou' ] = 0.09 # And turn on adaptation with a low value of spike-triggered adaptation currents. aln . params [ 'b' ] = 5.0 Let's have a look what the data looks like. We can access the data of each model by calling its internal attrivbutes. Here, we plot the structural connectivity matrix by calling aln.params['Cmat'] and fiber length matrix by calling aln.params['lengthMat'] . Of course, we can also access the dataset using the Dataset object itself. For example the functional conencity matrices of the BOLD timeseries in the datasets are given as list with ds.FCs . from matplotlib.colors import LogNorm fig , axs = plt . subplots ( 1 , 3 , figsize = ( 12 , 8 ), dpi = 75 ) fig . subplots_adjust ( wspace = 0.28 ) im = axs [ 0 ] . imshow ( aln . params [ 'Cmat' ], norm = LogNorm ( vmin = 10e-5 , vmax = np . max ( aln . params [ 'Cmat' ]))) axs [ 0 ] . set_title ( \"Cmat\" ) fig . colorbar ( im , ax = axs [ 0 ], fraction = 0.046 , pad = 0.04 ) im = axs [ 1 ] . imshow ( aln . params [ 'lengthMat' ], cmap = 'inferno' ) axs [ 1 ] . set_title ( \"Dmat\" ) fig . colorbar ( im , ax = axs [ 1 ], fraction = 0.046 , pad = 0.04 ) im = axs [ 2 ] . imshow ( ds . FCs [ 0 ], cmap = 'inferno' ) axs [ 2 ] . set_title ( \"Empirical FC\" ) fig . colorbar ( im , ax = axs [ 2 ], fraction = 0.046 , pad = 0.04 ) <matplotlib.colorbar.Colorbar at 0x12c0ac5c0> Run model We run the model with bold simulation by using bold=True . This simulates the Balloon-Windkessel BOLD model in parallel to the neural population model in order to estimate the blood oxigen levels of the underlying neural activity. The output of the bold model can be used to compare the simulated data to empirical fMRI data (resting-state fMRI for example). To save (a lot of) RAM, we can run the simulation in chunkwise mode. In this mode, the model will be simulated for a length of chunksize steps (not time in ms, but actual integration steps!), and the output of that chunk will be used to automatically reinitiate the model with the appropriate initial conditions. This allows for a serial continuation of the model without having to store all the data in memory and is particularly useful for very long and many parallel simulations. aln . run ( chunkwise = True , chunksize = 100000 , bold = True ) Results The outputs of the model can be accessed using the attribute model.outputs aln . outputs {'t': array([0.000e+00, 1.000e-01, 2.000e-01, ..., 9.598e+02, 9.599e+02, 9.600e+02]), 'rates_exc': array([[0.00835719, 0.00840018, 0.008441 , ..., 0.07789972, 0.07678947, 0.07575822]]), 'rates_inh': array([[6.67987791, 6.74212832, 6.82498266, ..., 9.74761859, 9.76436539, 9.75417725]]), 'BOLD': {'t': array([1.00000e-01, 2.00010e+03, 4.00010e+03, 6.00010e+03, 8.00010e+03, 1.00001e+04, 1.20001e+04, 1.40001e+04, 1.60001e+04, 1.80001e+04, 2.00001e+04, 2.20001e+04, 2.40001e+04]), 'BOLD': array([[1.37324205e-10, 2.32894551e-02, 2.52461497e-02, 1.57354848e-02, 9.56109432e-03, 1.05825534e-02, 1.12229272e-02, 1.22928019e-02, 1.53881680e-02, 1.50792887e-02, 1.27970412e-02, 1.30106312e-02, 1.40587017e-02]])}} For convenience, they can also be accessed directly using attributes of the model with the outputs name, like aln.rates_exc . The outputs are also available as xr DataArrays as aln.xr() . The since we used bold=True to simulate BOLD, we can also access aln.BOLD.BOLD for the actual BOLD activity, and aln.BOLD.t for the time steps of the BOLD simulation (which are downsampled to 0.5 Hz by default). Plot simulated activity # Plot functional connectivity and BOLD timeseries (z-scored) fig , axs = plt . subplots ( 1 , 2 , figsize = ( 6 , 2 ), dpi = 75 , gridspec_kw = { 'width_ratios' : [ 1 , 2 ]}) axs [ 0 ] . imshow ( func . fc ( aln . BOLD . BOLD [:, 5 :])) axs [ 1 ] . imshow ( scipy . stats . mstats . zscore ( aln . BOLD . BOLD [:, aln . BOLD . t_BOLD > 10000 ], axis = 1 ), aspect = 'auto' , extent = [ aln . BOLD . t_BOLD [ aln . BOLD . t_BOLD > 10000 ][ 0 ], aln . BOLD . t_BOLD [ - 1 ], 0 , aln . params [ 'N' ]]); axs [ 0 ] . set_title ( \"FC\" ) axs [ 0 ] . set_xlabel ( \"Node\" ) axs [ 0 ] . set_ylabel ( \"Node\" ) axs [ 1 ] . set_xlabel ( \"t [ms]\" ) # the results of the model are also accesible through an xarray DataArray fig , axs = plt . subplots ( 1 , 1 , figsize = ( 6 , 2 ), dpi = 75 ) plt . plot ( aln . xr () . time , aln . xr () . loc [ 'rates_exc' ] . T ); Correlation of simulated BOLD to empirical data We can compute the element-wise Pearson correlation of the functional connectivity matrices of the simulated data to the empirical data to estimate how well the model captures the inter-areal BOLD correlations found in empirical resting-state recordings. scores = [ func . matrix_correlation ( func . fc ( aln . BOLD . BOLD [:, 5 :]), fcemp ) for fcemp in ds . FCs ] print ( \"Correlation per subject:\" , [ f \" { s : .2 } \" for s in scores ]) print ( f \"Mean FC/FC correlation: { np . mean ( scores ) : .2 } \" ) Correlation per subject: ['0.52', '0.54', '0.67', '0.49', '0.69'] Mean FC/FC correlation: 0.58","title":"Example 0 aln minimal"},{"location":"examples/example-0-aln-minimal/#the-neural-mass-model","text":"In this example, we will learn about the basic of neurolib . We will create a two-population mean-field model of exponential integrate-and-fire neurons called the aln model. We will learn how to create a Model , set some parameters and run a simulation. We will also see how we can easily access the output of each simulation.","title":"The neural mass model"},{"location":"examples/example-0-aln-minimal/#aln-the-adaptive-linear-nonlinear-cascade-model","text":"The adaptive linear-nonlinear ( aln ) cascade model is a low-dimensional population model of spiking neural networks. Mathematically, it is a dynamical system of non-linear ODEs. The dynamical variables of the system simulated in the aln model describe the average firing rate and other macroscopic variables of a randomly connected, delay-coupled network of excitatory and inhibitory adative exponential integrate-and-fire neurons (AdEx) with non-linear synaptic currents. Ultimately, the model is a result of various steps of model reduction starting from the Fokker-Planck equation of the AdEx neuron subject to white noise input at many steps of input means \\(\\mu\\) and variances \\(\\sigma\\) . The resulting mean firing rates and mean membrane potentials are then stored in a lookup table and serve as the nonlinear firing rate transfer function, \\(r = \\Phi(\\mu, \\sigma)\\) .","title":"aln - the adaptive linear-nonlinear cascade model"},{"location":"examples/example-0-aln-minimal/#basic-use","text":"# change to the root directory of the project import os if os . getcwd () . split ( \"/\" )[ - 1 ] == \"examples\" : os . chdir ( '..' ) # This will reload all imports as soon as the code changes % load_ext autoreload % autoreload 2 try : import matplotlib.pyplot as plt except ImportError : import sys ! { sys . executable } - m pip install matplotlib import matplotlib.pyplot as plt import numpy as np import scipy # Let's import the aln model from neurolib.models.aln import ALNModel # Some useful functions are provided here import neurolib.utils.functions as func # a nice color map plt . rcParams [ 'image.cmap' ] = 'plasma'","title":"Basic use"},{"location":"examples/example-0-aln-minimal/#simulating-a-single-aln-node","text":"To create a single node, we simply instanciate the model without any arguments. # Create the model aln = ALNModel () # Each model comes with a set of default parameters which are are a dictionary. # Let's change the parameter that controls the duration of a simulation to 10s. aln . params [ 'duration' ] = 10.0 * 1000 # For convenience, we could also use: aln . params . duration = 10.0 * 1000 # In the aln model an Ornstein-Uhlenbeck process is simulated in parallel # as the source of input noise fluctuations. Here we can set the variance # of the process. # For more info: https://en.wikipedia.org/wiki/Ornstein%E2%80%93Uhlenbeck_process # Let's add some noise. aln . params [ 'sigma_ou' ] = 0.1 # Finally, we run the model aln . run ()","title":"Simulating a single aln node"},{"location":"examples/example-0-aln-minimal/#accessing-the-outputs","text":"Accessing the outputs is straight-forward. Every model's outputs are stored in the model.outputs attribute. According to the specific name of each of the model's outputs, they can also be accessed as a key of the Model object, i.e. aln['rates_exc'] . plt . plot ( aln [ 't' ], aln [ 'rates_exc' ] . T , lw = 2 , c = 'k' ) plt . xlabel ( \"t [ms]\" ) plt . ylabel ( \"Rate [Hz]\" ) plt . xlim ( 1000 , 2000 ); # Outputs are also available as an xr DataArray xr = aln . xr () print ( xr . dims ) # outputs can also be accessed via attributes in dot.notation print ( \"rates_exc\" , aln . rates_exc ) ('output', 'space', 'time') rates_exc [[0.54644307 0.48676051 0.43664265 ... 0.06910043 0.06969732 0.07031085]]","title":"Accessing the outputs"},{"location":"examples/example-0-aln-minimal/#bifurcation-diagram","text":"Bifurcation diagrams can give us an overview of how different parameters of the model affect its dynamics. The simplest method for drawing a bifurcation diagram is to simply change relevant parameters step by step and record the model's behavior in response to these changes. In this example, we want to see how the model's dynamics changes with respect to the external input currents to the excitatory population. These input currents could be due to couplings with other nodes in a brain network or we could model other factors like external electrical stimulation. Below, you can see a schematic of the aln model. As you can see, a single node consists of one excitatory (red) and one inhibitory population (blue). The parameter that controls the mean input to the excitatory population is \\(\\mu_{E}\\) or aln.params[\"mue_ext_mean\"] . Let's first decrease the duration of a single run so we can scan the parameter space a bit faster and let's also disable the noisy input. aln . params [ 'duration' ] = 2.0 * 1000 aln . params [ 'sigma_ou' ] = 0.0 Let's fix the input to the inhibitory population: aln . params [ 'mui_ext_mean' ] = 0.5 We draw a one-dimensional bifurcation diagram, so it is enough to loop through different values of mue_ext_mean and record the minimum and maximum of the rate for each parameter. max_rate_e = [] min_rate_e = [] # these are the different input values that we want to scan mue_inputs = np . linspace ( 0 , 2 , 50 ) for mue in mue_inputs : # Note: this has to be a vector since it is input for all nodes # (but we have only one node in this example) aln . params [ 'mue_ext_mean' ] = mue aln . run () # we add the maximum and the minimum of the last second of the # simulation to a list max_rate_e . append ( np . max ( aln . output [ 0 , - int ( 1000 / aln . params [ 'dt' ]):])) min_rate_e . append ( np . min ( aln . output [ 0 , - int ( 1000 / aln . params [ 'dt' ]):])) Let's plot the results! plt . plot ( mue_inputs , max_rate_e , c = 'k' , lw = 2 ) plt . plot ( mue_inputs , min_rate_e , c = 'k' , lw = 2 ) plt . title ( \"Bifurcation diagram of the aln model\" ) plt . xlabel ( \"Input to excitatory population\" ) plt . ylabel ( \"Min / max firing rate\" ) Text(0, 0.5, 'Min / max firing rate')","title":"Bifurcation diagram"},{"location":"examples/example-0-aln-minimal/#whole-brain-model","text":"neurolib comes with some example datasets for exploring its functionality. Please be aware that these datasets are not tested and should not be used for your research, only for experimentation with the software. A dataset for whole-brain modeling can consists of the following parts: A structural connectivity matrix capturing the synaptic connection strengths between brain areas, often derived from DTI tractography of the whole brain. The connectome is then typically parcellated in a preferred atlas (for exapmle the AAL2 atlas) and the number of axonal fibers connecting each brain area with every other area is counted. This number serves as a indication of the synaptic coupling strengths between the areas of the brain. A delay matrix which can be calculated from the average length of the axonal fibers connecting each brain area with another. A set of functional data that can act as a target for model optimization. Resting-state fMRI offers an easy and fairly unbiased way for calibrating whole-brain models. EEG data could be used as well. We can load a Dataset by passing the name of it in the constructor. from neurolib.utils.loadData import Dataset ds = Dataset ( \"gw\" ) We now create the aln model with a structural connectivity matrix and a delay matrix. In order to achieve a good fit of the BOLD activity to the empirical data, the model has to run for quite a while. A a rule of thumb, a simulation of resting-state BOLD activity should not be shorter than 3 minutes and preferrably longer than 5 minutes real time. If the empirical recordings are for example 10 minues long, ideally, a simulation of 10 minutes would be used to compare the output of the model to the resting state recording. aln = ALNModel ( Cmat = ds . Cmat , Dmat = ds . Dmat ) aln . params [ 'duration' ] = 0.2 * 60 * 1000 # Info: value 0.2*60*1000 is low for testing # use 5*60*1000 for real simulation After some optimization to the resting-state fMRI data of the dataset, we found a set of parameters that creates interesting whole-brain dynamics. We set the mean input of the excitatory and the inhibitory population to be close to the E-I limit cycle. aln . params [ 'mue_ext_mean' ] = 1.57 aln . params [ 'mui_ext_mean' ] = 1.6 # We set an appropriate level of noise aln . params [ 'sigma_ou' ] = 0.09 # And turn on adaptation with a low value of spike-triggered adaptation currents. aln . params [ 'b' ] = 5.0 Let's have a look what the data looks like. We can access the data of each model by calling its internal attrivbutes. Here, we plot the structural connectivity matrix by calling aln.params['Cmat'] and fiber length matrix by calling aln.params['lengthMat'] . Of course, we can also access the dataset using the Dataset object itself. For example the functional conencity matrices of the BOLD timeseries in the datasets are given as list with ds.FCs . from matplotlib.colors import LogNorm fig , axs = plt . subplots ( 1 , 3 , figsize = ( 12 , 8 ), dpi = 75 ) fig . subplots_adjust ( wspace = 0.28 ) im = axs [ 0 ] . imshow ( aln . params [ 'Cmat' ], norm = LogNorm ( vmin = 10e-5 , vmax = np . max ( aln . params [ 'Cmat' ]))) axs [ 0 ] . set_title ( \"Cmat\" ) fig . colorbar ( im , ax = axs [ 0 ], fraction = 0.046 , pad = 0.04 ) im = axs [ 1 ] . imshow ( aln . params [ 'lengthMat' ], cmap = 'inferno' ) axs [ 1 ] . set_title ( \"Dmat\" ) fig . colorbar ( im , ax = axs [ 1 ], fraction = 0.046 , pad = 0.04 ) im = axs [ 2 ] . imshow ( ds . FCs [ 0 ], cmap = 'inferno' ) axs [ 2 ] . set_title ( \"Empirical FC\" ) fig . colorbar ( im , ax = axs [ 2 ], fraction = 0.046 , pad = 0.04 ) <matplotlib.colorbar.Colorbar at 0x12c0ac5c0>","title":"Whole-brain model"},{"location":"examples/example-0-aln-minimal/#run-model","text":"We run the model with bold simulation by using bold=True . This simulates the Balloon-Windkessel BOLD model in parallel to the neural population model in order to estimate the blood oxigen levels of the underlying neural activity. The output of the bold model can be used to compare the simulated data to empirical fMRI data (resting-state fMRI for example). To save (a lot of) RAM, we can run the simulation in chunkwise mode. In this mode, the model will be simulated for a length of chunksize steps (not time in ms, but actual integration steps!), and the output of that chunk will be used to automatically reinitiate the model with the appropriate initial conditions. This allows for a serial continuation of the model without having to store all the data in memory and is particularly useful for very long and many parallel simulations. aln . run ( chunkwise = True , chunksize = 100000 , bold = True )","title":"Run model"},{"location":"examples/example-0-aln-minimal/#results","text":"The outputs of the model can be accessed using the attribute model.outputs aln . outputs {'t': array([0.000e+00, 1.000e-01, 2.000e-01, ..., 9.598e+02, 9.599e+02, 9.600e+02]), 'rates_exc': array([[0.00835719, 0.00840018, 0.008441 , ..., 0.07789972, 0.07678947, 0.07575822]]), 'rates_inh': array([[6.67987791, 6.74212832, 6.82498266, ..., 9.74761859, 9.76436539, 9.75417725]]), 'BOLD': {'t': array([1.00000e-01, 2.00010e+03, 4.00010e+03, 6.00010e+03, 8.00010e+03, 1.00001e+04, 1.20001e+04, 1.40001e+04, 1.60001e+04, 1.80001e+04, 2.00001e+04, 2.20001e+04, 2.40001e+04]), 'BOLD': array([[1.37324205e-10, 2.32894551e-02, 2.52461497e-02, 1.57354848e-02, 9.56109432e-03, 1.05825534e-02, 1.12229272e-02, 1.22928019e-02, 1.53881680e-02, 1.50792887e-02, 1.27970412e-02, 1.30106312e-02, 1.40587017e-02]])}} For convenience, they can also be accessed directly using attributes of the model with the outputs name, like aln.rates_exc . The outputs are also available as xr DataArrays as aln.xr() . The since we used bold=True to simulate BOLD, we can also access aln.BOLD.BOLD for the actual BOLD activity, and aln.BOLD.t for the time steps of the BOLD simulation (which are downsampled to 0.5 Hz by default).","title":"Results"},{"location":"examples/example-0-aln-minimal/#plot-simulated-activity","text":"# Plot functional connectivity and BOLD timeseries (z-scored) fig , axs = plt . subplots ( 1 , 2 , figsize = ( 6 , 2 ), dpi = 75 , gridspec_kw = { 'width_ratios' : [ 1 , 2 ]}) axs [ 0 ] . imshow ( func . fc ( aln . BOLD . BOLD [:, 5 :])) axs [ 1 ] . imshow ( scipy . stats . mstats . zscore ( aln . BOLD . BOLD [:, aln . BOLD . t_BOLD > 10000 ], axis = 1 ), aspect = 'auto' , extent = [ aln . BOLD . t_BOLD [ aln . BOLD . t_BOLD > 10000 ][ 0 ], aln . BOLD . t_BOLD [ - 1 ], 0 , aln . params [ 'N' ]]); axs [ 0 ] . set_title ( \"FC\" ) axs [ 0 ] . set_xlabel ( \"Node\" ) axs [ 0 ] . set_ylabel ( \"Node\" ) axs [ 1 ] . set_xlabel ( \"t [ms]\" ) # the results of the model are also accesible through an xarray DataArray fig , axs = plt . subplots ( 1 , 1 , figsize = ( 6 , 2 ), dpi = 75 ) plt . plot ( aln . xr () . time , aln . xr () . loc [ 'rates_exc' ] . T );","title":"Plot simulated activity"},{"location":"examples/example-0-aln-minimal/#correlation-of-simulated-bold-to-empirical-data","text":"We can compute the element-wise Pearson correlation of the functional connectivity matrices of the simulated data to the empirical data to estimate how well the model captures the inter-areal BOLD correlations found in empirical resting-state recordings. scores = [ func . matrix_correlation ( func . fc ( aln . BOLD . BOLD [:, 5 :]), fcemp ) for fcemp in ds . FCs ] print ( \"Correlation per subject:\" , [ f \" { s : .2 } \" for s in scores ]) print ( f \"Mean FC/FC correlation: { np . mean ( scores ) : .2 } \" ) Correlation per subject: ['0.52', '0.54', '0.67', '0.49', '0.69'] Mean FC/FC correlation: 0.58","title":"Correlation of simulated BOLD to empirical data"},{"location":"examples/example-0.1-hopf-minimal/","text":"(function() { function addWidgetsRenderer() { var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var scriptElement = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} scriptElement.src = widgetRendererSrc; document.body.appendChild(scriptElement); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); # change to the root directory of the project import os if os . getcwd () . split ( \"/\" )[ - 1 ] == \"examples\" : os . chdir ( '..' ) % load_ext autoreload % autoreload 2 try : import matplotlib.pyplot as plt except ImportError : import sys ! { sys . executable } - m pip install matplotlib import matplotlib.pyplot as plt import numpy as np # Let's import the hopf model from neurolib.models.hopf import HopfModel # Some useful functions are provided here import neurolib.utils.functions as func # a nice color map plt . rcParams [ 'image.cmap' ] = 'plasma' Single node simulation hopf = HopfModel () hopf . params [ 'duration' ] = 1.0 * 1000 hopf . params [ 'sigma_ou' ] = 0.03 hopf . run () plt . plot ( hopf . t , hopf . x . T , c = 'k' , lw = 2 ) # alternatively plot the results in the xarray: # plt.plot(hopfModel.xr[0, 0].time, hopfModel.xr[0, 0].values) plt . xlabel ( \"t [ms]\" ) plt . ylabel ( \"Activity\" ) Text(0, 0.5, 'Activity') Bifurcation diagram hopf = HopfModel () hopf . params [ 'duration' ] = 2.0 * 1000 max_x = [] min_x = [] # these are the different input values that we want to scan a_s = np . linspace ( - 2 , 2 , 50 ) for a in a_s : hopf . params [ 'a' ] = a hopf . run () # we add the maximum and the minimum of the last second of the # simulation to a list max_x . append ( np . max ( hopf . x [ 0 , - int ( 1000 / hopf . params [ 'dt' ]):])) min_x . append ( np . min ( hopf . x [ 0 , - int ( 1000 / hopf . params [ 'dt' ]):])) plt . plot ( a_s , max_x , c = 'k' , lw = 2 ) plt . plot ( a_s , min_x , c = 'k' , lw = 2 ) plt . title ( \"Bifurcation diagram of the Hopf oscillator\" ) plt . xlabel ( \"a\" ) plt . ylabel ( \"Min / max x\" ) Text(0, 0.5, 'Min / max x') Brain network from neurolib.utils.loadData import Dataset ds = Dataset ( \"hcp\" ) hopf = HopfModel ( Cmat = ds . Cmat , Dmat = ds . Dmat ) hopf . params [ 'w' ] = 1.0 hopf . params [ 'signalV' ] = 0 hopf . params [ 'duration' ] = 20 * 1000 hopf . params [ 'sigma_ou' ] = 0.14 hopf . params [ 'K_gl' ] = 0.6 hopf . run ( chunkwise = True ) plt . plot ( hopf . t , hopf . x [:: 5 , :] . T , alpha = 0.8 ); plt . xlim ( 0 , 200 ) plt . xlabel ( \"t [ms]\" ) Text(0.5, 0, 't [ms]') fig , axs = plt . subplots ( 1 , 2 , figsize = ( 8 , 2 )) axs [ 0 ] . imshow ( func . fc ( hopf . x [:, - 10000 :])) axs [ 1 ] . plot ( hopf . t , hopf . x [:: 5 , :] . T , alpha = 0.8 ); scores = [ func . matrix_correlation ( func . fc ( hopf . x [:, - int ( 5000 / hopf . params [ 'dt' ]):]), fcemp ) for fcemp in ds . FCs ] print ( \"Correlation per subject:\" , [ f \" { s : .2 } \" for s in scores ]) print ( \"Mean FC/FC correlation: {:.2f} \" . format ( np . mean ( scores ))) Correlation per subject: ['0.54', '0.63', '0.66', '0.53', '0.55', '0.55', '0.69'] Mean FC/FC correlation: 0.59","title":"Example 0.1 hopf minimal"},{"location":"examples/example-0.1-hopf-minimal/#single-node-simulation","text":"hopf = HopfModel () hopf . params [ 'duration' ] = 1.0 * 1000 hopf . params [ 'sigma_ou' ] = 0.03 hopf . run () plt . plot ( hopf . t , hopf . x . T , c = 'k' , lw = 2 ) # alternatively plot the results in the xarray: # plt.plot(hopfModel.xr[0, 0].time, hopfModel.xr[0, 0].values) plt . xlabel ( \"t [ms]\" ) plt . ylabel ( \"Activity\" ) Text(0, 0.5, 'Activity')","title":"Single node simulation"},{"location":"examples/example-0.1-hopf-minimal/#bifurcation-diagram","text":"hopf = HopfModel () hopf . params [ 'duration' ] = 2.0 * 1000 max_x = [] min_x = [] # these are the different input values that we want to scan a_s = np . linspace ( - 2 , 2 , 50 ) for a in a_s : hopf . params [ 'a' ] = a hopf . run () # we add the maximum and the minimum of the last second of the # simulation to a list max_x . append ( np . max ( hopf . x [ 0 , - int ( 1000 / hopf . params [ 'dt' ]):])) min_x . append ( np . min ( hopf . x [ 0 , - int ( 1000 / hopf . params [ 'dt' ]):])) plt . plot ( a_s , max_x , c = 'k' , lw = 2 ) plt . plot ( a_s , min_x , c = 'k' , lw = 2 ) plt . title ( \"Bifurcation diagram of the Hopf oscillator\" ) plt . xlabel ( \"a\" ) plt . ylabel ( \"Min / max x\" ) Text(0, 0.5, 'Min / max x')","title":"Bifurcation diagram"},{"location":"examples/example-0.1-hopf-minimal/#brain-network","text":"from neurolib.utils.loadData import Dataset ds = Dataset ( \"hcp\" ) hopf = HopfModel ( Cmat = ds . Cmat , Dmat = ds . Dmat ) hopf . params [ 'w' ] = 1.0 hopf . params [ 'signalV' ] = 0 hopf . params [ 'duration' ] = 20 * 1000 hopf . params [ 'sigma_ou' ] = 0.14 hopf . params [ 'K_gl' ] = 0.6 hopf . run ( chunkwise = True ) plt . plot ( hopf . t , hopf . x [:: 5 , :] . T , alpha = 0.8 ); plt . xlim ( 0 , 200 ) plt . xlabel ( \"t [ms]\" ) Text(0.5, 0, 't [ms]') fig , axs = plt . subplots ( 1 , 2 , figsize = ( 8 , 2 )) axs [ 0 ] . imshow ( func . fc ( hopf . x [:, - 10000 :])) axs [ 1 ] . plot ( hopf . t , hopf . x [:: 5 , :] . T , alpha = 0.8 ); scores = [ func . matrix_correlation ( func . fc ( hopf . x [:, - int ( 5000 / hopf . params [ 'dt' ]):]), fcemp ) for fcemp in ds . FCs ] print ( \"Correlation per subject:\" , [ f \" { s : .2 } \" for s in scores ]) print ( \"Mean FC/FC correlation: {:.2f} \" . format ( np . mean ( scores ))) Correlation per subject: ['0.54', '0.63', '0.66', '0.53', '0.55', '0.55', '0.69'] Mean FC/FC correlation: 0.59","title":"Brain network"},{"location":"examples/example-0.2-basic_analysis/","text":"(function() { function addWidgetsRenderer() { var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var scriptElement = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} scriptElement.src = widgetRendererSrc; document.body.appendChild(scriptElement); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); Introduction # change to the root directory of the project import os if os . getcwd () . split ( \"/\" )[ - 1 ] == \"examples\" : os . chdir ( '..' ) # This will reload all imports as soon as the code changes % load_ext autoreload % autoreload 2 try : import matplotlib.pyplot as plt except ImportError : import sys ! { sys . executable } - m pip install matplotlib import matplotlib.pyplot as plt from functools import partial import numpy as np from neurolib.models.aln import ALNModel from neurolib.utils.loadData import Dataset from neurolib.utils.signal import RatesSignal , BOLDSignal plt . rcParams [ 'image.cmap' ] = 'plasma' Run the ALN model Firstly, let us run a network model given the structural connectivity and fiber lengths. ds = Dataset ( \"gw\" ) # simulates the whole-brain model aln = ALNModel ( Cmat = ds . Cmat , Dmat = ds . Dmat ) # Resting state fits aln . params [ 'mue_ext_mean' ] = 1.57 aln . params [ 'mui_ext_mean' ] = 1.6 aln . params [ 'sigma_ou' ] = 0.09 aln . params [ 'b' ] = 5.0 aln . params [ 'duration' ] = 0.2 * 60 * 1000 # info: value 0.2*60*1000 is low for testing # use 5*60*1000 for real simulation aln . run ( chunkwise = True , bold = True ) WARNING:root:aln: BOLD simulation is supported only with chunkwise integration. Enabling chunkwise integration. Now we can cast the modelling result into our Signal class. Signal is a parent base class for any neuro signal. We also provide three child class for particular signals: RatesSignal (for firing rate of the populations), VoltageSignal (for average membrane potential of the populations), and BOLDSignal (for simulated BOLD). They only differ in name, labels and units. Nothing fancy. Of course, you can implement your own class for your particular results very easily as: from neurolib.utils.signal import Signal class PostSynapticCurrentSignal ( Signal ): name = \"Population post-synaptic current signal\" label = \"I_syn\" signal_type = \"post_current\" unit = \"mA\" and that's it. All useful methods and attributes are directly inhereted from the Signal parent. # Create Signal out of firing rates fr = RatesSignal . from_model_output ( aln , group = \"\" , time_in_ms = True ) # optional description fr . description = \"Output of the ALN model with default SC and fiber lengths\" # Create Signal out of BOLD simulated timeseries bold = BOLDSignal . from_model_output ( aln , group = \"BOLD\" , time_in_ms = True ) bold . description = \"Simulated BOLD of the ALN model with default SC and fiber lengths\" # let's check what's inside print ( fr ) print ( bold ) Population firing rate representing rate signal with unit of Hz with user-provided description: `Output of the ALN model with default SC and fiber lengths`. Shape of the signal is (2, 80, 8831) with dimensions ('output', 'space', 'time'). Population blood oxygen level-dependent signal representing bold signal with unit of % with user-provided description: `Simulated BOLD of the ALN model with default SC and fiber lengths`. Shape of the signal is (1, 80, 7) with dimensions ('output', 'space', 'time'). Signal automatically computes useful attributes like dt , sampling rate, starting and ending times. # inherent attributes print ( \"Inherent attributes:\" ) print ( fr . name ) print ( fr . label ) print ( fr . unit ) print ( fr . signal_type ) print ( fr . description ) # computed attributes print ( \" \\n Computed attributes:\" ) print ( fr . dt ) print ( fr . sampling_frequency ) print ( fr . start_time ) print ( fr . end_time ) print ( fr . shape ) Inherent attributes: Population firing rate q Hz rate Output of the ALN model with default SC and fiber lengths Computed attributes: 0.0001 10000.0 0.0 0.883 (2, 80, 8831) # internal representation of the signal is just xarray's DataArray print ( fr . data ) # xarray is just pandas on steroids, i.e. it supports multi-dimensional arrays, not only 2D # if you'd need simple numpy array just call .values on signal's data print ( type ( fr . data . values )) print ( fr . data . values . shape ) <xarray.DataArray (output: 2, space: 80, time: 8831)> array([[[1.33261450e-02, 1.36917651e-02, 1.40695947e-02, ..., 3.48158384e-03, 3.46784876e-03, 3.46133411e-03], [6.13965587e-01, 6.25356604e-01, 6.34768740e-01, ..., 3.59993904e-01, 3.54528049e-01, 3.49018287e-01], [6.36038906e-02, 6.35557804e-02, 6.33770702e-02, ..., 4.42949449e-02, 4.37566338e-02, 4.32171260e-02], ..., [2.50859629e-03, 2.52563325e-03, 2.54037707e-03, ..., 8.00547429e-03, 7.78636724e-03, 7.61333390e-03], [5.95617787e-02, 6.07513850e-02, 6.20942706e-02, ..., 3.26872805e-02, 3.33536801e-02, 3.40569905e-02], [4.96090615e-02, 4.84730168e-02, 4.73428175e-02, ..., 1.05820581e-01, 1.05724932e-01, 1.05846529e-01]], [[4.17821712e+00, 4.21196680e+00, 4.23883558e+00, ..., 1.01836901e+01, 1.00264571e+01, 9.86191716e+00], [6.83616353e+00, 6.91560104e+00, 6.97566672e+00, ..., 8.07743197e+00, 8.08297235e+00, 8.07994833e+00], [6.57108005e+00, 6.49135703e+00, 6.43050397e+00, ..., 8.93701663e+00, 8.95484465e+00, 8.97588108e+00], ..., [8.75902323e+00, 8.81787556e+00, 8.89506320e+00, ..., 7.48694404e+00, 7.41863238e+00, 7.35970182e+00], [4.15841271e+00, 4.15037911e+00, 4.15057015e+00, ..., 6.61282248e+00, 6.60115808e+00, 6.58597805e+00], [9.52609773e+00, 9.39861579e+00, 9.28794497e+00, ..., 5.83291993e+00, 5.90070345e+00, 5.94592106e+00]]]) Coordinates: * output (output) <U9 'rates_exc' 'rates_inh' * space (space) int64 0 1 2 3 4 5 6 7 8 9 ... 70 71 72 73 74 75 76 77 78 79 * time (time) float64 0.0 0.0001 0.0002 0.0003 ... 0.8828 0.8829 0.883 <class 'numpy.ndarray'> (2, 80, 8831) Now let's see what Signal can do... Just a side note, all operations can be done inplace (everything happens inside signal class), or altered signal is returned with the same attributes as the original one # basic operations norm = fr . normalize ( std = True , inplace = False ) # so, are all temporal means close to zero? print ( np . allclose ( norm . data . mean ( dim = \"time\" ), 0. )) # aand, are all temporal std close to 1? print ( np . allclose ( norm . data . std ( dim = \"time\" ), 1.0 )) plt . plot ( fr [ \"rates_exc\" ] . data . sel ({ \"space\" : 0 }), label = \"original\" ) plt . plot ( norm [ \"rates_exc\" ] . data . sel ({ \"space\" : 0 }), label = \"normalised\" ) # you can detrend the signal, all of it, or by segments (as indices within the signal) # let's first normalise (so inplace=False), then detrend (we can inplace=True) detrended = fr . normalize ( std = True , inplace = False ) detrended . detrend ( inplace = True ) plt . plot ( detrended [ \"rates_exc\" ] . data . sel ({ \"space\" : 0 }), label = \"normalised & detrended\" ) detrended_segments = fr . detrend ( segments = np . arange ( 20000 , 1000 ), inplace = False ) plt . legend () True True <matplotlib.legend.Legend at 0x1301a4320> so, the sampling frequency is too high, let's resample print ( fr . sampling_frequency ) plt . plot ( fr . data . time , fr [ \"rates_exc\" ] . data . sel ({ \"space\" : 0 }), label = \"original\" ) fr . resample ( to_frequency = 1000. , inplace = True ) print ( fr . sampling_frequency ) plt . plot ( fr . data . time , fr [ \"rates_exc\" ] . data . sel ({ \"space\" : 0 }), label = \"resampled\" ) plt . legend () 10000.0 1000.0 <matplotlib.legend.Legend at 0x131e0e940> More complete example Let's do a more complete example. Let's say, you run the model and want to extract phase and amplitude of the \\(\\alpha\\) band (i.e. 8-12Hz) for some phase-amplitude coupling analyses. # init again to start fresh fr = RatesSignal . from_model_output ( aln , group = \"\" , time_in_ms = True ) plt . plot ( fr . data . time , fr [ \"rates_exc\" ] . data . sel ({ \"space\" : 0 }), label = \"original\" ) # first resample fr . resample ( to_frequency = 1000. , inplace = True ) # next detrend fr . detrend ( inplace = True ) print ( fr . start_time , fr . end_time ) # next pad with 0s for 0.5 seconds in order to suppress edge effect when filtering padded = fr . pad ( how_much = 0.5 , in_seconds = True , padding_type = \"constant\" , side = \"both\" , constant_values = 0. , inplace = False ) print ( padded . start_time , padded . end_time ) # now filter - by default uses mne, if not installed, falls back to scipy basic IIR filter padded . filter ( low_freq = 8. , high_freq = 12. , inplace = True ) # now cut back the original length filtered = padded . sel ([ fr . start_time , fr . end_time ], inplace = False ) print ( filtered . start_time , filtered . end_time ) plt . plot ( filtered . data . time , filtered [ \"rates_exc\" ] . data . sel ({ \"space\" : 0 }), label = r \"filtered $\\alpha$\" ) # finally, get phase and amplitude via Hilbert transform phase = filtered . hilbert_transform ( return_as = \"phase_wrapped\" , inplace = False ) plt . plot ( phase . data . time , phase [ \"rates_exc\" ] . data . sel ({ \"space\" : 0 }), label = r \"phase $\\alpha$\" ) amplitude = filtered . hilbert_transform ( return_as = \"amplitude\" , inplace = False ) plt . plot ( amplitude . data . time , amplitude [ \"rates_exc\" ] . data . sel ({ \"space\" : 0 }), label = r \"amplitude $\\alpha$\" ) plt . legend () 0.0 0.882 -0.5 1.382 Setting up band-pass filter from 8 - 12 Hz FIR filter parameters --------------------- Designing a one-pass, zero-phase, non-causal bandpass filter: - Windowed time-domain design (firwin) method - Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation - Lower passband edge: 8.00 - Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 7.00 Hz) - Upper passband edge: 12.00 Hz - Upper transition bandwidth: 3.00 Hz (-6 dB cutoff frequency: 13.50 Hz) - Filter length: 1651 samples (1.651 sec) 0.0 0.882 <matplotlib.legend.Legend at 0x1322e6e80> # in case you forget that happened in the processing, you can easily check all steps: print ( phase . preprocessing_steps ) print ( amplitude . preprocessing_steps ) resample to 1000.0Hz -> detrend -> 0.5s constant both sides padding -> filter: low 8.0Hz - high 12.0Hz -> select x:0.882s -> Hilbert - wrapped phase resample to 1000.0Hz -> detrend -> 0.5s constant both sides padding -> filter: low 8.0Hz - high 12.0Hz -> select x:0.882s -> Hilbert - amplitude Saving / loading # and you can save your signal for future generations! (saved as netCDF file) phase . save ( \"phase_from_some_experiment\" ) # and then load it phase_loaded = RatesSignal . from_file ( \"phase_from_some_experiment\" ) # compare whether it is the same print ( phase == phase_loaded ) # the attributes are saved/loaded as well print ( phase_loaded . name ) print ( phase_loaded . unit ) print ( phase_loaded . preprocessing_steps ) # delete file os . remove ( \"phase_from_some_experiment.nc\" ) True Population firing rate Hz resample to 1000.0Hz -> detrend -> 0.5s constant both sides padding -> filter: low 8.0Hz - high 12.0Hz -> select x:0.882s -> Hilbert - wrapped phase Iterators Sometimes it is useful to apply or see something in a loop. That's why Signal supports both: iterating over space / outputs variables and applying some 1D function over temporal dimensions. # this will iterate over whole data and return one 1D temporal slice at the time, each slice is Signal class for name , ts in fr . iterate ( return_as = \"signal\" ): print ( name , type ( ts ), ts . start_time , ts . end_time ) # this will iterate over whole data and return one 1D temporal slice at the time, each slice is DataArray for name , ts in fr . iterate ( return_as = \"xr\" ): print ( name , type ( ts ), ts . shape , ts . shape ) ('rates_exc', 0) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 1) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 2) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 3) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 4) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 5) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 6) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 7) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 8) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 9) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 10) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 11) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 12) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 13) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 14) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 15) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 16) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 17) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 18) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 19) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 20) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 21) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 22) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 23) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 24) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 25) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 26) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 27) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 28) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 29) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 30) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 31) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 32) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 33) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 34) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 35) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 36) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 37) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 38) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 39) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 40) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 41) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 42) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 43) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 44) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 45) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 46) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 47) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 48) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 49) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 50) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 51) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 52) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 53) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 54) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 55) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 56) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 57) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 58) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 59) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 60) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 61) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 62) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 63) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 64) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 65) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 66) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 67) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 68) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 69) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 70) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 71) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 72) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 73) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 74) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 75) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 76) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 77) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 78) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 79) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 0) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 1) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 2) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 3) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 4) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 5) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 6) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 7) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 8) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 9) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 10) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 11) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 12) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 13) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 14) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 15) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 16) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 17) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 18) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 19) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 20) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 21) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 22) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 23) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 24) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 25) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 26) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 27) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 28) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 29) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 30) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 31) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 32) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 33) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 34) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 35) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 36) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 37) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 38) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 39) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 40) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 41) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 42) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 43) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 44) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 45) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 46) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 47) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 48) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 49) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 50) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 51) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 52) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 53) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 54) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 55) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 56) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 57) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 58) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 59) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 60) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 61) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 62) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 63) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 64) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 65) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 66) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 67) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 68) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 69) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 70) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 71) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 72) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 73) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 74) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 75) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 76) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 77) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 78) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 79) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 0) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 1) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 2) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 3) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 4) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 5) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 6) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 7) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 8) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 9) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 10) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 11) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 12) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 13) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 14) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 15) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 16) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 17) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 18) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 19) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 20) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 21) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 22) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 23) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 24) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 25) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 26) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 27) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 28) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 29) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 30) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 31) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 32) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 33) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 34) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 35) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 36) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 37) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 38) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 39) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 40) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 41) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 42) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 43) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 44) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 45) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 46) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 47) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 48) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 49) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 50) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 51) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 52) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 53) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 54) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 55) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 56) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 57) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 58) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 59) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 60) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 61) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 62) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 63) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 64) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 65) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 66) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 67) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 68) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 69) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 70) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 71) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 72) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 73) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 74) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 75) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 76) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 77) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 78) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 79) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 0) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 1) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 2) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 3) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 4) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 5) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 6) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 7) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 8) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 9) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 10) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 11) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 12) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 13) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 14) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 15) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 16) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 17) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 18) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 19) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 20) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 21) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 22) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 23) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 24) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 25) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 26) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 27) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 28) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 29) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 30) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 31) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 32) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 33) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 34) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 35) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 36) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 37) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 38) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 39) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 40) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 41) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 42) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 43) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 44) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 45) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 46) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 47) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 48) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 49) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 50) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 51) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 52) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 53) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 54) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 55) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 56) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 57) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 58) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 59) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 60) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 61) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 62) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 63) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 64) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 65) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 66) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 67) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 68) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 69) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 70) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 71) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 72) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 73) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 74) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 75) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 76) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 77) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 78) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 79) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) # sliding window - let's iterate over temporal windows of 0.5seconds, with 0.1s translation and boxcar window function for window in fr . sliding_window ( length = 0.5 , step = 0.1 , window_function = \"boxcar\" , lengths_in_seconds = True ): print ( type ( window ), window . shape , window . start_time , window . end_time ) <class 'neurolib.utils.signal.RatesSignal'> (2, 80, 500) 0.0 0.499 <class 'neurolib.utils.signal.RatesSignal'> (2, 80, 500) 0.1 0.599 <class 'neurolib.utils.signal.RatesSignal'> (2, 80, 500) 0.2 0.699 <class 'neurolib.utils.signal.RatesSignal'> (2, 80, 500) 0.3 0.799 # apply 1D function - Signal supports applying 1D function per temporal slice # both are supported: function that reduces temporal dimension (e.g. mean which reduces timeseries of length N to one number), # and functions that preserve shape # reduce mean = fr . apply ( partial ( np . mean , axis =- 1 ), inplace = False ) # mean is now xr.DataArray, not Signal; but the coordinates except time are preserved print ( type ( mean ), mean . shape , mean . coords ) # preserve shape absolute_value = fr . apply ( np . abs , inplace = False ) # still Signal print ( absolute_value . shape ) WARNING:root:Shape changed after operation! Old shape: (2, 80, 883), new shape: (2, 80); Cannot cast to Signal class, returing as `xr.DataArray` <class 'xarray.core.dataarray.DataArray'> (2, 80) Coordinates: * output (output) <U9 'rates_exc' 'rates_inh' * space (space) int64 0 1 2 3 4 5 6 7 8 9 ... 70 71 72 73 74 75 76 77 78 79 (2, 80, 883) Functional connectivity Lot of modelling effort actually goes to fitting the experimental functional connectivity with the modelled one. That's why Signal class supports functional connectivity computation and with other methods (like filtering and iterating over temporal windows) we can even do timeseries of FC or band-specific FC very easily within the couple of lines. # basic FC from excitatory rates - using correlation fc_exc = fr [ \"rates_exc\" ] . functional_connectivity ( fc_function = np . corrcoef ) # results is DataArray with space coordinates print ( type ( fc_exc ), fc_exc . shape , fc_exc . coords ) plt . subplot ( 1 , 2 , 1 ) plt . title ( \"Correlation FC\" ) plt . imshow ( fc_exc . values ) # FC from covariance fc_cov_exc = fr [ \"rates_exc\" ] . functional_connectivity ( fc_function = np . cov ) plt . subplot ( 1 , 2 , 2 ) plt . title ( \"Covariance FC\" ) plt . imshow ( fc_cov_exc . values ) # so fc_function can be any function that can take (nodes x time) array and transform it to (nodes x nodes) connectivity matrix <class 'xarray.core.dataarray.DataArray'> (80, 80) Coordinates: * space (space) int64 0 1 2 3 4 5 6 7 8 9 ... 70 71 72 73 74 75 76 77 78 79 <matplotlib.image.AxesImage at 0x131f1db70> # band-specific FC BANDS = { \"delta\" : { \"low_freq\" : 2 , \"high_freq\" : 4 }, \"theta\" : { \"low_freq\" : 4 , \"high_freq\" : 8 }, \"alpha\" : { \"low_freq\" : 8 , \"high_freq\" : 12 }, \"beta\" : { \"low_freq\" : 12 , \"high_freq\" : 30 }, \"low_gamma\" : { \"low_freq\" : 30 , \"high_freq\" : 60 }, \"high_gamma\" : { \"low_freq\" : 60 , \"high_freq\" : 120 }, } padded = fr . pad ( how_much = 0.5 , in_seconds = True , padding_type = \"constant\" , side = \"both\" , constant_values = 0. , inplace = False ) plt . figure ( figsize = ( 20 , 4 )) for ii , ( band , filt_spec ) in enumerate ( BANDS . items ()): print ( f \"Processing { band } ...\" ) filtered = padded . filter ( ** filt_spec , inplace = False ) filtered . sel ([ fr . start_time , fr . end_time ], inplace = True ) plt . subplot ( 1 , len ( BANDS ), ii + 1 ) fc = filtered [ \"rates_exc\" ] . functional_connectivity ( fc_function = np . corrcoef ) print ( filtered . preprocessing_steps ) plt . imshow ( fc ) plt . title ( f \" { band } : { filt_spec [ 'low_freq' ] } - { filt_spec [ 'high_freq' ] } Hz\" ) plt . show () Processing delta... Setting up band-pass filter from 2 - 4 Hz FIR filter parameters --------------------- Designing a one-pass, zero-phase, non-causal bandpass filter: - Windowed time-domain design (firwin) method - Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation - Lower passband edge: 2.00 - Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 1.00 Hz) - Upper passband edge: 4.00 Hz - Upper transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 5.00 Hz) - Filter length: 1651 samples (1.651 sec) resample to 1000.0Hz -> detrend -> 0.5s constant both sides padding -> filter: low 2Hz - high 4Hz -> select x:0.882s Processing theta... Setting up band-pass filter from 4 - 8 Hz FIR filter parameters --------------------- Designing a one-pass, zero-phase, non-causal bandpass filter: - Windowed time-domain design (firwin) method - Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation - Lower passband edge: 4.00 - Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz) - Upper passband edge: 8.00 Hz - Upper transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 9.00 Hz) - Filter length: 1651 samples (1.651 sec) resample to 1000.0Hz -> detrend -> 0.5s constant both sides padding -> filter: low 4Hz - high 8Hz -> select x:0.882s Processing alpha... Setting up band-pass filter from 8 - 12 Hz FIR filter parameters --------------------- Designing a one-pass, zero-phase, non-causal bandpass filter: - Windowed time-domain design (firwin) method - Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation - Lower passband edge: 8.00 - Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 7.00 Hz) - Upper passband edge: 12.00 Hz - Upper transition bandwidth: 3.00 Hz (-6 dB cutoff frequency: 13.50 Hz) - Filter length: 1651 samples (1.651 sec) resample to 1000.0Hz -> detrend -> 0.5s constant both sides padding -> filter: low 8Hz - high 12Hz -> select x:0.882s Processing beta... Setting up band-pass filter from 12 - 30 Hz FIR filter parameters --------------------- Designing a one-pass, zero-phase, non-causal bandpass filter: - Windowed time-domain design (firwin) method - Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation - Lower passband edge: 12.00 - Lower transition bandwidth: 3.00 Hz (-6 dB cutoff frequency: 10.50 Hz) - Upper passband edge: 30.00 Hz - Upper transition bandwidth: 7.50 Hz (-6 dB cutoff frequency: 33.75 Hz) - Filter length: 1101 samples (1.101 sec) resample to 1000.0Hz -> detrend -> 0.5s constant both sides padding -> filter: low 12Hz - high 30Hz -> select x:0.882s Processing low_gamma... Setting up band-pass filter from 30 - 60 Hz FIR filter parameters --------------------- Designing a one-pass, zero-phase, non-causal bandpass filter: - Windowed time-domain design (firwin) method - Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation - Lower passband edge: 30.00 - Lower transition bandwidth: 7.50 Hz (-6 dB cutoff frequency: 26.25 Hz) - Upper passband edge: 60.00 Hz - Upper transition bandwidth: 15.00 Hz (-6 dB cutoff frequency: 67.50 Hz) - Filter length: 441 samples (0.441 sec) resample to 1000.0Hz -> detrend -> 0.5s constant both sides padding -> filter: low 30Hz - high 60Hz -> select x:0.882s Processing high_gamma... Setting up band-pass filter from 60 - 1.2e+02 Hz FIR filter parameters --------------------- Designing a one-pass, zero-phase, non-causal bandpass filter: - Windowed time-domain design (firwin) method - Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation - Lower passband edge: 60.00 - Lower transition bandwidth: 15.00 Hz (-6 dB cutoff frequency: 52.50 Hz) - Upper passband edge: 120.00 Hz - Upper transition bandwidth: 30.00 Hz (-6 dB cutoff frequency: 135.00 Hz) - Filter length: 221 samples (0.221 sec) resample to 1000.0Hz -> detrend -> 0.5s constant both sides padding -> filter: low 60Hz - high 120Hz -> select x:0.882s # time-varying FC for window in fr . sliding_window ( length = 0.5 , step = 0.2 , window_function = \"boxcar\" , lengths_in_seconds = True ): fc = window [ \"rates_exc\" ] . functional_connectivity ( fc_function = np . corrcoef ) plt . imshow ( fc ) plt . title ( f \"FC: { window . start_time } - { window . end_time } s\" ) plt . show ()","title":"Example 0.2 basic analysis"},{"location":"examples/example-0.2-basic_analysis/#introduction","text":"# change to the root directory of the project import os if os . getcwd () . split ( \"/\" )[ - 1 ] == \"examples\" : os . chdir ( '..' ) # This will reload all imports as soon as the code changes % load_ext autoreload % autoreload 2 try : import matplotlib.pyplot as plt except ImportError : import sys ! { sys . executable } - m pip install matplotlib import matplotlib.pyplot as plt from functools import partial import numpy as np from neurolib.models.aln import ALNModel from neurolib.utils.loadData import Dataset from neurolib.utils.signal import RatesSignal , BOLDSignal plt . rcParams [ 'image.cmap' ] = 'plasma'","title":"Introduction"},{"location":"examples/example-0.2-basic_analysis/#run-the-aln-model","text":"Firstly, let us run a network model given the structural connectivity and fiber lengths. ds = Dataset ( \"gw\" ) # simulates the whole-brain model aln = ALNModel ( Cmat = ds . Cmat , Dmat = ds . Dmat ) # Resting state fits aln . params [ 'mue_ext_mean' ] = 1.57 aln . params [ 'mui_ext_mean' ] = 1.6 aln . params [ 'sigma_ou' ] = 0.09 aln . params [ 'b' ] = 5.0 aln . params [ 'duration' ] = 0.2 * 60 * 1000 # info: value 0.2*60*1000 is low for testing # use 5*60*1000 for real simulation aln . run ( chunkwise = True , bold = True ) WARNING:root:aln: BOLD simulation is supported only with chunkwise integration. Enabling chunkwise integration. Now we can cast the modelling result into our Signal class. Signal is a parent base class for any neuro signal. We also provide three child class for particular signals: RatesSignal (for firing rate of the populations), VoltageSignal (for average membrane potential of the populations), and BOLDSignal (for simulated BOLD). They only differ in name, labels and units. Nothing fancy. Of course, you can implement your own class for your particular results very easily as: from neurolib.utils.signal import Signal class PostSynapticCurrentSignal ( Signal ): name = \"Population post-synaptic current signal\" label = \"I_syn\" signal_type = \"post_current\" unit = \"mA\" and that's it. All useful methods and attributes are directly inhereted from the Signal parent. # Create Signal out of firing rates fr = RatesSignal . from_model_output ( aln , group = \"\" , time_in_ms = True ) # optional description fr . description = \"Output of the ALN model with default SC and fiber lengths\" # Create Signal out of BOLD simulated timeseries bold = BOLDSignal . from_model_output ( aln , group = \"BOLD\" , time_in_ms = True ) bold . description = \"Simulated BOLD of the ALN model with default SC and fiber lengths\" # let's check what's inside print ( fr ) print ( bold ) Population firing rate representing rate signal with unit of Hz with user-provided description: `Output of the ALN model with default SC and fiber lengths`. Shape of the signal is (2, 80, 8831) with dimensions ('output', 'space', 'time'). Population blood oxygen level-dependent signal representing bold signal with unit of % with user-provided description: `Simulated BOLD of the ALN model with default SC and fiber lengths`. Shape of the signal is (1, 80, 7) with dimensions ('output', 'space', 'time'). Signal automatically computes useful attributes like dt , sampling rate, starting and ending times. # inherent attributes print ( \"Inherent attributes:\" ) print ( fr . name ) print ( fr . label ) print ( fr . unit ) print ( fr . signal_type ) print ( fr . description ) # computed attributes print ( \" \\n Computed attributes:\" ) print ( fr . dt ) print ( fr . sampling_frequency ) print ( fr . start_time ) print ( fr . end_time ) print ( fr . shape ) Inherent attributes: Population firing rate q Hz rate Output of the ALN model with default SC and fiber lengths Computed attributes: 0.0001 10000.0 0.0 0.883 (2, 80, 8831) # internal representation of the signal is just xarray's DataArray print ( fr . data ) # xarray is just pandas on steroids, i.e. it supports multi-dimensional arrays, not only 2D # if you'd need simple numpy array just call .values on signal's data print ( type ( fr . data . values )) print ( fr . data . values . shape ) <xarray.DataArray (output: 2, space: 80, time: 8831)> array([[[1.33261450e-02, 1.36917651e-02, 1.40695947e-02, ..., 3.48158384e-03, 3.46784876e-03, 3.46133411e-03], [6.13965587e-01, 6.25356604e-01, 6.34768740e-01, ..., 3.59993904e-01, 3.54528049e-01, 3.49018287e-01], [6.36038906e-02, 6.35557804e-02, 6.33770702e-02, ..., 4.42949449e-02, 4.37566338e-02, 4.32171260e-02], ..., [2.50859629e-03, 2.52563325e-03, 2.54037707e-03, ..., 8.00547429e-03, 7.78636724e-03, 7.61333390e-03], [5.95617787e-02, 6.07513850e-02, 6.20942706e-02, ..., 3.26872805e-02, 3.33536801e-02, 3.40569905e-02], [4.96090615e-02, 4.84730168e-02, 4.73428175e-02, ..., 1.05820581e-01, 1.05724932e-01, 1.05846529e-01]], [[4.17821712e+00, 4.21196680e+00, 4.23883558e+00, ..., 1.01836901e+01, 1.00264571e+01, 9.86191716e+00], [6.83616353e+00, 6.91560104e+00, 6.97566672e+00, ..., 8.07743197e+00, 8.08297235e+00, 8.07994833e+00], [6.57108005e+00, 6.49135703e+00, 6.43050397e+00, ..., 8.93701663e+00, 8.95484465e+00, 8.97588108e+00], ..., [8.75902323e+00, 8.81787556e+00, 8.89506320e+00, ..., 7.48694404e+00, 7.41863238e+00, 7.35970182e+00], [4.15841271e+00, 4.15037911e+00, 4.15057015e+00, ..., 6.61282248e+00, 6.60115808e+00, 6.58597805e+00], [9.52609773e+00, 9.39861579e+00, 9.28794497e+00, ..., 5.83291993e+00, 5.90070345e+00, 5.94592106e+00]]]) Coordinates: * output (output) <U9 'rates_exc' 'rates_inh' * space (space) int64 0 1 2 3 4 5 6 7 8 9 ... 70 71 72 73 74 75 76 77 78 79 * time (time) float64 0.0 0.0001 0.0002 0.0003 ... 0.8828 0.8829 0.883 <class 'numpy.ndarray'> (2, 80, 8831) Now let's see what Signal can do... Just a side note, all operations can be done inplace (everything happens inside signal class), or altered signal is returned with the same attributes as the original one # basic operations norm = fr . normalize ( std = True , inplace = False ) # so, are all temporal means close to zero? print ( np . allclose ( norm . data . mean ( dim = \"time\" ), 0. )) # aand, are all temporal std close to 1? print ( np . allclose ( norm . data . std ( dim = \"time\" ), 1.0 )) plt . plot ( fr [ \"rates_exc\" ] . data . sel ({ \"space\" : 0 }), label = \"original\" ) plt . plot ( norm [ \"rates_exc\" ] . data . sel ({ \"space\" : 0 }), label = \"normalised\" ) # you can detrend the signal, all of it, or by segments (as indices within the signal) # let's first normalise (so inplace=False), then detrend (we can inplace=True) detrended = fr . normalize ( std = True , inplace = False ) detrended . detrend ( inplace = True ) plt . plot ( detrended [ \"rates_exc\" ] . data . sel ({ \"space\" : 0 }), label = \"normalised & detrended\" ) detrended_segments = fr . detrend ( segments = np . arange ( 20000 , 1000 ), inplace = False ) plt . legend () True True <matplotlib.legend.Legend at 0x1301a4320> so, the sampling frequency is too high, let's resample print ( fr . sampling_frequency ) plt . plot ( fr . data . time , fr [ \"rates_exc\" ] . data . sel ({ \"space\" : 0 }), label = \"original\" ) fr . resample ( to_frequency = 1000. , inplace = True ) print ( fr . sampling_frequency ) plt . plot ( fr . data . time , fr [ \"rates_exc\" ] . data . sel ({ \"space\" : 0 }), label = \"resampled\" ) plt . legend () 10000.0 1000.0 <matplotlib.legend.Legend at 0x131e0e940>","title":"Run the ALN model"},{"location":"examples/example-0.2-basic_analysis/#more-complete-example","text":"Let's do a more complete example. Let's say, you run the model and want to extract phase and amplitude of the \\(\\alpha\\) band (i.e. 8-12Hz) for some phase-amplitude coupling analyses. # init again to start fresh fr = RatesSignal . from_model_output ( aln , group = \"\" , time_in_ms = True ) plt . plot ( fr . data . time , fr [ \"rates_exc\" ] . data . sel ({ \"space\" : 0 }), label = \"original\" ) # first resample fr . resample ( to_frequency = 1000. , inplace = True ) # next detrend fr . detrend ( inplace = True ) print ( fr . start_time , fr . end_time ) # next pad with 0s for 0.5 seconds in order to suppress edge effect when filtering padded = fr . pad ( how_much = 0.5 , in_seconds = True , padding_type = \"constant\" , side = \"both\" , constant_values = 0. , inplace = False ) print ( padded . start_time , padded . end_time ) # now filter - by default uses mne, if not installed, falls back to scipy basic IIR filter padded . filter ( low_freq = 8. , high_freq = 12. , inplace = True ) # now cut back the original length filtered = padded . sel ([ fr . start_time , fr . end_time ], inplace = False ) print ( filtered . start_time , filtered . end_time ) plt . plot ( filtered . data . time , filtered [ \"rates_exc\" ] . data . sel ({ \"space\" : 0 }), label = r \"filtered $\\alpha$\" ) # finally, get phase and amplitude via Hilbert transform phase = filtered . hilbert_transform ( return_as = \"phase_wrapped\" , inplace = False ) plt . plot ( phase . data . time , phase [ \"rates_exc\" ] . data . sel ({ \"space\" : 0 }), label = r \"phase $\\alpha$\" ) amplitude = filtered . hilbert_transform ( return_as = \"amplitude\" , inplace = False ) plt . plot ( amplitude . data . time , amplitude [ \"rates_exc\" ] . data . sel ({ \"space\" : 0 }), label = r \"amplitude $\\alpha$\" ) plt . legend () 0.0 0.882 -0.5 1.382 Setting up band-pass filter from 8 - 12 Hz FIR filter parameters --------------------- Designing a one-pass, zero-phase, non-causal bandpass filter: - Windowed time-domain design (firwin) method - Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation - Lower passband edge: 8.00 - Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 7.00 Hz) - Upper passband edge: 12.00 Hz - Upper transition bandwidth: 3.00 Hz (-6 dB cutoff frequency: 13.50 Hz) - Filter length: 1651 samples (1.651 sec) 0.0 0.882 <matplotlib.legend.Legend at 0x1322e6e80> # in case you forget that happened in the processing, you can easily check all steps: print ( phase . preprocessing_steps ) print ( amplitude . preprocessing_steps ) resample to 1000.0Hz -> detrend -> 0.5s constant both sides padding -> filter: low 8.0Hz - high 12.0Hz -> select x:0.882s -> Hilbert - wrapped phase resample to 1000.0Hz -> detrend -> 0.5s constant both sides padding -> filter: low 8.0Hz - high 12.0Hz -> select x:0.882s -> Hilbert - amplitude","title":"More complete example"},{"location":"examples/example-0.2-basic_analysis/#saving-loading","text":"# and you can save your signal for future generations! (saved as netCDF file) phase . save ( \"phase_from_some_experiment\" ) # and then load it phase_loaded = RatesSignal . from_file ( \"phase_from_some_experiment\" ) # compare whether it is the same print ( phase == phase_loaded ) # the attributes are saved/loaded as well print ( phase_loaded . name ) print ( phase_loaded . unit ) print ( phase_loaded . preprocessing_steps ) # delete file os . remove ( \"phase_from_some_experiment.nc\" ) True Population firing rate Hz resample to 1000.0Hz -> detrend -> 0.5s constant both sides padding -> filter: low 8.0Hz - high 12.0Hz -> select x:0.882s -> Hilbert - wrapped phase","title":"Saving / loading"},{"location":"examples/example-0.2-basic_analysis/#iterators","text":"Sometimes it is useful to apply or see something in a loop. That's why Signal supports both: iterating over space / outputs variables and applying some 1D function over temporal dimensions. # this will iterate over whole data and return one 1D temporal slice at the time, each slice is Signal class for name , ts in fr . iterate ( return_as = \"signal\" ): print ( name , type ( ts ), ts . start_time , ts . end_time ) # this will iterate over whole data and return one 1D temporal slice at the time, each slice is DataArray for name , ts in fr . iterate ( return_as = \"xr\" ): print ( name , type ( ts ), ts . shape , ts . shape ) ('rates_exc', 0) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 1) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 2) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 3) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 4) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 5) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 6) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 7) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 8) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 9) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 10) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 11) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 12) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 13) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 14) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 15) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 16) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 17) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 18) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 19) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 20) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 21) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 22) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 23) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 24) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 25) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 26) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 27) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 28) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 29) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 30) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 31) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 32) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 33) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 34) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 35) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 36) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 37) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 38) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 39) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 40) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 41) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 42) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 43) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 44) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 45) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 46) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 47) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 48) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 49) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 50) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 51) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 52) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 53) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 54) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 55) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 56) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 57) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 58) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 59) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 60) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 61) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 62) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 63) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 64) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 65) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 66) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 67) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 68) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 69) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 70) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 71) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 72) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 73) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 74) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 75) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 76) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 77) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 78) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 79) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 0) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 1) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 2) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 3) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 4) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 5) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 6) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 7) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 8) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 9) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 10) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 11) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 12) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 13) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 14) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 15) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 16) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 17) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 18) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 19) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 20) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 21) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 22) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 23) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 24) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 25) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 26) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 27) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 28) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 29) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 30) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 31) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 32) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 33) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 34) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 35) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 36) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 37) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 38) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 39) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 40) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 41) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 42) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 43) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 44) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 45) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 46) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 47) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 48) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 49) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 50) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 51) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 52) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 53) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 54) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 55) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 56) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 57) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 58) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 59) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 60) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 61) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 62) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 63) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 64) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 65) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 66) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 67) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 68) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 69) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 70) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 71) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 72) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 73) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 74) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 75) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 76) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 77) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 78) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 79) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 0) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 1) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 2) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 3) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 4) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 5) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 6) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 7) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 8) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 9) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 10) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 11) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 12) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 13) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 14) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 15) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 16) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 17) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 18) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 19) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 20) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 21) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 22) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 23) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 24) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 25) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 26) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 27) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 28) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 29) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 30) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 31) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 32) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 33) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 34) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 35) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 36) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 37) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 38) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 39) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 40) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 41) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 42) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 43) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 44) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 45) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 46) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 47) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 48) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 49) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 50) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 51) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 52) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 53) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 54) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 55) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 56) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 57) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 58) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 59) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 60) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 61) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 62) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 63) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 64) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 65) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 66) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 67) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 68) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 69) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 70) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 71) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 72) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 73) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 74) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 75) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 76) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 77) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 78) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 79) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 0) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 1) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 2) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 3) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 4) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 5) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 6) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 7) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 8) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 9) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 10) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 11) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 12) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 13) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 14) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 15) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 16) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 17) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 18) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 19) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 20) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 21) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 22) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 23) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 24) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 25) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 26) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 27) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 28) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 29) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 30) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 31) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 32) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 33) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 34) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 35) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 36) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 37) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 38) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 39) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 40) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 41) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 42) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 43) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 44) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 45) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 46) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 47) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 48) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 49) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 50) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 51) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 52) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 53) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 54) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 55) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 56) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 57) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 58) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 59) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 60) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 61) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 62) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 63) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 64) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 65) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 66) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 67) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 68) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 69) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 70) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 71) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 72) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 73) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 74) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 75) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 76) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 77) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 78) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 79) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) # sliding window - let's iterate over temporal windows of 0.5seconds, with 0.1s translation and boxcar window function for window in fr . sliding_window ( length = 0.5 , step = 0.1 , window_function = \"boxcar\" , lengths_in_seconds = True ): print ( type ( window ), window . shape , window . start_time , window . end_time ) <class 'neurolib.utils.signal.RatesSignal'> (2, 80, 500) 0.0 0.499 <class 'neurolib.utils.signal.RatesSignal'> (2, 80, 500) 0.1 0.599 <class 'neurolib.utils.signal.RatesSignal'> (2, 80, 500) 0.2 0.699 <class 'neurolib.utils.signal.RatesSignal'> (2, 80, 500) 0.3 0.799 # apply 1D function - Signal supports applying 1D function per temporal slice # both are supported: function that reduces temporal dimension (e.g. mean which reduces timeseries of length N to one number), # and functions that preserve shape # reduce mean = fr . apply ( partial ( np . mean , axis =- 1 ), inplace = False ) # mean is now xr.DataArray, not Signal; but the coordinates except time are preserved print ( type ( mean ), mean . shape , mean . coords ) # preserve shape absolute_value = fr . apply ( np . abs , inplace = False ) # still Signal print ( absolute_value . shape ) WARNING:root:Shape changed after operation! Old shape: (2, 80, 883), new shape: (2, 80); Cannot cast to Signal class, returing as `xr.DataArray` <class 'xarray.core.dataarray.DataArray'> (2, 80) Coordinates: * output (output) <U9 'rates_exc' 'rates_inh' * space (space) int64 0 1 2 3 4 5 6 7 8 9 ... 70 71 72 73 74 75 76 77 78 79 (2, 80, 883)","title":"Iterators"},{"location":"examples/example-0.2-basic_analysis/#functional-connectivity","text":"Lot of modelling effort actually goes to fitting the experimental functional connectivity with the modelled one. That's why Signal class supports functional connectivity computation and with other methods (like filtering and iterating over temporal windows) we can even do timeseries of FC or band-specific FC very easily within the couple of lines. # basic FC from excitatory rates - using correlation fc_exc = fr [ \"rates_exc\" ] . functional_connectivity ( fc_function = np . corrcoef ) # results is DataArray with space coordinates print ( type ( fc_exc ), fc_exc . shape , fc_exc . coords ) plt . subplot ( 1 , 2 , 1 ) plt . title ( \"Correlation FC\" ) plt . imshow ( fc_exc . values ) # FC from covariance fc_cov_exc = fr [ \"rates_exc\" ] . functional_connectivity ( fc_function = np . cov ) plt . subplot ( 1 , 2 , 2 ) plt . title ( \"Covariance FC\" ) plt . imshow ( fc_cov_exc . values ) # so fc_function can be any function that can take (nodes x time) array and transform it to (nodes x nodes) connectivity matrix <class 'xarray.core.dataarray.DataArray'> (80, 80) Coordinates: * space (space) int64 0 1 2 3 4 5 6 7 8 9 ... 70 71 72 73 74 75 76 77 78 79 <matplotlib.image.AxesImage at 0x131f1db70> # band-specific FC BANDS = { \"delta\" : { \"low_freq\" : 2 , \"high_freq\" : 4 }, \"theta\" : { \"low_freq\" : 4 , \"high_freq\" : 8 }, \"alpha\" : { \"low_freq\" : 8 , \"high_freq\" : 12 }, \"beta\" : { \"low_freq\" : 12 , \"high_freq\" : 30 }, \"low_gamma\" : { \"low_freq\" : 30 , \"high_freq\" : 60 }, \"high_gamma\" : { \"low_freq\" : 60 , \"high_freq\" : 120 }, } padded = fr . pad ( how_much = 0.5 , in_seconds = True , padding_type = \"constant\" , side = \"both\" , constant_values = 0. , inplace = False ) plt . figure ( figsize = ( 20 , 4 )) for ii , ( band , filt_spec ) in enumerate ( BANDS . items ()): print ( f \"Processing { band } ...\" ) filtered = padded . filter ( ** filt_spec , inplace = False ) filtered . sel ([ fr . start_time , fr . end_time ], inplace = True ) plt . subplot ( 1 , len ( BANDS ), ii + 1 ) fc = filtered [ \"rates_exc\" ] . functional_connectivity ( fc_function = np . corrcoef ) print ( filtered . preprocessing_steps ) plt . imshow ( fc ) plt . title ( f \" { band } : { filt_spec [ 'low_freq' ] } - { filt_spec [ 'high_freq' ] } Hz\" ) plt . show () Processing delta... Setting up band-pass filter from 2 - 4 Hz FIR filter parameters --------------------- Designing a one-pass, zero-phase, non-causal bandpass filter: - Windowed time-domain design (firwin) method - Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation - Lower passband edge: 2.00 - Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 1.00 Hz) - Upper passband edge: 4.00 Hz - Upper transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 5.00 Hz) - Filter length: 1651 samples (1.651 sec) resample to 1000.0Hz -> detrend -> 0.5s constant both sides padding -> filter: low 2Hz - high 4Hz -> select x:0.882s Processing theta... Setting up band-pass filter from 4 - 8 Hz FIR filter parameters --------------------- Designing a one-pass, zero-phase, non-causal bandpass filter: - Windowed time-domain design (firwin) method - Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation - Lower passband edge: 4.00 - Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz) - Upper passband edge: 8.00 Hz - Upper transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 9.00 Hz) - Filter length: 1651 samples (1.651 sec) resample to 1000.0Hz -> detrend -> 0.5s constant both sides padding -> filter: low 4Hz - high 8Hz -> select x:0.882s Processing alpha... Setting up band-pass filter from 8 - 12 Hz FIR filter parameters --------------------- Designing a one-pass, zero-phase, non-causal bandpass filter: - Windowed time-domain design (firwin) method - Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation - Lower passband edge: 8.00 - Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 7.00 Hz) - Upper passband edge: 12.00 Hz - Upper transition bandwidth: 3.00 Hz (-6 dB cutoff frequency: 13.50 Hz) - Filter length: 1651 samples (1.651 sec) resample to 1000.0Hz -> detrend -> 0.5s constant both sides padding -> filter: low 8Hz - high 12Hz -> select x:0.882s Processing beta... Setting up band-pass filter from 12 - 30 Hz FIR filter parameters --------------------- Designing a one-pass, zero-phase, non-causal bandpass filter: - Windowed time-domain design (firwin) method - Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation - Lower passband edge: 12.00 - Lower transition bandwidth: 3.00 Hz (-6 dB cutoff frequency: 10.50 Hz) - Upper passband edge: 30.00 Hz - Upper transition bandwidth: 7.50 Hz (-6 dB cutoff frequency: 33.75 Hz) - Filter length: 1101 samples (1.101 sec) resample to 1000.0Hz -> detrend -> 0.5s constant both sides padding -> filter: low 12Hz - high 30Hz -> select x:0.882s Processing low_gamma... Setting up band-pass filter from 30 - 60 Hz FIR filter parameters --------------------- Designing a one-pass, zero-phase, non-causal bandpass filter: - Windowed time-domain design (firwin) method - Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation - Lower passband edge: 30.00 - Lower transition bandwidth: 7.50 Hz (-6 dB cutoff frequency: 26.25 Hz) - Upper passband edge: 60.00 Hz - Upper transition bandwidth: 15.00 Hz (-6 dB cutoff frequency: 67.50 Hz) - Filter length: 441 samples (0.441 sec) resample to 1000.0Hz -> detrend -> 0.5s constant both sides padding -> filter: low 30Hz - high 60Hz -> select x:0.882s Processing high_gamma... Setting up band-pass filter from 60 - 1.2e+02 Hz FIR filter parameters --------------------- Designing a one-pass, zero-phase, non-causal bandpass filter: - Windowed time-domain design (firwin) method - Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation - Lower passband edge: 60.00 - Lower transition bandwidth: 15.00 Hz (-6 dB cutoff frequency: 52.50 Hz) - Upper passband edge: 120.00 Hz - Upper transition bandwidth: 30.00 Hz (-6 dB cutoff frequency: 135.00 Hz) - Filter length: 221 samples (0.221 sec) resample to 1000.0Hz -> detrend -> 0.5s constant both sides padding -> filter: low 60Hz - high 120Hz -> select x:0.882s # time-varying FC for window in fr . sliding_window ( length = 0.5 , step = 0.2 , window_function = \"boxcar\" , lengths_in_seconds = True ): fc = window [ \"rates_exc\" ] . functional_connectivity ( fc_function = np . corrcoef ) plt . imshow ( fc ) plt . title ( f \"FC: { window . start_time } - { window . end_time } s\" ) plt . show ()","title":"Functional connectivity"},{"location":"examples/example-0.3-fhn-minimal/","text":"(function() { function addWidgetsRenderer() { var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var scriptElement = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} scriptElement.src = widgetRendererSrc; document.body.appendChild(scriptElement); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); The Fitz-Hugh Nagumo oscillator In this notebook, the basic use of the implementation of the Fitz-Hugh Nagumo ( fhn ) model is presented. Usually, the fhn model is used to represent a single neuron (for example in Cakan et al. (2014) , \"Heterogeneous delays in neural networks\"). This is due to the difference in timescales of the two equations that define the FHN model: The first equation is often referred to as the \"fast variable\" whereas the second one is the \"slow variable\". This makes it possible to create a model with a very fast spiking mechanism but with a slow refractory period. In our case, we are using a parameterization of the fhn model that is not quite as usual. Inspired by the paper by Kostova et al. (2004) \"FitzHugh\u2013Nagumo revisited: Types of bifurcations, periodical forcing and stability regions by a Lyapunov functional.\", the implementation in neurolib produces a slowly oscillating dynamics and has the advantage to incorporate an external input term that causes a Hopf bifurcation. This means, that the model roughly approximates the behaviour of the aln model: For low input values, there is a low-activity fixed point, for intermediate inputs, there is an oscillatory region, and for high input values, the system is in a high-activity fixed point. Thus, it offers a simple way of exploring the dynamics of a neural mass model with these properties, such as the aln model. We want to start by producing a bifurcation diagram of a single node. With neurolib , this can be done with a couple of lines of code, as seen further below. # change to the root directory of the project import os if os . getcwd () . split ( \"/\" )[ - 1 ] == \"examples\" : os . chdir ( '..' ) # This will reload all imports as soon as the code changes % load_ext autoreload % autoreload 2 try : import matplotlib.pyplot as plt except ImportError : import sys ! { sys . executable } - m pip install matplotlib import matplotlib.pyplot as plt import numpy as np # Let's import the fhn model from neurolib.models.fhn import FHNModel # Some useful functions are provided here import neurolib.utils.functions as func # a nice color map plt . rcParams [ 'image.cmap' ] = 'plasma' Single node simulation fhn = FHNModel () fhn . params [ 'duration' ] = 2.0 * 1000 Let's draw a simple one-dimensional bifurcation diagram of this model to orient ourselves in the parameter space max_x = [] min_x = [] # these are the different input values that we want to scan x_inputs = np . linspace ( 0 , 2 , 50 ) for x_ext in x_inputs : # Note: this has to be a vector since it is input for all nodes # (but we have only one node in this example) fhn . params [ 'x_ext' ] = [ x_ext ] fhn . run () # we add the maximum and the minimum of the last second of the # simulation to a list max_x . append ( np . max ( fhn . x [ 0 , - int ( 1000 / fhn . params [ 'dt' ]):])) min_x . append ( np . min ( fhn . x [ 0 , - int ( 1000 / fhn . params [ 'dt' ]):])) plt . plot ( x_inputs , max_x , c = 'k' , lw = 2 ) plt . plot ( x_inputs , min_x , c = 'k' , lw = 2 ) plt . title ( \"Bifurcation diagram of the FHN oscillator\" ) plt . xlabel ( \"Input to x\" ) plt . ylabel ( \"Min / max x\" ) Text(0, 0.5, 'Min / max x') In this model, there is a Hopf bifurcation happening at two input values. We can see the oscillatory region at input values from roughly 0.75 to 1.3 . Brain network from neurolib.utils.loadData import Dataset ds = Dataset ( \"hcp\" ) fhn = FHNModel ( Cmat = ds . Cmat , Dmat = ds . Dmat ) fhn . params [ 'duration' ] = 10 * 1000 # add some noise fhn . params [ 'sigma_ou' ] = . 01 # set the global coupling strenght of the brain network fhn . params [ 'K_gl' ] = 1.0 # let's put all nodes close to the limit cycle such that # noise can kick them in and out of the oscillation # all nodes get the same constant input fhn . params [ 'x_ext' ] = [ 0.72 ] * fhn . params [ 'N' ] fhn . run ( chunkwise = True , append_outputs = True ) plt . plot ( fhn . t , fhn . x [:: 5 , :] . T , alpha = 0.8 ); plt . xlabel ( \"t [ms]\" ) Text(0.5, 0, 't [ms]') fig , axs = plt . subplots ( 1 , 2 , figsize = ( 8 , 2 )) axs [ 0 ] . imshow ( func . fc ( fhn . x [:, - 10000 :])) axs [ 1 ] . plot ( fhn . t , fhn . x [:: 5 , :] . T , alpha = 0.8 ); scores = [ func . matrix_correlation ( func . fc ( fhn . x [:, - int ( 5000 / fhn . params [ 'dt' ]):]), fcemp ) for fcemp in ds . FCs ] print ( \"Correlation per subject:\" , [ f \" { s : .2 } \" for s in scores ]) print ( \"Mean FC/FC correlation: {:.2f} \" . format ( np . mean ( scores ))) Correlation per subject: ['0.41', '0.5', '0.5', '0.48', '0.49', '0.45', '0.54'] Mean FC/FC correlation: 0.48","title":"Example 0.3 fhn minimal"},{"location":"examples/example-0.3-fhn-minimal/#the-fitz-hugh-nagumo-oscillator","text":"In this notebook, the basic use of the implementation of the Fitz-Hugh Nagumo ( fhn ) model is presented. Usually, the fhn model is used to represent a single neuron (for example in Cakan et al. (2014) , \"Heterogeneous delays in neural networks\"). This is due to the difference in timescales of the two equations that define the FHN model: The first equation is often referred to as the \"fast variable\" whereas the second one is the \"slow variable\". This makes it possible to create a model with a very fast spiking mechanism but with a slow refractory period. In our case, we are using a parameterization of the fhn model that is not quite as usual. Inspired by the paper by Kostova et al. (2004) \"FitzHugh\u2013Nagumo revisited: Types of bifurcations, periodical forcing and stability regions by a Lyapunov functional.\", the implementation in neurolib produces a slowly oscillating dynamics and has the advantage to incorporate an external input term that causes a Hopf bifurcation. This means, that the model roughly approximates the behaviour of the aln model: For low input values, there is a low-activity fixed point, for intermediate inputs, there is an oscillatory region, and for high input values, the system is in a high-activity fixed point. Thus, it offers a simple way of exploring the dynamics of a neural mass model with these properties, such as the aln model. We want to start by producing a bifurcation diagram of a single node. With neurolib , this can be done with a couple of lines of code, as seen further below. # change to the root directory of the project import os if os . getcwd () . split ( \"/\" )[ - 1 ] == \"examples\" : os . chdir ( '..' ) # This will reload all imports as soon as the code changes % load_ext autoreload % autoreload 2 try : import matplotlib.pyplot as plt except ImportError : import sys ! { sys . executable } - m pip install matplotlib import matplotlib.pyplot as plt import numpy as np # Let's import the fhn model from neurolib.models.fhn import FHNModel # Some useful functions are provided here import neurolib.utils.functions as func # a nice color map plt . rcParams [ 'image.cmap' ] = 'plasma'","title":"The Fitz-Hugh Nagumo oscillator"},{"location":"examples/example-0.3-fhn-minimal/#single-node-simulation","text":"fhn = FHNModel () fhn . params [ 'duration' ] = 2.0 * 1000 Let's draw a simple one-dimensional bifurcation diagram of this model to orient ourselves in the parameter space max_x = [] min_x = [] # these are the different input values that we want to scan x_inputs = np . linspace ( 0 , 2 , 50 ) for x_ext in x_inputs : # Note: this has to be a vector since it is input for all nodes # (but we have only one node in this example) fhn . params [ 'x_ext' ] = [ x_ext ] fhn . run () # we add the maximum and the minimum of the last second of the # simulation to a list max_x . append ( np . max ( fhn . x [ 0 , - int ( 1000 / fhn . params [ 'dt' ]):])) min_x . append ( np . min ( fhn . x [ 0 , - int ( 1000 / fhn . params [ 'dt' ]):])) plt . plot ( x_inputs , max_x , c = 'k' , lw = 2 ) plt . plot ( x_inputs , min_x , c = 'k' , lw = 2 ) plt . title ( \"Bifurcation diagram of the FHN oscillator\" ) plt . xlabel ( \"Input to x\" ) plt . ylabel ( \"Min / max x\" ) Text(0, 0.5, 'Min / max x') In this model, there is a Hopf bifurcation happening at two input values. We can see the oscillatory region at input values from roughly 0.75 to 1.3 .","title":"Single node simulation"},{"location":"examples/example-0.3-fhn-minimal/#brain-network","text":"from neurolib.utils.loadData import Dataset ds = Dataset ( \"hcp\" ) fhn = FHNModel ( Cmat = ds . Cmat , Dmat = ds . Dmat ) fhn . params [ 'duration' ] = 10 * 1000 # add some noise fhn . params [ 'sigma_ou' ] = . 01 # set the global coupling strenght of the brain network fhn . params [ 'K_gl' ] = 1.0 # let's put all nodes close to the limit cycle such that # noise can kick them in and out of the oscillation # all nodes get the same constant input fhn . params [ 'x_ext' ] = [ 0.72 ] * fhn . params [ 'N' ] fhn . run ( chunkwise = True , append_outputs = True ) plt . plot ( fhn . t , fhn . x [:: 5 , :] . T , alpha = 0.8 ); plt . xlabel ( \"t [ms]\" ) Text(0.5, 0, 't [ms]') fig , axs = plt . subplots ( 1 , 2 , figsize = ( 8 , 2 )) axs [ 0 ] . imshow ( func . fc ( fhn . x [:, - 10000 :])) axs [ 1 ] . plot ( fhn . t , fhn . x [:: 5 , :] . T , alpha = 0.8 ); scores = [ func . matrix_correlation ( func . fc ( fhn . x [:, - int ( 5000 / fhn . params [ 'dt' ]):]), fcemp ) for fcemp in ds . FCs ] print ( \"Correlation per subject:\" , [ f \" { s : .2 } \" for s in scores ]) print ( \"Mean FC/FC correlation: {:.2f} \" . format ( np . mean ( scores ))) Correlation per subject: ['0.41', '0.5', '0.5', '0.48', '0.49', '0.45', '0.54'] Mean FC/FC correlation: 0.48","title":"Brain network"},{"location":"examples/example-0.4-wc-minimal/","text":"(function() { function addWidgetsRenderer() { var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var scriptElement = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} scriptElement.src = widgetRendererSrc; document.body.appendChild(scriptElement); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); The Wilson-Cowan model In this notebook, the basic use of the implementation of the Wilson-Cowan ( wc ) model is presented. In the wc model, the activity of a particular brain region is defined by a coupled system of excitatory (E) and inhibitory (I) neuronal populations with the mean firing rates of the E and I pools being the dynamic variables, as first described by Wilson and Cowan in 1972 ( H.R. Wilson and J.D. Cowan. Excitatory and inhibitory interactions in localized populations of model neurons . Biophys. J., 12:1\u201324 (1972)) # change to the root directory of the project import os if os . getcwd () . split ( \"/\" )[ - 1 ] == \"examples\" : os . chdir ( '..' ) % load_ext autoreload % autoreload 2 import matplotlib.pyplot as plt import numpy as np import glob from neurolib.models.wc import WCModel import neurolib.utils.loadData as ld import neurolib.utils.functions as func # a nice color map plt . rcParams [ 'image.cmap' ] = 'plasma' Bifurcation diagram wc = WCModel () wc . params [ 'duration' ] = 2.0 * 1000 Let's draw a simple one-dimensional bifurcation diagram of this model to orient ourselves in the parameter space max_exc = [] min_exc = [] # these are the different input values that we want to scan exc_inputs = np . linspace ( 0 , 3.5 , 50 ) for exc_ext in exc_inputs : # Note: this has to be a vector since it is input for all nodes # (but we have only one node in this example) wc . params [ 'exc_ext' ] = exc_ext wc . run () # we add the maximum and the minimum of the last second of the # simulation to a list max_exc . append ( np . max ( wc . exc [ 0 , - int ( 1000 / wc . params [ 'dt' ]):])) min_exc . append ( np . min ( wc . exc [ 0 , - int ( 1000 / wc . params [ 'dt' ]):])) plt . plot ( exc_inputs , max_exc , c = 'k' , lw = 2 ) plt . plot ( exc_inputs , min_exc , c = 'k' , lw = 2 ) plt . title ( \"Bifurcation diagram of the Wilson-Cowan model\" ) plt . xlabel ( \"Input to exc\" ) plt . ylabel ( \"Min / max exc\" ) Text(0,0.5,'Min / max exc') Single node simulation wc = WCModel () wc . params [ 'duration' ] = 1.0 * 1000 wc . params [ 'sigma_ou' ] = 0.01 wc . run () plt . plot ( wc . t , wc . exc . T , c = 'k' , lw = 2 ) plt . xlabel ( \"t [ms]\" ) plt . ylabel ( \"Activity\" ) Text(0,0.5,'Activity') Brain network from neurolib.utils.loadData import Dataset ds = Dataset ( \"hcp\" ) wc = WCModel ( Cmat = ds . Cmat , Dmat = ds . Dmat ) wc . params [ 'exc_ext' ] = 0.65 wc . params [ 'signalV' ] = 0 wc . params [ 'duration' ] = 20 * 1000 wc . params [ 'sigma_ou' ] = 0.14 wc . params [ 'K_gl' ] = 3.15 wc . run ( chunkwise = True ) fig , axs = plt . subplots ( 1 , 2 , figsize = ( 10 , 3 )) axs [ 0 ] . imshow ( func . fc ( wc . exc [:, - 10000 :])) axs [ 1 ] . plot ( wc . t , wc . exc [:: 5 , :] . T , alpha = 0.8 ); axs [ 1 ] . set_xlim ( 0 , 200 ) (0, 200) scores = [ func . matrix_correlation ( func . fc ( wc . exc [:, - int ( 5000 / wc . params [ 'dt' ]):]), fcemp ) for fcemp in ds . FCs ] print ( \"Correlation per subject:\" , [ f \" { s : .2 } \" for s in scores ]) print ( \"Mean FC/FC correlation: {:.2f} \" . format ( np . mean ( scores ))) Correlation per subject: ['0.13', '0.14', '0.13', '0.12', '0.11', '0.12', '0.12'] Mean FC/FC correlation: 0.13","title":"Example 0.4 wc minimal"},{"location":"examples/example-0.4-wc-minimal/#the-wilson-cowan-model","text":"In this notebook, the basic use of the implementation of the Wilson-Cowan ( wc ) model is presented. In the wc model, the activity of a particular brain region is defined by a coupled system of excitatory (E) and inhibitory (I) neuronal populations with the mean firing rates of the E and I pools being the dynamic variables, as first described by Wilson and Cowan in 1972 ( H.R. Wilson and J.D. Cowan. Excitatory and inhibitory interactions in localized populations of model neurons . Biophys. J., 12:1\u201324 (1972)) # change to the root directory of the project import os if os . getcwd () . split ( \"/\" )[ - 1 ] == \"examples\" : os . chdir ( '..' ) % load_ext autoreload % autoreload 2 import matplotlib.pyplot as plt import numpy as np import glob from neurolib.models.wc import WCModel import neurolib.utils.loadData as ld import neurolib.utils.functions as func # a nice color map plt . rcParams [ 'image.cmap' ] = 'plasma'","title":"The Wilson-Cowan model"},{"location":"examples/example-0.4-wc-minimal/#bifurcation-diagram","text":"wc = WCModel () wc . params [ 'duration' ] = 2.0 * 1000 Let's draw a simple one-dimensional bifurcation diagram of this model to orient ourselves in the parameter space max_exc = [] min_exc = [] # these are the different input values that we want to scan exc_inputs = np . linspace ( 0 , 3.5 , 50 ) for exc_ext in exc_inputs : # Note: this has to be a vector since it is input for all nodes # (but we have only one node in this example) wc . params [ 'exc_ext' ] = exc_ext wc . run () # we add the maximum and the minimum of the last second of the # simulation to a list max_exc . append ( np . max ( wc . exc [ 0 , - int ( 1000 / wc . params [ 'dt' ]):])) min_exc . append ( np . min ( wc . exc [ 0 , - int ( 1000 / wc . params [ 'dt' ]):])) plt . plot ( exc_inputs , max_exc , c = 'k' , lw = 2 ) plt . plot ( exc_inputs , min_exc , c = 'k' , lw = 2 ) plt . title ( \"Bifurcation diagram of the Wilson-Cowan model\" ) plt . xlabel ( \"Input to exc\" ) plt . ylabel ( \"Min / max exc\" ) Text(0,0.5,'Min / max exc')","title":"Bifurcation diagram"},{"location":"examples/example-0.4-wc-minimal/#single-node-simulation","text":"wc = WCModel () wc . params [ 'duration' ] = 1.0 * 1000 wc . params [ 'sigma_ou' ] = 0.01 wc . run () plt . plot ( wc . t , wc . exc . T , c = 'k' , lw = 2 ) plt . xlabel ( \"t [ms]\" ) plt . ylabel ( \"Activity\" ) Text(0,0.5,'Activity')","title":"Single node simulation"},{"location":"examples/example-0.4-wc-minimal/#brain-network","text":"from neurolib.utils.loadData import Dataset ds = Dataset ( \"hcp\" ) wc = WCModel ( Cmat = ds . Cmat , Dmat = ds . Dmat ) wc . params [ 'exc_ext' ] = 0.65 wc . params [ 'signalV' ] = 0 wc . params [ 'duration' ] = 20 * 1000 wc . params [ 'sigma_ou' ] = 0.14 wc . params [ 'K_gl' ] = 3.15 wc . run ( chunkwise = True ) fig , axs = plt . subplots ( 1 , 2 , figsize = ( 10 , 3 )) axs [ 0 ] . imshow ( func . fc ( wc . exc [:, - 10000 :])) axs [ 1 ] . plot ( wc . t , wc . exc [:: 5 , :] . T , alpha = 0.8 ); axs [ 1 ] . set_xlim ( 0 , 200 ) (0, 200) scores = [ func . matrix_correlation ( func . fc ( wc . exc [:, - int ( 5000 / wc . params [ 'dt' ]):]), fcemp ) for fcemp in ds . FCs ] print ( \"Correlation per subject:\" , [ f \" { s : .2 } \" for s in scores ]) print ( \"Mean FC/FC correlation: {:.2f} \" . format ( np . mean ( scores ))) Correlation per subject: ['0.13', '0.14', '0.13', '0.12', '0.11', '0.12', '0.12'] Mean FC/FC correlation: 0.13","title":"Brain network"},{"location":"examples/example-0.5-aln-external-stimulus/","text":"(function() { function addWidgetsRenderer() { var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var scriptElement = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} scriptElement.src = widgetRendererSrc; document.body.appendChild(scriptElement); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); Stimulation example This notebook will give you a simple example of how to construct a stimulus and apply it as an input current to the excitatory population of the aln model. # change to the root directory of the project import os if os . getcwd () . split ( \"/\" )[ - 1 ] in [ \"examples\" , \"dev\" ]: os . chdir ( '..' ) # This will reload all imports as soon as the code changes % load_ext autoreload % autoreload 2 try : import matplotlib.pyplot as plt except ImportError : import sys ! { sys . executable } - m pip install matplotlib import matplotlib.pyplot as plt import numpy as np import scipy # Let's import the aln model from neurolib.models.aln import ALNModel # Some useful functions are provided here import neurolib.utils.functions as func from neurolib.utils.stimulus import construct_stimulus First, we initialize a single node. model = ALNModel () model . params [ 'duration' ] = 5 * 1000 model . params [ 'sigma_ou' ] = 0.2 # we add some noise We can construct a simple stimulus using the function stimulus.construct_stimulus : stimulus = construct_stimulus ( \"rect\" , duration = model . params . duration , dt = model . params . dt , stim_amp = 1.0 , stim_freq = 1 ) stimulus = construct_stimulus ( \"ac\" , duration = model . params . duration , dt = model . params . dt , stim_amp = 1.0 , stim_freq = 1 ) The stimulus is then set as an input current parameter to the model. The parameter that models a current that goes to the excitatory population is called ext_exc_current . For the inhibitory population, we can use ext_inh_current . We can also set a firing rate input, that will then be integrated over the synapses using the parameter model.params['ext_exc_rate'] . model . params [ 'ext_exc_current' ] = stimulus model . run () When we plot the timeseries, we can see that the oscillatory activity locks to the stimulus. plt . figure ( figsize = ( 10 , 3 ), dpi = 150 ) plt . title ( \"1 Hz stimulus\" ) ax1 = plt . gca () ax1 . plot ( model . t , model . output . T , c = \"k\" ) ax2 = plt . gca () . twinx () ax2 . plot ( model . t , stimulus , lw = 2 , c = \"r\" , alpha = 0.8 ) ax1 . set_xlabel ( \"Time [ms]\" ) ax1 . set_ylabel ( \"Activity [Hz]\" ) ax2 . set_ylabel ( \"Stimulus [mV/ms]\" , color = 'r' ) ax2 . set_ylabel ( \"Stimulus [mV/ms]\" , color = 'r' ) ax2 . tick_params ( axis = 'y' , labelcolor = 'r' ) Brain network stimulation from neurolib.utils.loadData import Dataset ds = Dataset ( \"hcp\" ) model = ALNModel ( Cmat = ds . Cmat , Dmat = ds . Dmat ) # we chose a parameterization in which the brain network oscillates slowly # between up- and down-states model . params [ \"mue_ext_mean\" ] = 2.56 model . params [ \"mui_ext_mean\" ] = 3.52 model . params [ \"b\" ] = 4.67 model . params [ \"tauA\" ] = 1522.68 model . params [ \"sigma_ou\" ] = 0.40 model . params [ 'duration' ] = 0.2 * 60 * 1000 def plot_output_and_spectrum ( model , individual = False , vertical_mark = None ): \"\"\"A simple plotting function for the timeseries and the power spectrum of the activity. \"\"\" fig , axs = plt . subplots ( 1 , 2 , figsize = ( 8 , 2 ), dpi = 150 , gridspec_kw = { \"width_ratios\" : [ 2 , 1 ]}) axs [ 0 ] . plot ( model . t , model . output . T , lw = 1 ); axs [ 0 ] . set_xlabel ( \"Time [ms]\" ) axs [ 0 ] . set_ylabel ( \"Activity [Hz]\" ) frs , powers = func . getMeanPowerSpectrum ( model . output , dt = model . params . dt ) axs [ 1 ] . plot ( frs , powers , c = 'k' ) if individual : for o in model . output : frs , powers = func . getPowerSpectrum ( o , dt = model . params . dt ) axs [ 1 ] . plot ( frs , powers ) axs [ 1 ] . set_xlabel ( \"Frequency [Hz]\" ) axs [ 1 ] . set_ylabel ( \"Power\" ) plt . show () Without stimulation model . run ( chunkwise = True ) plot_output_and_spectrum ( model ) Constructing a stimulus neurolib helps you to create a few basic stimuli out of the box using the function stimulus.construct_stimulus() . # construct a stimulus ac_stimulus = construct_stimulus ( stim = \"ac\" , stim_freq = 25 , duration = model . params . duration , dt = model . params . dt ) # this stimulus is 1-dimensional. neurolib will threfore automatically apply it to *all nodes*. model . params [ 'ext_exc_current' ] = ac_stimulus * 5.0 model . run ( chunkwise = True ) plot_output_and_spectrum ( model ) Focal stimulation In the previous example, the stimulus was applied to all nodes simultaneously. We can also apply stimulation to a specific set of nodes. # this stimulus is 1-dimensional ac_stimulus = construct_stimulus ( stim = \"ac\" , stim_freq = 25 , duration = model . params . duration , dt = model . params . dt ) # let's make a N-dimensional stimulus vector out of it, by copying and pasting each entry N times ac_stimulus = np . tile ( ac_stimulus . T , ( model . params . N , 1 )) # We set the input to a bunch of nodes to zero. # This will have the effect that only nodes from 0 to 4 will be sitmulated! ac_stimulus [ 5 :, :] = 0 # multiply the stimulus amplitude model . params [ 'ext_exc_current' ] = ac_stimulus * 5.0 model . run ( chunkwise = True ) We can see that the spectrum has a peak at the frequency we stimulated with, but only in a subset of nodes (where we stimulated). plot_output_and_spectrum ( model , individual = True )","title":"Example 0.5 aln external stimulus"},{"location":"examples/example-0.5-aln-external-stimulus/#stimulation-example","text":"This notebook will give you a simple example of how to construct a stimulus and apply it as an input current to the excitatory population of the aln model. # change to the root directory of the project import os if os . getcwd () . split ( \"/\" )[ - 1 ] in [ \"examples\" , \"dev\" ]: os . chdir ( '..' ) # This will reload all imports as soon as the code changes % load_ext autoreload % autoreload 2 try : import matplotlib.pyplot as plt except ImportError : import sys ! { sys . executable } - m pip install matplotlib import matplotlib.pyplot as plt import numpy as np import scipy # Let's import the aln model from neurolib.models.aln import ALNModel # Some useful functions are provided here import neurolib.utils.functions as func from neurolib.utils.stimulus import construct_stimulus First, we initialize a single node. model = ALNModel () model . params [ 'duration' ] = 5 * 1000 model . params [ 'sigma_ou' ] = 0.2 # we add some noise We can construct a simple stimulus using the function stimulus.construct_stimulus : stimulus = construct_stimulus ( \"rect\" , duration = model . params . duration , dt = model . params . dt , stim_amp = 1.0 , stim_freq = 1 ) stimulus = construct_stimulus ( \"ac\" , duration = model . params . duration , dt = model . params . dt , stim_amp = 1.0 , stim_freq = 1 ) The stimulus is then set as an input current parameter to the model. The parameter that models a current that goes to the excitatory population is called ext_exc_current . For the inhibitory population, we can use ext_inh_current . We can also set a firing rate input, that will then be integrated over the synapses using the parameter model.params['ext_exc_rate'] . model . params [ 'ext_exc_current' ] = stimulus model . run () When we plot the timeseries, we can see that the oscillatory activity locks to the stimulus. plt . figure ( figsize = ( 10 , 3 ), dpi = 150 ) plt . title ( \"1 Hz stimulus\" ) ax1 = plt . gca () ax1 . plot ( model . t , model . output . T , c = \"k\" ) ax2 = plt . gca () . twinx () ax2 . plot ( model . t , stimulus , lw = 2 , c = \"r\" , alpha = 0.8 ) ax1 . set_xlabel ( \"Time [ms]\" ) ax1 . set_ylabel ( \"Activity [Hz]\" ) ax2 . set_ylabel ( \"Stimulus [mV/ms]\" , color = 'r' ) ax2 . set_ylabel ( \"Stimulus [mV/ms]\" , color = 'r' ) ax2 . tick_params ( axis = 'y' , labelcolor = 'r' )","title":"Stimulation example"},{"location":"examples/example-0.5-aln-external-stimulus/#brain-network-stimulation","text":"from neurolib.utils.loadData import Dataset ds = Dataset ( \"hcp\" ) model = ALNModel ( Cmat = ds . Cmat , Dmat = ds . Dmat ) # we chose a parameterization in which the brain network oscillates slowly # between up- and down-states model . params [ \"mue_ext_mean\" ] = 2.56 model . params [ \"mui_ext_mean\" ] = 3.52 model . params [ \"b\" ] = 4.67 model . params [ \"tauA\" ] = 1522.68 model . params [ \"sigma_ou\" ] = 0.40 model . params [ 'duration' ] = 0.2 * 60 * 1000 def plot_output_and_spectrum ( model , individual = False , vertical_mark = None ): \"\"\"A simple plotting function for the timeseries and the power spectrum of the activity. \"\"\" fig , axs = plt . subplots ( 1 , 2 , figsize = ( 8 , 2 ), dpi = 150 , gridspec_kw = { \"width_ratios\" : [ 2 , 1 ]}) axs [ 0 ] . plot ( model . t , model . output . T , lw = 1 ); axs [ 0 ] . set_xlabel ( \"Time [ms]\" ) axs [ 0 ] . set_ylabel ( \"Activity [Hz]\" ) frs , powers = func . getMeanPowerSpectrum ( model . output , dt = model . params . dt ) axs [ 1 ] . plot ( frs , powers , c = 'k' ) if individual : for o in model . output : frs , powers = func . getPowerSpectrum ( o , dt = model . params . dt ) axs [ 1 ] . plot ( frs , powers ) axs [ 1 ] . set_xlabel ( \"Frequency [Hz]\" ) axs [ 1 ] . set_ylabel ( \"Power\" ) plt . show ()","title":"Brain network stimulation"},{"location":"examples/example-0.5-aln-external-stimulus/#without-stimulation","text":"model . run ( chunkwise = True ) plot_output_and_spectrum ( model )","title":"Without stimulation"},{"location":"examples/example-0.5-aln-external-stimulus/#constructing-a-stimulus","text":"neurolib helps you to create a few basic stimuli out of the box using the function stimulus.construct_stimulus() . # construct a stimulus ac_stimulus = construct_stimulus ( stim = \"ac\" , stim_freq = 25 , duration = model . params . duration , dt = model . params . dt ) # this stimulus is 1-dimensional. neurolib will threfore automatically apply it to *all nodes*. model . params [ 'ext_exc_current' ] = ac_stimulus * 5.0 model . run ( chunkwise = True ) plot_output_and_spectrum ( model )","title":"Constructing a stimulus"},{"location":"examples/example-0.5-aln-external-stimulus/#focal-stimulation","text":"In the previous example, the stimulus was applied to all nodes simultaneously. We can also apply stimulation to a specific set of nodes. # this stimulus is 1-dimensional ac_stimulus = construct_stimulus ( stim = \"ac\" , stim_freq = 25 , duration = model . params . duration , dt = model . params . dt ) # let's make a N-dimensional stimulus vector out of it, by copying and pasting each entry N times ac_stimulus = np . tile ( ac_stimulus . T , ( model . params . N , 1 )) # We set the input to a bunch of nodes to zero. # This will have the effect that only nodes from 0 to 4 will be sitmulated! ac_stimulus [ 5 :, :] = 0 # multiply the stimulus amplitude model . params [ 'ext_exc_current' ] = ac_stimulus * 5.0 model . run ( chunkwise = True ) We can see that the spectrum has a peak at the frequency we stimulated with, but only in a subset of nodes (where we stimulated). plot_output_and_spectrum ( model , individual = True )","title":"Focal stimulation"},{"location":"examples/example-0.6-custom-model/","text":"(function() { function addWidgetsRenderer() { var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var scriptElement = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} scriptElement.src = widgetRendererSrc; document.body.appendChild(scriptElement); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); Minimal model implementation This notebook demonstrates how to implement your own model in neurolib . There are two main parts of each model: its class that inherits from the Model base class and its timeIntegration() function. # change to the root directory of the project import os if os . getcwd () . split ( \"/\" )[ - 2 ] == \"neurolib\" : os . chdir ( '..' ) % load_ext autoreload % autoreload 2 try : import matplotlib.pyplot as plt except ImportError : import sys ! { sys . executable } - m pip install matplotlib import matplotlib.pyplot as plt Model equations In this example we will implement a linear model with the following equation: \\(\\frac{d}{dt} x_i(t) = - \\frac{x_i(t)}{\\tau} + \\sum_{j=0}^{N} K G_{ij} x_j(t)\\) . Here, we simulate \\(N\\) nodes that are coupled in a network. \\(x_i\\) are the elements of an \\(N\\) -dimensional state vector, \\(\\tau\\) is the decay time constant, \\(G\\) is the adjacency matrix and \\(K\\) is the global coupling strength. Implementation We first create a class for the model called LinearModel which inherits lots of functionality from the Model base class. We define state_vars and default_output so that neurolib knows how to handle the variables of the system. Next, we define init_vars in order to use the autochunk integration scheme, so we can save a lot of RAM when we run very long simulations. class LinearModel(Model): state_vars = [\"x\"] default_output = \"x\" init_vars = [\"x_init\"] Next we define a simple parameter dictionary called params . In here, we can define all the necessary parameters of the model and change their values later. In this example, we set the timescale \\(\\tau\\) , the coupling strength \\(K\\) , the integration time step dt (in ms) and the duration to 100 ms. params = dict(tau=10, K=1e-2, dt=1e-1, duration=100) We are now ready to set up the constructor of our model! This method is supposed to set up the model and prepare it for integration. All the magic happens in the background! We pass the self.timeIntegration function and the parameter dictionary self.params to the base class using super().__init__() . def __init__(self, Cmat=np.zeros((1,1))): self.params['Cmat'] = Cmat super().__init__(self.timeIntegration, self.params) That wasn't too bad, was it? We are finally ready to define the time integration method that prepares all variables and passes it to the last function that will crunch the numbers. Here we prepare the numpy arrays that will hold the simulation results. We have to prepare them before we can execute the numba code. def timeIntegration(self, p): N = p['Cmat'].shape[0] t = np.arange(1, p['duration']/p['dt']) # holds time steps x = np.ndarray((N, len(t)+1)) # holds variable x Next, we make use of a neurolib convention to prepare the initial conditions of our model. If you remember, we defined init_vars above in order to use the autochunk feature. The autochunk feature will automatically fill this parameter with the last state of the last simulated chunk so the model integration can be continued without having to remember the entire output and state variables of the model indefinitely. In this line, we check whether x_init is set or not (which it will be, when we use chunkwise integration). If it is not set, we simply use random initial conditions using rand((N, 1)) . Remember that the convention for array dimensions is array[space, time] , meaning that we only fill in the first time step with the initial condition. # either use predefined initial conditions or random ones x[:, :1] = p.get('x_init') if p.get('x_init') is not None else rand((N, 1)) We're ready to call our accelerated integration part and return the results \ud83d\ude80! return njit_integrate(x, t, p['tau'], p['K'], N, p['Cmat'], p['dt']) Numba time integration Remember to put this function outside of the class definition, so we can use use numba acceleration to greatly increase the performance of our code. We first have to let numba know which part of the code to precompile. We do this by simply placing the decorator @numba.njit in the line above the integration function. Easy way of getting 100x faster code! \u2764\ufe0f numba ! @numba.njit def njit_integrate(x, t, tau, K, N, Cmat, dt): Next, we do some simple math. We first loop over all time steps. If you have prepared the array t as described above, you can simply loop over its length. In the next line, we calculate the coupling term from the model equation above. However, instead of looping over the sum, we use a little trick here and simply compute the dot product between the coupling matrix G and the state vector x . This results in a N -dimensional vector that carries the amount of input each node receives at each time step. Finally, we loop over all nodes so we can finally add up everything. for i in range(1, 1 + len(t)): # loop over time inp = Cmat.dot(x[:, i-1]) # input vector for n in range(N): # loop over nodes In the next line, we integrate the equation that we have shown above. This integration scheme is called Euler integration and is the most simple way of solving an ODE. The idea is easy and is best expressed as x_next = x_before + f(x) * dt where f(x) is simply the time derivative \\(\\frac{d}{dt} x_i(t)\\) shown above. x[n, i] = x[n, i-1] + (- x[n, i-1] / tau + K * inp[n]) * dt # model equations We're done! The only thing left to do is to return the data so that neurolib can take over from here on. The outputs of this simulation will be available in the model.outputs attribute. You can see an example time series below. return t, x Code import numba import numpy as np from numpy.random import random as rand from neurolib.models.model import Model class LinearModel ( Model ): state_vars = [ \"x\" ] default_output = \"x\" init_vars = [ \"x_init\" ] params = dict ( tau = 10 , K = 1e-2 , dt = 1e-1 , duration = 100 ) def __init__ ( self , Cmat = np . zeros (( 1 , 1 ))): self . params [ 'Cmat' ] = Cmat super () . __init__ ( self . timeIntegration , self . params ) def timeIntegration ( self , p ): p [ 'N' ] = p [ 'Cmat' ] . shape [ 0 ] # number of nodes t = np . arange ( 1 , p [ 'duration' ] / p [ 'dt' ] + 1 ) # holds time steps x = np . ndarray (( p [ 'N' ], len ( t ) + 1 )) # holds variable x # either use predefined initial conditions or random ones x [:, : 1 ] = p [ 'x_init' ] if 'x_init' in p else rand (( p [ 'N' ], 1 )) return njit_integrate ( x , t , p [ 'tau' ], p [ 'K' ], p [ 'N' ], p [ 'Cmat' ], p [ 'dt' ]) @numba . njit def njit_integrate ( x , t , tau , K , N , Cmat , dt ): for i in range ( 1 , 1 + len ( t )): # loop over time inp = Cmat . dot ( x [:, i - 1 ]) # input vector for n in range ( N ): # loop over nodes x [ n , i ] = x [ n , i - 1 ] + \\ ( - x [ n , i - 1 ] / tau + K * inp [ n ]) * dt # model equations return t , x Running the model We prepare a \"mock\" connectivity matrix, simply consisting of 12x12 random numbers, meaning that we will simulate 12 LinearModel 's in a network. Cmat = rand (( 12 , 12 )) # use a random connectivity matrix model = LinearModel ( Cmat ) # initialize the model That's it, we are finally ready to run the model. model . run () Plot outputs plt . plot ( model . t , model . output . T ); plt . xlabel ( \"Time [ms]\" ) plt . ylabel ( \"Activity $x$\" ) Text(0, 0.5, 'Activity $x$') BOLD and autochunk Since we've followed the model implementation guidelines, the model is also compatible with chunkwise integration and can produce a BOLD signal. Let's try it out! model . params . duration = 200000 model . run ( chunkwise = True , append_outputs = True , bold = True ) plt . plot ( model . BOLD . t_BOLD , model . BOLD . BOLD . T ); plt . xlabel ( \"Time [ms]\" ) plt . ylabel ( \"BOLD activity\" ) Text(0, 0.5, 'BOLD activity')","title":"Example 0.6 custom model"},{"location":"examples/example-0.6-custom-model/#minimal-model-implementation","text":"This notebook demonstrates how to implement your own model in neurolib . There are two main parts of each model: its class that inherits from the Model base class and its timeIntegration() function. # change to the root directory of the project import os if os . getcwd () . split ( \"/\" )[ - 2 ] == \"neurolib\" : os . chdir ( '..' ) % load_ext autoreload % autoreload 2 try : import matplotlib.pyplot as plt except ImportError : import sys ! { sys . executable } - m pip install matplotlib import matplotlib.pyplot as plt","title":"Minimal model implementation"},{"location":"examples/example-0.6-custom-model/#model-equations","text":"In this example we will implement a linear model with the following equation: \\(\\frac{d}{dt} x_i(t) = - \\frac{x_i(t)}{\\tau} + \\sum_{j=0}^{N} K G_{ij} x_j(t)\\) . Here, we simulate \\(N\\) nodes that are coupled in a network. \\(x_i\\) are the elements of an \\(N\\) -dimensional state vector, \\(\\tau\\) is the decay time constant, \\(G\\) is the adjacency matrix and \\(K\\) is the global coupling strength.","title":"Model equations"},{"location":"examples/example-0.6-custom-model/#implementation","text":"We first create a class for the model called LinearModel which inherits lots of functionality from the Model base class. We define state_vars and default_output so that neurolib knows how to handle the variables of the system. Next, we define init_vars in order to use the autochunk integration scheme, so we can save a lot of RAM when we run very long simulations. class LinearModel(Model): state_vars = [\"x\"] default_output = \"x\" init_vars = [\"x_init\"] Next we define a simple parameter dictionary called params . In here, we can define all the necessary parameters of the model and change their values later. In this example, we set the timescale \\(\\tau\\) , the coupling strength \\(K\\) , the integration time step dt (in ms) and the duration to 100 ms. params = dict(tau=10, K=1e-2, dt=1e-1, duration=100) We are now ready to set up the constructor of our model! This method is supposed to set up the model and prepare it for integration. All the magic happens in the background! We pass the self.timeIntegration function and the parameter dictionary self.params to the base class using super().__init__() . def __init__(self, Cmat=np.zeros((1,1))): self.params['Cmat'] = Cmat super().__init__(self.timeIntegration, self.params) That wasn't too bad, was it? We are finally ready to define the time integration method that prepares all variables and passes it to the last function that will crunch the numbers. Here we prepare the numpy arrays that will hold the simulation results. We have to prepare them before we can execute the numba code. def timeIntegration(self, p): N = p['Cmat'].shape[0] t = np.arange(1, p['duration']/p['dt']) # holds time steps x = np.ndarray((N, len(t)+1)) # holds variable x Next, we make use of a neurolib convention to prepare the initial conditions of our model. If you remember, we defined init_vars above in order to use the autochunk feature. The autochunk feature will automatically fill this parameter with the last state of the last simulated chunk so the model integration can be continued without having to remember the entire output and state variables of the model indefinitely. In this line, we check whether x_init is set or not (which it will be, when we use chunkwise integration). If it is not set, we simply use random initial conditions using rand((N, 1)) . Remember that the convention for array dimensions is array[space, time] , meaning that we only fill in the first time step with the initial condition. # either use predefined initial conditions or random ones x[:, :1] = p.get('x_init') if p.get('x_init') is not None else rand((N, 1)) We're ready to call our accelerated integration part and return the results \ud83d\ude80! return njit_integrate(x, t, p['tau'], p['K'], N, p['Cmat'], p['dt'])","title":"Implementation"},{"location":"examples/example-0.6-custom-model/#numba-time-integration","text":"Remember to put this function outside of the class definition, so we can use use numba acceleration to greatly increase the performance of our code. We first have to let numba know which part of the code to precompile. We do this by simply placing the decorator @numba.njit in the line above the integration function. Easy way of getting 100x faster code! \u2764\ufe0f numba ! @numba.njit def njit_integrate(x, t, tau, K, N, Cmat, dt): Next, we do some simple math. We first loop over all time steps. If you have prepared the array t as described above, you can simply loop over its length. In the next line, we calculate the coupling term from the model equation above. However, instead of looping over the sum, we use a little trick here and simply compute the dot product between the coupling matrix G and the state vector x . This results in a N -dimensional vector that carries the amount of input each node receives at each time step. Finally, we loop over all nodes so we can finally add up everything. for i in range(1, 1 + len(t)): # loop over time inp = Cmat.dot(x[:, i-1]) # input vector for n in range(N): # loop over nodes In the next line, we integrate the equation that we have shown above. This integration scheme is called Euler integration and is the most simple way of solving an ODE. The idea is easy and is best expressed as x_next = x_before + f(x) * dt where f(x) is simply the time derivative \\(\\frac{d}{dt} x_i(t)\\) shown above. x[n, i] = x[n, i-1] + (- x[n, i-1] / tau + K * inp[n]) * dt # model equations We're done! The only thing left to do is to return the data so that neurolib can take over from here on. The outputs of this simulation will be available in the model.outputs attribute. You can see an example time series below. return t, x","title":"Numba time integration"},{"location":"examples/example-0.6-custom-model/#code","text":"import numba import numpy as np from numpy.random import random as rand from neurolib.models.model import Model class LinearModel ( Model ): state_vars = [ \"x\" ] default_output = \"x\" init_vars = [ \"x_init\" ] params = dict ( tau = 10 , K = 1e-2 , dt = 1e-1 , duration = 100 ) def __init__ ( self , Cmat = np . zeros (( 1 , 1 ))): self . params [ 'Cmat' ] = Cmat super () . __init__ ( self . timeIntegration , self . params ) def timeIntegration ( self , p ): p [ 'N' ] = p [ 'Cmat' ] . shape [ 0 ] # number of nodes t = np . arange ( 1 , p [ 'duration' ] / p [ 'dt' ] + 1 ) # holds time steps x = np . ndarray (( p [ 'N' ], len ( t ) + 1 )) # holds variable x # either use predefined initial conditions or random ones x [:, : 1 ] = p [ 'x_init' ] if 'x_init' in p else rand (( p [ 'N' ], 1 )) return njit_integrate ( x , t , p [ 'tau' ], p [ 'K' ], p [ 'N' ], p [ 'Cmat' ], p [ 'dt' ]) @numba . njit def njit_integrate ( x , t , tau , K , N , Cmat , dt ): for i in range ( 1 , 1 + len ( t )): # loop over time inp = Cmat . dot ( x [:, i - 1 ]) # input vector for n in range ( N ): # loop over nodes x [ n , i ] = x [ n , i - 1 ] + \\ ( - x [ n , i - 1 ] / tau + K * inp [ n ]) * dt # model equations return t , x","title":"Code"},{"location":"examples/example-0.6-custom-model/#running-the-model","text":"We prepare a \"mock\" connectivity matrix, simply consisting of 12x12 random numbers, meaning that we will simulate 12 LinearModel 's in a network. Cmat = rand (( 12 , 12 )) # use a random connectivity matrix model = LinearModel ( Cmat ) # initialize the model That's it, we are finally ready to run the model. model . run ()","title":"Running the model"},{"location":"examples/example-0.6-custom-model/#plot-outputs","text":"plt . plot ( model . t , model . output . T ); plt . xlabel ( \"Time [ms]\" ) plt . ylabel ( \"Activity $x$\" ) Text(0, 0.5, 'Activity $x$')","title":"Plot outputs"},{"location":"examples/example-0.6-custom-model/#bold-and-autochunk","text":"Since we've followed the model implementation guidelines, the model is also compatible with chunkwise integration and can produce a BOLD signal. Let's try it out! model . params . duration = 200000 model . run ( chunkwise = True , append_outputs = True , bold = True ) plt . plot ( model . BOLD . t_BOLD , model . BOLD . BOLD . T ); plt . xlabel ( \"Time [ms]\" ) plt . ylabel ( \"BOLD activity\" ) Text(0, 0.5, 'BOLD activity')","title":"BOLD and autochunk"},{"location":"examples/example-1-aln-parameter-exploration/","text":"(function() { function addWidgetsRenderer() { var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var scriptElement = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} scriptElement.src = widgetRendererSrc; document.body.appendChild(scriptElement); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); # change to the root directory of the project import os if os . getcwd () . split ( \"/\" )[ - 1 ] == \"examples\" : os . chdir ( '..' ) # This will reload all imports as soon as the code changes % load_ext autoreload % autoreload 2 try : import matplotlib.pyplot as plt except ImportError : import sys ! { sys . executable } - m pip install matplotlib import matplotlib.pyplot as plt import numpy as np from neurolib.models.aln import ALNModel from neurolib.utils.parameterSpace import ParameterSpace from neurolib.optimize.exploration import BoxSearch # a nice color map plt . rcParams [ 'image.cmap' ] = 'plasma' aln = ALNModel () parameters = ParameterSpace ({ \"mue_ext_mean\" : np . linspace ( 0 , 3 , 2 ), \"mui_ext_mean\" : np . linspace ( 0 , 3 , 2 )}) # info: chose np.linspace(0, 3, 21) or more, values here are low for testing search = BoxSearch ( aln , parameters , filename = \"example-1.hdf\" ) search . run () search . loadResults () print ( \"Number of results: {} \" . format ( len ( search . results ))) # Example analysis of the results # The .results attribute is a list and can be indexed by the run # number (which is also the index of the pandas dataframe .dfResults). # Here we compute the maximum firing rate of the node in the last second # and add the result (a float) to the pandas dataframe. for i in search . dfResults . index : search . dfResults . loc [ i , 'max_r' ] = np . max ( search . results [ i ][ 'rates_exc' ][:, - int ( 1000 / aln . params [ 'dt' ]):]) plt . imshow ( search . dfResults . pivot_table ( values = 'max_r' , index = 'mui_ext_mean' , columns = 'mue_ext_mean' ), \\ extent = [ min ( search . dfResults . mue_ext_mean ), max ( search . dfResults . mue_ext_mean ), min ( search . dfResults . mui_ext_mean ), max ( search . dfResults . mui_ext_mean )], origin = 'lower' ) plt . colorbar ( label = 'Maximum rate [Hz]' ) plt . xlabel ( \"Input to E\" ) plt . ylabel ( \"Input to I\" ) Text(0, 0.5, 'Input to I')","title":"Example 1 aln parameter exploration"},{"location":"examples/example-1.1-custom-parameter-exploration/","text":"(function() { function addWidgetsRenderer() { var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var scriptElement = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} scriptElement.src = widgetRendererSrc; document.body.appendChild(scriptElement); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); A simple parameter exploration This notebook demonstrates a very simple parameter exploration of a custom function that we have defined. It is a simple function that returns the distance to a unit circle, so we expect our parameter exploration to resemble a circle. # change to the root directory of the project import os if os . getcwd () . split ( \"/\" )[ - 1 ] == \"examples\" : os . chdir ( '..' ) # This will reload all imports as soon as the code changes % load_ext autoreload % autoreload 2 try : import matplotlib.pyplot as plt except ImportError : import sys ! { sys . executable } - m pip install matplotlib import matplotlib.pyplot as plt import numpy as np from neurolib.utils.parameterSpace import ParameterSpace from neurolib.optimize.exploration import BoxSearch Define the evaluation function Here we define a very simple evaluation function. The function needs to take in traj as an argument, which is the pypet trajectory. This is how the function knows what parameters were assigned to it. Using the builtin function search.getParametersFromTraj(traj) we can then retrieve the parameters for this run. They are returned as a dictionary and can be accessed in the function. In the last step, we use search.saveToPypet(result_dict, traj) to save the results to the pypet trajectory and to an HDF. In between, the computational magic happens! def explore_me ( traj ): pars = search . getParametersFromTraj ( traj ) # let's calculate the distance to a circle computation_result = abs (( pars [ 'x' ] ** 2 + pars [ 'y' ] ** 2 ) - 1 ) result_dict = { \"distance\" : computation_result } search . saveToPypet ( result_dict , traj ) Define the parameter space and exploration Here we define which space we want to cover. For this, we use the builtin class ParameterSpace which provides a very easy interface to the exploration. To initialize the exploration, we simply pass the evaluation function and the parameter space to the BoxSearch class. parameters = ParameterSpace ({ \"x\" : np . linspace ( - 2 , 2 , 2 ), \"y\" : np . linspace ( - 2 , 2 , 2 )}) # info: chose np.linspace(-2, 2, 40) or more, values here are low for testing search = BoxSearch ( evalFunction = explore_me , parameterSpace = parameters , filename = \"example-1.1.hdf\" ) Run And off we go! search . run () Get results We can easily obtain the results from pypet. First we call search.loadResults() to make sure that the results are loaded from the hdf file to our instance. search . loadResults () print ( \"Number of results: {} \" . format ( len ( search . results ))) The runs are also ordered in a simple pandas dataframe called search.dfResults . We cycle through all results by calling search.results[i] and loading the desired result (here the distance to the circle) into the dataframe for i in search . dfResults . index : search . dfResults . loc [ i , 'distance' ] = search . results [ i ][ 'distance' ] search . dfResults .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } x y distance 0 -2.0 -2.000000 7.000000 1 -2.0 -1.897436 6.600263 2 -2.0 -1.794872 6.221565 3 -2.0 -1.692308 5.863905 4 -2.0 -1.589744 5.527285 ... ... ... ... 1595 2.0 1.589744 5.527285 1596 2.0 1.692308 5.863905 1597 2.0 1.794872 6.221565 1598 2.0 1.897436 6.600263 1599 2.0 2.000000 7.000000 1600 rows \u00d7 3 columns And of course a plot can visualize the results very easily. plt . imshow ( search . dfResults . pivot_table ( values = 'distance' , index = 'x' , columns = 'y' ), \\ extent = [ min ( search . dfResults . x ), max ( search . dfResults . x ), min ( search . dfResults . y ), max ( search . dfResults . y )], origin = 'lower' ) plt . colorbar ( label = 'Distance to the unit circle' ) <matplotlib.colorbar.Colorbar at 0x124a71588>","title":"Example 1.1 custom parameter exploration"},{"location":"examples/example-1.1-custom-parameter-exploration/#a-simple-parameter-exploration","text":"This notebook demonstrates a very simple parameter exploration of a custom function that we have defined. It is a simple function that returns the distance to a unit circle, so we expect our parameter exploration to resemble a circle. # change to the root directory of the project import os if os . getcwd () . split ( \"/\" )[ - 1 ] == \"examples\" : os . chdir ( '..' ) # This will reload all imports as soon as the code changes % load_ext autoreload % autoreload 2 try : import matplotlib.pyplot as plt except ImportError : import sys ! { sys . executable } - m pip install matplotlib import matplotlib.pyplot as plt import numpy as np from neurolib.utils.parameterSpace import ParameterSpace from neurolib.optimize.exploration import BoxSearch","title":"A simple parameter exploration"},{"location":"examples/example-1.1-custom-parameter-exploration/#define-the-evaluation-function","text":"Here we define a very simple evaluation function. The function needs to take in traj as an argument, which is the pypet trajectory. This is how the function knows what parameters were assigned to it. Using the builtin function search.getParametersFromTraj(traj) we can then retrieve the parameters for this run. They are returned as a dictionary and can be accessed in the function. In the last step, we use search.saveToPypet(result_dict, traj) to save the results to the pypet trajectory and to an HDF. In between, the computational magic happens! def explore_me ( traj ): pars = search . getParametersFromTraj ( traj ) # let's calculate the distance to a circle computation_result = abs (( pars [ 'x' ] ** 2 + pars [ 'y' ] ** 2 ) - 1 ) result_dict = { \"distance\" : computation_result } search . saveToPypet ( result_dict , traj )","title":"Define the evaluation function"},{"location":"examples/example-1.1-custom-parameter-exploration/#define-the-parameter-space-and-exploration","text":"Here we define which space we want to cover. For this, we use the builtin class ParameterSpace which provides a very easy interface to the exploration. To initialize the exploration, we simply pass the evaluation function and the parameter space to the BoxSearch class. parameters = ParameterSpace ({ \"x\" : np . linspace ( - 2 , 2 , 2 ), \"y\" : np . linspace ( - 2 , 2 , 2 )}) # info: chose np.linspace(-2, 2, 40) or more, values here are low for testing search = BoxSearch ( evalFunction = explore_me , parameterSpace = parameters , filename = \"example-1.1.hdf\" )","title":"Define the parameter space and exploration"},{"location":"examples/example-1.1-custom-parameter-exploration/#run","text":"And off we go! search . run ()","title":"Run"},{"location":"examples/example-1.1-custom-parameter-exploration/#get-results","text":"We can easily obtain the results from pypet. First we call search.loadResults() to make sure that the results are loaded from the hdf file to our instance. search . loadResults () print ( \"Number of results: {} \" . format ( len ( search . results ))) The runs are also ordered in a simple pandas dataframe called search.dfResults . We cycle through all results by calling search.results[i] and loading the desired result (here the distance to the circle) into the dataframe for i in search . dfResults . index : search . dfResults . loc [ i , 'distance' ] = search . results [ i ][ 'distance' ] search . dfResults .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } x y distance 0 -2.0 -2.000000 7.000000 1 -2.0 -1.897436 6.600263 2 -2.0 -1.794872 6.221565 3 -2.0 -1.692308 5.863905 4 -2.0 -1.589744 5.527285 ... ... ... ... 1595 2.0 1.589744 5.527285 1596 2.0 1.692308 5.863905 1597 2.0 1.794872 6.221565 1598 2.0 1.897436 6.600263 1599 2.0 2.000000 7.000000 1600 rows \u00d7 3 columns And of course a plot can visualize the results very easily. plt . imshow ( search . dfResults . pivot_table ( values = 'distance' , index = 'x' , columns = 'y' ), \\ extent = [ min ( search . dfResults . x ), max ( search . dfResults . x ), min ( search . dfResults . y ), max ( search . dfResults . y )], origin = 'lower' ) plt . colorbar ( label = 'Distance to the unit circle' ) <matplotlib.colorbar.Colorbar at 0x124a71588>","title":"Get results"},{"location":"examples/example-1.2-brain-network-exploration/","text":"(function() { function addWidgetsRenderer() { var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var scriptElement = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} scriptElement.src = widgetRendererSrc; document.body.appendChild(scriptElement); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); Parameter exploration of a brain network model This notebook demonstrates how to scan the parameter space of a brain network model using neurolib . We will simulate BOLD activity and compare the results to empirical data to identify optimal parameters of the model. The steps outlined in this notebook are the following: We load a DTI and resting-state fMRI dataset ( hcp ) and set up a brain network using the FHNModel . We simulate the system for a range of different parameter configurations. We load the simulated data from disk. We postprocess the results and obtain the model fit. Finally, we plot the results in the parameter space of the exploration. #hide # change to the root directory of the project import os if os . getcwd () . split ( \"/\" )[ - 1 ] == \"examples\" : os . chdir ( '..' ) # This will reload all imports as soon as the code changes % load_ext autoreload % autoreload 2 The autoreload extension is already loaded. To reload it, use: %reload_ext autoreload #hide import logging logging . getLogger () . setLevel ( logging . INFO ) import warnings warnings . filterwarnings ( \"ignore\" ) #hide try : import matplotlib.pyplot as plt except ImportError : import sys ! { sys . executable } - m pip install matplotlib import matplotlib.pyplot as plt import numpy as np # Let's import all the necessary functions for the parameter from neurolib.models.fhn import FHNModel from neurolib.utils.parameterSpace import ParameterSpace from neurolib.optimize.exploration import BoxSearch # load some utilty functions for explorations import neurolib.utils.pypetUtils as pu import neurolib.utils.paths as paths import neurolib.optimize.exploration.explorationUtils as eu # The brain network dataset from neurolib.utils.loadData import Dataset # Some useful functions are provided here import neurolib.utils.functions as func # a nice color map plt . rcParams [ 'image.cmap' ] = 'plasma' 1. Set up a brain network We load a dataset (in this case the hcp dataset from the Human Connectome Project) and initialize a model to run on each node of the brain network (here the FHNModel which is the Fitz-Hugh Nagumo model). ds = Dataset ( \"hcp\" ) model = FHNModel ( Cmat = ds . Cmat , Dmat = ds . Dmat ) model . params . duration = 20 * 1000 #ms # testing: model.params.duration = 20 * 1000 #ms # original: model.params.duration = 5 * 60 * 1000 #ms Running the model is as simple as entering model.run(chunkwise=True) . 2. Run the exploration We define a parameter range to explore. Our first parameter is x_ext , which is the input to each node of the FHNModel in a brain network. Therefore, this parameter is a list with N entries, one per node. Our next parameter is K_gl , the global coupling strength. Finally, we have the coupling parameter, which defines how each FHNModel is coupled to its adjacent nodes via either additive coupling ( activity += input ) or diffusive ( activity += (activity - input) ). parameters = ParameterSpace ({ \"x_ext\" : [ np . ones (( model . params [ 'N' ],)) * a for a in np . linspace ( 0 , 2 , 2 )] # testing: 2, original: 41 , \"K_gl\" : np . linspace ( 0 , 2 , 2 ) # testing: 2, original: 41 , \"coupling\" : [ \"additive\" , \"diffusive\" ] }, kind = \"grid\" ) search = BoxSearch ( model = model , parameterSpace = parameters , filename = \"example-1.2.0.hdf\" ) We run the exploration, simply by calling the run() function of the BoxSearch class. We can pass parameters to this function, that will be directly passed to the FHNModel.run() function of the simulated model. This way, we can easily specify to run the simulation chunkwise , without storing all the activity in memory, and simulate bold activity as well. Note that the default behaviour of the BoxSearch class is to save the default_output of each model and if bold is simulated, then also the BOLD data. If the exploration is initialized with BoxSearch(saveAllModelOutputs=True) , the exploration would save all outputs of the model. This can obviously create a lot of data to store, so please use this option at your own discretion. search . run ( chunkwise = True , bold = True ) 3. Load results A simple helper function for getting the trajectories of an hdf file created by pypet can be found in pypetUtils.py (aka pu ). This way, you can explore which explorations are in the file and decide later which one you want to load for analysis pu . getTrajectorynamesInFile ( os . path . join ( paths . HDF_DIR , \"example-1.2.0.hdf\" )) ['results-2020-04-08-02H-01M-53S', 'results-2020-04-08-02H-50M-09S'] The default behaviour will load the latest exploration. It's name is also stored in search.trajectoryName : search . trajectoryName 'results-2020-04-08-02H-50M-09S' Now we load all results. As said above, the newest exploration will be loaded by default. You can load results from earlier explorations by adding the argument trajectoryName=results-from-earlier and also chose another hdf file by using the argument filename=/path/to/explorations.hdf . Remember that using search.loadResults() will load all results to memory. This can cause a lot of RAM, depending on how big the exploration was. search . loadResults () print ( \"Number of results: {} \" . format ( len ( search . results ))) One way of loading a result without loading everything else into RAM is to use the builtin function search.getRun() . However, you need to know which runId you're looking for! For this, you can run search.loadDfResults() to create a pandas.DataFrame search.dfResults with all parameters (which also happens when you call search.loadResults() ). search . getRun ( 6 ) . params {'x_ext': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'K_gl': 0.15000000000000002, 'coupling': 'additive'} After loading the results with search.loadResults() they are now available as a simple list using search.results . Let's look at the time series of one result. rId = 2 # test:2, original: 1327 plt . plot ( search . results [ rId ] . t , search . results [ rId ] . x . T ); plt . xlabel ( \"Time [ms]\" ) plt . ylabel ( \"Activity\" ) Text(0, 0.5, 'Activity') Using search.loadResults() also created a pandas.DataFrame with the individual run's parameters and their runId . search . dfResults . iloc [ - 4 :] .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } x_ext K_gl coupling fc max_x amp_x 3358 2.0 1.95 additive 0.304496 2.446207 1.463651e+00 3359 2.0 1.95 diffusive 0.221238 0.872110 2.275957e-14 3360 2.0 2.00 additive 0.310389 2.489208 1.503437e+00 3361 2.0 2.00 diffusive 0.226729 0.872110 2.253753e-14 If you remember from before, the external input parameter x_ext is a list of length N (one per node). Since they're all the same in this example, we reduce the parameter to only the first entry of each list. search . dfResults . x_ext = [ a [ 0 ] for a in list ( search . dfResults . x_ext )] search . dfResults . iloc [ - 4 :] .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } x_ext K_gl coupling 3358 2.0 1.95 additive 3359 2.0 1.95 diffusive 3360 2.0 2.00 additive 3361 2.0 2.00 diffusive 4. Postprocessing We can use eu.processExplorationResults() from explorationUtils.py (aka eu ) to process the results from the simluation and store results in our pandas.DataFrame of all results called search.dfResults : eu . processExplorationResults ( search , model = model , ds = ds , bold_transient = 10000 ) This finally gives us a dataframe with parameters and respective values from postprocessing the results, which we can access using search.dfResults . We can use the utility function eu.findCloseResults() to navigate in this DataFrame and find for example the runId of a run for a specific parameter configuration. eu . findCloseResults ( search . dfResults , dist = 0.2 , K_gl = 0.5 , x_ext = 1.0 ) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } x_ext K_gl coupling fc max_x amp_x 1324 0.80 0.30 additive 0.364910 1.192267 1.428502 1325 0.80 0.30 diffusive 0.302487 0.576765 0.467873 1326 0.80 0.35 additive 0.337226 1.241613 1.511995 1327 0.80 0.35 diffusive 0.187238 0.547917 0.423548 1328 0.80 0.40 additive 0.200489 1.287626 1.590182 ... ... ... ... ... ... ... 1909 1.15 0.55 diffusive 0.363809 0.772698 0.577180 1910 1.15 0.60 additive 0.348988 1.234206 1.050313 1911 1.15 0.60 diffusive 0.278103 0.768822 0.566546 1912 1.15 0.65 additive 0.371943 1.276929 1.091328 1913 1.15 0.65 diffusive 0.292993 0.762355 0.550818 128 rows \u00d7 6 columns To understand what is happening in eu.processExplorationResults() , it helps to see how we could do postprocessing on the loaded data ourselves. Let's calculate the correlation to empirical functional connectivity using the builtin funtions func.fc() and func.matrix_correlation() . mean_corr = np . mean ([ func . matrix_correlation ( func . fc ( search . results [ rId ][ 'BOLD' ]), fc ) for fc in ds . FCs ]) print ( f \"Mean correlation of run { rId } with empirical FC matrices is { mean_corr : .02 } \" ) Mean correlation of run 3324 with empirical FC matrices is 0.28 5. Plot Another usefull function is eu.plotExplorationResults() , which helps you to visualize the results from the exploration. You can specify which parameters should be the x- and the y-axis using the par1=[parameter_name, parameter_label] and par2 arguments, and you can define by which paramter plane the results should be \"sliced\". plot_key_label = \"Maximum of output\" eu . plotExplorationResults ( search . dfResults , par1 = [ 'x_ext' , '$x_ {ext} $' ], par2 = [ 'K_gl' , '$K$' ], plot_key = 'max_x' , by = [ 'coupling' ], by_label = [ 'coupling' ], plot_key_label = plot_key_label , one_figure = True ) BOLD functional connectivity We want to find parameter for which the brain network model produces realistic BOLD functional connectivity. For this, we calculated the entry fc in search.dfResults by taking the func.fc() of the model.BOLD timeseries and compared it to empirical data using func.matrix_correlation . Below, the average of this value across all subjects of the dataset is plotted. A higher value (brighter color) means a better fit to the empirical data. Observe how the best solutions tend to cluster at the edges of bifurcations, indicating that correlations in the network are generated by multiple nodes undergoing bifurcation together, such as transitioning from the constant activity (fixed point) solution to an oscillation. plot_key_label = \"FC correlation\" eu . plotExplorationResults ( search . dfResults , par1 = [ 'x_ext' , '$x_ {ext} $' ], par2 = [ 'K_gl' , '$K$' ], plot_key = 'fc' , by = [ 'coupling' ], by_label = [ 'coupling' ], plot_key_label = plot_key_label , one_figure = True )","title":"Example 1.2 brain network exploration"},{"location":"examples/example-1.2-brain-network-exploration/#parameter-exploration-of-a-brain-network-model","text":"This notebook demonstrates how to scan the parameter space of a brain network model using neurolib . We will simulate BOLD activity and compare the results to empirical data to identify optimal parameters of the model. The steps outlined in this notebook are the following: We load a DTI and resting-state fMRI dataset ( hcp ) and set up a brain network using the FHNModel . We simulate the system for a range of different parameter configurations. We load the simulated data from disk. We postprocess the results and obtain the model fit. Finally, we plot the results in the parameter space of the exploration. #hide # change to the root directory of the project import os if os . getcwd () . split ( \"/\" )[ - 1 ] == \"examples\" : os . chdir ( '..' ) # This will reload all imports as soon as the code changes % load_ext autoreload % autoreload 2 The autoreload extension is already loaded. To reload it, use: %reload_ext autoreload #hide import logging logging . getLogger () . setLevel ( logging . INFO ) import warnings warnings . filterwarnings ( \"ignore\" ) #hide try : import matplotlib.pyplot as plt except ImportError : import sys ! { sys . executable } - m pip install matplotlib import matplotlib.pyplot as plt import numpy as np # Let's import all the necessary functions for the parameter from neurolib.models.fhn import FHNModel from neurolib.utils.parameterSpace import ParameterSpace from neurolib.optimize.exploration import BoxSearch # load some utilty functions for explorations import neurolib.utils.pypetUtils as pu import neurolib.utils.paths as paths import neurolib.optimize.exploration.explorationUtils as eu # The brain network dataset from neurolib.utils.loadData import Dataset # Some useful functions are provided here import neurolib.utils.functions as func # a nice color map plt . rcParams [ 'image.cmap' ] = 'plasma'","title":"Parameter exploration of a brain network model"},{"location":"examples/example-1.2-brain-network-exploration/#1-set-up-a-brain-network","text":"We load a dataset (in this case the hcp dataset from the Human Connectome Project) and initialize a model to run on each node of the brain network (here the FHNModel which is the Fitz-Hugh Nagumo model). ds = Dataset ( \"hcp\" ) model = FHNModel ( Cmat = ds . Cmat , Dmat = ds . Dmat ) model . params . duration = 20 * 1000 #ms # testing: model.params.duration = 20 * 1000 #ms # original: model.params.duration = 5 * 60 * 1000 #ms Running the model is as simple as entering model.run(chunkwise=True) .","title":"1. Set up a brain network"},{"location":"examples/example-1.2-brain-network-exploration/#2-run-the-exploration","text":"We define a parameter range to explore. Our first parameter is x_ext , which is the input to each node of the FHNModel in a brain network. Therefore, this parameter is a list with N entries, one per node. Our next parameter is K_gl , the global coupling strength. Finally, we have the coupling parameter, which defines how each FHNModel is coupled to its adjacent nodes via either additive coupling ( activity += input ) or diffusive ( activity += (activity - input) ). parameters = ParameterSpace ({ \"x_ext\" : [ np . ones (( model . params [ 'N' ],)) * a for a in np . linspace ( 0 , 2 , 2 )] # testing: 2, original: 41 , \"K_gl\" : np . linspace ( 0 , 2 , 2 ) # testing: 2, original: 41 , \"coupling\" : [ \"additive\" , \"diffusive\" ] }, kind = \"grid\" ) search = BoxSearch ( model = model , parameterSpace = parameters , filename = \"example-1.2.0.hdf\" ) We run the exploration, simply by calling the run() function of the BoxSearch class. We can pass parameters to this function, that will be directly passed to the FHNModel.run() function of the simulated model. This way, we can easily specify to run the simulation chunkwise , without storing all the activity in memory, and simulate bold activity as well. Note that the default behaviour of the BoxSearch class is to save the default_output of each model and if bold is simulated, then also the BOLD data. If the exploration is initialized with BoxSearch(saveAllModelOutputs=True) , the exploration would save all outputs of the model. This can obviously create a lot of data to store, so please use this option at your own discretion. search . run ( chunkwise = True , bold = True )","title":"2. Run the exploration"},{"location":"examples/example-1.2-brain-network-exploration/#3-load-results","text":"A simple helper function for getting the trajectories of an hdf file created by pypet can be found in pypetUtils.py (aka pu ). This way, you can explore which explorations are in the file and decide later which one you want to load for analysis pu . getTrajectorynamesInFile ( os . path . join ( paths . HDF_DIR , \"example-1.2.0.hdf\" )) ['results-2020-04-08-02H-01M-53S', 'results-2020-04-08-02H-50M-09S'] The default behaviour will load the latest exploration. It's name is also stored in search.trajectoryName : search . trajectoryName 'results-2020-04-08-02H-50M-09S' Now we load all results. As said above, the newest exploration will be loaded by default. You can load results from earlier explorations by adding the argument trajectoryName=results-from-earlier and also chose another hdf file by using the argument filename=/path/to/explorations.hdf . Remember that using search.loadResults() will load all results to memory. This can cause a lot of RAM, depending on how big the exploration was. search . loadResults () print ( \"Number of results: {} \" . format ( len ( search . results ))) One way of loading a result without loading everything else into RAM is to use the builtin function search.getRun() . However, you need to know which runId you're looking for! For this, you can run search.loadDfResults() to create a pandas.DataFrame search.dfResults with all parameters (which also happens when you call search.loadResults() ). search . getRun ( 6 ) . params {'x_ext': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'K_gl': 0.15000000000000002, 'coupling': 'additive'} After loading the results with search.loadResults() they are now available as a simple list using search.results . Let's look at the time series of one result. rId = 2 # test:2, original: 1327 plt . plot ( search . results [ rId ] . t , search . results [ rId ] . x . T ); plt . xlabel ( \"Time [ms]\" ) plt . ylabel ( \"Activity\" ) Text(0, 0.5, 'Activity') Using search.loadResults() also created a pandas.DataFrame with the individual run's parameters and their runId . search . dfResults . iloc [ - 4 :] .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } x_ext K_gl coupling fc max_x amp_x 3358 2.0 1.95 additive 0.304496 2.446207 1.463651e+00 3359 2.0 1.95 diffusive 0.221238 0.872110 2.275957e-14 3360 2.0 2.00 additive 0.310389 2.489208 1.503437e+00 3361 2.0 2.00 diffusive 0.226729 0.872110 2.253753e-14 If you remember from before, the external input parameter x_ext is a list of length N (one per node). Since they're all the same in this example, we reduce the parameter to only the first entry of each list. search . dfResults . x_ext = [ a [ 0 ] for a in list ( search . dfResults . x_ext )] search . dfResults . iloc [ - 4 :] .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } x_ext K_gl coupling 3358 2.0 1.95 additive 3359 2.0 1.95 diffusive 3360 2.0 2.00 additive 3361 2.0 2.00 diffusive","title":"3. Load results"},{"location":"examples/example-1.2-brain-network-exploration/#4-postprocessing","text":"We can use eu.processExplorationResults() from explorationUtils.py (aka eu ) to process the results from the simluation and store results in our pandas.DataFrame of all results called search.dfResults : eu . processExplorationResults ( search , model = model , ds = ds , bold_transient = 10000 ) This finally gives us a dataframe with parameters and respective values from postprocessing the results, which we can access using search.dfResults . We can use the utility function eu.findCloseResults() to navigate in this DataFrame and find for example the runId of a run for a specific parameter configuration. eu . findCloseResults ( search . dfResults , dist = 0.2 , K_gl = 0.5 , x_ext = 1.0 ) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } x_ext K_gl coupling fc max_x amp_x 1324 0.80 0.30 additive 0.364910 1.192267 1.428502 1325 0.80 0.30 diffusive 0.302487 0.576765 0.467873 1326 0.80 0.35 additive 0.337226 1.241613 1.511995 1327 0.80 0.35 diffusive 0.187238 0.547917 0.423548 1328 0.80 0.40 additive 0.200489 1.287626 1.590182 ... ... ... ... ... ... ... 1909 1.15 0.55 diffusive 0.363809 0.772698 0.577180 1910 1.15 0.60 additive 0.348988 1.234206 1.050313 1911 1.15 0.60 diffusive 0.278103 0.768822 0.566546 1912 1.15 0.65 additive 0.371943 1.276929 1.091328 1913 1.15 0.65 diffusive 0.292993 0.762355 0.550818 128 rows \u00d7 6 columns To understand what is happening in eu.processExplorationResults() , it helps to see how we could do postprocessing on the loaded data ourselves. Let's calculate the correlation to empirical functional connectivity using the builtin funtions func.fc() and func.matrix_correlation() . mean_corr = np . mean ([ func . matrix_correlation ( func . fc ( search . results [ rId ][ 'BOLD' ]), fc ) for fc in ds . FCs ]) print ( f \"Mean correlation of run { rId } with empirical FC matrices is { mean_corr : .02 } \" ) Mean correlation of run 3324 with empirical FC matrices is 0.28","title":"4. Postprocessing"},{"location":"examples/example-1.2-brain-network-exploration/#5-plot","text":"Another usefull function is eu.plotExplorationResults() , which helps you to visualize the results from the exploration. You can specify which parameters should be the x- and the y-axis using the par1=[parameter_name, parameter_label] and par2 arguments, and you can define by which paramter plane the results should be \"sliced\". plot_key_label = \"Maximum of output\" eu . plotExplorationResults ( search . dfResults , par1 = [ 'x_ext' , '$x_ {ext} $' ], par2 = [ 'K_gl' , '$K$' ], plot_key = 'max_x' , by = [ 'coupling' ], by_label = [ 'coupling' ], plot_key_label = plot_key_label , one_figure = True )","title":"5. Plot"},{"location":"examples/example-1.2-brain-network-exploration/#bold-functional-connectivity","text":"We want to find parameter for which the brain network model produces realistic BOLD functional connectivity. For this, we calculated the entry fc in search.dfResults by taking the func.fc() of the model.BOLD timeseries and compared it to empirical data using func.matrix_correlation . Below, the average of this value across all subjects of the dataset is plotted. A higher value (brighter color) means a better fit to the empirical data. Observe how the best solutions tend to cluster at the edges of bifurcations, indicating that correlations in the network are generated by multiple nodes undergoing bifurcation together, such as transitioning from the constant activity (fixed point) solution to an oscillation. plot_key_label = \"FC correlation\" eu . plotExplorationResults ( search . dfResults , par1 = [ 'x_ext' , '$x_ {ext} $' ], par2 = [ 'K_gl' , '$K$' ], plot_key = 'fc' , by = [ 'coupling' ], by_label = [ 'coupling' ], plot_key_label = plot_key_label , one_figure = True )","title":"BOLD functional connectivity"},{"location":"examples/example-1.2.1-brain-exploration-postprocessing/","text":"(function() { function addWidgetsRenderer() { var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var scriptElement = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} scriptElement.src = widgetRendererSrc; document.body.appendChild(scriptElement); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); Parameter exploration with custom run function and postprocessing This notebook demonstrates how to scan the parameter space of a brain network model using neurolib with a custom evaluation function to quickly find regions of interest. The evaluation function is designed to increase the speed for the exploration by focussing on regions where the simulated dynamics meets certain criteria. For this, the simulation is run in multiple, successive steps, that increase in duration. Iterative evaluation The evaluation of a simulation takes multiple steps: Step 1 runs for a few seconds and checks if there is any rate activity at all Step 2 runs a bit longer and checks if there is any BOLD activity Step 3 runs the full simulation Postprocessing In this scenario, we want to postprocess the simulated data as soon as the simulation is done and before writing the results to the hard disk. After the full simulation is run, the funciotnal connectivity (FC) of the BOLD signal is computed and compared to the empirical FC dataset. The Pearson correlation of the FC matrices is computed and the average is taken. We then tell pypet to save these postprocessed results along with the model output. #hide # change to the root directory of the project import os if os . getcwd () . split ( \"/\" )[ - 1 ] == \"examples\" : os . chdir ( '..' ) # This will reload all imports as soon as the code changes % load_ext autoreload % autoreload 2 #hide try : import matplotlib.pyplot as plt except ImportError : import sys ! { sys . executable } - m pip install matplotlib import matplotlib.pyplot as plt # a nice color map plt . rcParams [ 'image.cmap' ] = 'plasma' import numpy as np from neurolib.models.aln import ALNModel from neurolib.utils.parameterSpace import ParameterSpace from neurolib.optimize.exploration import BoxSearch import neurolib.utils.functions as func from neurolib.utils.loadData import Dataset ds = Dataset ( \"hcp\" ) Set up model model = ALNModel ( Cmat = ds . Cmat , Dmat = ds . Dmat ) # simulates the whole-brain model in 10s chunks by default if bold == True # Resting state fits model . params [ 'mue_ext_mean' ] = 1.57 model . params [ 'mui_ext_mean' ] = 1.6 #model.params['sigma_ou'] = 0.09 model . params [ 'b' ] = 5.0 model . params [ 'dt' ] = 0.2 model . params [ 'duration' ] = 0.2 * 1000 #ms # testing: model.params['duration'] = 0.2 * 60 * 1000 #ms # real: model.params['duration'] = 1.0 * 60 * 1000 #ms MainProcess root INFO aln: Model initialized. Define evaluation function def evaluateSimulation ( traj ): # get the model from the trajectory using `search.getModelFromTraj(traj)` model = search . getModelFromTraj ( traj ) # initiate the model with random initial contitions model . randomICs () defaultDuration = model . params [ 'duration' ] invalid_result = { \"fc\" : np . nan , \"fcd\" : np . nan } # -------- STAGEWISE EVALUATION -------- stagewise = True if stagewise : # -------- stage wise simulation -------- # Stage 1 : simulate for a few seconds to see if there is any activity # --------------------------------------- model . params [ 'duration' ] = 3 * 1000. model . run () # check if stage 1 was successful amplitude = np . max ( model . output [:, model . t > 500 ]) - np . min ( model . output [:, model . t > 500 ]) if amplitude < 0.05 : search . saveToPypet ( invalid_result , traj ) return invalid_result , {} # Stage 2: simulate BOLD for a few seconds to see if it moves # --------------------------------------- model . params [ 'duration' ] = 30 * 1000. model . run ( chunkwise = True , bold = True ) if np . max ( np . std ( model . outputs . BOLD . BOLD [:, 10 : 15 ], axis = 1 )) < 1e-5 : search . saveToPypet ( invalid_result , traj ) return invalid_result , {} # Stage 3: full and final simulation # --------------------------------------- model . params [ 'duration' ] = defaultDuration model . run ( chunkwise = True , bold = True ) # -------- POSTPROCESSING -------- # FC matrix correlation to all subject rs-fMRI BOLD_TRANSIENT = 10000 fc_score = np . mean ([ func . matrix_correlation ( func . fc ( model . BOLD . BOLD [:, model . BOLD . t_BOLD > BOLD_TRANSIENT ]), fc ) for fc in ds . FCs ]) # FCD to all subject rs-fMRI try : fcd_score = np . mean ([ func . ts_kolmogorov ( model . BOLD . BOLD [:, model . BOLD . t_BOLD > BOLD_TRANSIENT ], ds . BOLDs [ i ]) for i in range ( len ( ds . BOLDs ))]) except : fcd_score = np . nan # let's build the results dictionary result_dict = { \"fc\" : fc_score , \"fcd\" : fcd_score } # we could also save the output of the model by adding to the results_dict like this: # result_dict = {\"fc\" : fc_score, \"fcd\" : fcd_score, \"outputs\" : model.outputs} # Save the results to pypet. # Remember: This has to be dictionary! search . saveToPypet ( result_dict , traj ) Set up parameter exploration parameters = ParameterSpace ({ \"mue_ext_mean\" : np . linspace ( 0 , 3.0 , 2 ), \"mui_ext_mean\" : np . linspace ( 0.2 , 3.0 , 2 )}) # info: chose np.linspace(0, 3, 21) or more, values here are low for testing search = BoxSearch ( evalFunction = evaluateSimulation , model = model , parameterSpace = parameters , filename = \"example-1.2.1.hdf\" ) MainProcess root INFO Number of processes: 80 MainProcess pypet.storageservice.HDF5StorageService INFO I will use the hdf5 file `/mnt/raid/data/cakan/hdf/example-1.2.1.hdf`. MainProcess pypet.environment.Environment INFO Environment initialized. /home/cakan/anaconda/lib/python3.7/site-packages/pypet/parameter.py:884: FutureWarning: Conversion of the second argument of issubdtype from `str` to `str` is deprecated. In future, it will be treated as `np.str_ == np.dtype(str).type`. if np.issubdtype(dtype, np.str): MainProcess root INFO Number of parameter configurations: 4 MainProcess root INFO BoxSearch: Environment initialized. search . run () MainProcess pypet.environment.Environment INFO I am preparing the Trajectory for the experiment and initialise the store. MainProcess pypet.environment.Environment INFO Initialising the storage for the trajectory. MainProcess pypet.storageservice.HDF5StorageService INFO Initialising storage or updating meta data of Trajectory `results-2020-04-08-01H-16M-48S`. MainProcess pypet.storageservice.HDF5StorageService INFO Finished init or meta data update for `results-2020-04-08-01H-16M-48S`. MainProcess pypet.environment.Environment INFO ************************************************************ STARTING runs of trajectory `results-2020-04-08-01H-16M-48S`. ************************************************************ MainProcess pypet.storageservice.HDF5StorageService INFO Initialising storage or updating meta data of Trajectory `results-2020-04-08-01H-16M-48S`. MainProcess pypet.storageservice.HDF5StorageService INFO Finished init or meta data update for `results-2020-04-08-01H-16M-48S`. MainProcess pypet.environment.Environment INFO Starting multiprocessing with at most 80 processes running at the same time. MainProcess pypet INFO PROGRESS: Finished 0/4 runs [ ] 0.0% MainProcess pypet INFO PROGRESS: Finished 1/4 runs [===== ] 25.0%, remaining: 0:00:02 MainProcess pypet INFO PROGRESS: Finished 2/4 runs [========== ] 50.0%, remaining: 0:00:00 MainProcess pypet INFO PROGRESS: Finished 3/4 runs [=============== ] 75.0%, remaining: 0:00:09 MainProcess pypet INFO PROGRESS: Finished 4/4 runs [====================]100.0% MainProcess pypet.storageservice.HDF5StorageService INFO Initialising storage or updating meta data of Trajectory `results-2020-04-08-01H-16M-48S`. MainProcess pypet.storageservice.HDF5StorageService INFO Finished init or meta data update for `results-2020-04-08-01H-16M-48S`. MainProcess pypet.environment.Environment INFO ************************************************************ FINISHED all runs of trajectory `results-2020-04-08-01H-16M-48S`. ************************************************************ MainProcess pypet.environment.Environment INFO ************************************************************ STARTING FINAL STORING of trajectory `results-2020-04-08-01H-16M-48S` ************************************************************ MainProcess pypet.storageservice.HDF5StorageService INFO Start storing Trajectory `results-2020-04-08-01H-16M-48S`. MainProcess pypet.storageservice.HDF5StorageService INFO Storing branch `config`. /home/cakan/anaconda/lib/python3.7/site-packages/pypet/storageservice.py:4597: FutureWarning: Conversion of the second argument of issubdtype from `str` to `str` is deprecated. In future, it will be treated as `np.str_ == np.dtype(str).type`. if (np.issubdtype(val.dtype, str) or /home/cakan/anaconda/lib/python3.7/site-packages/pypet/storageservice.py:4598: FutureWarning: Conversion of the second argument of issubdtype from `bytes` to `bytes` is deprecated. In future, it will be treated as `np.bytes_ == np.dtype(bytes).type`. np.issubdtype(val.dtype, bytes)): MainProcess pypet.storageservice.HDF5StorageService INFO Storing branch `parameters`. /home/cakan/anaconda/lib/python3.7/site-packages/pypet/storageservice.py:3110: FutureWarning: Conversion of the second argument of issubdtype from `str` to `str` is deprecated. In future, it will be treated as `np.str_ == np.dtype(str).type`. np.issubdtype(data.dtype, str)): MainProcess pypet.storageservice.HDF5StorageService INFO Finished storing Trajectory `results-2020-04-08-01H-16M-48S`. MainProcess pypet.environment.Environment INFO ************************************************************ FINISHED FINAL STORING of trajectory `results-2020-04-08-01H-16M-48S`. ************************************************************ MainProcess pypet.environment.Environment INFO All runs of trajectory `results-2020-04-08-01H-16M-48S` were completed successfully. Load data search . loadResults () print ( \"Number of results: {} \" . format ( len ( search . results ))) MainProcess root INFO Loading results from /mnt/raid/data/cakan/hdf/example-1.2.1.hdf /mnt/antares_raid/home/cakan/projects/neurolib/neurolib/utils/pypetUtils.py:21: H5pyDeprecationWarning: The default file mode will change to 'r' (read-only) in h5py 3.0. To suppress this warning, pass the mode you need to h5py.File(), or set the global default h5.get_config().default_file_mode, or set the environment variable H5PY_DEFAULT_READONLY=1. Available modes are: 'r', 'r+', 'w', 'w-'/'x', 'a'. See the docs for details. hdf = h5py.File(filename) MainProcess root INFO Analyzing trajectory results-2020-04-08-01H-16M-48S MainProcess pypet.storageservice.HDF5StorageService INFO I will use the hdf5 file `/mnt/raid/data/cakan/hdf/example-1.2.1.hdf`. MainProcess pypet.storageservice.HDF5StorageService INFO Loading trajectory `results-2020-04-08-01H-16M-48S`. MainProcess pypet.storageservice.HDF5StorageService INFO Loading branch `config` in mode `2`. MainProcess pypet.storageservice.HDF5StorageService INFO Loading branch `parameters` in mode `2`. MainProcess pypet.storageservice.HDF5StorageService INFO Loading branch `results` in mode `1`. MainProcess root INFO Creating pandas dataframe ... MainProcess root INFO Creating results dictionary ... 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 4/4 [00:00<00:00, 219.06it/s] MainProcess root INFO All results loaded. Number of results: 4 for i in search . dfResults . index : search . dfResults . loc [ i , 'bold_cc' ] = np . mean ( search . results [ i ][ 'fc' ]) search . dfResults .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } mue_ext_mean mui_ext_mean bold_cc 0 0.0 0.0 0.174085 1 0.0 0.1 0.113122 2 0.0 0.2 0.488884 3 0.0 0.3 0.000000 4 0.0 0.4 0.000000 ... ... ... ... 956 3.0 2.6 -0.223068 957 3.0 2.7 -0.220481 958 3.0 2.8 -0.232276 959 3.0 2.9 -0.182681 960 3.0 3.0 -0.228365 961 rows \u00d7 3 columns Plot plt . figure ( dpi = 150 ) plt . imshow ( search . dfResults . pivot_table ( values = 'bold_cc' , index = 'mui_ext_mean' , columns = 'mue_ext_mean' ), \\ extent = [ min ( search . dfResults . mue_ext_mean ), max ( search . dfResults . mue_ext_mean ), min ( search . dfResults . mui_ext_mean ), max ( search . dfResults . mui_ext_mean )], origin = 'lower' ) plt . colorbar ( label = 'Mean correlation to empirical rs-FC' ) plt . xlabel ( \"Input to E\" ) plt . ylabel ( \"Input to I\" ) Text(0, 0.5, 'Input to I')","title":"Example 1.2.1 brain exploration postprocessing"},{"location":"examples/example-1.2.1-brain-exploration-postprocessing/#parameter-exploration-with-custom-run-function-and-postprocessing","text":"This notebook demonstrates how to scan the parameter space of a brain network model using neurolib with a custom evaluation function to quickly find regions of interest. The evaluation function is designed to increase the speed for the exploration by focussing on regions where the simulated dynamics meets certain criteria. For this, the simulation is run in multiple, successive steps, that increase in duration.","title":"Parameter exploration with custom run function and postprocessing"},{"location":"examples/example-1.2.1-brain-exploration-postprocessing/#iterative-evaluation","text":"The evaluation of a simulation takes multiple steps: Step 1 runs for a few seconds and checks if there is any rate activity at all Step 2 runs a bit longer and checks if there is any BOLD activity Step 3 runs the full simulation","title":"Iterative evaluation"},{"location":"examples/example-1.2.1-brain-exploration-postprocessing/#postprocessing","text":"In this scenario, we want to postprocess the simulated data as soon as the simulation is done and before writing the results to the hard disk. After the full simulation is run, the funciotnal connectivity (FC) of the BOLD signal is computed and compared to the empirical FC dataset. The Pearson correlation of the FC matrices is computed and the average is taken. We then tell pypet to save these postprocessed results along with the model output. #hide # change to the root directory of the project import os if os . getcwd () . split ( \"/\" )[ - 1 ] == \"examples\" : os . chdir ( '..' ) # This will reload all imports as soon as the code changes % load_ext autoreload % autoreload 2 #hide try : import matplotlib.pyplot as plt except ImportError : import sys ! { sys . executable } - m pip install matplotlib import matplotlib.pyplot as plt # a nice color map plt . rcParams [ 'image.cmap' ] = 'plasma' import numpy as np from neurolib.models.aln import ALNModel from neurolib.utils.parameterSpace import ParameterSpace from neurolib.optimize.exploration import BoxSearch import neurolib.utils.functions as func from neurolib.utils.loadData import Dataset ds = Dataset ( \"hcp\" )","title":"Postprocessing"},{"location":"examples/example-1.2.1-brain-exploration-postprocessing/#set-up-model","text":"model = ALNModel ( Cmat = ds . Cmat , Dmat = ds . Dmat ) # simulates the whole-brain model in 10s chunks by default if bold == True # Resting state fits model . params [ 'mue_ext_mean' ] = 1.57 model . params [ 'mui_ext_mean' ] = 1.6 #model.params['sigma_ou'] = 0.09 model . params [ 'b' ] = 5.0 model . params [ 'dt' ] = 0.2 model . params [ 'duration' ] = 0.2 * 1000 #ms # testing: model.params['duration'] = 0.2 * 60 * 1000 #ms # real: model.params['duration'] = 1.0 * 60 * 1000 #ms MainProcess root INFO aln: Model initialized.","title":"Set up model"},{"location":"examples/example-1.2.1-brain-exploration-postprocessing/#define-evaluation-function","text":"def evaluateSimulation ( traj ): # get the model from the trajectory using `search.getModelFromTraj(traj)` model = search . getModelFromTraj ( traj ) # initiate the model with random initial contitions model . randomICs () defaultDuration = model . params [ 'duration' ] invalid_result = { \"fc\" : np . nan , \"fcd\" : np . nan } # -------- STAGEWISE EVALUATION -------- stagewise = True if stagewise : # -------- stage wise simulation -------- # Stage 1 : simulate for a few seconds to see if there is any activity # --------------------------------------- model . params [ 'duration' ] = 3 * 1000. model . run () # check if stage 1 was successful amplitude = np . max ( model . output [:, model . t > 500 ]) - np . min ( model . output [:, model . t > 500 ]) if amplitude < 0.05 : search . saveToPypet ( invalid_result , traj ) return invalid_result , {} # Stage 2: simulate BOLD for a few seconds to see if it moves # --------------------------------------- model . params [ 'duration' ] = 30 * 1000. model . run ( chunkwise = True , bold = True ) if np . max ( np . std ( model . outputs . BOLD . BOLD [:, 10 : 15 ], axis = 1 )) < 1e-5 : search . saveToPypet ( invalid_result , traj ) return invalid_result , {} # Stage 3: full and final simulation # --------------------------------------- model . params [ 'duration' ] = defaultDuration model . run ( chunkwise = True , bold = True ) # -------- POSTPROCESSING -------- # FC matrix correlation to all subject rs-fMRI BOLD_TRANSIENT = 10000 fc_score = np . mean ([ func . matrix_correlation ( func . fc ( model . BOLD . BOLD [:, model . BOLD . t_BOLD > BOLD_TRANSIENT ]), fc ) for fc in ds . FCs ]) # FCD to all subject rs-fMRI try : fcd_score = np . mean ([ func . ts_kolmogorov ( model . BOLD . BOLD [:, model . BOLD . t_BOLD > BOLD_TRANSIENT ], ds . BOLDs [ i ]) for i in range ( len ( ds . BOLDs ))]) except : fcd_score = np . nan # let's build the results dictionary result_dict = { \"fc\" : fc_score , \"fcd\" : fcd_score } # we could also save the output of the model by adding to the results_dict like this: # result_dict = {\"fc\" : fc_score, \"fcd\" : fcd_score, \"outputs\" : model.outputs} # Save the results to pypet. # Remember: This has to be dictionary! search . saveToPypet ( result_dict , traj )","title":"Define evaluation function"},{"location":"examples/example-1.2.1-brain-exploration-postprocessing/#set-up-parameter-exploration","text":"parameters = ParameterSpace ({ \"mue_ext_mean\" : np . linspace ( 0 , 3.0 , 2 ), \"mui_ext_mean\" : np . linspace ( 0.2 , 3.0 , 2 )}) # info: chose np.linspace(0, 3, 21) or more, values here are low for testing search = BoxSearch ( evalFunction = evaluateSimulation , model = model , parameterSpace = parameters , filename = \"example-1.2.1.hdf\" ) MainProcess root INFO Number of processes: 80 MainProcess pypet.storageservice.HDF5StorageService INFO I will use the hdf5 file `/mnt/raid/data/cakan/hdf/example-1.2.1.hdf`. MainProcess pypet.environment.Environment INFO Environment initialized. /home/cakan/anaconda/lib/python3.7/site-packages/pypet/parameter.py:884: FutureWarning: Conversion of the second argument of issubdtype from `str` to `str` is deprecated. In future, it will be treated as `np.str_ == np.dtype(str).type`. if np.issubdtype(dtype, np.str): MainProcess root INFO Number of parameter configurations: 4 MainProcess root INFO BoxSearch: Environment initialized. search . run () MainProcess pypet.environment.Environment INFO I am preparing the Trajectory for the experiment and initialise the store. MainProcess pypet.environment.Environment INFO Initialising the storage for the trajectory. MainProcess pypet.storageservice.HDF5StorageService INFO Initialising storage or updating meta data of Trajectory `results-2020-04-08-01H-16M-48S`. MainProcess pypet.storageservice.HDF5StorageService INFO Finished init or meta data update for `results-2020-04-08-01H-16M-48S`. MainProcess pypet.environment.Environment INFO ************************************************************ STARTING runs of trajectory `results-2020-04-08-01H-16M-48S`. ************************************************************ MainProcess pypet.storageservice.HDF5StorageService INFO Initialising storage or updating meta data of Trajectory `results-2020-04-08-01H-16M-48S`. MainProcess pypet.storageservice.HDF5StorageService INFO Finished init or meta data update for `results-2020-04-08-01H-16M-48S`. MainProcess pypet.environment.Environment INFO Starting multiprocessing with at most 80 processes running at the same time. MainProcess pypet INFO PROGRESS: Finished 0/4 runs [ ] 0.0% MainProcess pypet INFO PROGRESS: Finished 1/4 runs [===== ] 25.0%, remaining: 0:00:02 MainProcess pypet INFO PROGRESS: Finished 2/4 runs [========== ] 50.0%, remaining: 0:00:00 MainProcess pypet INFO PROGRESS: Finished 3/4 runs [=============== ] 75.0%, remaining: 0:00:09 MainProcess pypet INFO PROGRESS: Finished 4/4 runs [====================]100.0% MainProcess pypet.storageservice.HDF5StorageService INFO Initialising storage or updating meta data of Trajectory `results-2020-04-08-01H-16M-48S`. MainProcess pypet.storageservice.HDF5StorageService INFO Finished init or meta data update for `results-2020-04-08-01H-16M-48S`. MainProcess pypet.environment.Environment INFO ************************************************************ FINISHED all runs of trajectory `results-2020-04-08-01H-16M-48S`. ************************************************************ MainProcess pypet.environment.Environment INFO ************************************************************ STARTING FINAL STORING of trajectory `results-2020-04-08-01H-16M-48S` ************************************************************ MainProcess pypet.storageservice.HDF5StorageService INFO Start storing Trajectory `results-2020-04-08-01H-16M-48S`. MainProcess pypet.storageservice.HDF5StorageService INFO Storing branch `config`. /home/cakan/anaconda/lib/python3.7/site-packages/pypet/storageservice.py:4597: FutureWarning: Conversion of the second argument of issubdtype from `str` to `str` is deprecated. In future, it will be treated as `np.str_ == np.dtype(str).type`. if (np.issubdtype(val.dtype, str) or /home/cakan/anaconda/lib/python3.7/site-packages/pypet/storageservice.py:4598: FutureWarning: Conversion of the second argument of issubdtype from `bytes` to `bytes` is deprecated. In future, it will be treated as `np.bytes_ == np.dtype(bytes).type`. np.issubdtype(val.dtype, bytes)): MainProcess pypet.storageservice.HDF5StorageService INFO Storing branch `parameters`. /home/cakan/anaconda/lib/python3.7/site-packages/pypet/storageservice.py:3110: FutureWarning: Conversion of the second argument of issubdtype from `str` to `str` is deprecated. In future, it will be treated as `np.str_ == np.dtype(str).type`. np.issubdtype(data.dtype, str)): MainProcess pypet.storageservice.HDF5StorageService INFO Finished storing Trajectory `results-2020-04-08-01H-16M-48S`. MainProcess pypet.environment.Environment INFO ************************************************************ FINISHED FINAL STORING of trajectory `results-2020-04-08-01H-16M-48S`. ************************************************************ MainProcess pypet.environment.Environment INFO All runs of trajectory `results-2020-04-08-01H-16M-48S` were completed successfully.","title":"Set up parameter exploration"},{"location":"examples/example-1.2.1-brain-exploration-postprocessing/#load-data","text":"search . loadResults () print ( \"Number of results: {} \" . format ( len ( search . results ))) MainProcess root INFO Loading results from /mnt/raid/data/cakan/hdf/example-1.2.1.hdf /mnt/antares_raid/home/cakan/projects/neurolib/neurolib/utils/pypetUtils.py:21: H5pyDeprecationWarning: The default file mode will change to 'r' (read-only) in h5py 3.0. To suppress this warning, pass the mode you need to h5py.File(), or set the global default h5.get_config().default_file_mode, or set the environment variable H5PY_DEFAULT_READONLY=1. Available modes are: 'r', 'r+', 'w', 'w-'/'x', 'a'. See the docs for details. hdf = h5py.File(filename) MainProcess root INFO Analyzing trajectory results-2020-04-08-01H-16M-48S MainProcess pypet.storageservice.HDF5StorageService INFO I will use the hdf5 file `/mnt/raid/data/cakan/hdf/example-1.2.1.hdf`. MainProcess pypet.storageservice.HDF5StorageService INFO Loading trajectory `results-2020-04-08-01H-16M-48S`. MainProcess pypet.storageservice.HDF5StorageService INFO Loading branch `config` in mode `2`. MainProcess pypet.storageservice.HDF5StorageService INFO Loading branch `parameters` in mode `2`. MainProcess pypet.storageservice.HDF5StorageService INFO Loading branch `results` in mode `1`. MainProcess root INFO Creating pandas dataframe ... MainProcess root INFO Creating results dictionary ... 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 4/4 [00:00<00:00, 219.06it/s] MainProcess root INFO All results loaded. Number of results: 4 for i in search . dfResults . index : search . dfResults . loc [ i , 'bold_cc' ] = np . mean ( search . results [ i ][ 'fc' ]) search . dfResults .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } mue_ext_mean mui_ext_mean bold_cc 0 0.0 0.0 0.174085 1 0.0 0.1 0.113122 2 0.0 0.2 0.488884 3 0.0 0.3 0.000000 4 0.0 0.4 0.000000 ... ... ... ... 956 3.0 2.6 -0.223068 957 3.0 2.7 -0.220481 958 3.0 2.8 -0.232276 959 3.0 2.9 -0.182681 960 3.0 3.0 -0.228365 961 rows \u00d7 3 columns","title":"Load data"},{"location":"examples/example-1.2.1-brain-exploration-postprocessing/#plot","text":"plt . figure ( dpi = 150 ) plt . imshow ( search . dfResults . pivot_table ( values = 'bold_cc' , index = 'mui_ext_mean' , columns = 'mue_ext_mean' ), \\ extent = [ min ( search . dfResults . mue_ext_mean ), max ( search . dfResults . mue_ext_mean ), min ( search . dfResults . mui_ext_mean ), max ( search . dfResults . mui_ext_mean )], origin = 'lower' ) plt . colorbar ( label = 'Mean correlation to empirical rs-FC' ) plt . xlabel ( \"Input to E\" ) plt . ylabel ( \"Input to I\" ) Text(0, 0.5, 'Input to I')","title":"Plot"},{"location":"examples/example-1.3-aln-bifurcation-diagram/","text":"(function() { function addWidgetsRenderer() { var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var scriptElement = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} scriptElement.src = widgetRendererSrc; document.body.appendChild(scriptElement); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); Bifurcation diagram of the aln model In this notebook, we will discover how easy it is to draw bifurcation diagrams in neurolib using its powerful BoxSearch class. Bifurcation diagrams are an important tool to understand a dynamical system, may it be a single neuron model or a whole-brain network. They show how a system behaves when certain parameters of the model are changed: whether the system transitions into an oscillation for example, or whethter the system remains in a fixed point (of sustained constant activity). We will use this to draw a map of the aln model: Since the aln model consists of two populations of Adex neurons, we will change its inputs to the excitatory and to the inhibitory population independently and do so for two different values of spike-frequency adaptation strength \\(b\\) . We will measure the activity of the system and identify regions of oscillatory activity and discover bistable states, in which the system can be in two different stable states for the same set of parameters. # change into the root directory of the project import os if os . getcwd () . split ( \"/\" )[ - 1 ] == \"examples\" : os . chdir ( '..' ) import logging logger = logging . getLogger () import warnings warnings . filterwarnings ( \"ignore\" ) #logger.setLevel(logging.DEBUG) #logging.disable(logging.WARNING) #logging.disable(logging.WARN) % load_ext autoreload % autoreload 2 import numpy as np import matplotlib.pyplot as plt from neurolib.models.aln import ALNModel from neurolib.utils.parameterSpace import ParameterSpace from neurolib.optimize.exploration import BoxSearch import neurolib.utils.functions as func import neurolib.utils.stimulus as stim import neurolib.optimize.exploration.explorationUtils as eu import neurolib.utils.devutils as du from neurolib.utils.loadData import Dataset plt . style . use ( \"seaborn-white\" ) plt . rcParams [ 'image.cmap' ] = 'plasma' Create the model model = ALNModel () model . params [ 'dt' ] = 0.1 # Integration time step, ms model . params [ 'duration' ] = 20 * 1000 # Simulation time, ms model . params [ 'save_dt' ] = 10.0 # 10 ms sampling steps for saving data, should be multiple of dt model . params [ \"tauA\" ] = 600.0 # Adaptation timescale, ms Measuring bistability The aln model has a region of bistability, in which two states are stable at the same time: the low-activity down-state , and the high-activity up-state . We can find these states by constructing a stimulus, which uncovers the bistable nature of the system: Initially, we apply a negative push to the system, to make sure that it is in the down-state . We then relax this stimulus slowly and wait for the system to settle. We then apply a sharp push in order to reach the up-state and release the stimulus slowly back again. The difference of the two states after the stimulus has relaxed back to zero is a sign for bistability. # we place the system in the bistable region model . params [ 'mue_ext_mean' ] = 2.5 model . params [ 'mui_ext_mean' ] = 2.5 # construct a stimulus rect_stimulus = stim . construct_stimulus ( stim = \"rect\" , duration = model . params . duration , dt = model . params . dt ) model . params [ 'ext_exc_current' ] = rect_stimulus * 5.0 model . run () plt . figure ( figsize = ( 5 , 3 ), dpi = 150 ) plt . plot ( model . t , model . output . T , lw = 3 , c = 'k' , label = 'rate' ) plt . plot ( model . t , rect_stimulus * 100 , lw = 3 , c = 'r' , label = \"stimulus\" ) plt . text ( 3000 , 7 , 'down-state' , fontsize = 16 ) plt . text ( 15000 , 35 , 'up-state' , fontsize = 16 ) plt . legend ( fontsize = 14 ) plt . xlim ( 1 , model . t [ - 1 ]) plt . xlabel ( \"Time [ms]\" ) plt . ylabel ( \"Activity [Hz]\" ) Text(0, 0.5, 'Activity [Hz]') Define evaluation function Let's construct a rather lengthy evaluation function which does exactly that, for every parameter configuration that we want to explore. We will also measure other things like the dominant frequency and amplitude of oscillations and the maximum rate of the excitatory population. def evaluateSimulation ( traj ): # get the model from the trajectory using `search.getModelFromTraj(traj)` model = search . getModelFromTraj ( traj ) # initiate the model with random initial contitions model . randomICs () defaultDuration = model . params [ 'duration' ] # -------- stage wise simulation -------- # Stage 3: full and final simulation # --------------------------------------- model . params [ 'duration' ] = defaultDuration rect_stimulus = stim . construct_stimulus ( stim = \"rect\" , duration = model . params . duration , dt = model . params . dt ) model . params [ 'ext_exc_current' ] = rect_stimulus * 5.0 model . run () # up down difference state_length = 2000 last_state = ( model . t > defaultDuration - state_length ) down_window = ( defaultDuration / 2 - state_length < model . t ) & ( model . t < defaultDuration / 2 ) # time period in ms where we expect the down-state up_window = ( defaultDuration - state_length < model . t ) & ( model . t < defaultDuration ) # and up state up_state_rate = np . mean ( model . output [:, up_window ], axis = 1 ) down_state_rate = np . mean ( model . output [:, down_window ], axis = 1 ) up_down_difference = np . max ( up_state_rate - down_state_rate ) # check rates! max_amp_output = np . max ( np . max ( model . output [:, up_window ], axis = 1 ) - np . min ( model . output [:, up_window ], axis = 1 ) ) max_output = np . max ( model . output [:, up_window ]) model_frs , model_pwrs = func . getMeanPowerSpectrum ( model . output , dt = model . params . dt , maxfr = 40 , spectrum_windowsize = 10 ) max_power = np . max ( model_pwrs ) model_frs , model_pwrs = func . getMeanPowerSpectrum ( model . output [:, up_window ], dt = model . params . dt , maxfr = 40 , spectrum_windowsize = 5 ) domfr = model_frs [ np . argmax ( model_pwrs )] result = { \"end\" : 3 , \"max_output\" : max_output , \"max_amp_output\" : max_amp_output , \"max_power\" : max_power , #\"model_pwrs\" : model_pwrs, #\"output\": model.output[:, ::int(model.params['save_dt']/model.params['dt'])], \"domfr\" : domfr , \"up_down_difference\" : up_down_difference } search . saveToPypet ( result , traj ) return Let's now define the parameter space over which we want to serach. We apply a grid search over the mean external input parameters to the excitatory and the inhibitory population mue_ext_mean / mui_ext_mean and do this for two values of spike-frequency adapation strength \\(b\\) , once without and once with adaptation. Exploration parameters # low number of parameters for testing: parameters = ParameterSpace ({ \"mue_ext_mean\" : np . linspace ( 0.0 , 4 , 2 ), \"mui_ext_mean\" : np . linspace ( 0.0 , 4 , 2 ), \"b\" : [ 0.0 , 20.0 ] }) # real: # parameters = ParameterSpace({\"mue_ext_mean\": np.linspace(0.0, 4, 41), # \"mui_ext_mean\": np.linspace(0.0, 4, 41), # \"b\": [0.0, 20.0] # }) search = BoxSearch ( evalFunction = evaluateSimulation , model = model , parameterSpace = parameters , filename = 'example-1.3-aln-bifurcation-diagram.hdf' ) Run search . run () Analysis search . loadResults ( all = False ) The results dataframe search . dfResults .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } mue_ext_mean mui_ext_mean b up_down_difference max_power max_output max_amp_output end domfr 0 0.0 0.0 0.0 0.000019 17.667024 0.038741 1.804112e-16 3.0 0.500025 1 0.0 0.0 20.0 0.000009 5.151867 0.037037 2.042227e-05 3.0 0.500025 2 0.0 0.1 0.0 0.000010 15.442743 0.024629 5.898060e-17 3.0 0.500025 3 0.0 0.1 20.0 0.000006 4.140367 0.024062 8.806702e-06 3.0 0.500025 4 0.0 0.2 0.0 0.000006 12.466959 0.012277 6.938894e-17 3.0 0.500025 ... ... ... ... ... ... ... ... ... ... 3357 4.0 3.8 20.0 0.000038 16.457953 29.965853 1.262658e-06 3.0 0.000000 3358 4.0 3.9 0.0 0.000674 137.416613 93.451476 0.000000e+00 3.0 0.000000 3359 4.0 3.9 20.0 0.000038 16.510310 29.928097 1.242441e-06 3.0 0.000000 3360 4.0 4.0 0.0 0.000674 138.075857 93.380582 0.000000e+00 3.0 0.000000 3361 4.0 4.0 20.0 0.000038 16.558048 29.891972 1.223808e-06 3.0 0.000000 3362 rows \u00d7 9 columns Plotting 2D bifurcation diagrams Let's draw the bifurcation diagrams. We will use a white contour for oscillatory areas (measured by max_amp_output ) and a green dashed lined for the bistable region (measured by up_down_difference ). We can use the function explorationUtils.plotExplorationResults() for this. plot_key_label = \"Max. $r_E$\" eu . plotExplorationResults ( search . dfResults , par1 = [ 'mue_ext_mean' , '$\\mu_e$' ], par2 = [ 'mui_ext_mean' , '$\\mu_i$' ], by = [ 'b' ], plot_key = 'max_output' , plot_clim = [ 0.0 , 80.0 ], nan_to_zero = False , plot_key_label = plot_key_label , one_figure = False , contour = [ \"max_amp_output\" , \"up_down_difference\" ], contour_color = [[ 'white' ], [ 'springgreen' ]], contour_levels = [[ 10 ], [ 10 ]], contour_alpha = [ 1.0 , 1.0 ], contour_kwargs = { 0 : { \"linewidths\" : ( 5 ,)}, 1 : { \"linestyles\" : \"--\" , \"linewidths\" : ( 5 ,)}}, #alpha_mask=\"relative_amplitude_BOLD\", mask_threshold = 0.1 , mask_alpha = 0.2 )","title":"Example 1.3 aln bifurcation diagram"},{"location":"examples/example-1.3-aln-bifurcation-diagram/#bifurcation-diagram-of-the-aln-model","text":"In this notebook, we will discover how easy it is to draw bifurcation diagrams in neurolib using its powerful BoxSearch class. Bifurcation diagrams are an important tool to understand a dynamical system, may it be a single neuron model or a whole-brain network. They show how a system behaves when certain parameters of the model are changed: whether the system transitions into an oscillation for example, or whethter the system remains in a fixed point (of sustained constant activity). We will use this to draw a map of the aln model: Since the aln model consists of two populations of Adex neurons, we will change its inputs to the excitatory and to the inhibitory population independently and do so for two different values of spike-frequency adaptation strength \\(b\\) . We will measure the activity of the system and identify regions of oscillatory activity and discover bistable states, in which the system can be in two different stable states for the same set of parameters. # change into the root directory of the project import os if os . getcwd () . split ( \"/\" )[ - 1 ] == \"examples\" : os . chdir ( '..' ) import logging logger = logging . getLogger () import warnings warnings . filterwarnings ( \"ignore\" ) #logger.setLevel(logging.DEBUG) #logging.disable(logging.WARNING) #logging.disable(logging.WARN) % load_ext autoreload % autoreload 2 import numpy as np import matplotlib.pyplot as plt from neurolib.models.aln import ALNModel from neurolib.utils.parameterSpace import ParameterSpace from neurolib.optimize.exploration import BoxSearch import neurolib.utils.functions as func import neurolib.utils.stimulus as stim import neurolib.optimize.exploration.explorationUtils as eu import neurolib.utils.devutils as du from neurolib.utils.loadData import Dataset plt . style . use ( \"seaborn-white\" ) plt . rcParams [ 'image.cmap' ] = 'plasma'","title":"Bifurcation diagram of the aln model"},{"location":"examples/example-1.3-aln-bifurcation-diagram/#create-the-model","text":"model = ALNModel () model . params [ 'dt' ] = 0.1 # Integration time step, ms model . params [ 'duration' ] = 20 * 1000 # Simulation time, ms model . params [ 'save_dt' ] = 10.0 # 10 ms sampling steps for saving data, should be multiple of dt model . params [ \"tauA\" ] = 600.0 # Adaptation timescale, ms","title":"Create the model"},{"location":"examples/example-1.3-aln-bifurcation-diagram/#measuring-bistability","text":"The aln model has a region of bistability, in which two states are stable at the same time: the low-activity down-state , and the high-activity up-state . We can find these states by constructing a stimulus, which uncovers the bistable nature of the system: Initially, we apply a negative push to the system, to make sure that it is in the down-state . We then relax this stimulus slowly and wait for the system to settle. We then apply a sharp push in order to reach the up-state and release the stimulus slowly back again. The difference of the two states after the stimulus has relaxed back to zero is a sign for bistability. # we place the system in the bistable region model . params [ 'mue_ext_mean' ] = 2.5 model . params [ 'mui_ext_mean' ] = 2.5 # construct a stimulus rect_stimulus = stim . construct_stimulus ( stim = \"rect\" , duration = model . params . duration , dt = model . params . dt ) model . params [ 'ext_exc_current' ] = rect_stimulus * 5.0 model . run () plt . figure ( figsize = ( 5 , 3 ), dpi = 150 ) plt . plot ( model . t , model . output . T , lw = 3 , c = 'k' , label = 'rate' ) plt . plot ( model . t , rect_stimulus * 100 , lw = 3 , c = 'r' , label = \"stimulus\" ) plt . text ( 3000 , 7 , 'down-state' , fontsize = 16 ) plt . text ( 15000 , 35 , 'up-state' , fontsize = 16 ) plt . legend ( fontsize = 14 ) plt . xlim ( 1 , model . t [ - 1 ]) plt . xlabel ( \"Time [ms]\" ) plt . ylabel ( \"Activity [Hz]\" ) Text(0, 0.5, 'Activity [Hz]')","title":"Measuring bistability"},{"location":"examples/example-1.3-aln-bifurcation-diagram/#define-evaluation-function","text":"Let's construct a rather lengthy evaluation function which does exactly that, for every parameter configuration that we want to explore. We will also measure other things like the dominant frequency and amplitude of oscillations and the maximum rate of the excitatory population. def evaluateSimulation ( traj ): # get the model from the trajectory using `search.getModelFromTraj(traj)` model = search . getModelFromTraj ( traj ) # initiate the model with random initial contitions model . randomICs () defaultDuration = model . params [ 'duration' ] # -------- stage wise simulation -------- # Stage 3: full and final simulation # --------------------------------------- model . params [ 'duration' ] = defaultDuration rect_stimulus = stim . construct_stimulus ( stim = \"rect\" , duration = model . params . duration , dt = model . params . dt ) model . params [ 'ext_exc_current' ] = rect_stimulus * 5.0 model . run () # up down difference state_length = 2000 last_state = ( model . t > defaultDuration - state_length ) down_window = ( defaultDuration / 2 - state_length < model . t ) & ( model . t < defaultDuration / 2 ) # time period in ms where we expect the down-state up_window = ( defaultDuration - state_length < model . t ) & ( model . t < defaultDuration ) # and up state up_state_rate = np . mean ( model . output [:, up_window ], axis = 1 ) down_state_rate = np . mean ( model . output [:, down_window ], axis = 1 ) up_down_difference = np . max ( up_state_rate - down_state_rate ) # check rates! max_amp_output = np . max ( np . max ( model . output [:, up_window ], axis = 1 ) - np . min ( model . output [:, up_window ], axis = 1 ) ) max_output = np . max ( model . output [:, up_window ]) model_frs , model_pwrs = func . getMeanPowerSpectrum ( model . output , dt = model . params . dt , maxfr = 40 , spectrum_windowsize = 10 ) max_power = np . max ( model_pwrs ) model_frs , model_pwrs = func . getMeanPowerSpectrum ( model . output [:, up_window ], dt = model . params . dt , maxfr = 40 , spectrum_windowsize = 5 ) domfr = model_frs [ np . argmax ( model_pwrs )] result = { \"end\" : 3 , \"max_output\" : max_output , \"max_amp_output\" : max_amp_output , \"max_power\" : max_power , #\"model_pwrs\" : model_pwrs, #\"output\": model.output[:, ::int(model.params['save_dt']/model.params['dt'])], \"domfr\" : domfr , \"up_down_difference\" : up_down_difference } search . saveToPypet ( result , traj ) return Let's now define the parameter space over which we want to serach. We apply a grid search over the mean external input parameters to the excitatory and the inhibitory population mue_ext_mean / mui_ext_mean and do this for two values of spike-frequency adapation strength \\(b\\) , once without and once with adaptation.","title":"Define evaluation function"},{"location":"examples/example-1.3-aln-bifurcation-diagram/#exploration-parameters","text":"# low number of parameters for testing: parameters = ParameterSpace ({ \"mue_ext_mean\" : np . linspace ( 0.0 , 4 , 2 ), \"mui_ext_mean\" : np . linspace ( 0.0 , 4 , 2 ), \"b\" : [ 0.0 , 20.0 ] }) # real: # parameters = ParameterSpace({\"mue_ext_mean\": np.linspace(0.0, 4, 41), # \"mui_ext_mean\": np.linspace(0.0, 4, 41), # \"b\": [0.0, 20.0] # }) search = BoxSearch ( evalFunction = evaluateSimulation , model = model , parameterSpace = parameters , filename = 'example-1.3-aln-bifurcation-diagram.hdf' )","title":"Exploration parameters"},{"location":"examples/example-1.3-aln-bifurcation-diagram/#run","text":"search . run ()","title":"Run"},{"location":"examples/example-1.3-aln-bifurcation-diagram/#analysis","text":"search . loadResults ( all = False )","title":"Analysis"},{"location":"examples/example-1.3-aln-bifurcation-diagram/#the-results-dataframe","text":"search . dfResults .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } mue_ext_mean mui_ext_mean b up_down_difference max_power max_output max_amp_output end domfr 0 0.0 0.0 0.0 0.000019 17.667024 0.038741 1.804112e-16 3.0 0.500025 1 0.0 0.0 20.0 0.000009 5.151867 0.037037 2.042227e-05 3.0 0.500025 2 0.0 0.1 0.0 0.000010 15.442743 0.024629 5.898060e-17 3.0 0.500025 3 0.0 0.1 20.0 0.000006 4.140367 0.024062 8.806702e-06 3.0 0.500025 4 0.0 0.2 0.0 0.000006 12.466959 0.012277 6.938894e-17 3.0 0.500025 ... ... ... ... ... ... ... ... ... ... 3357 4.0 3.8 20.0 0.000038 16.457953 29.965853 1.262658e-06 3.0 0.000000 3358 4.0 3.9 0.0 0.000674 137.416613 93.451476 0.000000e+00 3.0 0.000000 3359 4.0 3.9 20.0 0.000038 16.510310 29.928097 1.242441e-06 3.0 0.000000 3360 4.0 4.0 0.0 0.000674 138.075857 93.380582 0.000000e+00 3.0 0.000000 3361 4.0 4.0 20.0 0.000038 16.558048 29.891972 1.223808e-06 3.0 0.000000 3362 rows \u00d7 9 columns","title":"The results dataframe"},{"location":"examples/example-1.3-aln-bifurcation-diagram/#plotting-2d-bifurcation-diagrams","text":"Let's draw the bifurcation diagrams. We will use a white contour for oscillatory areas (measured by max_amp_output ) and a green dashed lined for the bistable region (measured by up_down_difference ). We can use the function explorationUtils.plotExplorationResults() for this. plot_key_label = \"Max. $r_E$\" eu . plotExplorationResults ( search . dfResults , par1 = [ 'mue_ext_mean' , '$\\mu_e$' ], par2 = [ 'mui_ext_mean' , '$\\mu_i$' ], by = [ 'b' ], plot_key = 'max_output' , plot_clim = [ 0.0 , 80.0 ], nan_to_zero = False , plot_key_label = plot_key_label , one_figure = False , contour = [ \"max_amp_output\" , \"up_down_difference\" ], contour_color = [[ 'white' ], [ 'springgreen' ]], contour_levels = [[ 10 ], [ 10 ]], contour_alpha = [ 1.0 , 1.0 ], contour_kwargs = { 0 : { \"linewidths\" : ( 5 ,)}, 1 : { \"linestyles\" : \"--\" , \"linewidths\" : ( 5 ,)}}, #alpha_mask=\"relative_amplitude_BOLD\", mask_threshold = 0.1 , mask_alpha = 0.2 )","title":"Plotting 2D bifurcation diagrams"},{"location":"examples/example-2-evolutionary-optimization-minimal/","text":"(function() { function addWidgetsRenderer() { var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var scriptElement = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} scriptElement.src = widgetRendererSrc; document.body.appendChild(scriptElement); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); Simple example of the evolutionary optimization framework This notebook provides a simple example for the use of the evolutionary optimization framework builtin to the library. Under the hood, the implementation of the evolutionary algorithm is powered by deap and pypet cares about the parallelization and storage of the simulation data for us. Here we demonstrate how to fit parameters of a the evaluation function optimize_me which simply computes the distance of the parameters to the unit circle and returns this as the fitness_tuple that DEAP expects. # change to the root directory of the project import os if os . getcwd () . split ( \"/\" )[ - 1 ] == \"examples\" : os . chdir ( '..' ) # This will reload all imports as soon as the code changes % load_ext autoreload % autoreload 2 try : import matplotlib.pyplot as plt except ImportError : import sys ! { sys . executable } - m pip install matplotlib seaborn import matplotlib.pyplot as plt import numpy as np import logging from neurolib.utils.parameterSpace import ParameterSpace from neurolib.optimize.evolution import Evolution import neurolib.optimize.evolution.evolutionaryUtils as eu import neurolib.utils.functions as func def optimize_me ( traj ): ind = evolution . getIndividualFromTraj ( traj ) logging . info ( \"Hello, I am {} \" . format ( ind . id )) logging . info ( \"You can also call me {} , or simply ( {:.2} , {:.2} ).\" . format ( ind . params , ind . x , ind . y )) # let's make a circle computation_result = abs (( ind . x ** 2 + ind . y ** 2 ) - 1 ) # DEAP wants a tuple as fitness, ALWAYS! fitness_tuple = ( computation_result ,) # we also require a dictionary with at least a single result for storing the results in the hdf result_dict = {} return fitness_tuple , result_dict pars = ParameterSpace ([ 'x' , 'y' ], [[ - 5.0 , 5.0 ], [ - 5.0 , 5.0 ]]) evolution = Evolution ( optimize_me , pars , weightList = [ - 1.0 ], POP_INIT_SIZE = 10 , POP_SIZE = 6 , NGEN = 4 , filename = \"example-2.0.hdf\" ) # info: chose POP_INIT_SIZE=100, POP_SIZE = 50, NGEN=10 for real exploration, # values here are low for testing: POP_INIT_SIZE=10, POP_SIZE = 6, NGEN=4 evolution . run ( verbose = True ) evolution . loadResults () evolution . info ( plot = True ) gens , all_scores = evolution . getScoresDuringEvolution ( reverse = True ) import matplotlib.pyplot as plt plt . figure ( figsize = ( 8 , 4 ), dpi = 200 ) plt . plot ( gens , np . nanmean ( all_scores , axis = 1 )) plt . fill_between ( gens , np . nanmin ( all_scores , axis = 1 ), np . nanmax ( all_scores , axis = 1 ), alpha = 0.3 ) plt . xlabel ( \"Generation #\" ) plt . ylabel ( \"Score\" )","title":"Example 2 evolutionary optimization minimal"},{"location":"examples/example-2-evolutionary-optimization-minimal/#simple-example-of-the-evolutionary-optimization-framework","text":"This notebook provides a simple example for the use of the evolutionary optimization framework builtin to the library. Under the hood, the implementation of the evolutionary algorithm is powered by deap and pypet cares about the parallelization and storage of the simulation data for us. Here we demonstrate how to fit parameters of a the evaluation function optimize_me which simply computes the distance of the parameters to the unit circle and returns this as the fitness_tuple that DEAP expects. # change to the root directory of the project import os if os . getcwd () . split ( \"/\" )[ - 1 ] == \"examples\" : os . chdir ( '..' ) # This will reload all imports as soon as the code changes % load_ext autoreload % autoreload 2 try : import matplotlib.pyplot as plt except ImportError : import sys ! { sys . executable } - m pip install matplotlib seaborn import matplotlib.pyplot as plt import numpy as np import logging from neurolib.utils.parameterSpace import ParameterSpace from neurolib.optimize.evolution import Evolution import neurolib.optimize.evolution.evolutionaryUtils as eu import neurolib.utils.functions as func def optimize_me ( traj ): ind = evolution . getIndividualFromTraj ( traj ) logging . info ( \"Hello, I am {} \" . format ( ind . id )) logging . info ( \"You can also call me {} , or simply ( {:.2} , {:.2} ).\" . format ( ind . params , ind . x , ind . y )) # let's make a circle computation_result = abs (( ind . x ** 2 + ind . y ** 2 ) - 1 ) # DEAP wants a tuple as fitness, ALWAYS! fitness_tuple = ( computation_result ,) # we also require a dictionary with at least a single result for storing the results in the hdf result_dict = {} return fitness_tuple , result_dict pars = ParameterSpace ([ 'x' , 'y' ], [[ - 5.0 , 5.0 ], [ - 5.0 , 5.0 ]]) evolution = Evolution ( optimize_me , pars , weightList = [ - 1.0 ], POP_INIT_SIZE = 10 , POP_SIZE = 6 , NGEN = 4 , filename = \"example-2.0.hdf\" ) # info: chose POP_INIT_SIZE=100, POP_SIZE = 50, NGEN=10 for real exploration, # values here are low for testing: POP_INIT_SIZE=10, POP_SIZE = 6, NGEN=4 evolution . run ( verbose = True ) evolution . loadResults () evolution . info ( plot = True ) gens , all_scores = evolution . getScoresDuringEvolution ( reverse = True ) import matplotlib.pyplot as plt plt . figure ( figsize = ( 8 , 4 ), dpi = 200 ) plt . plot ( gens , np . nanmean ( all_scores , axis = 1 )) plt . fill_between ( gens , np . nanmin ( all_scores , axis = 1 ), np . nanmax ( all_scores , axis = 1 ), alpha = 0.3 ) plt . xlabel ( \"Generation #\" ) plt . ylabel ( \"Score\" )","title":"Simple example of the evolutionary optimization framework"},{"location":"examples/example-2.0.1-save-and-load-evolution/","text":"(function() { function addWidgetsRenderer() { var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var scriptElement = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} scriptElement.src = widgetRendererSrc; document.body.appendChild(scriptElement); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); Saving and loading Evolution In this example, we will demonstrate how to save an evolutionary optimization on one machine or instance and load the results in another machine. This is useful, when the optimization is carried out on another computer as the analysis of the results are done. # change to the root directory of the project import os if os . getcwd () . split ( \"/\" )[ - 2 ] == \"neurolib\" : os . chdir ( '..' ) # This will reload all imports as soon as the code changes % load_ext autoreload % autoreload 2 # prepare logging import logging logger = logging . getLogger () logger . setLevel ( logging . INFO ) % load_ext autoreload % autoreload 2 We import the modules that we need for evolution from neurolib.utils.parameterSpace import ParameterSpace from neurolib.optimize.evolution import Evolution import numpy as np We will simply run the basic optimization on a circle from Example 2. def optimize_me ( traj ): ind = evolution . getIndividualFromTraj ( traj ) result = tuple ([ abs (( ind . x ** 2 + ind . y ** 2 ) - 1 )]) return result , { \"random_output\" : np . random . randint ( 100 )} pars = ParameterSpace ([ 'x' , 'y' ], [[ - 5.0 , 5.0 ], [ - 5.0 , 5.0 ]]) evolution = Evolution ( optimize_me , pars , weightList = [ - 1.0 ], POP_INIT_SIZE = 10 , POP_SIZE = 6 , NGEN = 4 , filename = \"example-2.0.1.hdf\" ) evolution . run ( verbose = True ) Save evolution Now that the optimization is done, we can serialize and save the evolution using the dill module. EVOLUTION_DILL = \"saved_evolution.dill\" evolution . saveEvolution ( EVOLUTION_DILL ) MainProcess root INFO Saving evolution to saved_evolution.dill Load evolution Here, we pretend as if we're on a completely new machine. We need to instantiate the Evolution class in order to fill it with the data from the previous optimization. For this, we create a \"mock\" evolution with some fake parameters and then load the dill file to fill out the mock values with the real ones. # initialize mock evolution for loading previously generated data pars = ParameterSpace ([ 'mock' ], [[ 0 , 1 ]]) evaluateSimulation = lambda x : x evolution_new = Evolution ( evaluateSimulation , pars ) evolution_new = evolution_new . loadEvolution ( EVOLUTION_DILL ) MainProcess root INFO weightList not set, assuming single fitness value to be maximized. MainProcess root INFO Trajectory Name: results-2021-02-15-12H-13M-39S MainProcess root INFO Storing data to: ./data/hdf/evolution.hdf MainProcess root INFO Trajectory Name: results-2021-02-15-12H-13M-39S MainProcess root INFO Number of cores: 8 MainProcess pypet.storageservice.HDF5StorageService INFO I will use the hdf5 file `./data/hdf/evolution.hdf`. MainProcess pypet.environment.Environment INFO Environment initialized. MainProcess root INFO Evolution: Using algorithm: adaptive /Users/caglar/anaconda/lib/python3.7/site-packages/deap/creator.py:141: RuntimeWarning: A class named 'FitnessMulti' has already been created and it will be overwritten. Consider deleting previous creation of that class or rename it. RuntimeWarning) /Users/caglar/anaconda/lib/python3.7/site-packages/deap/creator.py:141: RuntimeWarning: A class named 'Individual' has already been created and it will be overwritten. Consider deleting previous creation of that class or rename it. RuntimeWarning) MainProcess root INFO Evolution: Individual generation: <function randomParametersAdaptive at 0x7fd122dfa950> MainProcess root INFO Evolution: Mating operator: <function cxBlend at 0x7fd122dcdb70> MainProcess root INFO Evolution: Mutation operator: <function gaussianAdaptiveMutation_nStepSizes at 0x7fd122dfad90> MainProcess root INFO Evolution: Parent selection: <function selRank at 0x7fd122dfaae8> MainProcess root INFO Evolution: Selection operator: <function selBest_multiObj at 0x7fd122dfab70> Now, we should be able to do everything we want with the new evolution object. dfEvolution = evolution_new . dfEvolution () dfEvolution .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } x y score id gen f0 0 1.767126 0.547244 -2.422212 1 0 2.422212 1 1.908967 -0.899728 -3.453668 7 0 3.453668 2 2.047736 1.437642 -5.260036 9 0 5.260036 3 -1.521826 2.259241 -6.420126 8 0 6.420126 4 -0.898959 2.578525 -6.456920 0 0 6.456920 5 2.622927 -1.558091 -8.307394 3 0 8.307394 6 0.517562 1.942211 -3.040056 10 1 3.040056 7 -1.820438 2.712097 -9.669464 11 1 9.669464 8 0.777049 1.272183 -1.222253 12 1 1.222253 9 3.143349 0.980240 -9.841516 13 1 9.841516 10 2.267286 -0.238797 -4.197609 14 1 4.197609 11 2.098299 3.682854 -16.966271 15 1 16.966271 12 -1.746393 0.288008 -2.132837 16 2 2.132837 13 0.759040 0.168302 -0.395532 17 2 0.395532 14 -1.477419 2.202671 -6.034527 18 2 6.034527 15 0.384431 3.804135 -13.619231 19 2 13.619231 16 1.236164 -2.969863 -9.348190 20 2 9.348190 17 1.478068 0.033220 -1.185788 21 2 1.185788 18 2.544810 3.003174 -14.495107 22 3 14.495107 19 0.606182 -0.408578 -0.465607 23 3 0.465607 20 0.741795 0.783160 -0.163599 24 3 0.163599 21 1.678066 2.696300 -9.085941 25 3 9.085941 22 1.190213 -3.732895 -14.351114 26 3 14.351114 23 -2.492132 -1.219275 -6.697355 27 3 6.697355 We can also be able to load the hdf file in which all simulated was stored (\"random_output\" in the evaluation function above). evolution_new . loadResults () MainProcess root INFO Loading results from ./data/hdf/example-2.0.1.hdf MainProcess root INFO Analyzing trajectory results-2021-02-15-12H-13M-24S MainProcess pypet.storageservice.HDF5StorageService INFO I will use the hdf5 file `./data/hdf/example-2.0.1.hdf`. MainProcess pypet.storageservice.HDF5StorageService INFO Loading trajectory `results-2021-02-15-12H-13M-24S`. MainProcess pypet.storageservice.HDF5StorageService INFO Loading branch `config` in mode `2`. MainProcess pypet.storageservice.HDF5StorageService INFO Loading branch `derived_parameters` in mode `1`. MainProcess pypet.storageservice.HDF5StorageService INFO Loading branch `parameters` in mode `2`. MainProcess pypet.storageservice.HDF5StorageService INFO Loading branch `results` in mode `1`. We can load the output from the hdf file by passing the argument outputs=True to the dfEvolution() method: evolution_new . dfEvolution ( outputs = True ) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } x y score id gen random_output f0 0 1.767126 0.547244 -2.422212 1 0 1.0 2.422212 1 1.908967 -0.899728 -3.453668 7 0 1.0 3.453668 2 2.047736 1.437642 -5.260036 9 0 1.0 5.260036 3 -1.521826 2.259241 -6.420126 8 0 1.0 6.420126 4 -0.898959 2.578525 -6.456920 0 0 1.0 6.456920 5 2.622927 -1.558091 -8.307394 3 0 1.0 8.307394 6 0.517562 1.942211 -3.040056 10 1 51.0 3.040056 7 -1.820438 2.712097 -9.669464 11 1 51.0 9.669464 8 0.777049 1.272183 -1.222253 12 1 51.0 1.222253 9 3.143349 0.980240 -9.841516 13 1 51.0 9.841516 10 2.267286 -0.238797 -4.197609 14 1 51.0 4.197609 11 2.098299 3.682854 -16.966271 15 1 51.0 16.966271 12 -1.746393 0.288008 -2.132837 16 2 36.0 2.132837 13 0.759040 0.168302 -0.395532 17 2 36.0 0.395532 14 -1.477419 2.202671 -6.034527 18 2 36.0 6.034527 15 0.384431 3.804135 -13.619231 19 2 36.0 13.619231 16 1.236164 -2.969863 -9.348190 20 2 36.0 9.348190 17 1.478068 0.033220 -1.185788 21 2 36.0 1.185788 18 2.544810 3.003174 -14.495107 22 3 23.0 14.495107 19 0.606182 -0.408578 -0.465607 23 3 23.0 0.465607 20 0.741795 0.783160 -0.163599 24 3 23.0 0.163599 21 1.678066 2.696300 -9.085941 25 3 23.0 9.085941 22 1.190213 -3.732895 -14.351114 26 3 23.0 14.351114 23 -2.492132 -1.219275 -6.697355 27 3 23.0 6.697355 evolution . info () > Simulation parameters HDF file storage: ./data/hdf/example-2.0.1.hdf Trajectory Name: results-2021-02-15-12H-13M-24S Duration of evaluating initial population 0:00:01.093011 Duration of evolution 0:00:08.117928 Eval function: <function optimize_me at 0x7fd124ee4840> Parameter space: {'x': [-5.0, 5.0], 'y': [-5.0, 5.0]} > Evolution parameters Number of generations: 4 Initial population size: 10 Population size: 6 > Evolutionary operators Mating operator: <function cxBlend at 0x7fd122dcdb70> Mating paramter: {'alpha': 0.5} Selection operator: <function selBest_multiObj at 0x7fd122dfab70> Selection paramter: {} Parent selection operator: <function selRank at 0x7fd122dfaae8> Comments: no comments --- Info summary --- Valid: 6 Mean score (weighted fitness): -0.93 Parameter distribution (Generation 3): x: mean: 0.4360, std: 1.0159 y: mean: 0.3560, std: 0.5401 -------------------- Best 5 individuals: Printing 5 individuals Individual 0 Fitness values: 0.16 Score: -0.16 Weighted fitness: -0.16 Stats mean 0.16 std 0.00 min 0.16 max 0.16 model.params[\"x\"] = 0.74 model.params[\"y\"] = 0.78 Individual 1 Fitness values: 0.4 Score: -0.4 Weighted fitness: -0.4 Stats mean 0.40 std 0.00 min 0.40 max 0.40 model.params[\"x\"] = 0.76 model.params[\"y\"] = 0.17 Individual 2 Fitness values: 0.47 Score: -0.47 Weighted fitness: -0.47 Stats mean 0.47 std 0.00 min 0.47 max 0.47 model.params[\"x\"] = 0.61 model.params[\"y\"] = -0.41 Individual 3 Fitness values: 1.19 Score: -1.19 Weighted fitness: -1.19 Stats mean 1.19 std 0.00 min 1.19 max 1.19 model.params[\"x\"] = 1.48 model.params[\"y\"] = 0.03 Individual 4 Fitness values: 1.22 Score: -1.22 Weighted fitness: -1.22 Stats mean 1.22 std 0.00 min 1.22 max 1.22 model.params[\"x\"] = 0.78 model.params[\"y\"] = 1.27 -------------------- /Users/caglar/anaconda/lib/python3.7/site-packages/neurolib/optimize/evolution/evolutionaryUtils.py:212: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect. plt.tight_layout() MainProcess root INFO Saving plot to ./data/figures/results-2021-02-15-12H-13M-24S_hist_3.png There are 6 valid individuals Mean score across population: -0.93 <Figure size 432x288 with 0 Axes>","title":"Example 2.0.1 save and load evolution"},{"location":"examples/example-2.0.1-save-and-load-evolution/#saving-and-loading-evolution","text":"In this example, we will demonstrate how to save an evolutionary optimization on one machine or instance and load the results in another machine. This is useful, when the optimization is carried out on another computer as the analysis of the results are done. # change to the root directory of the project import os if os . getcwd () . split ( \"/\" )[ - 2 ] == \"neurolib\" : os . chdir ( '..' ) # This will reload all imports as soon as the code changes % load_ext autoreload % autoreload 2 # prepare logging import logging logger = logging . getLogger () logger . setLevel ( logging . INFO ) % load_ext autoreload % autoreload 2 We import the modules that we need for evolution from neurolib.utils.parameterSpace import ParameterSpace from neurolib.optimize.evolution import Evolution import numpy as np We will simply run the basic optimization on a circle from Example 2. def optimize_me ( traj ): ind = evolution . getIndividualFromTraj ( traj ) result = tuple ([ abs (( ind . x ** 2 + ind . y ** 2 ) - 1 )]) return result , { \"random_output\" : np . random . randint ( 100 )} pars = ParameterSpace ([ 'x' , 'y' ], [[ - 5.0 , 5.0 ], [ - 5.0 , 5.0 ]]) evolution = Evolution ( optimize_me , pars , weightList = [ - 1.0 ], POP_INIT_SIZE = 10 , POP_SIZE = 6 , NGEN = 4 , filename = \"example-2.0.1.hdf\" ) evolution . run ( verbose = True )","title":"Saving and loading Evolution"},{"location":"examples/example-2.0.1-save-and-load-evolution/#save-evolution","text":"Now that the optimization is done, we can serialize and save the evolution using the dill module. EVOLUTION_DILL = \"saved_evolution.dill\" evolution . saveEvolution ( EVOLUTION_DILL ) MainProcess root INFO Saving evolution to saved_evolution.dill","title":"Save evolution"},{"location":"examples/example-2.0.1-save-and-load-evolution/#load-evolution","text":"Here, we pretend as if we're on a completely new machine. We need to instantiate the Evolution class in order to fill it with the data from the previous optimization. For this, we create a \"mock\" evolution with some fake parameters and then load the dill file to fill out the mock values with the real ones. # initialize mock evolution for loading previously generated data pars = ParameterSpace ([ 'mock' ], [[ 0 , 1 ]]) evaluateSimulation = lambda x : x evolution_new = Evolution ( evaluateSimulation , pars ) evolution_new = evolution_new . loadEvolution ( EVOLUTION_DILL ) MainProcess root INFO weightList not set, assuming single fitness value to be maximized. MainProcess root INFO Trajectory Name: results-2021-02-15-12H-13M-39S MainProcess root INFO Storing data to: ./data/hdf/evolution.hdf MainProcess root INFO Trajectory Name: results-2021-02-15-12H-13M-39S MainProcess root INFO Number of cores: 8 MainProcess pypet.storageservice.HDF5StorageService INFO I will use the hdf5 file `./data/hdf/evolution.hdf`. MainProcess pypet.environment.Environment INFO Environment initialized. MainProcess root INFO Evolution: Using algorithm: adaptive /Users/caglar/anaconda/lib/python3.7/site-packages/deap/creator.py:141: RuntimeWarning: A class named 'FitnessMulti' has already been created and it will be overwritten. Consider deleting previous creation of that class or rename it. RuntimeWarning) /Users/caglar/anaconda/lib/python3.7/site-packages/deap/creator.py:141: RuntimeWarning: A class named 'Individual' has already been created and it will be overwritten. Consider deleting previous creation of that class or rename it. RuntimeWarning) MainProcess root INFO Evolution: Individual generation: <function randomParametersAdaptive at 0x7fd122dfa950> MainProcess root INFO Evolution: Mating operator: <function cxBlend at 0x7fd122dcdb70> MainProcess root INFO Evolution: Mutation operator: <function gaussianAdaptiveMutation_nStepSizes at 0x7fd122dfad90> MainProcess root INFO Evolution: Parent selection: <function selRank at 0x7fd122dfaae8> MainProcess root INFO Evolution: Selection operator: <function selBest_multiObj at 0x7fd122dfab70> Now, we should be able to do everything we want with the new evolution object. dfEvolution = evolution_new . dfEvolution () dfEvolution .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } x y score id gen f0 0 1.767126 0.547244 -2.422212 1 0 2.422212 1 1.908967 -0.899728 -3.453668 7 0 3.453668 2 2.047736 1.437642 -5.260036 9 0 5.260036 3 -1.521826 2.259241 -6.420126 8 0 6.420126 4 -0.898959 2.578525 -6.456920 0 0 6.456920 5 2.622927 -1.558091 -8.307394 3 0 8.307394 6 0.517562 1.942211 -3.040056 10 1 3.040056 7 -1.820438 2.712097 -9.669464 11 1 9.669464 8 0.777049 1.272183 -1.222253 12 1 1.222253 9 3.143349 0.980240 -9.841516 13 1 9.841516 10 2.267286 -0.238797 -4.197609 14 1 4.197609 11 2.098299 3.682854 -16.966271 15 1 16.966271 12 -1.746393 0.288008 -2.132837 16 2 2.132837 13 0.759040 0.168302 -0.395532 17 2 0.395532 14 -1.477419 2.202671 -6.034527 18 2 6.034527 15 0.384431 3.804135 -13.619231 19 2 13.619231 16 1.236164 -2.969863 -9.348190 20 2 9.348190 17 1.478068 0.033220 -1.185788 21 2 1.185788 18 2.544810 3.003174 -14.495107 22 3 14.495107 19 0.606182 -0.408578 -0.465607 23 3 0.465607 20 0.741795 0.783160 -0.163599 24 3 0.163599 21 1.678066 2.696300 -9.085941 25 3 9.085941 22 1.190213 -3.732895 -14.351114 26 3 14.351114 23 -2.492132 -1.219275 -6.697355 27 3 6.697355 We can also be able to load the hdf file in which all simulated was stored (\"random_output\" in the evaluation function above). evolution_new . loadResults () MainProcess root INFO Loading results from ./data/hdf/example-2.0.1.hdf MainProcess root INFO Analyzing trajectory results-2021-02-15-12H-13M-24S MainProcess pypet.storageservice.HDF5StorageService INFO I will use the hdf5 file `./data/hdf/example-2.0.1.hdf`. MainProcess pypet.storageservice.HDF5StorageService INFO Loading trajectory `results-2021-02-15-12H-13M-24S`. MainProcess pypet.storageservice.HDF5StorageService INFO Loading branch `config` in mode `2`. MainProcess pypet.storageservice.HDF5StorageService INFO Loading branch `derived_parameters` in mode `1`. MainProcess pypet.storageservice.HDF5StorageService INFO Loading branch `parameters` in mode `2`. MainProcess pypet.storageservice.HDF5StorageService INFO Loading branch `results` in mode `1`. We can load the output from the hdf file by passing the argument outputs=True to the dfEvolution() method: evolution_new . dfEvolution ( outputs = True ) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } x y score id gen random_output f0 0 1.767126 0.547244 -2.422212 1 0 1.0 2.422212 1 1.908967 -0.899728 -3.453668 7 0 1.0 3.453668 2 2.047736 1.437642 -5.260036 9 0 1.0 5.260036 3 -1.521826 2.259241 -6.420126 8 0 1.0 6.420126 4 -0.898959 2.578525 -6.456920 0 0 1.0 6.456920 5 2.622927 -1.558091 -8.307394 3 0 1.0 8.307394 6 0.517562 1.942211 -3.040056 10 1 51.0 3.040056 7 -1.820438 2.712097 -9.669464 11 1 51.0 9.669464 8 0.777049 1.272183 -1.222253 12 1 51.0 1.222253 9 3.143349 0.980240 -9.841516 13 1 51.0 9.841516 10 2.267286 -0.238797 -4.197609 14 1 51.0 4.197609 11 2.098299 3.682854 -16.966271 15 1 51.0 16.966271 12 -1.746393 0.288008 -2.132837 16 2 36.0 2.132837 13 0.759040 0.168302 -0.395532 17 2 36.0 0.395532 14 -1.477419 2.202671 -6.034527 18 2 36.0 6.034527 15 0.384431 3.804135 -13.619231 19 2 36.0 13.619231 16 1.236164 -2.969863 -9.348190 20 2 36.0 9.348190 17 1.478068 0.033220 -1.185788 21 2 36.0 1.185788 18 2.544810 3.003174 -14.495107 22 3 23.0 14.495107 19 0.606182 -0.408578 -0.465607 23 3 23.0 0.465607 20 0.741795 0.783160 -0.163599 24 3 23.0 0.163599 21 1.678066 2.696300 -9.085941 25 3 23.0 9.085941 22 1.190213 -3.732895 -14.351114 26 3 23.0 14.351114 23 -2.492132 -1.219275 -6.697355 27 3 23.0 6.697355 evolution . info () > Simulation parameters HDF file storage: ./data/hdf/example-2.0.1.hdf Trajectory Name: results-2021-02-15-12H-13M-24S Duration of evaluating initial population 0:00:01.093011 Duration of evolution 0:00:08.117928 Eval function: <function optimize_me at 0x7fd124ee4840> Parameter space: {'x': [-5.0, 5.0], 'y': [-5.0, 5.0]} > Evolution parameters Number of generations: 4 Initial population size: 10 Population size: 6 > Evolutionary operators Mating operator: <function cxBlend at 0x7fd122dcdb70> Mating paramter: {'alpha': 0.5} Selection operator: <function selBest_multiObj at 0x7fd122dfab70> Selection paramter: {} Parent selection operator: <function selRank at 0x7fd122dfaae8> Comments: no comments --- Info summary --- Valid: 6 Mean score (weighted fitness): -0.93 Parameter distribution (Generation 3): x: mean: 0.4360, std: 1.0159 y: mean: 0.3560, std: 0.5401 -------------------- Best 5 individuals: Printing 5 individuals Individual 0 Fitness values: 0.16 Score: -0.16 Weighted fitness: -0.16 Stats mean 0.16 std 0.00 min 0.16 max 0.16 model.params[\"x\"] = 0.74 model.params[\"y\"] = 0.78 Individual 1 Fitness values: 0.4 Score: -0.4 Weighted fitness: -0.4 Stats mean 0.40 std 0.00 min 0.40 max 0.40 model.params[\"x\"] = 0.76 model.params[\"y\"] = 0.17 Individual 2 Fitness values: 0.47 Score: -0.47 Weighted fitness: -0.47 Stats mean 0.47 std 0.00 min 0.47 max 0.47 model.params[\"x\"] = 0.61 model.params[\"y\"] = -0.41 Individual 3 Fitness values: 1.19 Score: -1.19 Weighted fitness: -1.19 Stats mean 1.19 std 0.00 min 1.19 max 1.19 model.params[\"x\"] = 1.48 model.params[\"y\"] = 0.03 Individual 4 Fitness values: 1.22 Score: -1.22 Weighted fitness: -1.22 Stats mean 1.22 std 0.00 min 1.22 max 1.22 model.params[\"x\"] = 0.78 model.params[\"y\"] = 1.27 -------------------- /Users/caglar/anaconda/lib/python3.7/site-packages/neurolib/optimize/evolution/evolutionaryUtils.py:212: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect. plt.tight_layout() MainProcess root INFO Saving plot to ./data/figures/results-2021-02-15-12H-13M-24S_hist_3.png There are 6 valid individuals Mean score across population: -0.93 <Figure size 432x288 with 0 Axes>","title":"Load evolution"},{"location":"examples/example-2.1-evolutionary-optimization-aln/","text":"(function() { function addWidgetsRenderer() { var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var scriptElement = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} scriptElement.src = widgetRendererSrc; document.body.appendChild(scriptElement); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); Evolutionary parameter search with a single neural mass model This notebook provides a simple example for the use of the evolutionary optimization framework built-in to the library. Under the hood, the implementation of the evolutionary algorithm is powered by deap and pypet cares about the parallelization and storage of the simulation data for us. We want to optimize for a simple target, namely finding a parameter configuration that produces activity with a peak power frequency spectrum at 25 Hz. In this notebook, we will also plot the evolutionary genealogy tree, to visualize how the population evolves over generations. # change to the root directory of the project import os if os . getcwd () . split ( \"/\" )[ - 1 ] == \"examples\" : os . chdir ( '..' ) # This will reload all imports as soon as the code changes % load_ext autoreload % autoreload 2 try : import matplotlib.pyplot as plt except ImportError : import sys ! { sys . executable } - m pip install matplotlib seaborn import matplotlib.pyplot as plt import numpy as np import logging from neurolib.models.aln import ALNModel from neurolib.utils.parameterSpace import ParameterSpace from neurolib.optimize.evolution import Evolution import neurolib.utils.functions as func import neurolib.optimize.evolution.deapUtils as deapUtils # a nice color map plt . rcParams [ 'image.cmap' ] = 'plasma' Model definition aln = ALNModel () # Here we define our evaluation function. This function will # be called reapedly and perform a single simulation. The object # that is passed to the function, `traj`, is a pypet trajectory # and serves as a \"bridge\" to load the parameter set of this # particular trajectory and execute a run. # Then the power spectrum of the run is computed and its maximum # is fitted to the target of 25 Hz peak frequency. def evaluateSimulation ( traj ): # The trajectory id is provided as an attribute rid = traj . id logging . info ( \"Running run id {} \" . format ( rid )) # this function provides the a model with the partuclar # parameter set for this given run model = evolution . getModelFromTraj ( traj ) # parameters can also be modified after loading model . params [ 'dt' ] = 0.1 model . params [ 'duration' ] = 2 * 1000. # and the simulation is run model . run () # compute power spectrum frs , powers = func . getPowerSpectrum ( model . rates_exc [:, - int ( 1000 / model . params [ 'dt' ]):], dt = model . params [ 'dt' ]) # find the peak frequency domfr = frs [ np . argmax ( powers )] # fitness evaluation: let's try to find a 25 Hz oscillation fitness = abs ( domfr - 25 ) # deap needs a fitness *tuple*! fitness_tuple = () # more fitness values could be added fitness_tuple += ( fitness , ) # we need to return the fitness tuple and the outputs of the model return fitness_tuple , model . outputs Initialize and run evolution The evolutionary algorithm tries to find the optimal parameter set that will maximize (or minimize) a certain fitness function. This achieved by seeding an initial population of size POP_INIT_SIZE that is randomly initiated in the parameter space parameterSpace . INIT: After simulating the initial population using evalFunction , only a subset of the individuals is kept, defined by POP_SIZE . START: Members of the remaining population are chosen based on their fitness (using rank selection) to mate and produce offspring . These offspring have parameters that are drawn from a normal distribution defined by the mean of the parameters between the two parents. Then the offspring population is evaluated and the process loops back to START: This process is repeated for NGEN generations. # Here we define the parameters and the range in which we want # to perform the evolutionary optimization. # Create a `ParameterSpace` pars = ParameterSpace ([ 'mue_ext_mean' , 'mui_ext_mean' ], [[ 0.0 , 4.0 ], [ 0.0 , 4.0 ]]) # Iitialize evolution with # :evaluateSimulation: The function that returns a fitness, # :pars: The parameter space and its boundaries to optimize # :model: The model that should be passed to the evaluation function # :weightList: A list of optimization weights for the `fitness_tuple`, # positive values will lead to a maximization, negative # values to a minimzation. The length of this list must # be the same as the length of the `fitness_tuple`. # # :POP_INIT_SIZE: The size of the initial population that will be # randomly sampled in the parameter space `pars`. # Should be higher than POP_SIZE. 50-200 might be a good # range to start experimenting with. # :POP_SIZE: Size of the population that should evolve. Must be an # even number. 20-100 might be a good range to start with. # :NGEN: Number of generations to simulate the evolution for. A good # range to start with might be 20-100. weightList = [ - 1.0 ] evolution = Evolution ( evalFunction = evaluateSimulation , parameterSpace = pars , model = aln , weightList = [ - 1.0 ], POP_INIT_SIZE = 4 , POP_SIZE = 4 , NGEN = 2 , filename = \"example-2.1.hdf\" ) # info: chose POP_INIT_SIZE=50, POP_SIZE = 20, NGEN=20 for real exploration, # values are lower here for testing # Enabling `verbose = True` will print statistics and generate plots # of the current population for each generation. evolution . run ( verbose = False ) Analysis Population # the current population is always accesible via pop = evolution . pop # we can also use the functions registered to deap # to select the best of the population: best_10 = evolution . toolbox . selBest ( pop , k = 10 ) # Remember, we performed a minimization so a fitness # of 0 is optimal print ( \"Best individual\" , best_10 [ 0 ], \"fitness\" , best_10 [ 0 ] . fitness ) Best individual [1.182184510022096, 0.29660620374273683, 0.4936712969767474, 0.07875430013351538] fitness (0.0,) We can look at the current population by calling evolution.dfPop() which returns a pandas dataframe with the parameters of each individual, its id, generation of birth, its outputs, and the fitness (called \"f0\" here). evolution . dfPop ( outputs = True ) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } mue_ext_mean mui_ext_mean score id gen t rates_exc rates_inh IA f0 0 1.182185 0.296606 0.0 294 13 [0.1, 0.2, 0.30000000000000004, 0.4, 0.5, 0.60... [[4.3201372225314945, 3.9353836030865286, 3.58... [[10.920182546008649, 11.229353479381396, 11.5... [[111.41612911461853, 111.36042105006122, 111.... 0.0 1 1.114270 0.240422 0.0 368 16 [0.1, 0.2, 0.30000000000000004, 0.4, 0.5, 0.60... [[4.3201372225314945, 3.9353836030865286, 3.58... [[10.920182546008649, 11.229353479381396, 11.5... [[111.41612911461853, 111.36042105006122, 111.... 0.0 2 0.910558 0.075463 0.0 403 18 [0.1, 0.2, 0.30000000000000004, 0.4, 0.5, 0.60... [[4.3201372225314945, 3.9353836030865286, 3.58... [[10.920182546008649, 11.229353479381396, 11.5... [[111.41612911461853, 111.36042105006122, 111.... 0.0 3 1.188440 0.356385 -1.0 171 7 [0.1, 0.2, 0.30000000000000004, 0.4, 0.5, 0.60... [[4.3201372225314945, 3.9353836030865286, 3.58... [[10.920182546008649, 11.229353479381396, 11.5... [[111.41612911461853, 111.36042105006122, 111.... 1.0 4 1.007371 0.113623 -1.0 177 7 [0.1, 0.2, 0.30000000000000004, 0.4, 0.5, 0.60... [[4.3201372225314945, 3.9353836030865286, 3.58... [[10.920182546008649, 11.229353479381396, 11.5... [[111.41612911461853, 111.36042105006122, 111.... 1.0 5 1.031484 0.120989 -1.0 192 8 [0.1, 0.2, 0.30000000000000004, 0.4, 0.5, 0.60... [[4.3201372225314945, 3.9353836030865286, 3.58... [[10.920182546008649, 11.229353479381396, 11.5... [[111.41612911461853, 111.36042105006122, 111.... 1.0 6 0.900787 0.038763 -1.0 193 8 [0.1, 0.2, 0.30000000000000004, 0.4, 0.5, 0.60... [[4.3201372225314945, 3.9353836030865286, 3.58... [[10.920182546008649, 11.229353479381396, 11.5... [[111.41612911461853, 111.36042105006122, 111.... 1.0 7 1.217021 0.213936 -1.0 245 10 [0.1, 0.2, 0.30000000000000004, 0.4, 0.5, 0.60... [[4.3201372225314945, 3.9353836030865286, 3.58... [[10.920182546008649, 11.229353479381396, 11.5... [[111.41612911461853, 111.36042105006122, 111.... 1.0 8 1.241895 0.365758 -1.0 248 10 [0.1, 0.2, 0.30000000000000004, 0.4, 0.5, 0.60... [[4.3201372225314945, 3.9353836030865286, 3.58... [[10.920182546008649, 11.229353479381396, 11.5... [[111.41612911461853, 111.36042105006122, 111.... 1.0 9 1.062928 0.265389 -1.0 267 11 [0.1, 0.2, 0.30000000000000004, 0.4, 0.5, 0.60... [[4.3201372225314945, 3.9353836030865286, 3.58... [[10.920182546008649, 11.229353479381396, 11.5... [[111.41612911461853, 111.36042105006122, 111.... 1.0 10 1.007366 0.110587 -1.0 286 12 [0.1, 0.2, 0.30000000000000004, 0.4, 0.5, 0.60... [[4.3201372225314945, 3.9353836030865286, 3.58... [[10.920182546008649, 11.229353479381396, 11.5... [[111.41612911461853, 111.36042105006122, 111.... 1.0 11 0.904612 0.123308 -1.0 320 14 [0.1, 0.2, 0.30000000000000004, 0.4, 0.5, 0.60... [[4.3201372225314945, 3.9353836030865286, 3.58... [[10.920182546008649, 11.229353479381396, 11.5... [[111.41612911461853, 111.36042105006122, 111.... 1.0 12 1.119281 0.188307 -1.0 330 15 [0.1, 0.2, 0.30000000000000004, 0.4, 0.5, 0.60... [[4.3201372225314945, 3.9353836030865286, 3.58... [[10.920182546008649, 11.229353479381396, 11.5... [[111.41612911461853, 111.36042105006122, 111.... 1.0 13 1.158463 0.227194 -1.0 342 15 [0.1, 0.2, 0.30000000000000004, 0.4, 0.5, 0.60... [[4.3201372225314945, 3.9353836030865286, 3.58... [[10.920182546008649, 11.229353479381396, 11.5... [[111.41612911461853, 111.36042105006122, 111.... 1.0 14 1.053327 0.281852 -1.0 344 15 [0.1, 0.2, 0.30000000000000004, 0.4, 0.5, 0.60... [[4.3201372225314945, 3.9353836030865286, 3.58... [[10.920182546008649, 11.229353479381396, 11.5... [[111.41612911461853, 111.36042105006122, 111.... 1.0 15 1.124747 0.318747 -1.0 360 16 [0.1, 0.2, 0.30000000000000004, 0.4, 0.5, 0.60... [[4.3201372225314945, 3.9353836030865286, 3.58... [[10.920182546008649, 11.229353479381396, 11.5... [[111.41612911461853, 111.36042105006122, 111.... 1.0 16 1.266317 0.360644 -1.0 364 16 [0.1, 0.2, 0.30000000000000004, 0.4, 0.5, 0.60... [[4.3201372225314945, 3.9353836030865286, 3.58... [[10.920182546008649, 11.229353479381396, 11.5... [[111.41612911461853, 111.36042105006122, 111.... 1.0 17 1.329988 0.388133 -1.0 365 16 [0.1, 0.2, 0.30000000000000004, 0.4, 0.5, 0.60... [[4.3201372225314945, 3.9353836030865286, 3.58... [[10.920182546008649, 11.229353479381396, 11.5... [[111.41612911461853, 111.36042105006122, 111.... 1.0 18 0.986030 0.189384 -1.0 390 18 [0.1, 0.2, 0.30000000000000004, 0.4, 0.5, 0.60... [[4.3201372225314945, 3.9353836030865286, 3.58... [[10.920182546008649, 11.229353479381396, 11.5... [[111.41612911461853, 111.36042105006122, 111.... 1.0 19 0.896915 0.125212 -1.0 399 18 [0.1, 0.2, 0.30000000000000004, 0.4, 0.5, 0.60... [[4.3201372225314945, 3.9353836030865286, 3.58... [[10.920182546008649, 11.229353479381396, 11.5... [[111.41612911461853, 111.36042105006122, 111.... 1.0 You can also view all individuals that were created during the entire evolution, by calling evolution.dfEvolution(): evolution . dfEvolution () .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } mue_ext_mean mui_ext_mean score id gen f0 0 1.400310 1.209331 -4.0 39 0 4.0 1 1.173593 0.662050 -5.0 31 0 5.0 2 1.134601 0.809371 -6.0 22 0 6.0 3 0.992049 0.694590 -6.0 29 0 6.0 4 1.470708 1.073607 -7.0 47 0 7.0 ... ... ... ... ... ... ... 395 1.881591 0.299691 -24.0 425 19 24.0 396 0.681422 0.489003 -8.0 426 19 8.0 397 1.430791 0.268028 -24.0 427 19 24.0 398 1.275903 0.534227 -3.0 428 19 3.0 399 0.870652 0.326687 -5.0 429 19 5.0 400 rows \u00d7 6 columns # a sinple overview of the current population (in this case the # last one) is given via the `info()` method. This provides a # a histogram of the score (= mean fitness) and scatterplots # and density estimates across orthogonal parameter space cross # sections. evolution . info ( plot = True ) > Simulation parameters HDF file storage: ./data/hdf/example-2.1.hdf Trajectory Name: results-2020-07-02-14H-20M-45S Duration of evaluating initial population 0:00:29.656935 Duration of evolution 0:03:50.565418 Model: <class 'neurolib.models.aln.model.ALNModel'> Model name: aln Eval function: <function evaluateSimulation at 0x10ba8cae8> Parameter space: {'mue_ext_mean': [0.0, 4.0], 'mui_ext_mean': [0.0, 4.0]} > Evolution parameters Number of generations: 20 Initial population size: 50 Population size: 20 > Evolutionary operators Mating operator: <function cxBlend at 0x11dcaf510> Mating paramter: {'alpha': 0.5} Selection operator: <function selBest_multiObj at 0x11f4d9d08> Selection paramter: {} Parent selection operator: <function selRank at 0x11f4d9c80> Comments: no comments --- Info summary --- Valid: 20 Mean score (weighted fitness): -0.85 Parameter distribution (Generation 19): mue_ext_mean: mean: 1.0852, std: 0.1270 mui_ext_mean: mean: 0.2200, std: 0.1042 -------------------- Best 5 individuals: Printing 5 individuals Individual 0 Fitness values: 0.0 Score: 0.0 Weighted fitness: -0.0 Stats mean 0.00 std 0.00 min 0.00 max 0.00 model.params[\"mue_ext_mean\"] = 1.18 model.params[\"mui_ext_mean\"] = 0.30 Individual 1 Fitness values: 0.0 Score: 0.0 Weighted fitness: -0.0 Stats mean 0.00 std 0.00 min 0.00 max 0.00 model.params[\"mue_ext_mean\"] = 1.11 model.params[\"mui_ext_mean\"] = 0.24 Individual 2 Fitness values: 0.0 Score: 0.0 Weighted fitness: -0.0 Stats mean 0.00 std 0.00 min 0.00 max 0.00 model.params[\"mue_ext_mean\"] = 0.91 model.params[\"mui_ext_mean\"] = 0.08 Individual 3 Fitness values: 1.0 Score: -1.0 Weighted fitness: -1.0 Stats mean 1.00 std 0.00 min 1.00 max 1.00 model.params[\"mue_ext_mean\"] = 1.19 model.params[\"mui_ext_mean\"] = 0.36 Individual 4 Fitness values: 1.0 Score: -1.0 Weighted fitness: -1.0 Stats mean 1.00 std 0.00 min 1.00 max 1.00 model.params[\"mue_ext_mean\"] = 1.01 model.params[\"mui_ext_mean\"] = 0.11 -------------------- MainProcess root INFO Saving plot to ./data/figures/results-2020-07-02-14H-20M-45S_hist_19.png There are 20 valid individuals Mean score across population: -0.85 <Figure size 432x288 with 0 Axes> Plotting genealogy tree neurolib keeps track of all individuals during the evolution. You can see all individuals from each generation by calling evolution.history . The object evolution.tree provides a network description of the genealogy of the evolution: each individual (indexed by its unique .id ) is connected to its parents. We can use this object in combination with the network library networkx to plot the tree: # we put this into a try except block since we don't do testing on networkx try : import matplotlib.pyplot as plt import networkx as nx from networkx.drawing.nx_pydot import graphviz_layout G = nx . DiGraph ( evolution . tree ) G = G . reverse () # Make the graph top-down pos = graphviz_layout ( G , prog = 'dot' ) plt . figure ( figsize = ( 8 , 8 )) nx . draw ( G , pos , node_size = 50 , alpha = 0.5 , node_color = list ( evolution . id_score . values ()), with_labels = False ) plt . show () except : print ( \"It looks like networkx or pydot are not installed\" ) /Users/caglar/anaconda/lib/python3.7/site-packages/networkx/drawing/nx_pylab.py:579: MatplotlibDeprecationWarning: The iterable function was deprecated in Matplotlib 3.1 and will be removed in 3.3. Use np.iterable instead. if not cb.iterable(width): /Users/caglar/anaconda/lib/python3.7/site-packages/networkx/drawing/nx_pylab.py:676: MatplotlibDeprecationWarning: The iterable function was deprecated in Matplotlib 3.1 and will be removed in 3.3. Use np.iterable instead. if cb.iterable(node_size): # many node sizes","title":"Example 2.1 evolutionary optimization aln"},{"location":"examples/example-2.1-evolutionary-optimization-aln/#evolutionary-parameter-search-with-a-single-neural-mass-model","text":"This notebook provides a simple example for the use of the evolutionary optimization framework built-in to the library. Under the hood, the implementation of the evolutionary algorithm is powered by deap and pypet cares about the parallelization and storage of the simulation data for us. We want to optimize for a simple target, namely finding a parameter configuration that produces activity with a peak power frequency spectrum at 25 Hz. In this notebook, we will also plot the evolutionary genealogy tree, to visualize how the population evolves over generations. # change to the root directory of the project import os if os . getcwd () . split ( \"/\" )[ - 1 ] == \"examples\" : os . chdir ( '..' ) # This will reload all imports as soon as the code changes % load_ext autoreload % autoreload 2 try : import matplotlib.pyplot as plt except ImportError : import sys ! { sys . executable } - m pip install matplotlib seaborn import matplotlib.pyplot as plt import numpy as np import logging from neurolib.models.aln import ALNModel from neurolib.utils.parameterSpace import ParameterSpace from neurolib.optimize.evolution import Evolution import neurolib.utils.functions as func import neurolib.optimize.evolution.deapUtils as deapUtils # a nice color map plt . rcParams [ 'image.cmap' ] = 'plasma'","title":"Evolutionary parameter search with a single neural mass model"},{"location":"examples/example-2.1-evolutionary-optimization-aln/#model-definition","text":"aln = ALNModel () # Here we define our evaluation function. This function will # be called reapedly and perform a single simulation. The object # that is passed to the function, `traj`, is a pypet trajectory # and serves as a \"bridge\" to load the parameter set of this # particular trajectory and execute a run. # Then the power spectrum of the run is computed and its maximum # is fitted to the target of 25 Hz peak frequency. def evaluateSimulation ( traj ): # The trajectory id is provided as an attribute rid = traj . id logging . info ( \"Running run id {} \" . format ( rid )) # this function provides the a model with the partuclar # parameter set for this given run model = evolution . getModelFromTraj ( traj ) # parameters can also be modified after loading model . params [ 'dt' ] = 0.1 model . params [ 'duration' ] = 2 * 1000. # and the simulation is run model . run () # compute power spectrum frs , powers = func . getPowerSpectrum ( model . rates_exc [:, - int ( 1000 / model . params [ 'dt' ]):], dt = model . params [ 'dt' ]) # find the peak frequency domfr = frs [ np . argmax ( powers )] # fitness evaluation: let's try to find a 25 Hz oscillation fitness = abs ( domfr - 25 ) # deap needs a fitness *tuple*! fitness_tuple = () # more fitness values could be added fitness_tuple += ( fitness , ) # we need to return the fitness tuple and the outputs of the model return fitness_tuple , model . outputs","title":"Model definition"},{"location":"examples/example-2.1-evolutionary-optimization-aln/#initialize-and-run-evolution","text":"The evolutionary algorithm tries to find the optimal parameter set that will maximize (or minimize) a certain fitness function. This achieved by seeding an initial population of size POP_INIT_SIZE that is randomly initiated in the parameter space parameterSpace . INIT: After simulating the initial population using evalFunction , only a subset of the individuals is kept, defined by POP_SIZE . START: Members of the remaining population are chosen based on their fitness (using rank selection) to mate and produce offspring . These offspring have parameters that are drawn from a normal distribution defined by the mean of the parameters between the two parents. Then the offspring population is evaluated and the process loops back to START: This process is repeated for NGEN generations. # Here we define the parameters and the range in which we want # to perform the evolutionary optimization. # Create a `ParameterSpace` pars = ParameterSpace ([ 'mue_ext_mean' , 'mui_ext_mean' ], [[ 0.0 , 4.0 ], [ 0.0 , 4.0 ]]) # Iitialize evolution with # :evaluateSimulation: The function that returns a fitness, # :pars: The parameter space and its boundaries to optimize # :model: The model that should be passed to the evaluation function # :weightList: A list of optimization weights for the `fitness_tuple`, # positive values will lead to a maximization, negative # values to a minimzation. The length of this list must # be the same as the length of the `fitness_tuple`. # # :POP_INIT_SIZE: The size of the initial population that will be # randomly sampled in the parameter space `pars`. # Should be higher than POP_SIZE. 50-200 might be a good # range to start experimenting with. # :POP_SIZE: Size of the population that should evolve. Must be an # even number. 20-100 might be a good range to start with. # :NGEN: Number of generations to simulate the evolution for. A good # range to start with might be 20-100. weightList = [ - 1.0 ] evolution = Evolution ( evalFunction = evaluateSimulation , parameterSpace = pars , model = aln , weightList = [ - 1.0 ], POP_INIT_SIZE = 4 , POP_SIZE = 4 , NGEN = 2 , filename = \"example-2.1.hdf\" ) # info: chose POP_INIT_SIZE=50, POP_SIZE = 20, NGEN=20 for real exploration, # values are lower here for testing # Enabling `verbose = True` will print statistics and generate plots # of the current population for each generation. evolution . run ( verbose = False )","title":"Initialize and run evolution"},{"location":"examples/example-2.1-evolutionary-optimization-aln/#analysis","text":"","title":"Analysis"},{"location":"examples/example-2.1-evolutionary-optimization-aln/#population","text":"# the current population is always accesible via pop = evolution . pop # we can also use the functions registered to deap # to select the best of the population: best_10 = evolution . toolbox . selBest ( pop , k = 10 ) # Remember, we performed a minimization so a fitness # of 0 is optimal print ( \"Best individual\" , best_10 [ 0 ], \"fitness\" , best_10 [ 0 ] . fitness ) Best individual [1.182184510022096, 0.29660620374273683, 0.4936712969767474, 0.07875430013351538] fitness (0.0,) We can look at the current population by calling evolution.dfPop() which returns a pandas dataframe with the parameters of each individual, its id, generation of birth, its outputs, and the fitness (called \"f0\" here). evolution . dfPop ( outputs = True ) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } mue_ext_mean mui_ext_mean score id gen t rates_exc rates_inh IA f0 0 1.182185 0.296606 0.0 294 13 [0.1, 0.2, 0.30000000000000004, 0.4, 0.5, 0.60... [[4.3201372225314945, 3.9353836030865286, 3.58... [[10.920182546008649, 11.229353479381396, 11.5... [[111.41612911461853, 111.36042105006122, 111.... 0.0 1 1.114270 0.240422 0.0 368 16 [0.1, 0.2, 0.30000000000000004, 0.4, 0.5, 0.60... [[4.3201372225314945, 3.9353836030865286, 3.58... [[10.920182546008649, 11.229353479381396, 11.5... [[111.41612911461853, 111.36042105006122, 111.... 0.0 2 0.910558 0.075463 0.0 403 18 [0.1, 0.2, 0.30000000000000004, 0.4, 0.5, 0.60... [[4.3201372225314945, 3.9353836030865286, 3.58... [[10.920182546008649, 11.229353479381396, 11.5... [[111.41612911461853, 111.36042105006122, 111.... 0.0 3 1.188440 0.356385 -1.0 171 7 [0.1, 0.2, 0.30000000000000004, 0.4, 0.5, 0.60... [[4.3201372225314945, 3.9353836030865286, 3.58... [[10.920182546008649, 11.229353479381396, 11.5... [[111.41612911461853, 111.36042105006122, 111.... 1.0 4 1.007371 0.113623 -1.0 177 7 [0.1, 0.2, 0.30000000000000004, 0.4, 0.5, 0.60... [[4.3201372225314945, 3.9353836030865286, 3.58... [[10.920182546008649, 11.229353479381396, 11.5... [[111.41612911461853, 111.36042105006122, 111.... 1.0 5 1.031484 0.120989 -1.0 192 8 [0.1, 0.2, 0.30000000000000004, 0.4, 0.5, 0.60... [[4.3201372225314945, 3.9353836030865286, 3.58... [[10.920182546008649, 11.229353479381396, 11.5... [[111.41612911461853, 111.36042105006122, 111.... 1.0 6 0.900787 0.038763 -1.0 193 8 [0.1, 0.2, 0.30000000000000004, 0.4, 0.5, 0.60... [[4.3201372225314945, 3.9353836030865286, 3.58... [[10.920182546008649, 11.229353479381396, 11.5... [[111.41612911461853, 111.36042105006122, 111.... 1.0 7 1.217021 0.213936 -1.0 245 10 [0.1, 0.2, 0.30000000000000004, 0.4, 0.5, 0.60... [[4.3201372225314945, 3.9353836030865286, 3.58... [[10.920182546008649, 11.229353479381396, 11.5... [[111.41612911461853, 111.36042105006122, 111.... 1.0 8 1.241895 0.365758 -1.0 248 10 [0.1, 0.2, 0.30000000000000004, 0.4, 0.5, 0.60... [[4.3201372225314945, 3.9353836030865286, 3.58... [[10.920182546008649, 11.229353479381396, 11.5... [[111.41612911461853, 111.36042105006122, 111.... 1.0 9 1.062928 0.265389 -1.0 267 11 [0.1, 0.2, 0.30000000000000004, 0.4, 0.5, 0.60... [[4.3201372225314945, 3.9353836030865286, 3.58... [[10.920182546008649, 11.229353479381396, 11.5... [[111.41612911461853, 111.36042105006122, 111.... 1.0 10 1.007366 0.110587 -1.0 286 12 [0.1, 0.2, 0.30000000000000004, 0.4, 0.5, 0.60... [[4.3201372225314945, 3.9353836030865286, 3.58... [[10.920182546008649, 11.229353479381396, 11.5... [[111.41612911461853, 111.36042105006122, 111.... 1.0 11 0.904612 0.123308 -1.0 320 14 [0.1, 0.2, 0.30000000000000004, 0.4, 0.5, 0.60... [[4.3201372225314945, 3.9353836030865286, 3.58... [[10.920182546008649, 11.229353479381396, 11.5... [[111.41612911461853, 111.36042105006122, 111.... 1.0 12 1.119281 0.188307 -1.0 330 15 [0.1, 0.2, 0.30000000000000004, 0.4, 0.5, 0.60... [[4.3201372225314945, 3.9353836030865286, 3.58... [[10.920182546008649, 11.229353479381396, 11.5... [[111.41612911461853, 111.36042105006122, 111.... 1.0 13 1.158463 0.227194 -1.0 342 15 [0.1, 0.2, 0.30000000000000004, 0.4, 0.5, 0.60... [[4.3201372225314945, 3.9353836030865286, 3.58... [[10.920182546008649, 11.229353479381396, 11.5... [[111.41612911461853, 111.36042105006122, 111.... 1.0 14 1.053327 0.281852 -1.0 344 15 [0.1, 0.2, 0.30000000000000004, 0.4, 0.5, 0.60... [[4.3201372225314945, 3.9353836030865286, 3.58... [[10.920182546008649, 11.229353479381396, 11.5... [[111.41612911461853, 111.36042105006122, 111.... 1.0 15 1.124747 0.318747 -1.0 360 16 [0.1, 0.2, 0.30000000000000004, 0.4, 0.5, 0.60... [[4.3201372225314945, 3.9353836030865286, 3.58... [[10.920182546008649, 11.229353479381396, 11.5... [[111.41612911461853, 111.36042105006122, 111.... 1.0 16 1.266317 0.360644 -1.0 364 16 [0.1, 0.2, 0.30000000000000004, 0.4, 0.5, 0.60... [[4.3201372225314945, 3.9353836030865286, 3.58... [[10.920182546008649, 11.229353479381396, 11.5... [[111.41612911461853, 111.36042105006122, 111.... 1.0 17 1.329988 0.388133 -1.0 365 16 [0.1, 0.2, 0.30000000000000004, 0.4, 0.5, 0.60... [[4.3201372225314945, 3.9353836030865286, 3.58... [[10.920182546008649, 11.229353479381396, 11.5... [[111.41612911461853, 111.36042105006122, 111.... 1.0 18 0.986030 0.189384 -1.0 390 18 [0.1, 0.2, 0.30000000000000004, 0.4, 0.5, 0.60... [[4.3201372225314945, 3.9353836030865286, 3.58... [[10.920182546008649, 11.229353479381396, 11.5... [[111.41612911461853, 111.36042105006122, 111.... 1.0 19 0.896915 0.125212 -1.0 399 18 [0.1, 0.2, 0.30000000000000004, 0.4, 0.5, 0.60... [[4.3201372225314945, 3.9353836030865286, 3.58... [[10.920182546008649, 11.229353479381396, 11.5... [[111.41612911461853, 111.36042105006122, 111.... 1.0 You can also view all individuals that were created during the entire evolution, by calling evolution.dfEvolution(): evolution . dfEvolution () .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } mue_ext_mean mui_ext_mean score id gen f0 0 1.400310 1.209331 -4.0 39 0 4.0 1 1.173593 0.662050 -5.0 31 0 5.0 2 1.134601 0.809371 -6.0 22 0 6.0 3 0.992049 0.694590 -6.0 29 0 6.0 4 1.470708 1.073607 -7.0 47 0 7.0 ... ... ... ... ... ... ... 395 1.881591 0.299691 -24.0 425 19 24.0 396 0.681422 0.489003 -8.0 426 19 8.0 397 1.430791 0.268028 -24.0 427 19 24.0 398 1.275903 0.534227 -3.0 428 19 3.0 399 0.870652 0.326687 -5.0 429 19 5.0 400 rows \u00d7 6 columns # a sinple overview of the current population (in this case the # last one) is given via the `info()` method. This provides a # a histogram of the score (= mean fitness) and scatterplots # and density estimates across orthogonal parameter space cross # sections. evolution . info ( plot = True ) > Simulation parameters HDF file storage: ./data/hdf/example-2.1.hdf Trajectory Name: results-2020-07-02-14H-20M-45S Duration of evaluating initial population 0:00:29.656935 Duration of evolution 0:03:50.565418 Model: <class 'neurolib.models.aln.model.ALNModel'> Model name: aln Eval function: <function evaluateSimulation at 0x10ba8cae8> Parameter space: {'mue_ext_mean': [0.0, 4.0], 'mui_ext_mean': [0.0, 4.0]} > Evolution parameters Number of generations: 20 Initial population size: 50 Population size: 20 > Evolutionary operators Mating operator: <function cxBlend at 0x11dcaf510> Mating paramter: {'alpha': 0.5} Selection operator: <function selBest_multiObj at 0x11f4d9d08> Selection paramter: {} Parent selection operator: <function selRank at 0x11f4d9c80> Comments: no comments --- Info summary --- Valid: 20 Mean score (weighted fitness): -0.85 Parameter distribution (Generation 19): mue_ext_mean: mean: 1.0852, std: 0.1270 mui_ext_mean: mean: 0.2200, std: 0.1042 -------------------- Best 5 individuals: Printing 5 individuals Individual 0 Fitness values: 0.0 Score: 0.0 Weighted fitness: -0.0 Stats mean 0.00 std 0.00 min 0.00 max 0.00 model.params[\"mue_ext_mean\"] = 1.18 model.params[\"mui_ext_mean\"] = 0.30 Individual 1 Fitness values: 0.0 Score: 0.0 Weighted fitness: -0.0 Stats mean 0.00 std 0.00 min 0.00 max 0.00 model.params[\"mue_ext_mean\"] = 1.11 model.params[\"mui_ext_mean\"] = 0.24 Individual 2 Fitness values: 0.0 Score: 0.0 Weighted fitness: -0.0 Stats mean 0.00 std 0.00 min 0.00 max 0.00 model.params[\"mue_ext_mean\"] = 0.91 model.params[\"mui_ext_mean\"] = 0.08 Individual 3 Fitness values: 1.0 Score: -1.0 Weighted fitness: -1.0 Stats mean 1.00 std 0.00 min 1.00 max 1.00 model.params[\"mue_ext_mean\"] = 1.19 model.params[\"mui_ext_mean\"] = 0.36 Individual 4 Fitness values: 1.0 Score: -1.0 Weighted fitness: -1.0 Stats mean 1.00 std 0.00 min 1.00 max 1.00 model.params[\"mue_ext_mean\"] = 1.01 model.params[\"mui_ext_mean\"] = 0.11 -------------------- MainProcess root INFO Saving plot to ./data/figures/results-2020-07-02-14H-20M-45S_hist_19.png There are 20 valid individuals Mean score across population: -0.85 <Figure size 432x288 with 0 Axes>","title":"Population"},{"location":"examples/example-2.1-evolutionary-optimization-aln/#plotting-genealogy-tree","text":"neurolib keeps track of all individuals during the evolution. You can see all individuals from each generation by calling evolution.history . The object evolution.tree provides a network description of the genealogy of the evolution: each individual (indexed by its unique .id ) is connected to its parents. We can use this object in combination with the network library networkx to plot the tree: # we put this into a try except block since we don't do testing on networkx try : import matplotlib.pyplot as plt import networkx as nx from networkx.drawing.nx_pydot import graphviz_layout G = nx . DiGraph ( evolution . tree ) G = G . reverse () # Make the graph top-down pos = graphviz_layout ( G , prog = 'dot' ) plt . figure ( figsize = ( 8 , 8 )) nx . draw ( G , pos , node_size = 50 , alpha = 0.5 , node_color = list ( evolution . id_score . values ()), with_labels = False ) plt . show () except : print ( \"It looks like networkx or pydot are not installed\" ) /Users/caglar/anaconda/lib/python3.7/site-packages/networkx/drawing/nx_pylab.py:579: MatplotlibDeprecationWarning: The iterable function was deprecated in Matplotlib 3.1 and will be removed in 3.3. Use np.iterable instead. if not cb.iterable(width): /Users/caglar/anaconda/lib/python3.7/site-packages/networkx/drawing/nx_pylab.py:676: MatplotlibDeprecationWarning: The iterable function was deprecated in Matplotlib 3.1 and will be removed in 3.3. Use np.iterable instead. if cb.iterable(node_size): # many node sizes","title":"Plotting genealogy tree"},{"location":"examples/example-2.2-evolution-brain-network-aln-resting-state-fit/","text":"(function() { function addWidgetsRenderer() { var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var scriptElement = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} scriptElement.src = widgetRendererSrc; document.body.appendChild(scriptElement); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); Evolutionary optimization of a whole-brain model This notebook provides an example for the use of the evolutionary optimization framework built-in to the library. Under the hood, the implementation of the evolutionary algorithm is powered by deap and pypet cares about the parallelization and storage of the simulation data for us. We want to optimize a whole-brain network that should produce simulated BOLD activity (fMRI data) that is similar to the empirical dataset. We measure the fitness of each simulation by computing the func.matrix_correlation of the functional connectivity func.fc(model.BOLD.BOLD) to the empirical data ds.FCs . The ones that are closest to the empirical data get a higher fitness and have a higher chance of reproducing and survival. # change to the root directory of the project import os if os . getcwd () . split ( \"/\" )[ - 1 ] == \"examples\" : os . chdir ( '..' ) # This will reload all imports as soon as the code changes % load_ext autoreload % autoreload 2 try : import matplotlib.pyplot as plt except ImportError : import sys ! { sys . executable } - m pip install matplotlib seaborn import matplotlib.pyplot as plt import numpy as np import logging from neurolib.models.aln import ALNModel from neurolib.utils.parameterSpace import ParameterSpace from neurolib.optimize.evolution import Evolution import neurolib.utils.functions as func from neurolib.utils.loadData import Dataset ds = Dataset ( \"hcp\" ) # a nice color map plt . rcParams [ 'image.cmap' ] = 'plasma' We create a brain network model using the empirical dataset ds : model = ALNModel ( Cmat = ds . Cmat , Dmat = ds . Dmat ) # simulates the whole-brain model in 10s chunks by default if bold == True # Resting state fits model . params [ 'mue_ext_mean' ] = 1.57 model . params [ 'mui_ext_mean' ] = 1.6 model . params [ 'sigma_ou' ] = 0.09 model . params [ 'b' ] = 5.0 model . params [ 'signalV' ] = 2 model . params [ 'dt' ] = 0.2 model . params [ 'duration' ] = 0.2 * 60 * 1000 #ms # testing: aln.params['duration'] = 0.2 * 60 * 1000 #ms # real: aln.params['duration'] = 1.0 * 60 * 1000 #ms Our evaluation function will do the following: first it will simulate the model for a short time to see whether there is any sufficient activity. This speeds up the evolution considerably, since large regions of the state space show almost no neuronal activity. Only then do we simulate the model for the full duration and compute the fitness using the empirical dataset. def evaluateSimulation ( traj ): rid = traj . id model = evolution . getModelFromTraj ( traj ) defaultDuration = model . params [ 'duration' ] invalid_result = ( np . nan ,) * len ( ds . BOLDs ) # -------- stage wise simulation -------- # Stage 1 : simulate for a few seconds to see if there is any activity # --------------------------------------- model . params [ 'duration' ] = 3 * 1000. model . run () # check if stage 1 was successful if np . max ( model . output [:, model . t > 500 ]) > 160 or np . max ( model . output [:, model . t > 500 ]) < 10 : return invalid_result , {} # Stage 2: full and final simulation # --------------------------------------- model . params [ 'duration' ] = defaultDuration model . run ( chunkwise = True , bold = True ) # -------- fitness evaluation here -------- scores = [] for i , fc in enumerate ( ds . FCs ): #range(len(ds.FCs)): fc_score = func . matrix_correlation ( func . fc ( model . BOLD . BOLD [:, 5 :]), fc ) scores . append ( fc_score ) meanFitness = np . mean ( scores ) fitness_tuple = ( meanFitness ,) #print(f\"fitness {meanFitness}\") #print(f\"scores {scores}\") fitness_tuple = tuple ( scores ) return fitness_tuple , {} We specify the parameter space that we want to search. pars = ParameterSpace ([ 'mue_ext_mean' , 'mui_ext_mean' , 'b' , 'sigma_ou' , 'Ke_gl' , 'signalV' ], [[ 0.0 , 3.0 ], [ 0.0 , 3.0 ], [ 0.0 , 100.0 ], [ 0.0 , 0.3 ], [ 0.0 , 500.0 ], [ 0.0 , 400.0 ]]) Note that we chose algorithm='nsga2' when we create the Evolution . This will use the multi-objective optimization algorithm by Deb et al. 2002. Although we have only one objective here (namely the FC fit), we could in principle add more objectives, like the FCD matrix fit or other objectives. For this, we would have to add these values to the fitness in the evaluation function above and add more weights in the definition of the Evolution . We can use positive weights for that objective to be maximized and negative ones for minimization. Please refer to the DEAP documentation for more information. evolution = Evolution ( evaluateSimulation , pars , algorithm = 'nsga2' , weightList = [ 1.0 ] * len ( ds . BOLDs ), model = model , POP_INIT_SIZE = 4 , POP_SIZE = 4 , NGEN = 2 , filename = \"example-2.2.hdf\" ) #testing: evolution = Evolution(evaluateSimulation, pars, algorithm = 'nsga2', weightList = [1.0] * len(ds.BOLDs), model = model, POP_INIT_SIZE=4, POP_SIZE = 4, NGEN=2) # real: evolution = Evolution(evaluateSimulation, pars, algorithm = 'nsga2', weightList = [1.0] * len(ds.BOLDs), model = model, POP_INIT_SIZE=1600, POP_SIZE = 160, NGEN=100) That's it, we can run the evolution now. evolution . run ( verbose = False ) We could now save the full evolution object for later analysis using evolution.saveEvolution() . Analysis The info() method gives us a useful overview of the evolution, like a summary of the evolution parameters, the statistics of the population and also scatterplots of the individuals in our search space. evolution . info () --- Info summary --- Valid: 160 Mean score (weighted fitness): 0.53 Parameters dictribution (Generation 99): mue_ext_mean: mean: 0.147, std: 0.02449 mui_ext_mean: mean: 0.1343, std: 0.05387 b: mean: 93.05, std: 5.84 sigma_ou: mean: 0.05296, std: 0.01099 Ke_gl: mean: 233.1, std: 20.57 signalV: mean: 344.3, std: 68.9 -------------------- Best 5 individuals: Printing 5 individuals Individual 0 pars mue_ext_mean 0.1557, mui_ext_mean 0.08049, b 96.18, sigma_ou 0.05687, Ke_gl 222.8, signalV 354.9 Fitness values: 0.5426 0.4137 0.6459 0.5287 0.552 0.7209 0.5181 0.4997 0.42 0.4226 0.4279 0.5029 0.652 0.5667 0.5394 0.5894 0.472 0.6361 0.5217 0.5899 0.6456 0.5204 0.637 0.7114 Individual 1 pars mue_ext_mean 0.172, mui_ext_mean 0.1519, b 83.8, sigma_ou 0.06809, Ke_gl 219.2, signalV 308.3 Fitness values: 0.5798 0.4495 0.6525 0.4953 0.5876 0.7077 0.5263 0.5381 0.4222 0.4486 0.4347 0.5051 0.6232 0.5411 0.5383 0.5532 0.4716 0.6162 0.5442 0.5476 0.6644 0.5176 0.5826 0.6867 Individual 2 pars mue_ext_mean 0.09511, mui_ext_mean 0.1325, b 84.53, sigma_ou 0.04644, Ke_gl 206.9, signalV 382.1 Fitness values: 0.5212 0.4309 0.6206 0.5142 0.551 0.6844 0.5321 0.4911 0.4151 0.4368 0.4358 0.4803 0.6534 0.535 0.5388 0.5712 0.4784 0.659 0.5016 0.5962 0.6281 0.5063 0.6328 0.7097 Individual 3 pars mue_ext_mean 0.1333, mui_ext_mean 0.1794, b 92.41, sigma_ou 0.04781, Ke_gl 247.8, signalV 374.4 Fitness values: 0.5359 0.4445 0.622 0.4913 0.5438 0.717 0.5579 0.4572 0.3963 0.4511 0.4247 0.4688 0.6558 0.5271 0.5403 0.5763 0.4736 0.6079 0.4863 0.6064 0.6628 0.5144 0.6055 0.6958 Individual 4 pars mue_ext_mean 0.2655, mui_ext_mean 0.2683, b 88.81, sigma_ou 0.04314, Ke_gl 231.0, signalV 371.8 Fitness values: 0.5668 0.4402 0.6421 0.5091 0.5613 0.6858 0.4896 0.516 0.4525 0.437 0.4513 0.5346 0.5927 0.5819 0.5021 0.5367 0.4718 0.6038 0.563 0.5354 0.5889 0.5078 0.5844 0.7061 -------------------- There are 160 valid individuals Mean score across population: 0.53 <Figure size 432x288 with 0 Axes> # This will load results from disk in case the session is # started newly and the trajectory is not in memory traj = evolution . loadResults () gens , all_scores = evolution . getScoresDuringEvolution ( reverse = True ) plt . figure ( figsize = ( 8 , 4 ), dpi = 200 ) plt . plot ( gens , np . nanmean ( all_scores , axis = 1 )) plt . fill_between ( gens , np . nanmin ( all_scores , axis = 1 ), np . nanmax ( all_scores , axis = 1 ), alpha = 0.3 ) plt . xlabel ( \"Generation #\" ) plt . ylabel ( \"Score\" ) Text(0, 0.5, 'Score')","title":"Example 2.2 evolution brain network aln resting state fit"},{"location":"examples/example-2.2-evolution-brain-network-aln-resting-state-fit/#evolutionary-optimization-of-a-whole-brain-model","text":"This notebook provides an example for the use of the evolutionary optimization framework built-in to the library. Under the hood, the implementation of the evolutionary algorithm is powered by deap and pypet cares about the parallelization and storage of the simulation data for us. We want to optimize a whole-brain network that should produce simulated BOLD activity (fMRI data) that is similar to the empirical dataset. We measure the fitness of each simulation by computing the func.matrix_correlation of the functional connectivity func.fc(model.BOLD.BOLD) to the empirical data ds.FCs . The ones that are closest to the empirical data get a higher fitness and have a higher chance of reproducing and survival. # change to the root directory of the project import os if os . getcwd () . split ( \"/\" )[ - 1 ] == \"examples\" : os . chdir ( '..' ) # This will reload all imports as soon as the code changes % load_ext autoreload % autoreload 2 try : import matplotlib.pyplot as plt except ImportError : import sys ! { sys . executable } - m pip install matplotlib seaborn import matplotlib.pyplot as plt import numpy as np import logging from neurolib.models.aln import ALNModel from neurolib.utils.parameterSpace import ParameterSpace from neurolib.optimize.evolution import Evolution import neurolib.utils.functions as func from neurolib.utils.loadData import Dataset ds = Dataset ( \"hcp\" ) # a nice color map plt . rcParams [ 'image.cmap' ] = 'plasma' We create a brain network model using the empirical dataset ds : model = ALNModel ( Cmat = ds . Cmat , Dmat = ds . Dmat ) # simulates the whole-brain model in 10s chunks by default if bold == True # Resting state fits model . params [ 'mue_ext_mean' ] = 1.57 model . params [ 'mui_ext_mean' ] = 1.6 model . params [ 'sigma_ou' ] = 0.09 model . params [ 'b' ] = 5.0 model . params [ 'signalV' ] = 2 model . params [ 'dt' ] = 0.2 model . params [ 'duration' ] = 0.2 * 60 * 1000 #ms # testing: aln.params['duration'] = 0.2 * 60 * 1000 #ms # real: aln.params['duration'] = 1.0 * 60 * 1000 #ms Our evaluation function will do the following: first it will simulate the model for a short time to see whether there is any sufficient activity. This speeds up the evolution considerably, since large regions of the state space show almost no neuronal activity. Only then do we simulate the model for the full duration and compute the fitness using the empirical dataset. def evaluateSimulation ( traj ): rid = traj . id model = evolution . getModelFromTraj ( traj ) defaultDuration = model . params [ 'duration' ] invalid_result = ( np . nan ,) * len ( ds . BOLDs ) # -------- stage wise simulation -------- # Stage 1 : simulate for a few seconds to see if there is any activity # --------------------------------------- model . params [ 'duration' ] = 3 * 1000. model . run () # check if stage 1 was successful if np . max ( model . output [:, model . t > 500 ]) > 160 or np . max ( model . output [:, model . t > 500 ]) < 10 : return invalid_result , {} # Stage 2: full and final simulation # --------------------------------------- model . params [ 'duration' ] = defaultDuration model . run ( chunkwise = True , bold = True ) # -------- fitness evaluation here -------- scores = [] for i , fc in enumerate ( ds . FCs ): #range(len(ds.FCs)): fc_score = func . matrix_correlation ( func . fc ( model . BOLD . BOLD [:, 5 :]), fc ) scores . append ( fc_score ) meanFitness = np . mean ( scores ) fitness_tuple = ( meanFitness ,) #print(f\"fitness {meanFitness}\") #print(f\"scores {scores}\") fitness_tuple = tuple ( scores ) return fitness_tuple , {} We specify the parameter space that we want to search. pars = ParameterSpace ([ 'mue_ext_mean' , 'mui_ext_mean' , 'b' , 'sigma_ou' , 'Ke_gl' , 'signalV' ], [[ 0.0 , 3.0 ], [ 0.0 , 3.0 ], [ 0.0 , 100.0 ], [ 0.0 , 0.3 ], [ 0.0 , 500.0 ], [ 0.0 , 400.0 ]]) Note that we chose algorithm='nsga2' when we create the Evolution . This will use the multi-objective optimization algorithm by Deb et al. 2002. Although we have only one objective here (namely the FC fit), we could in principle add more objectives, like the FCD matrix fit or other objectives. For this, we would have to add these values to the fitness in the evaluation function above and add more weights in the definition of the Evolution . We can use positive weights for that objective to be maximized and negative ones for minimization. Please refer to the DEAP documentation for more information. evolution = Evolution ( evaluateSimulation , pars , algorithm = 'nsga2' , weightList = [ 1.0 ] * len ( ds . BOLDs ), model = model , POP_INIT_SIZE = 4 , POP_SIZE = 4 , NGEN = 2 , filename = \"example-2.2.hdf\" ) #testing: evolution = Evolution(evaluateSimulation, pars, algorithm = 'nsga2', weightList = [1.0] * len(ds.BOLDs), model = model, POP_INIT_SIZE=4, POP_SIZE = 4, NGEN=2) # real: evolution = Evolution(evaluateSimulation, pars, algorithm = 'nsga2', weightList = [1.0] * len(ds.BOLDs), model = model, POP_INIT_SIZE=1600, POP_SIZE = 160, NGEN=100) That's it, we can run the evolution now. evolution . run ( verbose = False ) We could now save the full evolution object for later analysis using evolution.saveEvolution() .","title":"Evolutionary optimization of a whole-brain model"},{"location":"examples/example-2.2-evolution-brain-network-aln-resting-state-fit/#analysis","text":"The info() method gives us a useful overview of the evolution, like a summary of the evolution parameters, the statistics of the population and also scatterplots of the individuals in our search space. evolution . info () --- Info summary --- Valid: 160 Mean score (weighted fitness): 0.53 Parameters dictribution (Generation 99): mue_ext_mean: mean: 0.147, std: 0.02449 mui_ext_mean: mean: 0.1343, std: 0.05387 b: mean: 93.05, std: 5.84 sigma_ou: mean: 0.05296, std: 0.01099 Ke_gl: mean: 233.1, std: 20.57 signalV: mean: 344.3, std: 68.9 -------------------- Best 5 individuals: Printing 5 individuals Individual 0 pars mue_ext_mean 0.1557, mui_ext_mean 0.08049, b 96.18, sigma_ou 0.05687, Ke_gl 222.8, signalV 354.9 Fitness values: 0.5426 0.4137 0.6459 0.5287 0.552 0.7209 0.5181 0.4997 0.42 0.4226 0.4279 0.5029 0.652 0.5667 0.5394 0.5894 0.472 0.6361 0.5217 0.5899 0.6456 0.5204 0.637 0.7114 Individual 1 pars mue_ext_mean 0.172, mui_ext_mean 0.1519, b 83.8, sigma_ou 0.06809, Ke_gl 219.2, signalV 308.3 Fitness values: 0.5798 0.4495 0.6525 0.4953 0.5876 0.7077 0.5263 0.5381 0.4222 0.4486 0.4347 0.5051 0.6232 0.5411 0.5383 0.5532 0.4716 0.6162 0.5442 0.5476 0.6644 0.5176 0.5826 0.6867 Individual 2 pars mue_ext_mean 0.09511, mui_ext_mean 0.1325, b 84.53, sigma_ou 0.04644, Ke_gl 206.9, signalV 382.1 Fitness values: 0.5212 0.4309 0.6206 0.5142 0.551 0.6844 0.5321 0.4911 0.4151 0.4368 0.4358 0.4803 0.6534 0.535 0.5388 0.5712 0.4784 0.659 0.5016 0.5962 0.6281 0.5063 0.6328 0.7097 Individual 3 pars mue_ext_mean 0.1333, mui_ext_mean 0.1794, b 92.41, sigma_ou 0.04781, Ke_gl 247.8, signalV 374.4 Fitness values: 0.5359 0.4445 0.622 0.4913 0.5438 0.717 0.5579 0.4572 0.3963 0.4511 0.4247 0.4688 0.6558 0.5271 0.5403 0.5763 0.4736 0.6079 0.4863 0.6064 0.6628 0.5144 0.6055 0.6958 Individual 4 pars mue_ext_mean 0.2655, mui_ext_mean 0.2683, b 88.81, sigma_ou 0.04314, Ke_gl 231.0, signalV 371.8 Fitness values: 0.5668 0.4402 0.6421 0.5091 0.5613 0.6858 0.4896 0.516 0.4525 0.437 0.4513 0.5346 0.5927 0.5819 0.5021 0.5367 0.4718 0.6038 0.563 0.5354 0.5889 0.5078 0.5844 0.7061 -------------------- There are 160 valid individuals Mean score across population: 0.53 <Figure size 432x288 with 0 Axes> # This will load results from disk in case the session is # started newly and the trajectory is not in memory traj = evolution . loadResults () gens , all_scores = evolution . getScoresDuringEvolution ( reverse = True ) plt . figure ( figsize = ( 8 , 4 ), dpi = 200 ) plt . plot ( gens , np . nanmean ( all_scores , axis = 1 )) plt . fill_between ( gens , np . nanmin ( all_scores , axis = 1 ), np . nanmax ( all_scores , axis = 1 ), alpha = 0.3 ) plt . xlabel ( \"Generation #\" ) plt . ylabel ( \"Score\" ) Text(0, 0.5, 'Score')","title":"Analysis"},{"location":"examples/example-3-meg-functional-connectivity/","text":"(function() { function addWidgetsRenderer() { var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var scriptElement = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} scriptElement.src = widgetRendererSrc; document.body.appendChild(scriptElement); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); Modeling resting-state MEG-Data In this example we will learn how to use neurolib to simulate resting state functional connectivity of MEG recordings. In the first part of the notebook, we will compute the frequency specific functional connectivity matrix of an examplary resting state MEG recording from the YouR-Study Uhlhaas, P.J., Gajwani, R., Gross, J. et al. The Youth Mental Health Risk and Resilience Study (YouR-Study). BMC Psychiatry 17, 43 (2017) . To this end we will: Band-Pass filter the signal Apply the hilbert -transformation to extract the signal envelope Orthogonalize the signal envelopes of two examplary regions Low-Pass filter the signal envelopes and compute the pairwise envelope correlations which yields the functional connectivity matrix. We follow the approach presented in Hipp, J., Hawellek, D., Corbetta, M. et al. , Large-scale cortical correlation structure of spontaneous oscillatory activity. Nat Neurosci 15, 884\u2013890 (2012) In the second part of this notebook, we will use a whole-brain model to simulate brain activity and compute functional connectivity matrix of the simulated signal envelope, as was done for the empirical MEG data. The parameters of this model have been previously optimized with neurolib 's evolutionary algorithms (not shown here). Finally, we will compute the fit (Pearson correlation) of the simulated functional connectivity to the empirical MEG data, which was used as a fitting objective in a previous optimization procedure. # change to the root directory of the project import os if os . getcwd () . split ( \"/\" )[ - 1 ] == \"examples\" : os . chdir ( '..' ) # This will reload all imports as soon as the code changes % load_ext autoreload % autoreload 2 import os import numpy as np import xarray as xr import matplotlib.pyplot as plt import seaborn as sns import ipywidgets as widgets from IPython.utils import io import warnings warnings . simplefilter ( action = 'ignore' , category = FutureWarning ) import time import pandas as pd Empirical Functional Connectivity Load MEG-Data First off, let's load the MEG data using the Signal class from neurolib . Our example data has already been preprocessed and projected into source space using the AAL2 atlas. from neurolib.utils.signal import Signal signal = Signal . from_file ( os . path . join ( 'examples' , 'data' , 'rs-meg.nc' )) region_labels = signal . data . regions . values nr_regions = len ( region_labels ) display ( signal . data ) /* CSS stylesheet for displaying xarray objects in jupyterlab. * */ :root { --xr-font-color0: var(--jp-content-font-color0, rgba(0, 0, 0, 1)); --xr-font-color2: var(--jp-content-font-color2, rgba(0, 0, 0, 0.54)); --xr-font-color3: var(--jp-content-font-color3, rgba(0, 0, 0, 0.38)); --xr-border-color: var(--jp-border-color2, #e0e0e0); --xr-disabled-color: var(--jp-layout-color3, #bdbdbd); --xr-background-color: var(--jp-layout-color0, white); --xr-background-color-row-even: var(--jp-layout-color1, white); --xr-background-color-row-odd: var(--jp-layout-color2, #eeeeee); } html[theme=dark], body.vscode-dark { --xr-font-color0: rgba(255, 255, 255, 1); --xr-font-color2: rgba(255, 255, 255, 0.54); --xr-font-color3: rgba(255, 255, 255, 0.38); --xr-border-color: #1F1F1F; --xr-disabled-color: #515151; --xr-background-color: #111111; --xr-background-color-row-even: #111111; --xr-background-color-row-odd: #313131; } .xr-wrap { display: block; min-width: 300px; max-width: 700px; } .xr-text-repr-fallback { /* fallback to plain text repr when CSS is not injected (untrusted notebook) */ display: none; } .xr-header { padding-top: 6px; padding-bottom: 6px; margin-bottom: 4px; border-bottom: solid 1px var(--xr-border-color); } .xr-header > div, .xr-header > ul { display: inline; margin-top: 0; margin-bottom: 0; } .xr-obj-type, .xr-array-name { margin-left: 2px; margin-right: 10px; } .xr-obj-type { color: var(--xr-font-color2); } .xr-sections { padding-left: 0 !important; display: grid; grid-template-columns: 150px auto auto 1fr 20px 20px; } .xr-section-item { display: contents; } .xr-section-item input { display: none; } .xr-section-item input + label { color: var(--xr-disabled-color); } .xr-section-item input:enabled + label { cursor: pointer; color: var(--xr-font-color2); } .xr-section-item input:enabled + label:hover { color: var(--xr-font-color0); } .xr-section-summary { grid-column: 1; color: var(--xr-font-color2); font-weight: 500; } .xr-section-summary > span { display: inline-block; padding-left: 0.5em; } .xr-section-summary-in:disabled + label { color: var(--xr-font-color2); } .xr-section-summary-in + label:before { display: inline-block; content: '\u25ba'; font-size: 11px; width: 15px; text-align: center; } .xr-section-summary-in:disabled + label:before { color: var(--xr-disabled-color); } .xr-section-summary-in:checked + label:before { content: '\u25bc'; } .xr-section-summary-in:checked + label > span { display: none; } .xr-section-summary, .xr-section-inline-details { padding-top: 4px; padding-bottom: 4px; } .xr-section-inline-details { grid-column: 2 / -1; } .xr-section-details { display: none; grid-column: 1 / -1; margin-bottom: 5px; } .xr-section-summary-in:checked ~ .xr-section-details { display: contents; } .xr-array-wrap { grid-column: 1 / -1; display: grid; grid-template-columns: 20px auto; } .xr-array-wrap > label { grid-column: 1; vertical-align: top; } .xr-preview { color: var(--xr-font-color3); } .xr-array-preview, .xr-array-data { padding: 0 5px !important; grid-column: 2; } .xr-array-data, .xr-array-in:checked ~ .xr-array-preview { display: none; } .xr-array-in:checked ~ .xr-array-data, .xr-array-preview { display: inline-block; } .xr-dim-list { display: inline-block !important; list-style: none; padding: 0 !important; margin: 0; } .xr-dim-list li { display: inline-block; padding: 0; margin: 0; } .xr-dim-list:before { content: '('; } .xr-dim-list:after { content: ')'; } .xr-dim-list li:not(:last-child):after { content: ','; padding-right: 5px; } .xr-has-index { font-weight: bold; } .xr-var-list, .xr-var-item { display: contents; } .xr-var-item > div, .xr-var-item label, .xr-var-item > .xr-var-name span { background-color: var(--xr-background-color-row-even); margin-bottom: 0; } .xr-var-item > .xr-var-name:hover span { padding-right: 5px; } .xr-var-list > li:nth-child(odd) > div, .xr-var-list > li:nth-child(odd) > label, .xr-var-list > li:nth-child(odd) > .xr-var-name span { background-color: var(--xr-background-color-row-odd); } .xr-var-name { grid-column: 1; } .xr-var-dims { grid-column: 2; } .xr-var-dtype { grid-column: 3; text-align: right; color: var(--xr-font-color2); } .xr-var-preview { grid-column: 4; } .xr-var-name, .xr-var-dims, .xr-var-dtype, .xr-preview, .xr-attrs dt { white-space: nowrap; overflow: hidden; text-overflow: ellipsis; padding-right: 10px; } .xr-var-name:hover, .xr-var-dims:hover, .xr-var-dtype:hover, .xr-attrs dt:hover { overflow: visible; width: auto; z-index: 1; } .xr-var-attrs, .xr-var-data { display: none; background-color: var(--xr-background-color) !important; padding-bottom: 5px !important; } .xr-var-attrs-in:checked ~ .xr-var-attrs, .xr-var-data-in:checked ~ .xr-var-data { display: block; } .xr-var-data > table { float: right; } .xr-var-name span, .xr-var-data, .xr-attrs { padding-left: 25px !important; } .xr-attrs, .xr-var-attrs, .xr-var-data { grid-column: 1 / -1; } dl.xr-attrs { padding: 0; margin: 0; display: grid; grid-template-columns: 125px auto; } .xr-attrs dt, .xr-attrs dd { padding: 0; margin: 0; float: left; padding-right: 10px; width: auto; } .xr-attrs dt { font-weight: normal; grid-column: 1; } .xr-attrs dt:hover span { display: inline-block; background: var(--xr-background-color); padding-right: 10px; } .xr-attrs dd { grid-column: 2; white-space: pre-wrap; word-break: break-all; } .xr-icon-database, .xr-icon-file-text2 { display: inline-block; vertical-align: middle; width: 1em; height: 1.5em !important; stroke-width: 0; stroke: currentColor; fill: currentColor; } <xarray.DataArray (regions: 94, time: 6000)> array([[-0.17628077, -0.33449804, -0.27283166, ..., 0.20004052, 0.19379806, 0.0271034 ], [ 0.00513031, 0.0319704 , 0.18478207, ..., 0.22112991, 0.30244658, 0.21108818], [ 0.01999333, -0.1601617 , -0.21931987, ..., 0.01844522, -0.03713842, 0.08175757], ..., [-0.2381615 , -0.34838511, -0.50638238, ..., -0.08763395, -0.05396606, -0.06218967], [-0.09900261, -0.1525903 , -0.16444704, ..., 0.04080438, 0.01664182, 0.15847579], [ 0.13203698, 0.17482835, 0.21212731, ..., -0.19971229, -0.01869223, -0.16379495]]) Coordinates: * time (time) float64 0.0 0.01 0.02 0.03 0.04 ... 59.96 59.97 59.98 59.99 * regions (regions) object 'PreCG.L' 'PreCG.R' 'SFG.L' ... 'ITG.L' 'ITG.R' Attributes: name: rest meg label: signal_type: unit: T description: MEG recording in AAL2 space process_steps_0: resample to 100.0Hz xarray.DataArray regions : 94 time : 6000 -0.1763 -0.3345 -0.2728 -0.1313 ... -0.2128 -0.1997 -0.01869 -0.1638 array([[-0.17628077, -0.33449804, -0.27283166, ..., 0.20004052, 0.19379806, 0.0271034 ], [ 0.00513031, 0.0319704 , 0.18478207, ..., 0.22112991, 0.30244658, 0.21108818], [ 0.01999333, -0.1601617 , -0.21931987, ..., 0.01844522, -0.03713842, 0.08175757], ..., [-0.2381615 , -0.34838511, -0.50638238, ..., -0.08763395, -0.05396606, -0.06218967], [-0.09900261, -0.1525903 , -0.16444704, ..., 0.04080438, 0.01664182, 0.15847579], [ 0.13203698, 0.17482835, 0.21212731, ..., -0.19971229, -0.01869223, -0.16379495]]) Coordinates: (2) time (time) float64 0.0 0.01 0.02 ... 59.97 59.98 59.99 array([0.000e+00, 1.000e-02, 2.000e-02, ..., 5.997e+01, 5.998e+01, 5.999e+01]) regions (regions) object 'PreCG.L' 'PreCG.R' ... 'ITG.R' array(['PreCG.L', 'PreCG.R', 'SFG.L', 'SFG.R', 'MFG.L', 'MFG.R', 'IFGoperc.L', 'IFGoperc.R', 'IFGtriang.L', 'IFGtriang.R', 'IFGorb.L', 'IFGorb.R', 'ROL.L', 'ROL.R', 'SMA.L', 'SMA.R', 'OLF.L', 'OLF.R', 'SFGmed.L', 'SFGmed.R', 'PFCventmed.L', 'PFCventmed.R', 'REC.L', 'REC.R', 'OFCmed.L', 'OFCmed.R', 'OFCant.L', 'OFCant.R', 'OFCpos.L', 'OFCpos.R', 'OFClat.L', 'OFClat.R', 'INS.L', 'INS.R', 'ACC.L', 'ACC.R', 'MCC.L', 'MCC.R', 'PCC.L', 'PCC.R', 'HIP.L', 'HIP.R', 'PHG.L', 'PHG.R', 'AMYG.L', 'AMYG.R', 'CAL.L', 'CAL.R', 'CUN.L', 'CUN.R', 'LING.L', 'LING.R', 'SOG.L', 'SOG.R', 'MOG.L', 'MOG.R', 'IOG.L', 'IOG.R', 'FFG.L', 'FFG.R', 'PoCG.L', 'PoCG.R', 'SPG.L', 'SPG.R', 'IPG.L', 'IPG.R', 'SMG.L', 'SMG.R', 'ANG.L', 'ANG.R', 'PCUN.L', 'PCUN.R', 'PCL.L', 'PCL.R', 'CAU.L', 'CAU.R', 'PUT.L', 'PUT.R', 'PAL.L', 'PAL.R', 'THA.L', 'THA.R', 'HES.L', 'HES.R', 'STG.L', 'STG.R', 'TPOsup.L', 'TPOsup.R', 'MTG.L', 'MTG.R', 'TPOmid.L', 'TPOmid.R', 'ITG.L', 'ITG.R'], dtype=object) Attributes: (6) name : rest meg label : signal_type : unit : T description : MEG recording in AAL2 space process_steps_0 : resample to 100.0Hz Band-Pass filter and Hilbert transform We will now filter the signal into the desidered frequency band and apply the hilbert transform on the band-passed filtered signal. This will provide us with the analytic representation of the signal, which we can then use to extract the signal's envelope and its phase. In the following, we plot each processing step for an example target region that you can chose using the widgets below (default: left Precentral Gyrus) . Furthermore, we can also choose the frequency range that we'd like to filter the signal in (default: alpha (8-12Hz)) . print ( 'Select a region from the AAL2 atlas and a frequency range' ) # Select a Region target = widgets . Select ( options = region_labels , value = 'PreCG.L' , description = 'Regions' , tooltips = [ 'Description of slow' , 'Description of regular' , 'Description of fast' ], layout = widgets . Layout ( width = '50%' , height = '150px' )) display ( target ) # Select Frequency Range freq = widgets . IntRangeSlider ( min = 1 , max = 46 , description = 'Frequency (Hz)' , value = [ 8 , 12 ], layout = widgets . Layout ( width = '80%' ), style = { 'description_width' : 'initial' }) display ( freq ) Select a region from the AAL2 atlas and a frequency range var element = $('#221f3741-a6f2-4953-ab3c-c99bd1d8e0d7'); {\"model_id\": \"41aae5986603415191ff2695f4c18988\", \"version_major\": 2, \"version_minor\": 0} var element = $('#c1de21cb-6ca3-46e8-9d10-c4a4ec1cfd06'); {\"model_id\": \"2b32589435254e43bcf5ffccadeb7aef\", \"version_major\": 2, \"version_minor\": 0} # Define how many timepoints you'd like to plot plot_timepoints = 1000 # Plot unfiltered Signal fig , ax = plt . subplots ( 2 , 1 , figsize = ( 12 , 8 ), sharex = True ) sns . lineplot ( x = signal . data . time [: plot_timepoints ], y = signal . data . sel ( regions = target . value )[: plot_timepoints ], ax = ax [ 0 ], color = 'k' , alpha = 0.6 ) ax [ 0 ] . set_title ( f 'Unfiltered Signal ( { target . value } )' ); # Band Pass Filter the Signal signal . filter ( freq . value [ 0 ], freq . value [ 1 ], inplace = True ); # Apply hilbert-transform to extract the signal envelope complex_signal = signal . hilbert_transform ( 'complex' , inplace = False ) signal_env = np . abs ( complex_signal . data ) # Plot filtered Signal and Signal Envelope sns . lineplot ( x = signal . data . time [: plot_timepoints ], y = signal . data . sel ( regions = target . value )[: plot_timepoints ], ax = ax [ 1 ], label = 'Bandpass-Filtered Signal' ) sns . lineplot ( x = signal_env . time [: plot_timepoints ], y = signal_env . sel ( regions = target . value )[: plot_timepoints ], ax = ax [ 1 ], label = 'Signal Envelope' ) ax [ 1 ] . set_title ( f 'Filtered Signal ( { target . value } )' ); ax [ 1 ] . legend ( bbox_to_anchor = ( 1.2 , 1 ), borderaxespad = 0 ) sns . despine ( trim = True ) Setting up band-pass filter from 8 - 12 Hz FIR filter parameters --------------------- Designing a one-pass, zero-phase, non-causal bandpass filter: - Windowed time-domain design (firwin) method - Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation - Lower passband edge: 8.00 - Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 7.00 Hz) - Upper passband edge: 12.00 Hz - Upper transition bandwidth: 3.00 Hz (-6 dB cutoff frequency: 13.50 Hz) - Filter length: 165 samples (1.650 sec) Orthogonalized signal envelope Now we are going to address the main methodological issue of MEG when it comes to the analysis of the cortical functional connectivity structure, i.e. its low spatial resolution. The electric field generated by any given neural source spreads widely over the cortex so that the signal captured at the MEG sensors is a complex mixture of signals from multiple underlying neural sources. To account for the effect of electric field spread on our MEG connectivity measures, we adapted the orthogonalization approach by Hipp, J., Hawellek, D., Corbetta, M. et al. Large-scale cortical correlation structure of spontaneous oscillatory activity. Nat Neurosci 15, 884\u2013890 (2012) link . The basic idea here is that a signal generated by one neural source and measured at two separate sensors must have exactly the same phase at both sensors. In contrast, signals from different neural sources have different phases. And thus it is possible to eliminate the effect of a reference signal on the target signal by removing the signal component that has the same phase as a reference region. Formally, this can be expressed as: \\(Y_{\\perp X}(t,f) = imag\\big(\\ Y(t,f)\\ \\frac{X(t,f)^\\star}{|X(t,f)|}\\ \\big)\\ \\label{eq:orth}\\) . Here, \\(Y\\) represents the analytic signal from our target regions that is being orthogonalized with respect to the signal from region \\(X\\) . Using the widgets below, you can choose the reference region \\(X\\) (default: right Precentral Gyrus) print ( 'Select a reference region for the orthogonalization' ) # Select a Region referenz = widgets . Select ( options = region_labels , value = 'PreCG.R' , description = 'Regions' , tooltips = [ 'Description of slow' , 'Description of regular' , 'Description of fast' ], layout = widgets . Layout ( width = '50%' , height = '150px' )) display ( referenz ) Select a reference region for the orthogonalization var element = $('#c96fc8f3-e9c7-4161-a584-04d3132c6ab6'); {\"model_id\": \"a504574764ac4d00bf5e0bac9ded4a3f\", \"version_major\": 2, \"version_minor\": 0} # Perform Orthogonalization signal_conj = complex_signal . data . conj () conj_div_env = signal_conj / signal_env orth_signal = ( complex_signal . data . sel ( regions = target . value ) * conj_div_env . sel ( regions = referenz . value )) . imag orth_env = np . abs ( orth_signal ) # Plot fig , ax = plt . subplots ( 2 , 1 , figsize = ( 12 , 8 ), sharex = True ) sns . lineplot ( x = signal . data . time [: plot_timepoints ], y = signal . data . sel ( regions = referenz . value )[: plot_timepoints ], ax = ax [ 0 ]) sns . lineplot ( x = signal_env . time [: plot_timepoints ], y = signal_env . sel ( regions = referenz . value )[: plot_timepoints ], ax = ax [ 0 ]) ax [ 0 ] . set_title ( f 'Referenz Region X ( { referenz . value } )' ); sns . lineplot ( x = signal . data . time [: plot_timepoints ], y = signal . data . sel ( regions = target . value )[: plot_timepoints ], ax = ax [ 1 ], label = 'Bandpass-Filtered Signal' ) sns . lineplot ( x = signal_env . time [: plot_timepoints ], y = signal_env . sel ( regions = target . value )[: plot_timepoints ], ax = ax [ 1 ], label = 'Signal Envelope' ) sns . lineplot ( x = orth_env . time [: plot_timepoints ], y = orth_env [: plot_timepoints ], ax = ax [ 1 ], label = 'Orthogonalized Envelope' ) ax [ 1 ] . legend ( bbox_to_anchor = ( 1.2 , 1 ), borderaxespad = 0 ) ax [ 1 ] . set_title ( f 'Target Region Y ( { target . value } )' ); sns . despine ( trim = True ) Low-Pass filtering of the envelopes As a last step, before calculating the envelope correlations, we need to low-pass filter the signal envelopes since the connectivity measures of (ultra)-low frequency components of the MEG-signal correspond best to the functional connectivity as measured using fMRI. Below, you can choose the low-pass frequency (default: 0.2 Hz) . low_pass = widgets . FloatSlider ( value = 0.2 , min = 0 , max = 2.0 , step = 0.1 , description = 'Low-Pass Frequency (Hz)' , disabled = False , readout = True , readout_format = '.1f' , layout = widgets . Layout ( width = '80%' ), style = { 'description_width' : 'initial' }) display ( low_pass ) var element = $('#3d0a2521-c45f-4a57-8352-1364ba07b2d2'); {\"model_id\": \"590abb91282e4a629382d424b1b3f43b\", \"version_major\": 2, \"version_minor\": 0} with io . capture_output () as captured : low_orth_env = Signal ( orth_env ) . filter ( low_freq = None , high_freq = low_pass . value , inplace = False ) low_signal_env = Signal ( signal_env . sel ( regions = referenz . value )) . filter ( low_freq = None , high_freq = low_pass . value , inplace = False ) # Plot fig , ax = plt . subplots ( 1 , 2 , figsize = ( 15 , 4 ), sharey = True ) sns . lineplot ( x = signal_env . time [: plot_timepoints ], y = signal_env . sel ( regions = referenz . value )[: plot_timepoints ], ax = ax [ 0 ]) sns . lineplot ( x = low_signal_env . data . time [: plot_timepoints ], y = low_signal_env . data [: plot_timepoints ], ax = ax [ 0 ]) ax [ 0 ] . set_title ( f 'Referenz Region X ( { referenz . value } )' ); sns . lineplot ( x = orth_env . time [: plot_timepoints ], y = orth_env [: plot_timepoints ], ax = ax [ 1 ], label = 'Orthogonalized Envelope' ) sns . lineplot ( x = low_orth_env . data . time [: plot_timepoints ], y = low_orth_env . data [: plot_timepoints ], ax = ax [ 1 ], label = 'Low-Passed Orthogonalized Envelope' ) ax [ 1 ] . legend ( bbox_to_anchor = ( 1 , - 0.18 ), borderaxespad = 0 ) ax [ 1 ] . set_title ( f 'Target Region Y ( { target . value } )' ); sns . despine ( trim = True ) print ( f 'Orthogonalized envelope correlation between { referenz . value } and { target . value } : ' , np . round ( np . corrcoef ( low_orth_env . data , low_signal_env . data )[ 0 , 1 ], 2 )) Orthogonalized envelope correlation between PreCG.R and PreCG.L: 0.13 Computing the functional connectivity matrix We will now define a function that iterates over each pair of brain regions and performs the previously presented processing steps, i.e. that extracts the envelopes, performs the orthogonalization, applies the low-pass filter, and returns the functional connectivity matrix that contains the pairwise envelope correlations. This step may take a minute. def orth_fc ( signal , low_pass ): nr_regions = signal . data . shape [ 0 ] progress = widgets . IntProgress ( min = 0 , max = nr_regions , description = ( 'Calculating FC Matrix' ), layout = widgets . Layout ( width = '80%' ), style = { 'description_width' : 'initial' }) display ( progress ) complex_signal = signal . hilbert_transform ( 'complex' , inplace = False ) signal_env = signal . hilbert_transform ( 'amplitude' , inplace = False ); conj_div_env = complex_signal . data . conj () / signal_env . data # Low-pass filter Signal envelope with io . capture_output () as captured : signal_env . filter ( low_freq = None , high_freq = low_pass ) corr = [] for complex_region in complex_signal . data : orth_signal = ( complex_region * conj_div_env ) . imag orth_env = np . abs ( orth_signal ) . T orth_env = Signal ( orth_env ) with io . capture_output () as captured : orth_env . filter ( low_freq = None , high_freq = low_pass ) corr_mat = np . corrcoef ( orth_env . data , signal_env . data ) corr . append ( np . diag ( corr_mat , k = nr_regions )) progress . value += 1 fc = np . array ( corr ) # Since the orthogonalization process is not symmetric we take the mean of both directions. fc = ( fc . T + fc ) / 2. np . fill_diagonal ( fc , 0 ) return fc # Execute Function fc = orth_fc ( signal , low_pass . value ) var element = $('#650ebf8c-0b0d-49f2-9439-e26a4cdb32d4'); {\"model_id\": \"8fedf793b5e8446d9b85a2c29c2898e3\", \"version_major\": 2, \"version_minor\": 0} Let's now plot the functional connectivity matrix. We label only every second row/column since right and left regions alternate in the AAL2 atlas. fig , ax = plt . subplots ( figsize = ( 10 , 8 )) sns . heatmap ( fc , square = True , ax = ax , cmap = 'YlGnBu' , linewidth = 0.005 , cbar_kws = { \"shrink\" : . 8 }) ticks = [ tick [: - 2 ] for tick in region_labels [:: 2 ]] ax . set_xticks ( np . arange ( 0 , 94 , 2 )); ax . set_yticks ( np . arange ( 0 , 94 , 2 )) ax . set_xticklabels ( ticks , rotation = 90 , fontsize = 8 ); ax . set_yticklabels ( ticks , rotation = 0 , fontsize = 8 ); Exclude subcortical regions For the following whole-brain simulation we are only interested in the cortical regions. So we'll now exclude all subcortical regions: * Hippocampus: 41 - 44 * Amygdala: 45-46 * Basal Ganglia: 75-80 * Thalamus: 81-82 Attention: AAL indices start with 1 exclude = list ( range ( 40 , 46 )) + list ( range ( 74 , 82 )) tmp = np . delete ( fc , exclude , axis = 0 ) emp_fc = np . delete ( tmp , exclude , axis = 1 ) # Exclude regions from the list of region labels emp_labels = np . delete ( region_labels , exclude ) Whole-brain model In this part of the notebook, we will use neurolib to simulate the functional connectivity. We will therefore: Load structural connectivity matrices from the Human Connectome Project and initiate the whole-brain model using the Wilson-Cowan model to simulate each brain region Set the global coupling strength , exc. background input , and the noise strength parameters of the model Run the simulation Compute the functional connectivity using the signal envelopes Please refer to the wc-minimal example for an introduction to the Wilson-Cowan model. Initiate whole-brain model # Let's import the neurolib from neurolib.models.wc import WCModel from neurolib.utils.loadData import Dataset # First we load the structural data set from the Human Connectome Project ds = Dataset ( \"hcp\" ) # We initiate the Wilson-Cowan model wc = WCModel ( Cmat = ds . Cmat , Dmat = ds . Dmat , seed = 0 ) Parameter settings You may now choose parameters settings for the global coupling , the excitatory background input , and the noise strength , which will be used when we run the model. The final fit between simulated and empirical connectivity matrices will depend on the parameters choosen here. global_coupling = widgets . FloatSlider ( value = 6.55 , min = 0. , max = 20.0 , step = 0.01 , description = 'Global Coupling' , disabled = False , readout = True , readout_format = '.2f' , layout = widgets . Layout ( width = '80%' ), style = { 'description_width' : 'initial' }) exc_drive = widgets . FloatSlider ( value = 1.58 , min = 0.0 , max = 4.0 , step = 0.01 , description = 'Exc. Background Drive' , disabled = False , readout = True , readout_format = '.2f' , layout = widgets . Layout ( width = '80%' ), style = { 'description_width' : 'initial' }) inh_drive = widgets . FloatSlider ( value = 2.83 , min = 0.0 , max = 4.0 , step = 0.01 , description = 'Inh. Background Drive' , disabled = False , readout = True , readout_format = '.2f' , layout = widgets . Layout ( width = '80%' ), style = { 'description_width' : 'initial' }) noise_level = widgets . FloatSlider ( value = 0.02 , min = 0.001 , max = 0.05 , step = 0.001 , description = 'Noise Level' , disabled = False , readout = True , readout_format = '.3f' , layout = widgets . Layout ( width = '80%' ), style = { 'description_width' : 'initial' }) display ( global_coupling ) display ( exc_drive ) display ( inh_drive ) display ( noise_level ) var element = $('#2ca3de81-6306-4003-8785-83ad823c60fc'); {\"model_id\": \"7662588d0a0e4afbacf45b59966e2e39\", \"version_major\": 2, \"version_minor\": 0} var element = $('#812f5481-97a4-43ee-8ce7-dc9cfe0e7e22'); {\"model_id\": \"f719be98bca94fa3a5b56d33ae923b2a\", \"version_major\": 2, \"version_minor\": 0} var element = $('#50c7c05c-2712-4b2a-bb16-9a2507aa4d8f'); {\"model_id\": \"b76f3cb668664e35b89c73ec66af9fb3\", \"version_major\": 2, \"version_minor\": 0} var element = $('#d53718dd-1f6d-48b9-a561-d8fef1c77180'); {\"model_id\": \"401a2193341040ff9edeccc67a69cc65\", \"version_major\": 2, \"version_minor\": 0} Run the simulation Let's now run the whole-brain model using the defined parameter settings. This may take some time since we're simulating a complete minute here. # Let's set the previously defined parameters # note: the duraiton here is short for testing: wc . params [ 'duration' ] = 10 * 1000 # use longer simulation for real run: #wc.params['duration'] = 1*60*1000 wc . params [ 'K_gl' ] = global_coupling . value wc . params [ 'exc_ext' ] = exc_drive . value wc . params [ 'inh_ext' ] = inh_drive . value wc . params [ 'sigma_ou' ] = noise_level . value # Run the model wc . run () Simulated functional connectivity We'll now compute the functional connectivity matrix containing the pairwise envelope correlations between all cortical regions of the AAL2 atlas. We'll thus follow the processing steps as before, i.e. band-pass filter the signal, extract the signal envelopes using the hilbert transformation, low-pass filter the envelopes and compute the pairwise pearson correlations. Note that we don't apply the orthogonalization scheme here, since this was only done to account to the electric field spread in the empirical data. # Create xr DataArray from the simulated excitatory timeseries (keeping the region labels) sim_signal = xr . DataArray ( wc . exc [:, int ( 1000 / wc . params . dt ):], dims = ( \"regions\" , \"time\" ), coords = { \"regions\" : emp_labels , \"time\" : wc . t [ int ( 1000 / wc . params . dt ):] / 1000 }, attrs = { 'atlas' : 'AAL2' }) # Initialize Figure fig , ax = plt . subplots ( figsize = ( 12 , 4 )) # Filter signal sim_signal = Signal ( sim_signal ) sim_signal . resample ( to_frequency = 100 ) with io . capture_output () as captured : sim_signal . filter ( freq . value [ 0 ], freq . value [ 1 ], inplace = True ); sns . lineplot ( x = sim_signal . data . time [: plot_timepoints ], y = sim_signal . data . sel ( regions = target . value )[: plot_timepoints ], ax = ax , label = 'Filtered Signal' ) # Extract signal envelope sim_signal . hilbert_transform ( 'amplitude' , inplace = True ) sns . lineplot ( x = sim_signal . data . time [: plot_timepoints ], y = sim_signal . data . sel ( regions = target . value )[: plot_timepoints ], ax = ax , label = 'Signal Envelope' ) # Low-Pass Filter with io . capture_output () as captured : sim_signal . filter ( low_freq = None , high_freq = low_pass . value , inplace = True ) sns . lineplot ( x = sim_signal . data . time [: plot_timepoints ], y = sim_signal . data . sel ( regions = target . value )[: plot_timepoints ], ax = ax , label = 'Low-Pass Signal Envelope' ) ax . legend ( bbox_to_anchor = ( 1.2 , 1 ), borderaxespad = 0 ) ax . set_title ( f 'Simulated Signal of Target Region Y ( { target . value } )' ); sns . despine ( trim = True ) To compute the simulated functional connectivity matrix we use the fc functions from neurolib. import neurolib.utils.functions as func # Compute the functional connectivity matrix sim_fc = func . fc ( sim_signal . data ) # Set diagonal to zero np . fill_diagonal ( sim_fc , 0 ) # Plot Empirical and simulated connectivity matrix fig , ax = plt . subplots ( 1 , 2 , figsize = ( 16 , 10 )) sns . heatmap ( emp_fc , square = True , ax = ax [ 0 ], cmap = 'YlGnBu' , linewidth = 0.005 , cbar_kws = { \"shrink\" : . 5 }) ax [ 0 ] . set_title ( 'Empirical FC' , pad = 10 ); sns . heatmap ( sim_fc , square = True , ax = ax [ 1 ], cmap = 'YlGnBu' , linewidth = 0.005 , cbar_kws = { \"shrink\" : . 5 }) ax [ 1 ] . set_title ( 'Simulated FC' , pad = 10 ); ticks = [ tick [: - 2 ] for tick in emp_labels [:: 2 ]] for ax in ax : ax . set_xticks ( np . arange ( 0 , 80 , 2 )); ax . set_yticks ( np . arange ( 0 , 80 , 2 )) ax . set_xticklabels ( ticks , rotation = 90 , fontsize = 8 ); ax . set_yticklabels ( ticks , rotation = 0 , fontsize = 8 ); Model fit Lastly, we may evaluate the model fit by computing the pearson correlation between our simulated functional connectivity matrix and the empirical one. Additionally we'll also plot the correlation between structural and functional connectivity matrices to have a reference. # Compare structural and simulated connectivity to the empirical functional connectivity struct_emp = np . corrcoef ( emp_fc . flatten (), ds . Cmat . flatten ())[ 0 , 1 ] sim_emp = np . corrcoef ( emp_fc . flatten (), sim_fc . flatten ())[ 0 , 1 ] # Plot fig , ax = plt . subplots ( figsize = ( 6 , 6 )) splot = sns . barplot ( x = [ 'Structural Connectivity' , 'Simulated Connectivity' ], y = [ struct_emp , sim_emp ], ax = ax ) ax . set_title ( 'Correlation to Empiral Functional Connectivity' , pad = 10 ) for p in splot . patches : splot . annotate ( format ( p . get_height (), '.2f' ), ( p . get_x () + p . get_width () / 2. , p . get_height ()), ha = 'center' , va = 'center' , size = 20 , color = 'white' , xytext = ( 0 , - 12 ), textcoords = 'offset points' ) sns . despine () print ( f \"Parameters: \\t Global Coupling: { wc . params [ 'K_gl' ] } \\n\\t\\t Exc. Background Drive: { wc . params [ 'exc_ext' ] } \" ) print ( f \" \\t\\t Noise Level: { wc . params [ 'sigma_ou' ] } \" ) Parameters: Global Coupling: 6.55 Exc. Background Drive: 1.58 Noise Level: 0.02","title":"Example 3 meg functional connectivity"},{"location":"examples/example-3-meg-functional-connectivity/#modeling-resting-state-meg-data","text":"In this example we will learn how to use neurolib to simulate resting state functional connectivity of MEG recordings. In the first part of the notebook, we will compute the frequency specific functional connectivity matrix of an examplary resting state MEG recording from the YouR-Study Uhlhaas, P.J., Gajwani, R., Gross, J. et al. The Youth Mental Health Risk and Resilience Study (YouR-Study). BMC Psychiatry 17, 43 (2017) . To this end we will: Band-Pass filter the signal Apply the hilbert -transformation to extract the signal envelope Orthogonalize the signal envelopes of two examplary regions Low-Pass filter the signal envelopes and compute the pairwise envelope correlations which yields the functional connectivity matrix. We follow the approach presented in Hipp, J., Hawellek, D., Corbetta, M. et al. , Large-scale cortical correlation structure of spontaneous oscillatory activity. Nat Neurosci 15, 884\u2013890 (2012) In the second part of this notebook, we will use a whole-brain model to simulate brain activity and compute functional connectivity matrix of the simulated signal envelope, as was done for the empirical MEG data. The parameters of this model have been previously optimized with neurolib 's evolutionary algorithms (not shown here). Finally, we will compute the fit (Pearson correlation) of the simulated functional connectivity to the empirical MEG data, which was used as a fitting objective in a previous optimization procedure. # change to the root directory of the project import os if os . getcwd () . split ( \"/\" )[ - 1 ] == \"examples\" : os . chdir ( '..' ) # This will reload all imports as soon as the code changes % load_ext autoreload % autoreload 2 import os import numpy as np import xarray as xr import matplotlib.pyplot as plt import seaborn as sns import ipywidgets as widgets from IPython.utils import io import warnings warnings . simplefilter ( action = 'ignore' , category = FutureWarning ) import time import pandas as pd","title":"Modeling resting-state MEG-Data"},{"location":"examples/example-3-meg-functional-connectivity/#empirical-functional-connectivity","text":"","title":"Empirical Functional Connectivity"},{"location":"examples/example-3-meg-functional-connectivity/#load-meg-data","text":"First off, let's load the MEG data using the Signal class from neurolib . Our example data has already been preprocessed and projected into source space using the AAL2 atlas. from neurolib.utils.signal import Signal signal = Signal . from_file ( os . path . join ( 'examples' , 'data' , 'rs-meg.nc' )) region_labels = signal . data . regions . values nr_regions = len ( region_labels ) display ( signal . data ) /* CSS stylesheet for displaying xarray objects in jupyterlab. * */ :root { --xr-font-color0: var(--jp-content-font-color0, rgba(0, 0, 0, 1)); --xr-font-color2: var(--jp-content-font-color2, rgba(0, 0, 0, 0.54)); --xr-font-color3: var(--jp-content-font-color3, rgba(0, 0, 0, 0.38)); --xr-border-color: var(--jp-border-color2, #e0e0e0); --xr-disabled-color: var(--jp-layout-color3, #bdbdbd); --xr-background-color: var(--jp-layout-color0, white); --xr-background-color-row-even: var(--jp-layout-color1, white); --xr-background-color-row-odd: var(--jp-layout-color2, #eeeeee); } html[theme=dark], body.vscode-dark { --xr-font-color0: rgba(255, 255, 255, 1); --xr-font-color2: rgba(255, 255, 255, 0.54); --xr-font-color3: rgba(255, 255, 255, 0.38); --xr-border-color: #1F1F1F; --xr-disabled-color: #515151; --xr-background-color: #111111; --xr-background-color-row-even: #111111; --xr-background-color-row-odd: #313131; } .xr-wrap { display: block; min-width: 300px; max-width: 700px; } .xr-text-repr-fallback { /* fallback to plain text repr when CSS is not injected (untrusted notebook) */ display: none; } .xr-header { padding-top: 6px; padding-bottom: 6px; margin-bottom: 4px; border-bottom: solid 1px var(--xr-border-color); } .xr-header > div, .xr-header > ul { display: inline; margin-top: 0; margin-bottom: 0; } .xr-obj-type, .xr-array-name { margin-left: 2px; margin-right: 10px; } .xr-obj-type { color: var(--xr-font-color2); } .xr-sections { padding-left: 0 !important; display: grid; grid-template-columns: 150px auto auto 1fr 20px 20px; } .xr-section-item { display: contents; } .xr-section-item input { display: none; } .xr-section-item input + label { color: var(--xr-disabled-color); } .xr-section-item input:enabled + label { cursor: pointer; color: var(--xr-font-color2); } .xr-section-item input:enabled + label:hover { color: var(--xr-font-color0); } .xr-section-summary { grid-column: 1; color: var(--xr-font-color2); font-weight: 500; } .xr-section-summary > span { display: inline-block; padding-left: 0.5em; } .xr-section-summary-in:disabled + label { color: var(--xr-font-color2); } .xr-section-summary-in + label:before { display: inline-block; content: '\u25ba'; font-size: 11px; width: 15px; text-align: center; } .xr-section-summary-in:disabled + label:before { color: var(--xr-disabled-color); } .xr-section-summary-in:checked + label:before { content: '\u25bc'; } .xr-section-summary-in:checked + label > span { display: none; } .xr-section-summary, .xr-section-inline-details { padding-top: 4px; padding-bottom: 4px; } .xr-section-inline-details { grid-column: 2 / -1; } .xr-section-details { display: none; grid-column: 1 / -1; margin-bottom: 5px; } .xr-section-summary-in:checked ~ .xr-section-details { display: contents; } .xr-array-wrap { grid-column: 1 / -1; display: grid; grid-template-columns: 20px auto; } .xr-array-wrap > label { grid-column: 1; vertical-align: top; } .xr-preview { color: var(--xr-font-color3); } .xr-array-preview, .xr-array-data { padding: 0 5px !important; grid-column: 2; } .xr-array-data, .xr-array-in:checked ~ .xr-array-preview { display: none; } .xr-array-in:checked ~ .xr-array-data, .xr-array-preview { display: inline-block; } .xr-dim-list { display: inline-block !important; list-style: none; padding: 0 !important; margin: 0; } .xr-dim-list li { display: inline-block; padding: 0; margin: 0; } .xr-dim-list:before { content: '('; } .xr-dim-list:after { content: ')'; } .xr-dim-list li:not(:last-child):after { content: ','; padding-right: 5px; } .xr-has-index { font-weight: bold; } .xr-var-list, .xr-var-item { display: contents; } .xr-var-item > div, .xr-var-item label, .xr-var-item > .xr-var-name span { background-color: var(--xr-background-color-row-even); margin-bottom: 0; } .xr-var-item > .xr-var-name:hover span { padding-right: 5px; } .xr-var-list > li:nth-child(odd) > div, .xr-var-list > li:nth-child(odd) > label, .xr-var-list > li:nth-child(odd) > .xr-var-name span { background-color: var(--xr-background-color-row-odd); } .xr-var-name { grid-column: 1; } .xr-var-dims { grid-column: 2; } .xr-var-dtype { grid-column: 3; text-align: right; color: var(--xr-font-color2); } .xr-var-preview { grid-column: 4; } .xr-var-name, .xr-var-dims, .xr-var-dtype, .xr-preview, .xr-attrs dt { white-space: nowrap; overflow: hidden; text-overflow: ellipsis; padding-right: 10px; } .xr-var-name:hover, .xr-var-dims:hover, .xr-var-dtype:hover, .xr-attrs dt:hover { overflow: visible; width: auto; z-index: 1; } .xr-var-attrs, .xr-var-data { display: none; background-color: var(--xr-background-color) !important; padding-bottom: 5px !important; } .xr-var-attrs-in:checked ~ .xr-var-attrs, .xr-var-data-in:checked ~ .xr-var-data { display: block; } .xr-var-data > table { float: right; } .xr-var-name span, .xr-var-data, .xr-attrs { padding-left: 25px !important; } .xr-attrs, .xr-var-attrs, .xr-var-data { grid-column: 1 / -1; } dl.xr-attrs { padding: 0; margin: 0; display: grid; grid-template-columns: 125px auto; } .xr-attrs dt, .xr-attrs dd { padding: 0; margin: 0; float: left; padding-right: 10px; width: auto; } .xr-attrs dt { font-weight: normal; grid-column: 1; } .xr-attrs dt:hover span { display: inline-block; background: var(--xr-background-color); padding-right: 10px; } .xr-attrs dd { grid-column: 2; white-space: pre-wrap; word-break: break-all; } .xr-icon-database, .xr-icon-file-text2 { display: inline-block; vertical-align: middle; width: 1em; height: 1.5em !important; stroke-width: 0; stroke: currentColor; fill: currentColor; } <xarray.DataArray (regions: 94, time: 6000)> array([[-0.17628077, -0.33449804, -0.27283166, ..., 0.20004052, 0.19379806, 0.0271034 ], [ 0.00513031, 0.0319704 , 0.18478207, ..., 0.22112991, 0.30244658, 0.21108818], [ 0.01999333, -0.1601617 , -0.21931987, ..., 0.01844522, -0.03713842, 0.08175757], ..., [-0.2381615 , -0.34838511, -0.50638238, ..., -0.08763395, -0.05396606, -0.06218967], [-0.09900261, -0.1525903 , -0.16444704, ..., 0.04080438, 0.01664182, 0.15847579], [ 0.13203698, 0.17482835, 0.21212731, ..., -0.19971229, -0.01869223, -0.16379495]]) Coordinates: * time (time) float64 0.0 0.01 0.02 0.03 0.04 ... 59.96 59.97 59.98 59.99 * regions (regions) object 'PreCG.L' 'PreCG.R' 'SFG.L' ... 'ITG.L' 'ITG.R' Attributes: name: rest meg label: signal_type: unit: T description: MEG recording in AAL2 space process_steps_0: resample to 100.0Hz xarray.DataArray regions : 94 time : 6000 -0.1763 -0.3345 -0.2728 -0.1313 ... -0.2128 -0.1997 -0.01869 -0.1638 array([[-0.17628077, -0.33449804, -0.27283166, ..., 0.20004052, 0.19379806, 0.0271034 ], [ 0.00513031, 0.0319704 , 0.18478207, ..., 0.22112991, 0.30244658, 0.21108818], [ 0.01999333, -0.1601617 , -0.21931987, ..., 0.01844522, -0.03713842, 0.08175757], ..., [-0.2381615 , -0.34838511, -0.50638238, ..., -0.08763395, -0.05396606, -0.06218967], [-0.09900261, -0.1525903 , -0.16444704, ..., 0.04080438, 0.01664182, 0.15847579], [ 0.13203698, 0.17482835, 0.21212731, ..., -0.19971229, -0.01869223, -0.16379495]]) Coordinates: (2) time (time) float64 0.0 0.01 0.02 ... 59.97 59.98 59.99 array([0.000e+00, 1.000e-02, 2.000e-02, ..., 5.997e+01, 5.998e+01, 5.999e+01]) regions (regions) object 'PreCG.L' 'PreCG.R' ... 'ITG.R' array(['PreCG.L', 'PreCG.R', 'SFG.L', 'SFG.R', 'MFG.L', 'MFG.R', 'IFGoperc.L', 'IFGoperc.R', 'IFGtriang.L', 'IFGtriang.R', 'IFGorb.L', 'IFGorb.R', 'ROL.L', 'ROL.R', 'SMA.L', 'SMA.R', 'OLF.L', 'OLF.R', 'SFGmed.L', 'SFGmed.R', 'PFCventmed.L', 'PFCventmed.R', 'REC.L', 'REC.R', 'OFCmed.L', 'OFCmed.R', 'OFCant.L', 'OFCant.R', 'OFCpos.L', 'OFCpos.R', 'OFClat.L', 'OFClat.R', 'INS.L', 'INS.R', 'ACC.L', 'ACC.R', 'MCC.L', 'MCC.R', 'PCC.L', 'PCC.R', 'HIP.L', 'HIP.R', 'PHG.L', 'PHG.R', 'AMYG.L', 'AMYG.R', 'CAL.L', 'CAL.R', 'CUN.L', 'CUN.R', 'LING.L', 'LING.R', 'SOG.L', 'SOG.R', 'MOG.L', 'MOG.R', 'IOG.L', 'IOG.R', 'FFG.L', 'FFG.R', 'PoCG.L', 'PoCG.R', 'SPG.L', 'SPG.R', 'IPG.L', 'IPG.R', 'SMG.L', 'SMG.R', 'ANG.L', 'ANG.R', 'PCUN.L', 'PCUN.R', 'PCL.L', 'PCL.R', 'CAU.L', 'CAU.R', 'PUT.L', 'PUT.R', 'PAL.L', 'PAL.R', 'THA.L', 'THA.R', 'HES.L', 'HES.R', 'STG.L', 'STG.R', 'TPOsup.L', 'TPOsup.R', 'MTG.L', 'MTG.R', 'TPOmid.L', 'TPOmid.R', 'ITG.L', 'ITG.R'], dtype=object) Attributes: (6) name : rest meg label : signal_type : unit : T description : MEG recording in AAL2 space process_steps_0 : resample to 100.0Hz","title":"Load MEG-Data"},{"location":"examples/example-3-meg-functional-connectivity/#band-pass-filter-and-hilbert-transform","text":"We will now filter the signal into the desidered frequency band and apply the hilbert transform on the band-passed filtered signal. This will provide us with the analytic representation of the signal, which we can then use to extract the signal's envelope and its phase. In the following, we plot each processing step for an example target region that you can chose using the widgets below (default: left Precentral Gyrus) . Furthermore, we can also choose the frequency range that we'd like to filter the signal in (default: alpha (8-12Hz)) . print ( 'Select a region from the AAL2 atlas and a frequency range' ) # Select a Region target = widgets . Select ( options = region_labels , value = 'PreCG.L' , description = 'Regions' , tooltips = [ 'Description of slow' , 'Description of regular' , 'Description of fast' ], layout = widgets . Layout ( width = '50%' , height = '150px' )) display ( target ) # Select Frequency Range freq = widgets . IntRangeSlider ( min = 1 , max = 46 , description = 'Frequency (Hz)' , value = [ 8 , 12 ], layout = widgets . Layout ( width = '80%' ), style = { 'description_width' : 'initial' }) display ( freq ) Select a region from the AAL2 atlas and a frequency range var element = $('#221f3741-a6f2-4953-ab3c-c99bd1d8e0d7'); {\"model_id\": \"41aae5986603415191ff2695f4c18988\", \"version_major\": 2, \"version_minor\": 0} var element = $('#c1de21cb-6ca3-46e8-9d10-c4a4ec1cfd06'); {\"model_id\": \"2b32589435254e43bcf5ffccadeb7aef\", \"version_major\": 2, \"version_minor\": 0} # Define how many timepoints you'd like to plot plot_timepoints = 1000 # Plot unfiltered Signal fig , ax = plt . subplots ( 2 , 1 , figsize = ( 12 , 8 ), sharex = True ) sns . lineplot ( x = signal . data . time [: plot_timepoints ], y = signal . data . sel ( regions = target . value )[: plot_timepoints ], ax = ax [ 0 ], color = 'k' , alpha = 0.6 ) ax [ 0 ] . set_title ( f 'Unfiltered Signal ( { target . value } )' ); # Band Pass Filter the Signal signal . filter ( freq . value [ 0 ], freq . value [ 1 ], inplace = True ); # Apply hilbert-transform to extract the signal envelope complex_signal = signal . hilbert_transform ( 'complex' , inplace = False ) signal_env = np . abs ( complex_signal . data ) # Plot filtered Signal and Signal Envelope sns . lineplot ( x = signal . data . time [: plot_timepoints ], y = signal . data . sel ( regions = target . value )[: plot_timepoints ], ax = ax [ 1 ], label = 'Bandpass-Filtered Signal' ) sns . lineplot ( x = signal_env . time [: plot_timepoints ], y = signal_env . sel ( regions = target . value )[: plot_timepoints ], ax = ax [ 1 ], label = 'Signal Envelope' ) ax [ 1 ] . set_title ( f 'Filtered Signal ( { target . value } )' ); ax [ 1 ] . legend ( bbox_to_anchor = ( 1.2 , 1 ), borderaxespad = 0 ) sns . despine ( trim = True ) Setting up band-pass filter from 8 - 12 Hz FIR filter parameters --------------------- Designing a one-pass, zero-phase, non-causal bandpass filter: - Windowed time-domain design (firwin) method - Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation - Lower passband edge: 8.00 - Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 7.00 Hz) - Upper passband edge: 12.00 Hz - Upper transition bandwidth: 3.00 Hz (-6 dB cutoff frequency: 13.50 Hz) - Filter length: 165 samples (1.650 sec)","title":"Band-Pass filter and Hilbert transform"},{"location":"examples/example-3-meg-functional-connectivity/#orthogonalized-signal-envelope","text":"Now we are going to address the main methodological issue of MEG when it comes to the analysis of the cortical functional connectivity structure, i.e. its low spatial resolution. The electric field generated by any given neural source spreads widely over the cortex so that the signal captured at the MEG sensors is a complex mixture of signals from multiple underlying neural sources. To account for the effect of electric field spread on our MEG connectivity measures, we adapted the orthogonalization approach by Hipp, J., Hawellek, D., Corbetta, M. et al. Large-scale cortical correlation structure of spontaneous oscillatory activity. Nat Neurosci 15, 884\u2013890 (2012) link . The basic idea here is that a signal generated by one neural source and measured at two separate sensors must have exactly the same phase at both sensors. In contrast, signals from different neural sources have different phases. And thus it is possible to eliminate the effect of a reference signal on the target signal by removing the signal component that has the same phase as a reference region. Formally, this can be expressed as: \\(Y_{\\perp X}(t,f) = imag\\big(\\ Y(t,f)\\ \\frac{X(t,f)^\\star}{|X(t,f)|}\\ \\big)\\ \\label{eq:orth}\\) . Here, \\(Y\\) represents the analytic signal from our target regions that is being orthogonalized with respect to the signal from region \\(X\\) . Using the widgets below, you can choose the reference region \\(X\\) (default: right Precentral Gyrus) print ( 'Select a reference region for the orthogonalization' ) # Select a Region referenz = widgets . Select ( options = region_labels , value = 'PreCG.R' , description = 'Regions' , tooltips = [ 'Description of slow' , 'Description of regular' , 'Description of fast' ], layout = widgets . Layout ( width = '50%' , height = '150px' )) display ( referenz ) Select a reference region for the orthogonalization var element = $('#c96fc8f3-e9c7-4161-a584-04d3132c6ab6'); {\"model_id\": \"a504574764ac4d00bf5e0bac9ded4a3f\", \"version_major\": 2, \"version_minor\": 0} # Perform Orthogonalization signal_conj = complex_signal . data . conj () conj_div_env = signal_conj / signal_env orth_signal = ( complex_signal . data . sel ( regions = target . value ) * conj_div_env . sel ( regions = referenz . value )) . imag orth_env = np . abs ( orth_signal ) # Plot fig , ax = plt . subplots ( 2 , 1 , figsize = ( 12 , 8 ), sharex = True ) sns . lineplot ( x = signal . data . time [: plot_timepoints ], y = signal . data . sel ( regions = referenz . value )[: plot_timepoints ], ax = ax [ 0 ]) sns . lineplot ( x = signal_env . time [: plot_timepoints ], y = signal_env . sel ( regions = referenz . value )[: plot_timepoints ], ax = ax [ 0 ]) ax [ 0 ] . set_title ( f 'Referenz Region X ( { referenz . value } )' ); sns . lineplot ( x = signal . data . time [: plot_timepoints ], y = signal . data . sel ( regions = target . value )[: plot_timepoints ], ax = ax [ 1 ], label = 'Bandpass-Filtered Signal' ) sns . lineplot ( x = signal_env . time [: plot_timepoints ], y = signal_env . sel ( regions = target . value )[: plot_timepoints ], ax = ax [ 1 ], label = 'Signal Envelope' ) sns . lineplot ( x = orth_env . time [: plot_timepoints ], y = orth_env [: plot_timepoints ], ax = ax [ 1 ], label = 'Orthogonalized Envelope' ) ax [ 1 ] . legend ( bbox_to_anchor = ( 1.2 , 1 ), borderaxespad = 0 ) ax [ 1 ] . set_title ( f 'Target Region Y ( { target . value } )' ); sns . despine ( trim = True )","title":"Orthogonalized signal envelope"},{"location":"examples/example-3-meg-functional-connectivity/#low-pass-filtering-of-the-envelopes","text":"As a last step, before calculating the envelope correlations, we need to low-pass filter the signal envelopes since the connectivity measures of (ultra)-low frequency components of the MEG-signal correspond best to the functional connectivity as measured using fMRI. Below, you can choose the low-pass frequency (default: 0.2 Hz) . low_pass = widgets . FloatSlider ( value = 0.2 , min = 0 , max = 2.0 , step = 0.1 , description = 'Low-Pass Frequency (Hz)' , disabled = False , readout = True , readout_format = '.1f' , layout = widgets . Layout ( width = '80%' ), style = { 'description_width' : 'initial' }) display ( low_pass ) var element = $('#3d0a2521-c45f-4a57-8352-1364ba07b2d2'); {\"model_id\": \"590abb91282e4a629382d424b1b3f43b\", \"version_major\": 2, \"version_minor\": 0} with io . capture_output () as captured : low_orth_env = Signal ( orth_env ) . filter ( low_freq = None , high_freq = low_pass . value , inplace = False ) low_signal_env = Signal ( signal_env . sel ( regions = referenz . value )) . filter ( low_freq = None , high_freq = low_pass . value , inplace = False ) # Plot fig , ax = plt . subplots ( 1 , 2 , figsize = ( 15 , 4 ), sharey = True ) sns . lineplot ( x = signal_env . time [: plot_timepoints ], y = signal_env . sel ( regions = referenz . value )[: plot_timepoints ], ax = ax [ 0 ]) sns . lineplot ( x = low_signal_env . data . time [: plot_timepoints ], y = low_signal_env . data [: plot_timepoints ], ax = ax [ 0 ]) ax [ 0 ] . set_title ( f 'Referenz Region X ( { referenz . value } )' ); sns . lineplot ( x = orth_env . time [: plot_timepoints ], y = orth_env [: plot_timepoints ], ax = ax [ 1 ], label = 'Orthogonalized Envelope' ) sns . lineplot ( x = low_orth_env . data . time [: plot_timepoints ], y = low_orth_env . data [: plot_timepoints ], ax = ax [ 1 ], label = 'Low-Passed Orthogonalized Envelope' ) ax [ 1 ] . legend ( bbox_to_anchor = ( 1 , - 0.18 ), borderaxespad = 0 ) ax [ 1 ] . set_title ( f 'Target Region Y ( { target . value } )' ); sns . despine ( trim = True ) print ( f 'Orthogonalized envelope correlation between { referenz . value } and { target . value } : ' , np . round ( np . corrcoef ( low_orth_env . data , low_signal_env . data )[ 0 , 1 ], 2 )) Orthogonalized envelope correlation between PreCG.R and PreCG.L: 0.13","title":"Low-Pass filtering of the envelopes"},{"location":"examples/example-3-meg-functional-connectivity/#computing-the-functional-connectivity-matrix","text":"We will now define a function that iterates over each pair of brain regions and performs the previously presented processing steps, i.e. that extracts the envelopes, performs the orthogonalization, applies the low-pass filter, and returns the functional connectivity matrix that contains the pairwise envelope correlations. This step may take a minute. def orth_fc ( signal , low_pass ): nr_regions = signal . data . shape [ 0 ] progress = widgets . IntProgress ( min = 0 , max = nr_regions , description = ( 'Calculating FC Matrix' ), layout = widgets . Layout ( width = '80%' ), style = { 'description_width' : 'initial' }) display ( progress ) complex_signal = signal . hilbert_transform ( 'complex' , inplace = False ) signal_env = signal . hilbert_transform ( 'amplitude' , inplace = False ); conj_div_env = complex_signal . data . conj () / signal_env . data # Low-pass filter Signal envelope with io . capture_output () as captured : signal_env . filter ( low_freq = None , high_freq = low_pass ) corr = [] for complex_region in complex_signal . data : orth_signal = ( complex_region * conj_div_env ) . imag orth_env = np . abs ( orth_signal ) . T orth_env = Signal ( orth_env ) with io . capture_output () as captured : orth_env . filter ( low_freq = None , high_freq = low_pass ) corr_mat = np . corrcoef ( orth_env . data , signal_env . data ) corr . append ( np . diag ( corr_mat , k = nr_regions )) progress . value += 1 fc = np . array ( corr ) # Since the orthogonalization process is not symmetric we take the mean of both directions. fc = ( fc . T + fc ) / 2. np . fill_diagonal ( fc , 0 ) return fc # Execute Function fc = orth_fc ( signal , low_pass . value ) var element = $('#650ebf8c-0b0d-49f2-9439-e26a4cdb32d4'); {\"model_id\": \"8fedf793b5e8446d9b85a2c29c2898e3\", \"version_major\": 2, \"version_minor\": 0} Let's now plot the functional connectivity matrix. We label only every second row/column since right and left regions alternate in the AAL2 atlas. fig , ax = plt . subplots ( figsize = ( 10 , 8 )) sns . heatmap ( fc , square = True , ax = ax , cmap = 'YlGnBu' , linewidth = 0.005 , cbar_kws = { \"shrink\" : . 8 }) ticks = [ tick [: - 2 ] for tick in region_labels [:: 2 ]] ax . set_xticks ( np . arange ( 0 , 94 , 2 )); ax . set_yticks ( np . arange ( 0 , 94 , 2 )) ax . set_xticklabels ( ticks , rotation = 90 , fontsize = 8 ); ax . set_yticklabels ( ticks , rotation = 0 , fontsize = 8 );","title":"Computing the functional connectivity matrix"},{"location":"examples/example-3-meg-functional-connectivity/#exclude-subcortical-regions","text":"For the following whole-brain simulation we are only interested in the cortical regions. So we'll now exclude all subcortical regions: * Hippocampus: 41 - 44 * Amygdala: 45-46 * Basal Ganglia: 75-80 * Thalamus: 81-82 Attention: AAL indices start with 1 exclude = list ( range ( 40 , 46 )) + list ( range ( 74 , 82 )) tmp = np . delete ( fc , exclude , axis = 0 ) emp_fc = np . delete ( tmp , exclude , axis = 1 ) # Exclude regions from the list of region labels emp_labels = np . delete ( region_labels , exclude )","title":"Exclude subcortical regions"},{"location":"examples/example-3-meg-functional-connectivity/#whole-brain-model","text":"In this part of the notebook, we will use neurolib to simulate the functional connectivity. We will therefore: Load structural connectivity matrices from the Human Connectome Project and initiate the whole-brain model using the Wilson-Cowan model to simulate each brain region Set the global coupling strength , exc. background input , and the noise strength parameters of the model Run the simulation Compute the functional connectivity using the signal envelopes Please refer to the wc-minimal example for an introduction to the Wilson-Cowan model.","title":"Whole-brain model"},{"location":"examples/example-3-meg-functional-connectivity/#initiate-whole-brain-model","text":"# Let's import the neurolib from neurolib.models.wc import WCModel from neurolib.utils.loadData import Dataset # First we load the structural data set from the Human Connectome Project ds = Dataset ( \"hcp\" ) # We initiate the Wilson-Cowan model wc = WCModel ( Cmat = ds . Cmat , Dmat = ds . Dmat , seed = 0 )","title":"Initiate whole-brain model"},{"location":"examples/example-3-meg-functional-connectivity/#parameter-settings","text":"You may now choose parameters settings for the global coupling , the excitatory background input , and the noise strength , which will be used when we run the model. The final fit between simulated and empirical connectivity matrices will depend on the parameters choosen here. global_coupling = widgets . FloatSlider ( value = 6.55 , min = 0. , max = 20.0 , step = 0.01 , description = 'Global Coupling' , disabled = False , readout = True , readout_format = '.2f' , layout = widgets . Layout ( width = '80%' ), style = { 'description_width' : 'initial' }) exc_drive = widgets . FloatSlider ( value = 1.58 , min = 0.0 , max = 4.0 , step = 0.01 , description = 'Exc. Background Drive' , disabled = False , readout = True , readout_format = '.2f' , layout = widgets . Layout ( width = '80%' ), style = { 'description_width' : 'initial' }) inh_drive = widgets . FloatSlider ( value = 2.83 , min = 0.0 , max = 4.0 , step = 0.01 , description = 'Inh. Background Drive' , disabled = False , readout = True , readout_format = '.2f' , layout = widgets . Layout ( width = '80%' ), style = { 'description_width' : 'initial' }) noise_level = widgets . FloatSlider ( value = 0.02 , min = 0.001 , max = 0.05 , step = 0.001 , description = 'Noise Level' , disabled = False , readout = True , readout_format = '.3f' , layout = widgets . Layout ( width = '80%' ), style = { 'description_width' : 'initial' }) display ( global_coupling ) display ( exc_drive ) display ( inh_drive ) display ( noise_level ) var element = $('#2ca3de81-6306-4003-8785-83ad823c60fc'); {\"model_id\": \"7662588d0a0e4afbacf45b59966e2e39\", \"version_major\": 2, \"version_minor\": 0} var element = $('#812f5481-97a4-43ee-8ce7-dc9cfe0e7e22'); {\"model_id\": \"f719be98bca94fa3a5b56d33ae923b2a\", \"version_major\": 2, \"version_minor\": 0} var element = $('#50c7c05c-2712-4b2a-bb16-9a2507aa4d8f'); {\"model_id\": \"b76f3cb668664e35b89c73ec66af9fb3\", \"version_major\": 2, \"version_minor\": 0} var element = $('#d53718dd-1f6d-48b9-a561-d8fef1c77180'); {\"model_id\": \"401a2193341040ff9edeccc67a69cc65\", \"version_major\": 2, \"version_minor\": 0}","title":"Parameter settings"},{"location":"examples/example-3-meg-functional-connectivity/#run-the-simulation","text":"Let's now run the whole-brain model using the defined parameter settings. This may take some time since we're simulating a complete minute here. # Let's set the previously defined parameters # note: the duraiton here is short for testing: wc . params [ 'duration' ] = 10 * 1000 # use longer simulation for real run: #wc.params['duration'] = 1*60*1000 wc . params [ 'K_gl' ] = global_coupling . value wc . params [ 'exc_ext' ] = exc_drive . value wc . params [ 'inh_ext' ] = inh_drive . value wc . params [ 'sigma_ou' ] = noise_level . value # Run the model wc . run ()","title":"Run the simulation"},{"location":"examples/example-3-meg-functional-connectivity/#simulated-functional-connectivity","text":"We'll now compute the functional connectivity matrix containing the pairwise envelope correlations between all cortical regions of the AAL2 atlas. We'll thus follow the processing steps as before, i.e. band-pass filter the signal, extract the signal envelopes using the hilbert transformation, low-pass filter the envelopes and compute the pairwise pearson correlations. Note that we don't apply the orthogonalization scheme here, since this was only done to account to the electric field spread in the empirical data. # Create xr DataArray from the simulated excitatory timeseries (keeping the region labels) sim_signal = xr . DataArray ( wc . exc [:, int ( 1000 / wc . params . dt ):], dims = ( \"regions\" , \"time\" ), coords = { \"regions\" : emp_labels , \"time\" : wc . t [ int ( 1000 / wc . params . dt ):] / 1000 }, attrs = { 'atlas' : 'AAL2' }) # Initialize Figure fig , ax = plt . subplots ( figsize = ( 12 , 4 )) # Filter signal sim_signal = Signal ( sim_signal ) sim_signal . resample ( to_frequency = 100 ) with io . capture_output () as captured : sim_signal . filter ( freq . value [ 0 ], freq . value [ 1 ], inplace = True ); sns . lineplot ( x = sim_signal . data . time [: plot_timepoints ], y = sim_signal . data . sel ( regions = target . value )[: plot_timepoints ], ax = ax , label = 'Filtered Signal' ) # Extract signal envelope sim_signal . hilbert_transform ( 'amplitude' , inplace = True ) sns . lineplot ( x = sim_signal . data . time [: plot_timepoints ], y = sim_signal . data . sel ( regions = target . value )[: plot_timepoints ], ax = ax , label = 'Signal Envelope' ) # Low-Pass Filter with io . capture_output () as captured : sim_signal . filter ( low_freq = None , high_freq = low_pass . value , inplace = True ) sns . lineplot ( x = sim_signal . data . time [: plot_timepoints ], y = sim_signal . data . sel ( regions = target . value )[: plot_timepoints ], ax = ax , label = 'Low-Pass Signal Envelope' ) ax . legend ( bbox_to_anchor = ( 1.2 , 1 ), borderaxespad = 0 ) ax . set_title ( f 'Simulated Signal of Target Region Y ( { target . value } )' ); sns . despine ( trim = True ) To compute the simulated functional connectivity matrix we use the fc functions from neurolib. import neurolib.utils.functions as func # Compute the functional connectivity matrix sim_fc = func . fc ( sim_signal . data ) # Set diagonal to zero np . fill_diagonal ( sim_fc , 0 ) # Plot Empirical and simulated connectivity matrix fig , ax = plt . subplots ( 1 , 2 , figsize = ( 16 , 10 )) sns . heatmap ( emp_fc , square = True , ax = ax [ 0 ], cmap = 'YlGnBu' , linewidth = 0.005 , cbar_kws = { \"shrink\" : . 5 }) ax [ 0 ] . set_title ( 'Empirical FC' , pad = 10 ); sns . heatmap ( sim_fc , square = True , ax = ax [ 1 ], cmap = 'YlGnBu' , linewidth = 0.005 , cbar_kws = { \"shrink\" : . 5 }) ax [ 1 ] . set_title ( 'Simulated FC' , pad = 10 ); ticks = [ tick [: - 2 ] for tick in emp_labels [:: 2 ]] for ax in ax : ax . set_xticks ( np . arange ( 0 , 80 , 2 )); ax . set_yticks ( np . arange ( 0 , 80 , 2 )) ax . set_xticklabels ( ticks , rotation = 90 , fontsize = 8 ); ax . set_yticklabels ( ticks , rotation = 0 , fontsize = 8 );","title":"Simulated functional connectivity"},{"location":"examples/example-3-meg-functional-connectivity/#model-fit","text":"Lastly, we may evaluate the model fit by computing the pearson correlation between our simulated functional connectivity matrix and the empirical one. Additionally we'll also plot the correlation between structural and functional connectivity matrices to have a reference. # Compare structural and simulated connectivity to the empirical functional connectivity struct_emp = np . corrcoef ( emp_fc . flatten (), ds . Cmat . flatten ())[ 0 , 1 ] sim_emp = np . corrcoef ( emp_fc . flatten (), sim_fc . flatten ())[ 0 , 1 ] # Plot fig , ax = plt . subplots ( figsize = ( 6 , 6 )) splot = sns . barplot ( x = [ 'Structural Connectivity' , 'Simulated Connectivity' ], y = [ struct_emp , sim_emp ], ax = ax ) ax . set_title ( 'Correlation to Empiral Functional Connectivity' , pad = 10 ) for p in splot . patches : splot . annotate ( format ( p . get_height (), '.2f' ), ( p . get_x () + p . get_width () / 2. , p . get_height ()), ha = 'center' , va = 'center' , size = 20 , color = 'white' , xytext = ( 0 , - 12 ), textcoords = 'offset points' ) sns . despine () print ( f \"Parameters: \\t Global Coupling: { wc . params [ 'K_gl' ] } \\n\\t\\t Exc. Background Drive: { wc . params [ 'exc_ext' ] } \" ) print ( f \" \\t\\t Noise Level: { wc . params [ 'sigma_ou' ] } \" ) Parameters: Global Coupling: 6.55 Exc. Background Drive: 1.58 Noise Level: 0.02","title":"Model fit"},{"location":"exploration/boxsearch/","text":"BoxSearch Paremter box search for a given model and a range of parameters. __init__ ( self , model = None , parameterSpace = None , evalFunction = None , filename = None , saveAllModelOutputs = False ) special Either a model has to be passed, or an evalFunction. If an evalFunction is passed, then the evalFunction will be called and the model is accessible to the evalFunction via self.getModelFromTraj(traj) . The parameters of the current run are accible via self.getParametersFromTraj(traj) . If no evaluation function is passed, then the model is simulated using Model.run() for every parameter. Parameters: Name Type Description Default model `neurolib.models.model.Model`, optional Model to run for each parameter (or model to pass to the evaluation funciton if an evaluation function is used), defaults to None None parameterSpace `neurolib.utils.parameterSpace.ParameterSpace`, optional Parameter space to explore, defaults to None None evalFunction function, optional Evaluation function to call for each run., defaults to None None filename str HDF5 storage file name, if left empty, defaults to exploration.hdf None saveAllModelOutputs bool If True, save all outputs of model, else only default output of the model will be saved. Note: if saveAllModelOutputs==False and the model's parameter model.params['bold']==True, then BOLD output will be saved as well, defaults to False False Source code in neurolib/optimize/exploration/exploration.py def __init__ ( self , model = None , parameterSpace = None , evalFunction = None , filename = None , saveAllModelOutputs = False ): \"\"\"Either a model has to be passed, or an evalFunction. If an evalFunction is passed, then the evalFunction will be called and the model is accessible to the evalFunction via `self.getModelFromTraj(traj)`. The parameters of the current run are accible via `self.getParametersFromTraj(traj)`. If no evaluation function is passed, then the model is simulated using `Model.run()` for every parameter. :param model: Model to run for each parameter (or model to pass to the evaluation funciton if an evaluation function is used), defaults to None :type model: `neurolib.models.model.Model`, optional :param parameterSpace: Parameter space to explore, defaults to None :type parameterSpace: `neurolib.utils.parameterSpace.ParameterSpace`, optional :param evalFunction: Evaluation function to call for each run., defaults to None :type evalFunction: function, optional :param filename: HDF5 storage file name, if left empty, defaults to ``exploration.hdf`` :type filename: str :param saveAllModelOutputs: If True, save all outputs of model, else only default output of the model will be saved. Note: if saveAllModelOutputs==False and the model's parameter model.params['bold']==True, then BOLD output will be saved as well, defaults to False :type saveAllModelOutputs: bool \"\"\" self . model = model if evalFunction is None and model is not None : self . evalFunction = self . _runModel elif evalFunction is not None : self . evalFunction = evalFunction assert ( evalFunction is not None ) or ( model is not None ), \"Either a model has to be specified or an evalFunction.\" assert parameterSpace is not None , \"No parameters to explore.\" self . parameterSpace = parameterSpace self . exploreParameters = parameterSpace . dict () # TODO: use random ICs for every explored point or rather reuse the ones that are generated at model # initialization self . useRandomICs = False filename = filename or \"exploration.hdf\" self . filename = filename self . saveAllModelOutputs = saveAllModelOutputs # bool to check whether pypet was initialized properly self . initialized = False self . _initializeExploration ( self . filename ) self . results = None aggregateResultsToDfResults ( self , arrays = True , fillna = False ) Aggregate all results in to dfResults dataframe. Parameters: Name Type Description Default arrays bool, optional Load array results (like timeseries) if True. If False, only load scalar results, defaults to True True fillna bool, optional Fill nan results (for example if they're not returned in a subset of runs) with zeros, default to False False Source code in neurolib/optimize/exploration/exploration.py def aggregateResultsToDfResults ( self , arrays = True , fillna = False ): \"\"\"Aggregate all results in to dfResults dataframe. :param arrays: Load array results (like timeseries) if True. If False, only load scalar results, defaults to True :type arrays: bool, optional :param fillna: Fill nan results (for example if they're not returned in a subset of runs) with zeros, default to False :type fillna: bool, optional \"\"\" nan_value = np . nan logging . info ( \"Aggregating results to `dfResults` ...\" ) # for i, result in tqdm.tqdm(self.results.items()): for runId , parameters in tqdm . tqdm ( self . dfResults . iterrows (), total = len ( self . dfResults )): # if the results were previously loaded into memory, use them if hasattr ( self , \"results\" ): # only if the length matches the number of results if len ( self . results ) == len ( self . dfResults ): result = self . results [ runId ] # else, load results individually from hdf file else : result = self . getRun ( runId ) # else, load results individually from hdf file else : result = self . getRun ( runId ) for key , value in result . items (): # only save floats, ints and arrays if isinstance ( value , ( float , int , np . ndarray )): # save 1-dim arrays if isinstance ( value , np . ndarray ) and arrays : # to save a numpy array, convert column to object type if key not in self . dfResults : self . dfResults [ key ] = None self . dfResults [ key ] = self . dfResults [ key ] . astype ( object ) self . dfResults . at [ runId , key ] = value elif isinstance ( value , ( float , int )): # save numbers self . dfResults . loc [ runId , key ] = value else : self . dfResults . loc [ runId , key ] = nan_value # drop nan columns self . dfResults = self . dfResults . dropna ( axis = \"columns\" , how = \"all\" ) if fillna : self . dfResults = self . dfResults . fillna ( 0 ) getModelFromTraj ( self , traj ) Return the appropriate model with parameters for this run Parameters: Name Type Description Default traj Pypet trajectory of current run required Returns: Type Description Model with the parameters of this run. Source code in neurolib/optimize/exploration/exploration.py def getModelFromTraj ( self , traj ): \"\"\"Return the appropriate model with parameters for this run :params traj: Pypet trajectory of current run :returns model: Model with the parameters of this run. \"\"\" model = self . model runParams = self . getParametersFromTraj ( traj ) model . params . update ( runParams ) return model getParametersFromTraj ( self , traj ) Returns the parameters of the current run as a (dot.able) dictionary Parameters: Name Type Description Default traj Union[`pypet.traject,y.Traject,y`] Pypet trajectory required Returns: Type Description dict Parameter set of the current run Source code in neurolib/optimize/exploration/exploration.py def getParametersFromTraj ( self , traj ): \"\"\"Returns the parameters of the current run as a (dot.able) dictionary :param traj: Pypet trajectory :type traj: `pypet.trajectory.Trajectory` :return: Parameter set of the current run :rtype: dict \"\"\" # DO NOT use short names for star notation dicts runParams = self . traj . parameters . f_to_dict ( short_names = not self . parameterSpace . star , fast_access = True ) runParams = self . _validatePypetParameters ( runParams ) return dotdict ( runParams ) getResult ( self , runId ) Returns either a loaded result or reads from disk. Parameters: Name Type Description Default runId int runId of result required Returns: Type Description dict result Source code in neurolib/optimize/exploration/exploration.py def getResult ( self , runId ): \"\"\"Returns either a loaded result or reads from disk. :param runId: runId of result :type runId: int :return: result :rtype: dict \"\"\" # if hasattr(self, \"results\"): # # load result from either the preloaded .result attribute (from .loadResults) # result = self.results[runId] # else: # # or from disk if results haven't been loaded yet # result = self.getRun(runId) # load result from either the preloaded .result attribute (from .loadResults) # or from disk if results haven't been loaded yet # result = self.results[runId] if hasattr(self, \"results\") else self.getRun(runId) return self . results [ runId ] if hasattr ( self , \"results\" ) else self . getRun ( runId ) getRun ( self , runId , filename = None , trajectoryName = None , pypetShortNames = True ) Load the simulated data of a run and its parameters from a pypetTrajectory. Parameters: Name Type Description Default runId int ID of the run required Returns: Type Description Dictionary with simulated data and parameters of the run. Source code in neurolib/optimize/exploration/exploration.py def getRun ( self , runId , filename = None , trajectoryName = None , pypetShortNames = True ): \"\"\"Load the simulated data of a run and its parameters from a pypetTrajectory. :param runId: ID of the run :type runId: int :return: Dictionary with simulated data and parameters of the run. :type return: dict \"\"\" # chose HDF file to load filename = self . HDF_FILE or filename # either use loaded pypetTrajectory or load from HDF file if it isn't available pypetTrajectory = ( self . pypetTrajectory if hasattr ( self , \"pypetTrajectory\" ) else pu . loadPypetTrajectory ( filename , trajectoryName ) ) # # if there was no pypetTrajectory loaded before # if pypetTrajectory is None: # # chose HDF file to load # filename = self.HDF_FILE or filename # pypetTrajectory = pu.loadPypetTrajectory(filename, trajectoryName) return pu . getRun ( runId , pypetTrajectory , pypetShortNames = pypetShortNames ) info ( self ) Print info about the current search. Source code in neurolib/optimize/exploration/exploration.py def info ( self ): \"\"\"Print info about the current search.\"\"\" now = datetime . datetime . now () . strftime ( \"%Y-%m- %d -%HH-%MM-%SS\" ) print ( f \"Exploration info ( { now } )\" ) print ( f \"HDF name: { self . HDF_FILE } \" ) print ( f \"Trajectory name: { self . trajectoryName } \" ) if self . model is not None : print ( f \"Model: { self . model . name } \" ) if hasattr ( self , \"nRuns\" ): print ( f \"Number of runs { self . nRuns } \" ) print ( f \"Explored parameters: { self . exploreParameters . keys () } \" ) if hasattr ( self , \"_t_end_exploration\" ) and hasattr ( self , \"_t_start_exploration\" ): print ( f \"Duration of exploration: { self . _t_end_exploration - self . _t_start_exploration } \" ) loadDfResults ( self , filename = None , trajectoryName = None ) Load results from a previous simulation. Parameters: Name Type Description Default filename str, optional hdf file name in which results are stored, defaults to None None trajectoryName str, optional Name of the trajectory inside the hdf file, newest will be used if left empty, defaults to None None Source code in neurolib/optimize/exploration/exploration.py def loadDfResults ( self , filename = None , trajectoryName = None ): \"\"\"Load results from a previous simulation. :param filename: hdf file name in which results are stored, defaults to None :type filename: str, optional :param trajectoryName: Name of the trajectory inside the hdf file, newest will be used if left empty, defaults to None :type trajectoryName: str, optional \"\"\" # chose HDF file to load filename = filename or self . HDF_FILE self . pypetTrajectory = pu . loadPypetTrajectory ( filename , trajectoryName ) self . nResults = len ( self . pypetTrajectory . f_get_run_names ()) exploredParameters = self . pypetTrajectory . f_get_explored_parameters () # create pandas dataframe of all runs with parameters as keys logging . info ( \"Creating `dfResults` dataframe ...\" ) niceParKeys = [ p [ 11 :] for p in exploredParameters . keys ()] if not self . parameterSpace : niceParKeys = [ p . split ( \".\" )[ - 1 ] for p in niceParKeys ] self . dfResults = pd . DataFrame ( columns = niceParKeys , dtype = object ) for nicep , p in zip ( niceParKeys , exploredParameters . keys ()): self . dfResults [ nicep ] = exploredParameters [ p ] . f_get_range () loadResults ( self , all = True , filename = None , trajectoryName = None , pypetShortNames = True , memory_cap = 95.0 ) Load results from a hdf file of a previous simulation. Parameters: Name Type Description Default all bool, optional Load all simulated results into memory, which will be available as the .results attribute. Can use a lot of RAM if your simulation is large, please use this with caution. , defaults to True True filename str, optional hdf file name in which results are stored, defaults to None None trajectoryName str, optional Name of the trajectory inside the hdf file, newest will be used if left empty, defaults to None None pypetShortNames bool Use pypet short names as keys for the results dictionary. Use if you are experiencing errors due to natural naming collisions. True memory_cap float, int, optional Percentage memory cap between 0 and 100. If all=True is used, a memory cap can be set to avoid filling up the available RAM. Example: use memory_cap = 95 to avoid loading more data if memory is at 95% use, defaults to 95 95.0 Source code in neurolib/optimize/exploration/exploration.py def loadResults ( self , all = True , filename = None , trajectoryName = None , pypetShortNames = True , memory_cap = 95.0 ): \"\"\"Load results from a hdf file of a previous simulation. :param all: Load all simulated results into memory, which will be available as the `.results` attribute. Can use a lot of RAM if your simulation is large, please use this with caution. , defaults to True :type all: bool, optional :param filename: hdf file name in which results are stored, defaults to None :type filename: str, optional :param trajectoryName: Name of the trajectory inside the hdf file, newest will be used if left empty, defaults to None :type trajectoryName: str, optional :param pypetShortNames: Use pypet short names as keys for the results dictionary. Use if you are experiencing errors due to natural naming collisions. :type pypetShortNames: bool :param memory_cap: Percentage memory cap between 0 and 100. If `all=True` is used, a memory cap can be set to avoid filling up the available RAM. Example: use `memory_cap = 95` to avoid loading more data if memory is at 95% use, defaults to 95 :type memory_cap: float, int, optional \"\"\" self . loadDfResults ( filename , trajectoryName ) # make a list of dictionaries with results self . results = dotdict ({}) if all : logging . info ( \"Loading all results to `results` dictionary ...\" ) for rInd in tqdm . tqdm ( range ( self . nResults ), total = self . nResults ): # check if enough memory is available if memory_cap : assert isinstance ( memory_cap , ( int , float )), \"`memory_cap` must be float.\" assert ( memory_cap > 0 ) and ( memory_cap < 100 ), \"`memory_cap` must be between 0 and 100\" # check ram usage with psutil used_memory_percent = psutil . virtual_memory ()[ 2 ] if used_memory_percent > memory_cap : raise MemoryError ( f \"Memory use is at { used_memory_percent } % and capped at { memory_cap } . Aborting.\" ) self . pypetTrajectory . results [ rInd ] . f_load () result = self . pypetTrajectory . results [ rInd ] . f_to_dict ( fast_access = True , short_names = pypetShortNames ) result = dotdict ( result ) self . pypetTrajectory . results [ rInd ] . f_remove () self . results [ rInd ] = copy . deepcopy ( result ) # Postprocess result keys if pypet short names aren't used # Before: results.run_00000001.outputs.rates_inh # After: outputs.rates_inh if not pypetShortNames : for i , r in self . results . items (): new_dict = dotdict ({}) for key , value in r . items (): new_key = \"\" . join ( key . split ( \".\" , 2 )[ 2 :]) new_dict [ new_key ] = r [ key ] self . results [ i ] = copy . deepcopy ( new_dict ) self . aggregateResultsToDfResults () logging . info ( \"All results loaded.\" ) run ( self , ** kwargs ) Call this function to run the exploration Source code in neurolib/optimize/exploration/exploration.py def run ( self , ** kwargs ): \"\"\" Call this function to run the exploration \"\"\" self . runKwargs = kwargs assert self . initialized , \"Pypet environment not initialized yet.\" self . _t_start_exploration = datetime . datetime . now () self . env . run ( self . evalFunction ) self . _t_end_exploration = datetime . datetime . now () saveToPypet ( self , outputs , traj ) This function takes simulation results in the form of a nested dictionary and stores all data into the pypet hdf file. Parameters: Name Type Description Default outputs dict Simulation outputs as a dictionary. required traj Union[`pypet.traject,y.Traject,y`] Pypet trajectory required Source code in neurolib/optimize/exploration/exploration.py def saveToPypet ( self , outputs , traj ): \"\"\"This function takes simulation results in the form of a nested dictionary and stores all data into the pypet hdf file. :param outputs: Simulation outputs as a dictionary. :type outputs: dict :param traj: Pypet trajectory :type traj: `pypet.trajectory.Trajectory` \"\"\" def makeSaveStringForPypet ( value , savestr ): \"\"\"Builds the pypet-style results string from the results dictionary's keys. \"\"\" for k , v in value . items (): if isinstance ( v , dict ): _savestr = savestr + k + \".\" makeSaveStringForPypet ( v , _savestr ) else : _savestr = savestr + k self . traj . f_add_result ( _savestr , v ) assert isinstance ( outputs , dict ), \"Outputs must be an instance of dict.\" value = outputs savestr = \"results.$.\" makeSaveStringForPypet ( value , savestr ) xr ( self , bold = False ) Return xr.Dataset from the exploration results. Parameters: Name Type Description Default bold bool if True, will load and return only BOLD output False Source code in neurolib/optimize/exploration/exploration.py def xr ( self , bold = False ): \"\"\" Return `xr.Dataset` from the exploration results. :param bold: if True, will load and return only BOLD output :type bold: bool \"\"\" assert self . results is not None , \"Run `loadResults()` first to populate the results\" assert len ( self . results ) == len ( self . dfResults ) # create intrisinsic dims for one run timeDictKey , run_coords = self . _getCoordsFromRun ( self . results [ 0 ], bold = bold ) dataarrays = [] orig_search_coords = pypet . cartesian_product ( self . exploreParameters ) for runId , run_result in self . results . items (): # take exploration coordinates for this run expl_coords = { k : v [ runId ] for k , v in orig_search_coords . items ()} outputs = [] run_result = self . _filterDictionaryBold ( run_result , bold = bold ) for key , value in run_result . items (): if key == timeDictKey : continue outputs . append ( value ) # create DataArray for run only - we need to add exploration coordinates data_temp = xr . DataArray ( np . stack ( outputs ), dims = [ \"output\" , \"space\" , \"time\" ], coords = run_coords , name = \"exploration\" ) expand_coords = {} # iterate exploration coordinates for k , v in expl_coords . items (): # if single values, just assing if isinstance ( v , ( str , float , int )): expand_coords [ k ] = [ v ] # if arrays, check whether they can be sqeezed into one value elif isinstance ( v , np . ndarray ): if np . unique ( v ) . size == 1 : # if yes, just assing that one value expand_coords [ k ] = [ float ( np . unique ( v ))] else : # if no, sorry - coordinates cannot be array raise ValueError ( \"Cannot squeeze coordinates\" ) # assing exploration coordinates to the DataArray dataarrays . append ( data_temp . expand_dims ( expand_coords )) # finally, combine all arrays into one combined = xr . combine_by_coords ( dataarrays )[ \"exploration\" ] if self . parameterSpace . star : combined . attrs = { k : list ( self . model . params [ k ] . keys ()) for k in orig_search_coords . keys ()} return combined","title":"BoxSearch"},{"location":"exploration/boxsearch/#boxsearch","text":"Paremter box search for a given model and a range of parameters.","title":"BoxSearch"},{"location":"exploration/boxsearch/#neurolib.optimize.exploration.exploration.BoxSearch.__init__","text":"Either a model has to be passed, or an evalFunction. If an evalFunction is passed, then the evalFunction will be called and the model is accessible to the evalFunction via self.getModelFromTraj(traj) . The parameters of the current run are accible via self.getParametersFromTraj(traj) . If no evaluation function is passed, then the model is simulated using Model.run() for every parameter. Parameters: Name Type Description Default model `neurolib.models.model.Model`, optional Model to run for each parameter (or model to pass to the evaluation funciton if an evaluation function is used), defaults to None None parameterSpace `neurolib.utils.parameterSpace.ParameterSpace`, optional Parameter space to explore, defaults to None None evalFunction function, optional Evaluation function to call for each run., defaults to None None filename str HDF5 storage file name, if left empty, defaults to exploration.hdf None saveAllModelOutputs bool If True, save all outputs of model, else only default output of the model will be saved. Note: if saveAllModelOutputs==False and the model's parameter model.params['bold']==True, then BOLD output will be saved as well, defaults to False False Source code in neurolib/optimize/exploration/exploration.py def __init__ ( self , model = None , parameterSpace = None , evalFunction = None , filename = None , saveAllModelOutputs = False ): \"\"\"Either a model has to be passed, or an evalFunction. If an evalFunction is passed, then the evalFunction will be called and the model is accessible to the evalFunction via `self.getModelFromTraj(traj)`. The parameters of the current run are accible via `self.getParametersFromTraj(traj)`. If no evaluation function is passed, then the model is simulated using `Model.run()` for every parameter. :param model: Model to run for each parameter (or model to pass to the evaluation funciton if an evaluation function is used), defaults to None :type model: `neurolib.models.model.Model`, optional :param parameterSpace: Parameter space to explore, defaults to None :type parameterSpace: `neurolib.utils.parameterSpace.ParameterSpace`, optional :param evalFunction: Evaluation function to call for each run., defaults to None :type evalFunction: function, optional :param filename: HDF5 storage file name, if left empty, defaults to ``exploration.hdf`` :type filename: str :param saveAllModelOutputs: If True, save all outputs of model, else only default output of the model will be saved. Note: if saveAllModelOutputs==False and the model's parameter model.params['bold']==True, then BOLD output will be saved as well, defaults to False :type saveAllModelOutputs: bool \"\"\" self . model = model if evalFunction is None and model is not None : self . evalFunction = self . _runModel elif evalFunction is not None : self . evalFunction = evalFunction assert ( evalFunction is not None ) or ( model is not None ), \"Either a model has to be specified or an evalFunction.\" assert parameterSpace is not None , \"No parameters to explore.\" self . parameterSpace = parameterSpace self . exploreParameters = parameterSpace . dict () # TODO: use random ICs for every explored point or rather reuse the ones that are generated at model # initialization self . useRandomICs = False filename = filename or \"exploration.hdf\" self . filename = filename self . saveAllModelOutputs = saveAllModelOutputs # bool to check whether pypet was initialized properly self . initialized = False self . _initializeExploration ( self . filename ) self . results = None","title":"__init__()"},{"location":"exploration/boxsearch/#neurolib.optimize.exploration.exploration.BoxSearch.aggregateResultsToDfResults","text":"Aggregate all results in to dfResults dataframe. Parameters: Name Type Description Default arrays bool, optional Load array results (like timeseries) if True. If False, only load scalar results, defaults to True True fillna bool, optional Fill nan results (for example if they're not returned in a subset of runs) with zeros, default to False False Source code in neurolib/optimize/exploration/exploration.py def aggregateResultsToDfResults ( self , arrays = True , fillna = False ): \"\"\"Aggregate all results in to dfResults dataframe. :param arrays: Load array results (like timeseries) if True. If False, only load scalar results, defaults to True :type arrays: bool, optional :param fillna: Fill nan results (for example if they're not returned in a subset of runs) with zeros, default to False :type fillna: bool, optional \"\"\" nan_value = np . nan logging . info ( \"Aggregating results to `dfResults` ...\" ) # for i, result in tqdm.tqdm(self.results.items()): for runId , parameters in tqdm . tqdm ( self . dfResults . iterrows (), total = len ( self . dfResults )): # if the results were previously loaded into memory, use them if hasattr ( self , \"results\" ): # only if the length matches the number of results if len ( self . results ) == len ( self . dfResults ): result = self . results [ runId ] # else, load results individually from hdf file else : result = self . getRun ( runId ) # else, load results individually from hdf file else : result = self . getRun ( runId ) for key , value in result . items (): # only save floats, ints and arrays if isinstance ( value , ( float , int , np . ndarray )): # save 1-dim arrays if isinstance ( value , np . ndarray ) and arrays : # to save a numpy array, convert column to object type if key not in self . dfResults : self . dfResults [ key ] = None self . dfResults [ key ] = self . dfResults [ key ] . astype ( object ) self . dfResults . at [ runId , key ] = value elif isinstance ( value , ( float , int )): # save numbers self . dfResults . loc [ runId , key ] = value else : self . dfResults . loc [ runId , key ] = nan_value # drop nan columns self . dfResults = self . dfResults . dropna ( axis = \"columns\" , how = \"all\" ) if fillna : self . dfResults = self . dfResults . fillna ( 0 )","title":"aggregateResultsToDfResults()"},{"location":"exploration/boxsearch/#neurolib.optimize.exploration.exploration.BoxSearch.getModelFromTraj","text":"Return the appropriate model with parameters for this run Parameters: Name Type Description Default traj Pypet trajectory of current run required Returns: Type Description Model with the parameters of this run. Source code in neurolib/optimize/exploration/exploration.py def getModelFromTraj ( self , traj ): \"\"\"Return the appropriate model with parameters for this run :params traj: Pypet trajectory of current run :returns model: Model with the parameters of this run. \"\"\" model = self . model runParams = self . getParametersFromTraj ( traj ) model . params . update ( runParams ) return model","title":"getModelFromTraj()"},{"location":"exploration/boxsearch/#neurolib.optimize.exploration.exploration.BoxSearch.getParametersFromTraj","text":"Returns the parameters of the current run as a (dot.able) dictionary Parameters: Name Type Description Default traj Union[`pypet.traject,y.Traject,y`] Pypet trajectory required Returns: Type Description dict Parameter set of the current run Source code in neurolib/optimize/exploration/exploration.py def getParametersFromTraj ( self , traj ): \"\"\"Returns the parameters of the current run as a (dot.able) dictionary :param traj: Pypet trajectory :type traj: `pypet.trajectory.Trajectory` :return: Parameter set of the current run :rtype: dict \"\"\" # DO NOT use short names for star notation dicts runParams = self . traj . parameters . f_to_dict ( short_names = not self . parameterSpace . star , fast_access = True ) runParams = self . _validatePypetParameters ( runParams ) return dotdict ( runParams )","title":"getParametersFromTraj()"},{"location":"exploration/boxsearch/#neurolib.optimize.exploration.exploration.BoxSearch.getResult","text":"Returns either a loaded result or reads from disk. Parameters: Name Type Description Default runId int runId of result required Returns: Type Description dict result Source code in neurolib/optimize/exploration/exploration.py def getResult ( self , runId ): \"\"\"Returns either a loaded result or reads from disk. :param runId: runId of result :type runId: int :return: result :rtype: dict \"\"\" # if hasattr(self, \"results\"): # # load result from either the preloaded .result attribute (from .loadResults) # result = self.results[runId] # else: # # or from disk if results haven't been loaded yet # result = self.getRun(runId) # load result from either the preloaded .result attribute (from .loadResults) # or from disk if results haven't been loaded yet # result = self.results[runId] if hasattr(self, \"results\") else self.getRun(runId) return self . results [ runId ] if hasattr ( self , \"results\" ) else self . getRun ( runId )","title":"getResult()"},{"location":"exploration/boxsearch/#neurolib.optimize.exploration.exploration.BoxSearch.getRun","text":"Load the simulated data of a run and its parameters from a pypetTrajectory. Parameters: Name Type Description Default runId int ID of the run required Returns: Type Description Dictionary with simulated data and parameters of the run. Source code in neurolib/optimize/exploration/exploration.py def getRun ( self , runId , filename = None , trajectoryName = None , pypetShortNames = True ): \"\"\"Load the simulated data of a run and its parameters from a pypetTrajectory. :param runId: ID of the run :type runId: int :return: Dictionary with simulated data and parameters of the run. :type return: dict \"\"\" # chose HDF file to load filename = self . HDF_FILE or filename # either use loaded pypetTrajectory or load from HDF file if it isn't available pypetTrajectory = ( self . pypetTrajectory if hasattr ( self , \"pypetTrajectory\" ) else pu . loadPypetTrajectory ( filename , trajectoryName ) ) # # if there was no pypetTrajectory loaded before # if pypetTrajectory is None: # # chose HDF file to load # filename = self.HDF_FILE or filename # pypetTrajectory = pu.loadPypetTrajectory(filename, trajectoryName) return pu . getRun ( runId , pypetTrajectory , pypetShortNames = pypetShortNames )","title":"getRun()"},{"location":"exploration/boxsearch/#neurolib.optimize.exploration.exploration.BoxSearch.info","text":"Print info about the current search. Source code in neurolib/optimize/exploration/exploration.py def info ( self ): \"\"\"Print info about the current search.\"\"\" now = datetime . datetime . now () . strftime ( \"%Y-%m- %d -%HH-%MM-%SS\" ) print ( f \"Exploration info ( { now } )\" ) print ( f \"HDF name: { self . HDF_FILE } \" ) print ( f \"Trajectory name: { self . trajectoryName } \" ) if self . model is not None : print ( f \"Model: { self . model . name } \" ) if hasattr ( self , \"nRuns\" ): print ( f \"Number of runs { self . nRuns } \" ) print ( f \"Explored parameters: { self . exploreParameters . keys () } \" ) if hasattr ( self , \"_t_end_exploration\" ) and hasattr ( self , \"_t_start_exploration\" ): print ( f \"Duration of exploration: { self . _t_end_exploration - self . _t_start_exploration } \" )","title":"info()"},{"location":"exploration/boxsearch/#neurolib.optimize.exploration.exploration.BoxSearch.loadDfResults","text":"Load results from a previous simulation. Parameters: Name Type Description Default filename str, optional hdf file name in which results are stored, defaults to None None trajectoryName str, optional Name of the trajectory inside the hdf file, newest will be used if left empty, defaults to None None Source code in neurolib/optimize/exploration/exploration.py def loadDfResults ( self , filename = None , trajectoryName = None ): \"\"\"Load results from a previous simulation. :param filename: hdf file name in which results are stored, defaults to None :type filename: str, optional :param trajectoryName: Name of the trajectory inside the hdf file, newest will be used if left empty, defaults to None :type trajectoryName: str, optional \"\"\" # chose HDF file to load filename = filename or self . HDF_FILE self . pypetTrajectory = pu . loadPypetTrajectory ( filename , trajectoryName ) self . nResults = len ( self . pypetTrajectory . f_get_run_names ()) exploredParameters = self . pypetTrajectory . f_get_explored_parameters () # create pandas dataframe of all runs with parameters as keys logging . info ( \"Creating `dfResults` dataframe ...\" ) niceParKeys = [ p [ 11 :] for p in exploredParameters . keys ()] if not self . parameterSpace : niceParKeys = [ p . split ( \".\" )[ - 1 ] for p in niceParKeys ] self . dfResults = pd . DataFrame ( columns = niceParKeys , dtype = object ) for nicep , p in zip ( niceParKeys , exploredParameters . keys ()): self . dfResults [ nicep ] = exploredParameters [ p ] . f_get_range ()","title":"loadDfResults()"},{"location":"exploration/boxsearch/#neurolib.optimize.exploration.exploration.BoxSearch.loadResults","text":"Load results from a hdf file of a previous simulation. Parameters: Name Type Description Default all bool, optional Load all simulated results into memory, which will be available as the .results attribute. Can use a lot of RAM if your simulation is large, please use this with caution. , defaults to True True filename str, optional hdf file name in which results are stored, defaults to None None trajectoryName str, optional Name of the trajectory inside the hdf file, newest will be used if left empty, defaults to None None pypetShortNames bool Use pypet short names as keys for the results dictionary. Use if you are experiencing errors due to natural naming collisions. True memory_cap float, int, optional Percentage memory cap between 0 and 100. If all=True is used, a memory cap can be set to avoid filling up the available RAM. Example: use memory_cap = 95 to avoid loading more data if memory is at 95% use, defaults to 95 95.0 Source code in neurolib/optimize/exploration/exploration.py def loadResults ( self , all = True , filename = None , trajectoryName = None , pypetShortNames = True , memory_cap = 95.0 ): \"\"\"Load results from a hdf file of a previous simulation. :param all: Load all simulated results into memory, which will be available as the `.results` attribute. Can use a lot of RAM if your simulation is large, please use this with caution. , defaults to True :type all: bool, optional :param filename: hdf file name in which results are stored, defaults to None :type filename: str, optional :param trajectoryName: Name of the trajectory inside the hdf file, newest will be used if left empty, defaults to None :type trajectoryName: str, optional :param pypetShortNames: Use pypet short names as keys for the results dictionary. Use if you are experiencing errors due to natural naming collisions. :type pypetShortNames: bool :param memory_cap: Percentage memory cap between 0 and 100. If `all=True` is used, a memory cap can be set to avoid filling up the available RAM. Example: use `memory_cap = 95` to avoid loading more data if memory is at 95% use, defaults to 95 :type memory_cap: float, int, optional \"\"\" self . loadDfResults ( filename , trajectoryName ) # make a list of dictionaries with results self . results = dotdict ({}) if all : logging . info ( \"Loading all results to `results` dictionary ...\" ) for rInd in tqdm . tqdm ( range ( self . nResults ), total = self . nResults ): # check if enough memory is available if memory_cap : assert isinstance ( memory_cap , ( int , float )), \"`memory_cap` must be float.\" assert ( memory_cap > 0 ) and ( memory_cap < 100 ), \"`memory_cap` must be between 0 and 100\" # check ram usage with psutil used_memory_percent = psutil . virtual_memory ()[ 2 ] if used_memory_percent > memory_cap : raise MemoryError ( f \"Memory use is at { used_memory_percent } % and capped at { memory_cap } . Aborting.\" ) self . pypetTrajectory . results [ rInd ] . f_load () result = self . pypetTrajectory . results [ rInd ] . f_to_dict ( fast_access = True , short_names = pypetShortNames ) result = dotdict ( result ) self . pypetTrajectory . results [ rInd ] . f_remove () self . results [ rInd ] = copy . deepcopy ( result ) # Postprocess result keys if pypet short names aren't used # Before: results.run_00000001.outputs.rates_inh # After: outputs.rates_inh if not pypetShortNames : for i , r in self . results . items (): new_dict = dotdict ({}) for key , value in r . items (): new_key = \"\" . join ( key . split ( \".\" , 2 )[ 2 :]) new_dict [ new_key ] = r [ key ] self . results [ i ] = copy . deepcopy ( new_dict ) self . aggregateResultsToDfResults () logging . info ( \"All results loaded.\" )","title":"loadResults()"},{"location":"exploration/boxsearch/#neurolib.optimize.exploration.exploration.BoxSearch.run","text":"Call this function to run the exploration Source code in neurolib/optimize/exploration/exploration.py def run ( self , ** kwargs ): \"\"\" Call this function to run the exploration \"\"\" self . runKwargs = kwargs assert self . initialized , \"Pypet environment not initialized yet.\" self . _t_start_exploration = datetime . datetime . now () self . env . run ( self . evalFunction ) self . _t_end_exploration = datetime . datetime . now ()","title":"run()"},{"location":"exploration/boxsearch/#neurolib.optimize.exploration.exploration.BoxSearch.saveToPypet","text":"This function takes simulation results in the form of a nested dictionary and stores all data into the pypet hdf file. Parameters: Name Type Description Default outputs dict Simulation outputs as a dictionary. required traj Union[`pypet.traject,y.Traject,y`] Pypet trajectory required Source code in neurolib/optimize/exploration/exploration.py def saveToPypet ( self , outputs , traj ): \"\"\"This function takes simulation results in the form of a nested dictionary and stores all data into the pypet hdf file. :param outputs: Simulation outputs as a dictionary. :type outputs: dict :param traj: Pypet trajectory :type traj: `pypet.trajectory.Trajectory` \"\"\" def makeSaveStringForPypet ( value , savestr ): \"\"\"Builds the pypet-style results string from the results dictionary's keys. \"\"\" for k , v in value . items (): if isinstance ( v , dict ): _savestr = savestr + k + \".\" makeSaveStringForPypet ( v , _savestr ) else : _savestr = savestr + k self . traj . f_add_result ( _savestr , v ) assert isinstance ( outputs , dict ), \"Outputs must be an instance of dict.\" value = outputs savestr = \"results.$.\" makeSaveStringForPypet ( value , savestr )","title":"saveToPypet()"},{"location":"exploration/boxsearch/#neurolib.optimize.exploration.exploration.BoxSearch.xr","text":"Return xr.Dataset from the exploration results. Parameters: Name Type Description Default bold bool if True, will load and return only BOLD output False Source code in neurolib/optimize/exploration/exploration.py def xr ( self , bold = False ): \"\"\" Return `xr.Dataset` from the exploration results. :param bold: if True, will load and return only BOLD output :type bold: bool \"\"\" assert self . results is not None , \"Run `loadResults()` first to populate the results\" assert len ( self . results ) == len ( self . dfResults ) # create intrisinsic dims for one run timeDictKey , run_coords = self . _getCoordsFromRun ( self . results [ 0 ], bold = bold ) dataarrays = [] orig_search_coords = pypet . cartesian_product ( self . exploreParameters ) for runId , run_result in self . results . items (): # take exploration coordinates for this run expl_coords = { k : v [ runId ] for k , v in orig_search_coords . items ()} outputs = [] run_result = self . _filterDictionaryBold ( run_result , bold = bold ) for key , value in run_result . items (): if key == timeDictKey : continue outputs . append ( value ) # create DataArray for run only - we need to add exploration coordinates data_temp = xr . DataArray ( np . stack ( outputs ), dims = [ \"output\" , \"space\" , \"time\" ], coords = run_coords , name = \"exploration\" ) expand_coords = {} # iterate exploration coordinates for k , v in expl_coords . items (): # if single values, just assing if isinstance ( v , ( str , float , int )): expand_coords [ k ] = [ v ] # if arrays, check whether they can be sqeezed into one value elif isinstance ( v , np . ndarray ): if np . unique ( v ) . size == 1 : # if yes, just assing that one value expand_coords [ k ] = [ float ( np . unique ( v ))] else : # if no, sorry - coordinates cannot be array raise ValueError ( \"Cannot squeeze coordinates\" ) # assing exploration coordinates to the DataArray dataarrays . append ( data_temp . expand_dims ( expand_coords )) # finally, combine all arrays into one combined = xr . combine_by_coords ( dataarrays )[ \"exploration\" ] if self . parameterSpace . star : combined . attrs = { k : list ( self . model . params [ k ] . keys ()) for k in orig_search_coords . keys ()} return combined","title":"xr()"},{"location":"models/model/","text":"Models Models are the core of neurolib . The Model superclass will help you to load, simulate, and analyse models. It also makes it very easy to implement your own neural mass model (see Example 0.6 custom model ). Loading a model To load a model, we need to import the submodule of a model and instantiate it. This example shows how to load a single node of the ALNModel . See Example 0 aln minimal on how to simulate a whole-brain network using this model. from neurolib.models.aln import ALNModel # Import the model model = ALNModel() # Create an instance model.run() # Run it Model base class methods The Model base class runs models, manages their outputs, parameters and more. This class should serve as the base class for all implemented models. output property readonly Returns value of default output as defined by self.default_output . Note that all outputs are saved in the attribute self.outputs . __getitem__ ( self , key ) special Index outputs with a dictionary-like key, e.g., model['rates_exc'] . Source code in neurolib/models/model.py def __getitem__ ( self , key ): \"\"\"Index outputs with a dictionary-like key, e.g., `model['rates_exc']`.\"\"\" return self . getOutput ( key ) autochunk ( self , inputs = None , chunksize = 1 , append_outputs = False , bold = False ) Executes a single chunk of integration, either for a given duration or a single timestep dt . Gathers all inputs to the model and resets the initial conditions as a preparation for the next chunk. Parameters: Name Type Description Default inputs list[np.ndarray|], optional list of input values, ordered according to self.input_vars, defaults to None None chunksize int, optional length of a chunk to simulate in dt, defaults 1 1 append_outputs bool, optional append the chunkwise outputs to the outputs attribute, defaults to False False Source code in neurolib/models/model.py def autochunk ( self , inputs = None , chunksize = 1 , append_outputs = False , bold = False ): \"\"\"Executes a single chunk of integration, either for a given duration or a single timestep `dt`. Gathers all inputs to the model and resets the initial conditions as a preparation for the next chunk. :param inputs: list of input values, ordered according to self.input_vars, defaults to None :type inputs: list[np.ndarray|], optional :param chunksize: length of a chunk to simulate in dt, defaults 1 :type chunksize: int, optional :param append_outputs: append the chunkwise outputs to the outputs attribute, defaults to False :type append_outputs: bool, optional \"\"\" # set the duration for this chunk self . params [ \"duration\" ] = chunksize * self . params [ \"dt\" ] # set inputs if inputs is not None : self . setInputs ( inputs ) # run integration self . integrate ( append_outputs = append_outputs , simulate_bold = bold ) # set initial conditions to last state for the next chunk self . setInitialValuesToLastState () checkChunkwise ( self , chunksize ) Checks if the model fulfills requirements for chunkwise simulation. Checks whether the sampling rate for outputs fits to chunksize and duration. Throws errors if not. Source code in neurolib/models/model.py def checkChunkwise ( self , chunksize ): \"\"\"Checks if the model fulfills requirements for chunkwise simulation. Checks whether the sampling rate for outputs fits to chunksize and duration. Throws errors if not.\"\"\" assert self . state_vars is not None , \"State variable names not given.\" assert self . init_vars is not None , \"Initial value variable names not given.\" assert len ( self . state_vars ) == len ( self . init_vars ), \"State variables are not same length as initial values.\" # throw a warning if the user is nasty if int ( self . params [ \"duration\" ] / self . params [ \"dt\" ]) % chunksize != 0 : logging . warning ( f \"It is strongly advised to use a `chunksize` ( { chunksize } ) that is a divisor of `duration / dt` ( { int ( self . params [ 'duration' ] / self . params [ 'dt' ]) } ).\" ) # if `sampling_dt` is set, do some checks if self . params . get ( \"sampling_dt\" ) is not None : # sample_dt checks are required after setting chunksize assert ( chunksize * self . params [ \"dt\" ] >= self . params [ \"sampling_dt\" ] ), \"`chunksize * dt` must be >= `sampling_dt`\" # ugly floating point modulo hack: instead of float1%float2==0, we do # (float1/float2)%1==0 assert (( chunksize * self . params [ \"dt\" ]) / self . params [ \"sampling_dt\" ]) % 1 == 0 , ( f \"Chunksize { chunksize * self . params [ 'dt' ] } must be divisible by sampling dt \" f \" { self . params [ 'sampling_dt' ] } \" ) assert ( ( self . params [ \"duration\" ] % ( chunksize * self . params [ \"dt\" ])) / self . params [ \"sampling_dt\" ] ) % 1 == 0 , ( f \"Last chunk of size { self . params [ 'duration' ] % ( chunksize * self . params [ 'dt' ]) } must be divisible by sampling dt \" f \" { self . params [ 'sampling_dt' ] } \" ) clearModelState ( self ) Clears the model's state to create a fresh one Source code in neurolib/models/model.py def clearModelState ( self ): \"\"\"Clears the model's state to create a fresh one\"\"\" self . state = dotdict ({}) self . outputs = dotdict ({}) # reinitialize bold model if self . params . get ( \"bold\" ): self . initializeBold () getMaxDelay ( self ) Computes the maximum delay of the model. This function should be overloaded if the model has internal delays (additional to delay between nodes defined by Dmat) such as the delay between an excitatory and inhibitory population within each brain area. If this function is not overloaded, the maximum delay is assumed to be defined from the global delay matrix Dmat . Note: Maxmimum delay is given in units of dt. Returns: Type Description int maxmimum delay of the model in units of dt Source code in neurolib/models/model.py def getMaxDelay ( self ): \"\"\"Computes the maximum delay of the model. This function should be overloaded if the model has internal delays (additional to delay between nodes defined by Dmat) such as the delay between an excitatory and inhibitory population within each brain area. If this function is not overloaded, the maximum delay is assumed to be defined from the global delay matrix `Dmat`. Note: Maxmimum delay is given in units of dt. :return: maxmimum delay of the model in units of dt :rtype: int \"\"\" dt = self . params . get ( \"dt\" ) Dmat = self . params . get ( \"lengthMat\" ) if Dmat is not None : # divide Dmat by signalV signalV = self . params . get ( \"signalV\" ) or 0 if signalV > 0 : Dmat = Dmat / signalV else : # if signalV is 0, eliminate delays Dmat = Dmat * 0.0 # only if Dmat and dt exist, a global max delay can be computed if Dmat is not None and dt is not None : Dmat_ndt = np . around ( Dmat / dt ) # delay matrix in multiples of dt max_global_delay = int ( np . amax ( Dmat_ndt )) else : max_global_delay = 0 return max_global_delay getOutput ( self , name ) Get an output of a given name (dot.semarated) Parameters: Name Type Description Default name str A key, grouped outputs in the form group.subgroup.variable required Returns: Type Description Output data Source code in neurolib/models/model.py def getOutput ( self , name ): \"\"\"Get an output of a given name (dot.semarated) :param name: A key, grouped outputs in the form group.subgroup.variable :type name: str :returns: Output data \"\"\" assert isinstance ( name , str ), \"Output name must be a string.\" keys = name . split ( \".\" ) lastOutput = self . outputs . copy () for i , k in enumerate ( keys ): assert k in lastOutput , f \"Key { k } not found in outputs.\" lastOutput = lastOutput [ k ] return lastOutput getOutputs ( self , group = '' ) Get all outputs of an output group. Examples: getOutputs(\"BOLD\") or simply getOutputs() Parameters: Name Type Description Default group str Group name, subgroups separated by dots. If left empty (default), all outputs of the root group are returned. '' Source code in neurolib/models/model.py def getOutputs ( self , group = \"\" ): \"\"\"Get all outputs of an output group. Examples: `getOutputs(\"BOLD\")` or simply `getOutputs()` :param group: Group name, subgroups separated by dots. If left empty (default), all outputs of the root group are returned. :type group: str \"\"\" assert isinstance ( group , str ), \"Group name must be a string.\" def filterOutputsFromGroupDict ( groupDict ): \"\"\"Return a dictionary with the output data of a group disregarding all other nested dicts. :param groupDict: Dictionary of outputs (can include other groups) :type groupDict: dict \"\"\" assert isinstance ( groupDict , dict ), \"Not a dictionary.\" # make a deep copy of the dictionary returnDict = groupDict . copy () for key , value in groupDict . items (): if isinstance ( value , dict ): del returnDict [ key ] return returnDict # if a group deeper than the root is given, select the last node lastOutput = self . outputs . copy () if len ( group ) > 0 : keys = group . split ( \".\" ) for i , k in enumerate ( keys ): assert k in lastOutput , f \"Key { k } not found in outputs.\" lastOutput = lastOutput [ k ] assert isinstance ( lastOutput , dict ), f \"Key { k } does not refer to a group.\" # filter out all output *groups* that might be in this node and return only output data return filterOutputsFromGroupDict ( lastOutput ) initializeBold ( self ) Initialize BOLD model. Source code in neurolib/models/model.py def initializeBold ( self ): \"\"\"Initialize BOLD model.\"\"\" self . boldInitialized = False # function to transform model state before passing it to the bold model # Note: This can be used like the parameter \\epsilon in Friston2000 # (neural efficacy) by multiplying the input with a constant via # self.boldInputTransform = lambda x: x * epsilon if not hasattr ( self , \"boldInputTransform\" ): self . boldInputTransform = None self . boldModel = bold . BOLDModel ( self . params [ \"N\" ], self . params [ \"dt\" ]) self . boldInitialized = True initializeRun ( self , initializeBold = False ) Initialization before each run. Parameters: Name Type Description Default initializeBold bool initialize BOLD model False Source code in neurolib/models/model.py def initializeRun ( self , initializeBold = False ): \"\"\"Initialization before each run. :param initializeBold: initialize BOLD model :type initializeBold: bool \"\"\" # get the maxDelay of the system self . maxDelay = self . getMaxDelay () # length of the initial condition self . startindt = self . maxDelay + 1 # check dt / sampling_dt self . setSamplingDt () # force bold if params['bold'] == True if self . params . get ( \"bold\" ): initializeBold = True # set up the bold model, if it didn't happen yet if initializeBold and not self . boldInitialized : self . initializeBold () integrate ( self , append_outputs = False , simulate_bold = False ) Calls each models integration function and saves the state and the outputs of the model. Parameters: Name Type Description Default append bool, optional append the chunkwise outputs to the outputs attribute, defaults to False, defaults to False required Source code in neurolib/models/model.py def integrate ( self , append_outputs = False , simulate_bold = False ): \"\"\"Calls each models `integration` function and saves the state and the outputs of the model. :param append: append the chunkwise outputs to the outputs attribute, defaults to False, defaults to False :type append: bool, optional \"\"\" # run integration t , * variables = self . integration ( self . params ) self . storeOutputsAndStates ( t , variables , append = append_outputs ) # force bold if params['bold'] == True if self . params . get ( \"bold\" ): simulate_bold = True # bold simulation after integration if simulate_bold and self . boldInitialized : self . simulateBold ( t , variables , append = True ) integrateChunkwise ( self , chunksize , bold = False , append_outputs = False ) Repeatedly calls the chunkwise integration for the whole duration of the simulation. If bold==True , the BOLD model is simulated after each chunk. Parameters: Name Type Description Default chunksize int size of each chunk to simulate in units of dt required bold bool, optional simulate BOLD model after each chunk, defaults to False False append_outputs bool, optional append the chunkwise outputs to the outputs attribute, defaults to False False Source code in neurolib/models/model.py def integrateChunkwise ( self , chunksize , bold = False , append_outputs = False ): \"\"\"Repeatedly calls the chunkwise integration for the whole duration of the simulation. If `bold==True`, the BOLD model is simulated after each chunk. :param chunksize: size of each chunk to simulate in units of dt :type chunksize: int :param bold: simulate BOLD model after each chunk, defaults to False :type bold: bool, optional :param append_outputs: append the chunkwise outputs to the outputs attribute, defaults to False :type append_outputs: bool, optional \"\"\" totalDuration = self . params [ \"duration\" ] dt = self . params [ \"dt\" ] # create a shallow copy of the parameters lastT = 0 while totalDuration - lastT >= dt - 1e-6 : # Determine the size of the next chunk # account for floating point errors remainingChunkSize = int ( round (( totalDuration - lastT ) / dt )) currentChunkSize = min ( chunksize , remainingChunkSize ) self . autochunk ( chunksize = currentChunkSize , append_outputs = append_outputs , bold = bold ) # we save the last simulated time step lastT += currentChunkSize * dt # or # lastT = self.state[\"t\"][-1] # set duration back to its original value self . params [ \"duration\" ] = totalDuration randomICs ( self , min = 0 , max = 1 ) Generates a new set of uniformly-distributed random initial conditions for the model. TODO: All parameters are drawn from the same distribution / range. Allow for independent ranges. Parameters: Name Type Description Default min float Minium of uniform distribution 0 max float Maximum of uniform distribution 1 Source code in neurolib/models/model.py def randomICs ( self , min = 0 , max = 1 ): \"\"\"Generates a new set of uniformly-distributed random initial conditions for the model. TODO: All parameters are drawn from the same distribution / range. Allow for independent ranges. :param min: Minium of uniform distribution :type min: float :param max: Maximum of uniform distribution :type max: float \"\"\" for iv in self . init_vars : if self . params [ iv ] . ndim == 1 : self . params [ iv ] = np . random . uniform ( min , max , ( self . params [ \"N\" ])) elif self . params [ iv ] . ndim == 2 : self . params [ iv ] = np . random . uniform ( min , max , ( self . params [ \"N\" ], 1 )) run ( self , inputs = None , chunkwise = False , chunksize = None , bold = False , append = False , append_outputs = None , continue_run = False ) Main interfacing function to run a model. The model can be run in three different ways: 1) model.run() starts a new run. 2) model.run(chunkwise=True) runs the simulation in chunks of length chunksize . 3) mode.run(continue_run=True) continues the simulation of a previous run. Parameters: Name Type Description Default inputs list[np.ndarray|] list of inputs to the model, must have the same order as model.input_vars. Note: no sanity check is performed for performance reasons. Take care of the inputs yourself. None chunkwise bool, optional simulate model chunkwise or in one single run, defaults to False False chunksize int, optional size of the chunk to simulate in dt, if set will imply chunkwise=True, defaults to 2s None bold bool, optional simulate BOLD signal (only for chunkwise integration), defaults to False False append bool, optional append the chunkwise outputs to the outputs attribute, defaults to False, defaults to False False continue_run bool continue a simulation by using the initial values from a previous simulation False Source code in neurolib/models/model.py def run ( self , inputs = None , chunkwise = False , chunksize = None , bold = False , append = False , append_outputs = None , continue_run = False , ): \"\"\" Main interfacing function to run a model. The model can be run in three different ways: 1) `model.run()` starts a new run. 2) `model.run(chunkwise=True)` runs the simulation in chunks of length `chunksize`. 3) `mode.run(continue_run=True)` continues the simulation of a previous run. :param inputs: list of inputs to the model, must have the same order as model.input_vars. Note: no sanity check is performed for performance reasons. Take care of the inputs yourself. :type inputs: list[np.ndarray|] :param chunkwise: simulate model chunkwise or in one single run, defaults to False :type chunkwise: bool, optional :param chunksize: size of the chunk to simulate in dt, if set will imply chunkwise=True, defaults to 2s :type chunksize: int, optional :param bold: simulate BOLD signal (only for chunkwise integration), defaults to False :type bold: bool, optional :param append: append the chunkwise outputs to the outputs attribute, defaults to False, defaults to False :type append: bool, optional :param continue_run: continue a simulation by using the initial values from a previous simulation :type continue_run: bool \"\"\" # TODO: legacy argument support if append_outputs is not None : append = append_outputs # if a previous run is not to be continued clear the model's state if continue_run is False : self . clearModelState () self . initializeRun ( initializeBold = bold ) # enable chunkwise if chunksize is set chunkwise = chunkwise if chunksize is None else True if chunkwise is False : self . integrate ( append_outputs = append , simulate_bold = bold ) if continue_run : self . setInitialValuesToLastState () else : if chunksize is None : chunksize = int ( 2000 / self . params [ \"dt\" ]) # check if model is safe for chunkwise integration # and whether sampling_dt is compatible with duration and chunksize self . checkChunkwise ( chunksize ) if bold and not self . boldInitialized : logging . warn ( f \" { self . name } : BOLD model not initialized, not simulating BOLD. Use `run(bold=True)`\" ) bold = False self . integrateChunkwise ( chunksize = chunksize , bold = bold , append_outputs = append ) # check if there was a problem with the simulated data self . checkOutputs () setInitialValuesToLastState ( self ) Reads the last state of the model and sets the initial conditions to that state for continuing a simulation. Source code in neurolib/models/model.py def setInitialValuesToLastState ( self ): \"\"\"Reads the last state of the model and sets the initial conditions to that state for continuing a simulation.\"\"\" for iv , sv in zip ( self . init_vars , self . state_vars ): # if state variables are one-dimensional (in space only) if ( self . state [ sv ] . ndim == 0 ) or ( self . state [ sv ] . ndim == 1 ): self . params [ iv ] = self . state [ sv ] # if they are space-time arrays else : # we set the next initial condition to the last state self . params [ iv ] = self . state [ sv ][:, - self . startindt :] setInputs ( self , inputs ) Take inputs from a list and store it in the appropriate model parameter for external input. TODO: This is not safe yet, checks should be implemented whether the model has inputs defined or not for example. Parameters: Name Type Description Default inputs list[np.ndarray(), ...] list of inputs required Source code in neurolib/models/model.py def setInputs ( self , inputs ): \"\"\"Take inputs from a list and store it in the appropriate model parameter for external input. TODO: This is not safe yet, checks should be implemented whether the model has inputs defined or not for example. :param inputs: list of inputs :type inputs: list[np.ndarray(), ...] \"\"\" for i , iv in enumerate ( self . input_vars ): self . params [ iv ] = inputs [ i ] . copy () setOutput ( self , name , data , append = False , removeICs = False ) Adds an output to the model, typically a simulation result. Parameters: Name Type Description Default name str Name of the output in dot.notation, a la \"outputgroup.output\" required data `numpy.ndarray` Output data, can't be a dictionary! required Source code in neurolib/models/model.py def setOutput ( self , name , data , append = False , removeICs = False ): \"\"\"Adds an output to the model, typically a simulation result. :params name: Name of the output in dot.notation, a la \"outputgroup.output\" :type name: str :params data: Output data, can't be a dictionary! :type data: `numpy.ndarray` \"\"\" assert not isinstance ( data , dict ), \"Output data cannot be a dictionary.\" assert isinstance ( name , str ), \"Output name must be a string.\" assert isinstance ( data , np . ndarray ), \"Output must be a `numpy.ndarray`.\" # remove initial conditions from output if removeICs and name != \"t\" : if data . ndim == 1 : data = data [ self . startindt :] elif data . ndim == 2 : data = data [:, self . startindt :] else : raise ValueError ( f \"Don't know how to truncate data of shape { data . shape } .\" ) # subsample to sampling dt if data . ndim == 1 : data = data [:: self . sample_every ] elif data . ndim == 2 : data = data [:, :: self . sample_every ] else : raise ValueError ( f \"Don't know how to subsample data of shape { data . shape } .\" ) # if the output is a single name (not dot.separated) if \".\" not in name : # append data if append and name in self . outputs : # special treatment for time data: # increment the time by the last recorded duration if name == \"t\" : data += self . outputs [ name ][ - 1 ] self . outputs [ name ] = np . hstack (( self . outputs [ name ], data )) else : # save all data into output dict self . outputs [ name ] = data # set output as an attribute setattr ( self , name , self . outputs [ name ]) else : # build results dictionary and write into self.outputs # dot.notation iteration keys = name . split ( \".\" ) level = self . outputs # not copy, reference! for i , k in enumerate ( keys ): # if it's the last iteration, store data if i == len ( keys ) - 1 : # TODO: this needs to be append-aware like above # if append: # if k == \"t\": # data += level[k][-1] # level[k] = np.hstack((level[k], data)) # else: # level[k] = data level [ k ] = data # if key is in outputs, then go deeper elif k in level : level = level [ k ] setattr ( self , k , level ) # if it's a new key, create new nested dictionary, set attribute, then go deeper else : level [ k ] = dotdict ({}) setattr ( self , k , level [ k ]) level = level [ k ] setSamplingDt ( self ) Checks if sampling_dt is set correctly and sets self. sample_every 1) Check if sampling_dt is multiple of dt 2) Check if semplind_dt is greater than duration Source code in neurolib/models/model.py def setSamplingDt ( self ): \"\"\"Checks if sampling_dt is set correctly and sets self.`sample_every` 1) Check if sampling_dt is multiple of dt 2) Check if semplind_dt is greater than duration \"\"\" if self . params . get ( \"sampling_dt\" ) is None : self . sample_every = 1 elif self . params . get ( \"sampling_dt\" ) > 0 : assert self . params [ \"sampling_dt\" ] >= self . params [ \"dt\" ], \"`sampling_dt` needs to be >= `dt`\" assert ( self . params [ \"duration\" ] >= self . params [ \"sampling_dt\" ] ), \"`sampling_dt` needs to be lower than `duration`\" self . sample_every = int ( self . params [ \"sampling_dt\" ] / self . params [ \"dt\" ]) else : raise ValueError ( f \"Can't handle `sampling_dt`= { self . params . get ( 'sampling_dt' ) } \" ) setStateVariables ( self , name , data ) Saves the models current state variables. TODO: Cut state variables to length of self.maxDelay However, this could be time-memory tradeoff Parameters: Name Type Description Default name str name of the state variable required data np.ndarray value of the variable required Source code in neurolib/models/model.py def setStateVariables ( self , name , data ): \"\"\"Saves the models current state variables. TODO: Cut state variables to length of self.maxDelay However, this could be time-memory tradeoff :param name: name of the state variable :type name: str :param data: value of the variable :type data: np.ndarray \"\"\" # old # self.state[name] = data.copy() # if the data is temporal, cut off initial values # NOTE: this shuold actually check for # if data.shape[1] > 1: # else: data.copy() # there coulb be (N, 1)-dimensional output, right now # it is requred to be of shape (N, ) if data . ndim == 2 : self . state [ name ] = data [:, - self . startindt :] . copy () else : self . state [ name ] = data . copy () simulateBold ( self , t , variables , append = False ) Gets the default output of the model and simulates the BOLD model. Adds the simulated BOLD signal to outputs. Source code in neurolib/models/model.py def simulateBold ( self , t , variables , append = False ): \"\"\"Gets the default output of the model and simulates the BOLD model. Adds the simulated BOLD signal to outputs. \"\"\" if self . boldInitialized : # first we loop through all state variables for svn , sv in zip ( self . state_vars , variables ): # the default output is used as the input for the bold model if svn == self . default_output : bold_input = sv [:, self . startindt :] # logging.debug(f\"BOLD input `{svn}` of shape {bold_input.shape}\") if bold_input . shape [ 1 ] >= self . boldModel . samplingRate_NDt : # only if the length of the output has a zero mod to the sampling rate, # the downsampled output from the boldModel can correctly appended to previous data # so: we are lazy here and simply disable appending in that case ... if not bold_input . shape [ 1 ] % self . boldModel . samplingRate_NDt == 0 : append = False logging . warn ( f \"Output size { bold_input . shape [ 1 ] } is not a multiple of BOLD sampling length { self . boldModel . samplingRate_NDt } , will not append data.\" ) logging . debug ( f \"Simulating BOLD: boldModel.run(append= { append } )\" ) # transform bold input according to self.boldInputTransform if self . boldInputTransform : bold_input = self . boldInputTransform ( bold_input ) # simulate bold model self . boldModel . run ( bold_input , append = append ) t_BOLD = self . boldModel . t_BOLD BOLD = self . boldModel . BOLD self . setOutput ( \"BOLD.t_BOLD\" , t_BOLD ) self . setOutput ( \"BOLD.BOLD\" , BOLD ) else : logging . warn ( f \"Will not simulate BOLD if output { bold_input . shape [ 1 ] * self . params [ 'dt' ] } not at least of duration { self . boldModel . samplingRate_NDt * self . params [ 'dt' ] } \" ) else : logging . warn ( \"BOLD model not initialized, not simulating BOLD. Use `run(bold=True)`\" ) storeOutputsAndStates ( self , t , variables , append = False ) Takes the simulated variables of the integration and stores it to the appropriate model output and state object. Parameters: Name Type Description Default t list time vector required variables numpy.ndarray variable from time integration required append bool, optional append output to existing output or overwrite, defaults to False False Source code in neurolib/models/model.py def storeOutputsAndStates ( self , t , variables , append = False ): \"\"\"Takes the simulated variables of the integration and stores it to the appropriate model output and state object. :param t: time vector :type t: list :param variables: variable from time integration :type variables: numpy.ndarray :param append: append output to existing output or overwrite, defaults to False :type append: bool, optional \"\"\" # save time array self . setOutput ( \"t\" , t , append = append , removeICs = True ) self . setStateVariables ( \"t\" , t ) # save outputs for svn , sv in zip ( self . state_vars , variables ): if svn in self . output_vars : self . setOutput ( svn , sv , append = append , removeICs = True ) self . setStateVariables ( svn , sv ) xr ( self , group = '' ) Converts a group of outputs to xarray. Output group needs to contain an element that starts with the letter \"t\" or it will not recognize any time axis. Parameters: Name Type Description Default group str Output group name, example: \"BOLD\". Leave empty for top group. '' Source code in neurolib/models/model.py def xr ( self , group = \"\" ): \"\"\"Converts a group of outputs to xarray. Output group needs to contain an element that starts with the letter \"t\" or it will not recognize any time axis. :param group: Output group name, example: \"BOLD\". Leave empty for top group. :type group: str \"\"\" assert isinstance ( group , str ), \"Group name must be a string.\" # take all outputs of one group: disregard all dictionaries because they are subgroups outputDict = self . getOutputs ( group ) # make sure that there is a time array timeDictKey = \"\" if \"t\" in outputDict : timeDictKey = \"t\" else : for k in outputDict : if k . startswith ( \"t\" ): timeDictKey = k logging . info ( f \"Assuming { k } to be the time axis.\" ) break assert len ( timeDictKey ) > 0 , f \"No time array found (starting with t) in output group { group } .\" t = outputDict [ timeDictKey ] . copy () del outputDict [ timeDictKey ] outputs = [] outputNames = [] for key , value in outputDict . items (): outputNames . append ( key ) outputs . append ( value ) nNodes = outputs [ 0 ] . shape [ 0 ] nodes = list ( range ( nNodes )) allOutputsStacked = np . stack ( outputs ) # What? Where? When? result = xr . DataArray ( allOutputsStacked , coords = [ outputNames , nodes , t ], dims = [ \"output\" , \"space\" , \"time\" ]) return result","title":"Models"},{"location":"models/model/#models","text":"Models are the core of neurolib . The Model superclass will help you to load, simulate, and analyse models. It also makes it very easy to implement your own neural mass model (see Example 0.6 custom model ).","title":"Models"},{"location":"models/model/#loading-a-model","text":"To load a model, we need to import the submodule of a model and instantiate it. This example shows how to load a single node of the ALNModel . See Example 0 aln minimal on how to simulate a whole-brain network using this model. from neurolib.models.aln import ALNModel # Import the model model = ALNModel() # Create an instance model.run() # Run it","title":"Loading a model"},{"location":"models/model/#model-base-class-methods","text":"The Model base class runs models, manages their outputs, parameters and more. This class should serve as the base class for all implemented models.","title":"Model base class methods"},{"location":"models/model/#neurolib.models.model.Model.output","text":"Returns value of default output as defined by self.default_output . Note that all outputs are saved in the attribute self.outputs .","title":"output"},{"location":"models/model/#neurolib.models.model.Model.__getitem__","text":"Index outputs with a dictionary-like key, e.g., model['rates_exc'] . Source code in neurolib/models/model.py def __getitem__ ( self , key ): \"\"\"Index outputs with a dictionary-like key, e.g., `model['rates_exc']`.\"\"\" return self . getOutput ( key )","title":"__getitem__()"},{"location":"models/model/#neurolib.models.model.Model.autochunk","text":"Executes a single chunk of integration, either for a given duration or a single timestep dt . Gathers all inputs to the model and resets the initial conditions as a preparation for the next chunk. Parameters: Name Type Description Default inputs list[np.ndarray|], optional list of input values, ordered according to self.input_vars, defaults to None None chunksize int, optional length of a chunk to simulate in dt, defaults 1 1 append_outputs bool, optional append the chunkwise outputs to the outputs attribute, defaults to False False Source code in neurolib/models/model.py def autochunk ( self , inputs = None , chunksize = 1 , append_outputs = False , bold = False ): \"\"\"Executes a single chunk of integration, either for a given duration or a single timestep `dt`. Gathers all inputs to the model and resets the initial conditions as a preparation for the next chunk. :param inputs: list of input values, ordered according to self.input_vars, defaults to None :type inputs: list[np.ndarray|], optional :param chunksize: length of a chunk to simulate in dt, defaults 1 :type chunksize: int, optional :param append_outputs: append the chunkwise outputs to the outputs attribute, defaults to False :type append_outputs: bool, optional \"\"\" # set the duration for this chunk self . params [ \"duration\" ] = chunksize * self . params [ \"dt\" ] # set inputs if inputs is not None : self . setInputs ( inputs ) # run integration self . integrate ( append_outputs = append_outputs , simulate_bold = bold ) # set initial conditions to last state for the next chunk self . setInitialValuesToLastState ()","title":"autochunk()"},{"location":"models/model/#neurolib.models.model.Model.checkChunkwise","text":"Checks if the model fulfills requirements for chunkwise simulation. Checks whether the sampling rate for outputs fits to chunksize and duration. Throws errors if not. Source code in neurolib/models/model.py def checkChunkwise ( self , chunksize ): \"\"\"Checks if the model fulfills requirements for chunkwise simulation. Checks whether the sampling rate for outputs fits to chunksize and duration. Throws errors if not.\"\"\" assert self . state_vars is not None , \"State variable names not given.\" assert self . init_vars is not None , \"Initial value variable names not given.\" assert len ( self . state_vars ) == len ( self . init_vars ), \"State variables are not same length as initial values.\" # throw a warning if the user is nasty if int ( self . params [ \"duration\" ] / self . params [ \"dt\" ]) % chunksize != 0 : logging . warning ( f \"It is strongly advised to use a `chunksize` ( { chunksize } ) that is a divisor of `duration / dt` ( { int ( self . params [ 'duration' ] / self . params [ 'dt' ]) } ).\" ) # if `sampling_dt` is set, do some checks if self . params . get ( \"sampling_dt\" ) is not None : # sample_dt checks are required after setting chunksize assert ( chunksize * self . params [ \"dt\" ] >= self . params [ \"sampling_dt\" ] ), \"`chunksize * dt` must be >= `sampling_dt`\" # ugly floating point modulo hack: instead of float1%float2==0, we do # (float1/float2)%1==0 assert (( chunksize * self . params [ \"dt\" ]) / self . params [ \"sampling_dt\" ]) % 1 == 0 , ( f \"Chunksize { chunksize * self . params [ 'dt' ] } must be divisible by sampling dt \" f \" { self . params [ 'sampling_dt' ] } \" ) assert ( ( self . params [ \"duration\" ] % ( chunksize * self . params [ \"dt\" ])) / self . params [ \"sampling_dt\" ] ) % 1 == 0 , ( f \"Last chunk of size { self . params [ 'duration' ] % ( chunksize * self . params [ 'dt' ]) } must be divisible by sampling dt \" f \" { self . params [ 'sampling_dt' ] } \" )","title":"checkChunkwise()"},{"location":"models/model/#neurolib.models.model.Model.clearModelState","text":"Clears the model's state to create a fresh one Source code in neurolib/models/model.py def clearModelState ( self ): \"\"\"Clears the model's state to create a fresh one\"\"\" self . state = dotdict ({}) self . outputs = dotdict ({}) # reinitialize bold model if self . params . get ( \"bold\" ): self . initializeBold ()","title":"clearModelState()"},{"location":"models/model/#neurolib.models.model.Model.getMaxDelay","text":"Computes the maximum delay of the model. This function should be overloaded if the model has internal delays (additional to delay between nodes defined by Dmat) such as the delay between an excitatory and inhibitory population within each brain area. If this function is not overloaded, the maximum delay is assumed to be defined from the global delay matrix Dmat . Note: Maxmimum delay is given in units of dt. Returns: Type Description int maxmimum delay of the model in units of dt Source code in neurolib/models/model.py def getMaxDelay ( self ): \"\"\"Computes the maximum delay of the model. This function should be overloaded if the model has internal delays (additional to delay between nodes defined by Dmat) such as the delay between an excitatory and inhibitory population within each brain area. If this function is not overloaded, the maximum delay is assumed to be defined from the global delay matrix `Dmat`. Note: Maxmimum delay is given in units of dt. :return: maxmimum delay of the model in units of dt :rtype: int \"\"\" dt = self . params . get ( \"dt\" ) Dmat = self . params . get ( \"lengthMat\" ) if Dmat is not None : # divide Dmat by signalV signalV = self . params . get ( \"signalV\" ) or 0 if signalV > 0 : Dmat = Dmat / signalV else : # if signalV is 0, eliminate delays Dmat = Dmat * 0.0 # only if Dmat and dt exist, a global max delay can be computed if Dmat is not None and dt is not None : Dmat_ndt = np . around ( Dmat / dt ) # delay matrix in multiples of dt max_global_delay = int ( np . amax ( Dmat_ndt )) else : max_global_delay = 0 return max_global_delay","title":"getMaxDelay()"},{"location":"models/model/#neurolib.models.model.Model.getOutput","text":"Get an output of a given name (dot.semarated) Parameters: Name Type Description Default name str A key, grouped outputs in the form group.subgroup.variable required Returns: Type Description Output data Source code in neurolib/models/model.py def getOutput ( self , name ): \"\"\"Get an output of a given name (dot.semarated) :param name: A key, grouped outputs in the form group.subgroup.variable :type name: str :returns: Output data \"\"\" assert isinstance ( name , str ), \"Output name must be a string.\" keys = name . split ( \".\" ) lastOutput = self . outputs . copy () for i , k in enumerate ( keys ): assert k in lastOutput , f \"Key { k } not found in outputs.\" lastOutput = lastOutput [ k ] return lastOutput","title":"getOutput()"},{"location":"models/model/#neurolib.models.model.Model.getOutputs","text":"Get all outputs of an output group. Examples: getOutputs(\"BOLD\") or simply getOutputs() Parameters: Name Type Description Default group str Group name, subgroups separated by dots. If left empty (default), all outputs of the root group are returned. '' Source code in neurolib/models/model.py def getOutputs ( self , group = \"\" ): \"\"\"Get all outputs of an output group. Examples: `getOutputs(\"BOLD\")` or simply `getOutputs()` :param group: Group name, subgroups separated by dots. If left empty (default), all outputs of the root group are returned. :type group: str \"\"\" assert isinstance ( group , str ), \"Group name must be a string.\" def filterOutputsFromGroupDict ( groupDict ): \"\"\"Return a dictionary with the output data of a group disregarding all other nested dicts. :param groupDict: Dictionary of outputs (can include other groups) :type groupDict: dict \"\"\" assert isinstance ( groupDict , dict ), \"Not a dictionary.\" # make a deep copy of the dictionary returnDict = groupDict . copy () for key , value in groupDict . items (): if isinstance ( value , dict ): del returnDict [ key ] return returnDict # if a group deeper than the root is given, select the last node lastOutput = self . outputs . copy () if len ( group ) > 0 : keys = group . split ( \".\" ) for i , k in enumerate ( keys ): assert k in lastOutput , f \"Key { k } not found in outputs.\" lastOutput = lastOutput [ k ] assert isinstance ( lastOutput , dict ), f \"Key { k } does not refer to a group.\" # filter out all output *groups* that might be in this node and return only output data return filterOutputsFromGroupDict ( lastOutput )","title":"getOutputs()"},{"location":"models/model/#neurolib.models.model.Model.initializeBold","text":"Initialize BOLD model. Source code in neurolib/models/model.py def initializeBold ( self ): \"\"\"Initialize BOLD model.\"\"\" self . boldInitialized = False # function to transform model state before passing it to the bold model # Note: This can be used like the parameter \\epsilon in Friston2000 # (neural efficacy) by multiplying the input with a constant via # self.boldInputTransform = lambda x: x * epsilon if not hasattr ( self , \"boldInputTransform\" ): self . boldInputTransform = None self . boldModel = bold . BOLDModel ( self . params [ \"N\" ], self . params [ \"dt\" ]) self . boldInitialized = True","title":"initializeBold()"},{"location":"models/model/#neurolib.models.model.Model.initializeRun","text":"Initialization before each run. Parameters: Name Type Description Default initializeBold bool initialize BOLD model False Source code in neurolib/models/model.py def initializeRun ( self , initializeBold = False ): \"\"\"Initialization before each run. :param initializeBold: initialize BOLD model :type initializeBold: bool \"\"\" # get the maxDelay of the system self . maxDelay = self . getMaxDelay () # length of the initial condition self . startindt = self . maxDelay + 1 # check dt / sampling_dt self . setSamplingDt () # force bold if params['bold'] == True if self . params . get ( \"bold\" ): initializeBold = True # set up the bold model, if it didn't happen yet if initializeBold and not self . boldInitialized : self . initializeBold ()","title":"initializeRun()"},{"location":"models/model/#neurolib.models.model.Model.integrate","text":"Calls each models integration function and saves the state and the outputs of the model. Parameters: Name Type Description Default append bool, optional append the chunkwise outputs to the outputs attribute, defaults to False, defaults to False required Source code in neurolib/models/model.py def integrate ( self , append_outputs = False , simulate_bold = False ): \"\"\"Calls each models `integration` function and saves the state and the outputs of the model. :param append: append the chunkwise outputs to the outputs attribute, defaults to False, defaults to False :type append: bool, optional \"\"\" # run integration t , * variables = self . integration ( self . params ) self . storeOutputsAndStates ( t , variables , append = append_outputs ) # force bold if params['bold'] == True if self . params . get ( \"bold\" ): simulate_bold = True # bold simulation after integration if simulate_bold and self . boldInitialized : self . simulateBold ( t , variables , append = True )","title":"integrate()"},{"location":"models/model/#neurolib.models.model.Model.integrateChunkwise","text":"Repeatedly calls the chunkwise integration for the whole duration of the simulation. If bold==True , the BOLD model is simulated after each chunk. Parameters: Name Type Description Default chunksize int size of each chunk to simulate in units of dt required bold bool, optional simulate BOLD model after each chunk, defaults to False False append_outputs bool, optional append the chunkwise outputs to the outputs attribute, defaults to False False Source code in neurolib/models/model.py def integrateChunkwise ( self , chunksize , bold = False , append_outputs = False ): \"\"\"Repeatedly calls the chunkwise integration for the whole duration of the simulation. If `bold==True`, the BOLD model is simulated after each chunk. :param chunksize: size of each chunk to simulate in units of dt :type chunksize: int :param bold: simulate BOLD model after each chunk, defaults to False :type bold: bool, optional :param append_outputs: append the chunkwise outputs to the outputs attribute, defaults to False :type append_outputs: bool, optional \"\"\" totalDuration = self . params [ \"duration\" ] dt = self . params [ \"dt\" ] # create a shallow copy of the parameters lastT = 0 while totalDuration - lastT >= dt - 1e-6 : # Determine the size of the next chunk # account for floating point errors remainingChunkSize = int ( round (( totalDuration - lastT ) / dt )) currentChunkSize = min ( chunksize , remainingChunkSize ) self . autochunk ( chunksize = currentChunkSize , append_outputs = append_outputs , bold = bold ) # we save the last simulated time step lastT += currentChunkSize * dt # or # lastT = self.state[\"t\"][-1] # set duration back to its original value self . params [ \"duration\" ] = totalDuration","title":"integrateChunkwise()"},{"location":"models/model/#neurolib.models.model.Model.randomICs","text":"Generates a new set of uniformly-distributed random initial conditions for the model. TODO: All parameters are drawn from the same distribution / range. Allow for independent ranges. Parameters: Name Type Description Default min float Minium of uniform distribution 0 max float Maximum of uniform distribution 1 Source code in neurolib/models/model.py def randomICs ( self , min = 0 , max = 1 ): \"\"\"Generates a new set of uniformly-distributed random initial conditions for the model. TODO: All parameters are drawn from the same distribution / range. Allow for independent ranges. :param min: Minium of uniform distribution :type min: float :param max: Maximum of uniform distribution :type max: float \"\"\" for iv in self . init_vars : if self . params [ iv ] . ndim == 1 : self . params [ iv ] = np . random . uniform ( min , max , ( self . params [ \"N\" ])) elif self . params [ iv ] . ndim == 2 : self . params [ iv ] = np . random . uniform ( min , max , ( self . params [ \"N\" ], 1 ))","title":"randomICs()"},{"location":"models/model/#neurolib.models.model.Model.run","text":"Main interfacing function to run a model. The model can be run in three different ways: 1) model.run() starts a new run. 2) model.run(chunkwise=True) runs the simulation in chunks of length chunksize . 3) mode.run(continue_run=True) continues the simulation of a previous run. Parameters: Name Type Description Default inputs list[np.ndarray|] list of inputs to the model, must have the same order as model.input_vars. Note: no sanity check is performed for performance reasons. Take care of the inputs yourself. None chunkwise bool, optional simulate model chunkwise or in one single run, defaults to False False chunksize int, optional size of the chunk to simulate in dt, if set will imply chunkwise=True, defaults to 2s None bold bool, optional simulate BOLD signal (only for chunkwise integration), defaults to False False append bool, optional append the chunkwise outputs to the outputs attribute, defaults to False, defaults to False False continue_run bool continue a simulation by using the initial values from a previous simulation False Source code in neurolib/models/model.py def run ( self , inputs = None , chunkwise = False , chunksize = None , bold = False , append = False , append_outputs = None , continue_run = False , ): \"\"\" Main interfacing function to run a model. The model can be run in three different ways: 1) `model.run()` starts a new run. 2) `model.run(chunkwise=True)` runs the simulation in chunks of length `chunksize`. 3) `mode.run(continue_run=True)` continues the simulation of a previous run. :param inputs: list of inputs to the model, must have the same order as model.input_vars. Note: no sanity check is performed for performance reasons. Take care of the inputs yourself. :type inputs: list[np.ndarray|] :param chunkwise: simulate model chunkwise or in one single run, defaults to False :type chunkwise: bool, optional :param chunksize: size of the chunk to simulate in dt, if set will imply chunkwise=True, defaults to 2s :type chunksize: int, optional :param bold: simulate BOLD signal (only for chunkwise integration), defaults to False :type bold: bool, optional :param append: append the chunkwise outputs to the outputs attribute, defaults to False, defaults to False :type append: bool, optional :param continue_run: continue a simulation by using the initial values from a previous simulation :type continue_run: bool \"\"\" # TODO: legacy argument support if append_outputs is not None : append = append_outputs # if a previous run is not to be continued clear the model's state if continue_run is False : self . clearModelState () self . initializeRun ( initializeBold = bold ) # enable chunkwise if chunksize is set chunkwise = chunkwise if chunksize is None else True if chunkwise is False : self . integrate ( append_outputs = append , simulate_bold = bold ) if continue_run : self . setInitialValuesToLastState () else : if chunksize is None : chunksize = int ( 2000 / self . params [ \"dt\" ]) # check if model is safe for chunkwise integration # and whether sampling_dt is compatible with duration and chunksize self . checkChunkwise ( chunksize ) if bold and not self . boldInitialized : logging . warn ( f \" { self . name } : BOLD model not initialized, not simulating BOLD. Use `run(bold=True)`\" ) bold = False self . integrateChunkwise ( chunksize = chunksize , bold = bold , append_outputs = append ) # check if there was a problem with the simulated data self . checkOutputs ()","title":"run()"},{"location":"models/model/#neurolib.models.model.Model.setInitialValuesToLastState","text":"Reads the last state of the model and sets the initial conditions to that state for continuing a simulation. Source code in neurolib/models/model.py def setInitialValuesToLastState ( self ): \"\"\"Reads the last state of the model and sets the initial conditions to that state for continuing a simulation.\"\"\" for iv , sv in zip ( self . init_vars , self . state_vars ): # if state variables are one-dimensional (in space only) if ( self . state [ sv ] . ndim == 0 ) or ( self . state [ sv ] . ndim == 1 ): self . params [ iv ] = self . state [ sv ] # if they are space-time arrays else : # we set the next initial condition to the last state self . params [ iv ] = self . state [ sv ][:, - self . startindt :]","title":"setInitialValuesToLastState()"},{"location":"models/model/#neurolib.models.model.Model.setInputs","text":"Take inputs from a list and store it in the appropriate model parameter for external input. TODO: This is not safe yet, checks should be implemented whether the model has inputs defined or not for example. Parameters: Name Type Description Default inputs list[np.ndarray(), ...] list of inputs required Source code in neurolib/models/model.py def setInputs ( self , inputs ): \"\"\"Take inputs from a list and store it in the appropriate model parameter for external input. TODO: This is not safe yet, checks should be implemented whether the model has inputs defined or not for example. :param inputs: list of inputs :type inputs: list[np.ndarray(), ...] \"\"\" for i , iv in enumerate ( self . input_vars ): self . params [ iv ] = inputs [ i ] . copy ()","title":"setInputs()"},{"location":"models/model/#neurolib.models.model.Model.setOutput","text":"Adds an output to the model, typically a simulation result. Parameters: Name Type Description Default name str Name of the output in dot.notation, a la \"outputgroup.output\" required data `numpy.ndarray` Output data, can't be a dictionary! required Source code in neurolib/models/model.py def setOutput ( self , name , data , append = False , removeICs = False ): \"\"\"Adds an output to the model, typically a simulation result. :params name: Name of the output in dot.notation, a la \"outputgroup.output\" :type name: str :params data: Output data, can't be a dictionary! :type data: `numpy.ndarray` \"\"\" assert not isinstance ( data , dict ), \"Output data cannot be a dictionary.\" assert isinstance ( name , str ), \"Output name must be a string.\" assert isinstance ( data , np . ndarray ), \"Output must be a `numpy.ndarray`.\" # remove initial conditions from output if removeICs and name != \"t\" : if data . ndim == 1 : data = data [ self . startindt :] elif data . ndim == 2 : data = data [:, self . startindt :] else : raise ValueError ( f \"Don't know how to truncate data of shape { data . shape } .\" ) # subsample to sampling dt if data . ndim == 1 : data = data [:: self . sample_every ] elif data . ndim == 2 : data = data [:, :: self . sample_every ] else : raise ValueError ( f \"Don't know how to subsample data of shape { data . shape } .\" ) # if the output is a single name (not dot.separated) if \".\" not in name : # append data if append and name in self . outputs : # special treatment for time data: # increment the time by the last recorded duration if name == \"t\" : data += self . outputs [ name ][ - 1 ] self . outputs [ name ] = np . hstack (( self . outputs [ name ], data )) else : # save all data into output dict self . outputs [ name ] = data # set output as an attribute setattr ( self , name , self . outputs [ name ]) else : # build results dictionary and write into self.outputs # dot.notation iteration keys = name . split ( \".\" ) level = self . outputs # not copy, reference! for i , k in enumerate ( keys ): # if it's the last iteration, store data if i == len ( keys ) - 1 : # TODO: this needs to be append-aware like above # if append: # if k == \"t\": # data += level[k][-1] # level[k] = np.hstack((level[k], data)) # else: # level[k] = data level [ k ] = data # if key is in outputs, then go deeper elif k in level : level = level [ k ] setattr ( self , k , level ) # if it's a new key, create new nested dictionary, set attribute, then go deeper else : level [ k ] = dotdict ({}) setattr ( self , k , level [ k ]) level = level [ k ]","title":"setOutput()"},{"location":"models/model/#neurolib.models.model.Model.setSamplingDt","text":"Checks if sampling_dt is set correctly and sets self. sample_every 1) Check if sampling_dt is multiple of dt 2) Check if semplind_dt is greater than duration Source code in neurolib/models/model.py def setSamplingDt ( self ): \"\"\"Checks if sampling_dt is set correctly and sets self.`sample_every` 1) Check if sampling_dt is multiple of dt 2) Check if semplind_dt is greater than duration \"\"\" if self . params . get ( \"sampling_dt\" ) is None : self . sample_every = 1 elif self . params . get ( \"sampling_dt\" ) > 0 : assert self . params [ \"sampling_dt\" ] >= self . params [ \"dt\" ], \"`sampling_dt` needs to be >= `dt`\" assert ( self . params [ \"duration\" ] >= self . params [ \"sampling_dt\" ] ), \"`sampling_dt` needs to be lower than `duration`\" self . sample_every = int ( self . params [ \"sampling_dt\" ] / self . params [ \"dt\" ]) else : raise ValueError ( f \"Can't handle `sampling_dt`= { self . params . get ( 'sampling_dt' ) } \" )","title":"setSamplingDt()"},{"location":"models/model/#neurolib.models.model.Model.setStateVariables","text":"Saves the models current state variables. TODO: Cut state variables to length of self.maxDelay However, this could be time-memory tradeoff Parameters: Name Type Description Default name str name of the state variable required data np.ndarray value of the variable required Source code in neurolib/models/model.py def setStateVariables ( self , name , data ): \"\"\"Saves the models current state variables. TODO: Cut state variables to length of self.maxDelay However, this could be time-memory tradeoff :param name: name of the state variable :type name: str :param data: value of the variable :type data: np.ndarray \"\"\" # old # self.state[name] = data.copy() # if the data is temporal, cut off initial values # NOTE: this shuold actually check for # if data.shape[1] > 1: # else: data.copy() # there coulb be (N, 1)-dimensional output, right now # it is requred to be of shape (N, ) if data . ndim == 2 : self . state [ name ] = data [:, - self . startindt :] . copy () else : self . state [ name ] = data . copy ()","title":"setStateVariables()"},{"location":"models/model/#neurolib.models.model.Model.simulateBold","text":"Gets the default output of the model and simulates the BOLD model. Adds the simulated BOLD signal to outputs. Source code in neurolib/models/model.py def simulateBold ( self , t , variables , append = False ): \"\"\"Gets the default output of the model and simulates the BOLD model. Adds the simulated BOLD signal to outputs. \"\"\" if self . boldInitialized : # first we loop through all state variables for svn , sv in zip ( self . state_vars , variables ): # the default output is used as the input for the bold model if svn == self . default_output : bold_input = sv [:, self . startindt :] # logging.debug(f\"BOLD input `{svn}` of shape {bold_input.shape}\") if bold_input . shape [ 1 ] >= self . boldModel . samplingRate_NDt : # only if the length of the output has a zero mod to the sampling rate, # the downsampled output from the boldModel can correctly appended to previous data # so: we are lazy here and simply disable appending in that case ... if not bold_input . shape [ 1 ] % self . boldModel . samplingRate_NDt == 0 : append = False logging . warn ( f \"Output size { bold_input . shape [ 1 ] } is not a multiple of BOLD sampling length { self . boldModel . samplingRate_NDt } , will not append data.\" ) logging . debug ( f \"Simulating BOLD: boldModel.run(append= { append } )\" ) # transform bold input according to self.boldInputTransform if self . boldInputTransform : bold_input = self . boldInputTransform ( bold_input ) # simulate bold model self . boldModel . run ( bold_input , append = append ) t_BOLD = self . boldModel . t_BOLD BOLD = self . boldModel . BOLD self . setOutput ( \"BOLD.t_BOLD\" , t_BOLD ) self . setOutput ( \"BOLD.BOLD\" , BOLD ) else : logging . warn ( f \"Will not simulate BOLD if output { bold_input . shape [ 1 ] * self . params [ 'dt' ] } not at least of duration { self . boldModel . samplingRate_NDt * self . params [ 'dt' ] } \" ) else : logging . warn ( \"BOLD model not initialized, not simulating BOLD. Use `run(bold=True)`\" )","title":"simulateBold()"},{"location":"models/model/#neurolib.models.model.Model.storeOutputsAndStates","text":"Takes the simulated variables of the integration and stores it to the appropriate model output and state object. Parameters: Name Type Description Default t list time vector required variables numpy.ndarray variable from time integration required append bool, optional append output to existing output or overwrite, defaults to False False Source code in neurolib/models/model.py def storeOutputsAndStates ( self , t , variables , append = False ): \"\"\"Takes the simulated variables of the integration and stores it to the appropriate model output and state object. :param t: time vector :type t: list :param variables: variable from time integration :type variables: numpy.ndarray :param append: append output to existing output or overwrite, defaults to False :type append: bool, optional \"\"\" # save time array self . setOutput ( \"t\" , t , append = append , removeICs = True ) self . setStateVariables ( \"t\" , t ) # save outputs for svn , sv in zip ( self . state_vars , variables ): if svn in self . output_vars : self . setOutput ( svn , sv , append = append , removeICs = True ) self . setStateVariables ( svn , sv )","title":"storeOutputsAndStates()"},{"location":"models/model/#neurolib.models.model.Model.xr","text":"Converts a group of outputs to xarray. Output group needs to contain an element that starts with the letter \"t\" or it will not recognize any time axis. Parameters: Name Type Description Default group str Output group name, example: \"BOLD\". Leave empty for top group. '' Source code in neurolib/models/model.py def xr ( self , group = \"\" ): \"\"\"Converts a group of outputs to xarray. Output group needs to contain an element that starts with the letter \"t\" or it will not recognize any time axis. :param group: Output group name, example: \"BOLD\". Leave empty for top group. :type group: str \"\"\" assert isinstance ( group , str ), \"Group name must be a string.\" # take all outputs of one group: disregard all dictionaries because they are subgroups outputDict = self . getOutputs ( group ) # make sure that there is a time array timeDictKey = \"\" if \"t\" in outputDict : timeDictKey = \"t\" else : for k in outputDict : if k . startswith ( \"t\" ): timeDictKey = k logging . info ( f \"Assuming { k } to be the time axis.\" ) break assert len ( timeDictKey ) > 0 , f \"No time array found (starting with t) in output group { group } .\" t = outputDict [ timeDictKey ] . copy () del outputDict [ timeDictKey ] outputs = [] outputNames = [] for key , value in outputDict . items (): outputNames . append ( key ) outputs . append ( value ) nNodes = outputs [ 0 ] . shape [ 0 ] nodes = list ( range ( nNodes )) allOutputsStacked = np . stack ( outputs ) # What? Where? When? result = xr . DataArray ( allOutputsStacked , coords = [ outputNames , nodes , t ], dims = [ \"output\" , \"space\" , \"time\" ]) return result","title":"xr()"},{"location":"models/parameters/","text":"Parameters Model parameters in neurolib are stored as a dictionary-like object params as one of a model's attributes. Changing parameters is straightforward: from neurolib.models.aln import ALNModel # Import the model model = ALNModel () # Create an instance model . params [ 'duration' ] = 10 * 1000 # in ms model . run () # Run it Parameters are dotdict objects that can also be accessed using the more simple syntax model.params.parameter_name = 123 (see Collections ). Default parameters The default parameters of a model are stored in the loadDefaultParams.py within each model's directory. This function is called by the model.py file upon initialisation and returns all necessary parameters of the model. Below is an example function that prepares the structural connectivity matrices Cmat and Dmat , all parameters of the model, and its initial values. def loadDefaultParams ( Cmat = None , Dmat = None , seed = None ): \"\"\"Load default parameters for a model :param Cmat: Structural connectivity matrix (adjacency matrix) of coupling strengths, will be normalized to 1. If not given, then a single node simulation will be assumed, defaults to None :type Cmat: numpy.ndarray, optional :param Dmat: Fiber length matrix, will be used for computing the delay matrix together with the signal transmission speed parameter `signalV`, defaults to None :type Dmat: numpy.ndarray, optional :param seed: Seed for the random number generator, defaults to None :type seed: int, optional :return: A dictionary with the default parameters of the model :rtype: dict \"\"\" params = dotdict ({}) ### runtime parameters params . dt = 0.1 # ms 0.1ms is reasonable params . duration = 2000 # Simulation duration (ms) np . random . seed ( seed ) # seed for RNG of noise and ICs # set seed to 0 if None, pypet will complain otherwise params . seed = seed or 0 # make sure that seed=0 remains None if seed == 0 : seed = None # ------------------------------------------------------------------------ # global whole-brain network parameters # ------------------------------------------------------------------------ # the coupling parameter determines how nodes are coupled. # \"diffusive\" for diffusive coupling, \"additive\" for additive coupling params . coupling = \"diffusive\" params . signalV = 20.0 params . K_gl = 0.6 # global coupling strength if Cmat is None : params . N = 1 params . Cmat = np . zeros (( 1 , 1 )) params . lengthMat = np . zeros (( 1 , 1 )) else : params . Cmat = Cmat . copy () # coupling matrix np . fill_diagonal ( params . Cmat , 0 ) # no self connections params . N = len ( params . Cmat ) # number of nodes params . lengthMat = Dmat # ------------------------------------------------------------------------ # local node parameters # ------------------------------------------------------------------------ # external input parameters: params . tau_ou = 5.0 # ms Timescale of the Ornstein-Uhlenbeck noise process params . sigma_ou = 0.0 # mV/ms/sqrt(ms) noise intensity params . x_ou_mean = 0.0 # mV/ms (OU process) [0-5] params . y_ou_mean = 0.0 # mV/ms (OU process) [0-5] # neural mass model parameters params . a = 0.25 # Hopf bifurcation parameter params . w = 0.2 # Oscillator frequency, 32 Hz at w = 0.2 # ------------------------------------------------------------------------ # initial values of the state variables params . xs_init = 0.5 * np . random . uniform ( - 1 , 1 , ( params . N , 1 )) params . ys_init = 0.5 * np . random . uniform ( - 1 , 1 , ( params . N , 1 )) # Ornstein-Uhlenbeck noise state variables params . x_ou = np . zeros (( params . N ,)) params . y_ou = np . zeros (( params . N ,)) # values of the external inputs params . x_ext = np . zeros (( params . N ,)) params . y_ext = np . zeros (( params . N ,)) return params","title":"Parameters"},{"location":"models/parameters/#parameters","text":"Model parameters in neurolib are stored as a dictionary-like object params as one of a model's attributes. Changing parameters is straightforward: from neurolib.models.aln import ALNModel # Import the model model = ALNModel () # Create an instance model . params [ 'duration' ] = 10 * 1000 # in ms model . run () # Run it Parameters are dotdict objects that can also be accessed using the more simple syntax model.params.parameter_name = 123 (see Collections ).","title":"Parameters"},{"location":"models/parameters/#default-parameters","text":"The default parameters of a model are stored in the loadDefaultParams.py within each model's directory. This function is called by the model.py file upon initialisation and returns all necessary parameters of the model. Below is an example function that prepares the structural connectivity matrices Cmat and Dmat , all parameters of the model, and its initial values. def loadDefaultParams ( Cmat = None , Dmat = None , seed = None ): \"\"\"Load default parameters for a model :param Cmat: Structural connectivity matrix (adjacency matrix) of coupling strengths, will be normalized to 1. If not given, then a single node simulation will be assumed, defaults to None :type Cmat: numpy.ndarray, optional :param Dmat: Fiber length matrix, will be used for computing the delay matrix together with the signal transmission speed parameter `signalV`, defaults to None :type Dmat: numpy.ndarray, optional :param seed: Seed for the random number generator, defaults to None :type seed: int, optional :return: A dictionary with the default parameters of the model :rtype: dict \"\"\" params = dotdict ({}) ### runtime parameters params . dt = 0.1 # ms 0.1ms is reasonable params . duration = 2000 # Simulation duration (ms) np . random . seed ( seed ) # seed for RNG of noise and ICs # set seed to 0 if None, pypet will complain otherwise params . seed = seed or 0 # make sure that seed=0 remains None if seed == 0 : seed = None # ------------------------------------------------------------------------ # global whole-brain network parameters # ------------------------------------------------------------------------ # the coupling parameter determines how nodes are coupled. # \"diffusive\" for diffusive coupling, \"additive\" for additive coupling params . coupling = \"diffusive\" params . signalV = 20.0 params . K_gl = 0.6 # global coupling strength if Cmat is None : params . N = 1 params . Cmat = np . zeros (( 1 , 1 )) params . lengthMat = np . zeros (( 1 , 1 )) else : params . Cmat = Cmat . copy () # coupling matrix np . fill_diagonal ( params . Cmat , 0 ) # no self connections params . N = len ( params . Cmat ) # number of nodes params . lengthMat = Dmat # ------------------------------------------------------------------------ # local node parameters # ------------------------------------------------------------------------ # external input parameters: params . tau_ou = 5.0 # ms Timescale of the Ornstein-Uhlenbeck noise process params . sigma_ou = 0.0 # mV/ms/sqrt(ms) noise intensity params . x_ou_mean = 0.0 # mV/ms (OU process) [0-5] params . y_ou_mean = 0.0 # mV/ms (OU process) [0-5] # neural mass model parameters params . a = 0.25 # Hopf bifurcation parameter params . w = 0.2 # Oscillator frequency, 32 Hz at w = 0.2 # ------------------------------------------------------------------------ # initial values of the state variables params . xs_init = 0.5 * np . random . uniform ( - 1 , 1 , ( params . N , 1 )) params . ys_init = 0.5 * np . random . uniform ( - 1 , 1 , ( params . N , 1 )) # Ornstein-Uhlenbeck noise state variables params . x_ou = np . zeros (( params . N ,)) params . y_ou = np . zeros (( params . N ,)) # values of the external inputs params . x_ext = np . zeros (( params . N ,)) params . y_ext = np . zeros (( params . N ,)) return params","title":"Default parameters"},{"location":"optimization/evolution/","text":"Evolution Evolutionary parameter optimization. This class helps you to optimize any function or model using an evlutionary algorithm. It uses the package deap and supports its builtin mating and selection functions as well as custom ones. __init__ ( self , evalFunction , parameterSpace , weightList = None , model = None , filename = 'evolution.hdf' , ncores = None , POP_INIT_SIZE = 100 , POP_SIZE = 20 , NGEN = 10 , algorithm = 'adaptive' , matingOperator = None , MATE_P = None , mutationOperator = None , MUTATE_P = None , selectionOperator = None , SELECT_P = None , parentSelectionOperator = None , PARENT_SELECT_P = None , individualGenerator = None , IND_GENERATOR_P = None ) special Initialize evolutionary optimization. Parameters: Name Type Description Default evalFunction function Evaluation function of a run that provides a fitness vector and simulation outputs required parameterSpace `neurolib.utils.parameterSpace.ParameterSpace` Parameter space to run evolution in. required weightList list[float], optional List of floats that defines the dimensionality of the fitness vector returned from evalFunction and the weights of each component for multiobjective optimization (positive = maximize, negative = minimize). If not given, then a single positive weight will be used, defaults to None None model `neurolib.models.model.Model`, optional Model to simulate, defaults to None None filename str, optional HDF file to store all results in, defaults to \"evolution.hdf\" 'evolution.hdf' ncores int, optional Number of cores to simulate on (max cores default), defaults to None None POP_INIT_SIZE int, optional Size of first population to initialize evolution with (random, uniformly distributed), defaults to 100 100 POP_SIZE int, optional Size of the population during evolution, defaults to 20 20 NGEN int, optional Numbers of generations to evaluate, defaults to 10 10 matingOperator Union[deap operat,, optional] Custom mating operator, defaults to deap.tools.cxBlend None MATE_P dict, optional Mating operator keyword arguments (for the default crossover operator cxBlend, this defaults alpha = 0.5) None mutationOperator Union[deap operat,, optional] Custom mutation operator, defaults to du.gaussianAdaptiveMutation_nStepSizes None MUTATE_P dict, optional Mutation operator keyword arguments None selectionOperator Union[deap operat,, optional] Custom selection operator, defaults to du.selBest_multiObj None SELECT_P dict, optional Selection operator keyword arguments None parentSelectionOperator Operator for parent selection, defaults to du.selRank None PARENT_SELECT_P dict, optional Parent selection operator keyword arguments (for the default operator selRank, this defaults to s = 1.5 in Eiben&Smith p.81) None individualGenerator Function to generate initial individuals, defaults to du.randomParametersAdaptive None Source code in neurolib/optimize/evolution/evolution.py def __init__ ( self , evalFunction , parameterSpace , weightList = None , model = None , filename = \"evolution.hdf\" , ncores = None , POP_INIT_SIZE = 100 , POP_SIZE = 20 , NGEN = 10 , algorithm = \"adaptive\" , matingOperator = None , MATE_P = None , mutationOperator = None , MUTATE_P = None , selectionOperator = None , SELECT_P = None , parentSelectionOperator = None , PARENT_SELECT_P = None , individualGenerator = None , IND_GENERATOR_P = None , ): \"\"\"Initialize evolutionary optimization. :param evalFunction: Evaluation function of a run that provides a fitness vector and simulation outputs :type evalFunction: function :param parameterSpace: Parameter space to run evolution in. :type parameterSpace: `neurolib.utils.parameterSpace.ParameterSpace` :param weightList: List of floats that defines the dimensionality of the fitness vector returned from evalFunction and the weights of each component for multiobjective optimization (positive = maximize, negative = minimize). If not given, then a single positive weight will be used, defaults to None :type weightList: list[float], optional :param model: Model to simulate, defaults to None :type model: `neurolib.models.model.Model`, optional :param filename: HDF file to store all results in, defaults to \"evolution.hdf\" :type filename: str, optional :param ncores: Number of cores to simulate on (max cores default), defaults to None :type ncores: int, optional :param POP_INIT_SIZE: Size of first population to initialize evolution with (random, uniformly distributed), defaults to 100 :type POP_INIT_SIZE: int, optional :param POP_SIZE: Size of the population during evolution, defaults to 20 :type POP_SIZE: int, optional :param NGEN: Numbers of generations to evaluate, defaults to 10 :type NGEN: int, optional :param matingOperator: Custom mating operator, defaults to deap.tools.cxBlend :type matingOperator: deap operator, optional :param MATE_P: Mating operator keyword arguments (for the default crossover operator cxBlend, this defaults `alpha` = 0.5) :type MATE_P: dict, optional :param mutationOperator: Custom mutation operator, defaults to du.gaussianAdaptiveMutation_nStepSizes :type mutationOperator: deap operator, optional :param MUTATE_P: Mutation operator keyword arguments :type MUTATE_P: dict, optional :param selectionOperator: Custom selection operator, defaults to du.selBest_multiObj :type selectionOperator: deap operator, optional :param SELECT_P: Selection operator keyword arguments :type SELECT_P: dict, optional :param parentSelectionOperator: Operator for parent selection, defaults to du.selRank :param PARENT_SELECT_P: Parent selection operator keyword arguments (for the default operator selRank, this defaults to `s` = 1.5 in Eiben&Smith p.81) :type PARENT_SELECT_P: dict, optional :param individualGenerator: Function to generate initial individuals, defaults to du.randomParametersAdaptive \"\"\" if weightList is None : logging . info ( \"weightList not set, assuming single fitness value to be maximized.\" ) weightList = [ 1.0 ] trajectoryName = \"results\" + datetime . datetime . now () . strftime ( \"-%Y-%m- %d -%HH-%MM-%SS\" ) logging . info ( f \"Trajectory Name: { trajectoryName } \" ) self . HDF_FILE = os . path . join ( paths . HDF_DIR , filename ) trajectoryFileName = self . HDF_FILE logging . info ( \"Storing data to: {} \" . format ( trajectoryFileName )) logging . info ( \"Trajectory Name: {} \" . format ( trajectoryName )) if ncores is None : ncores = multiprocessing . cpu_count () logging . info ( \"Number of cores: {} \" . format ( ncores )) # initialize pypet environment # env = pp.Environment(trajectory=trajectoryName, filename=trajectoryFileName) env = pp . Environment ( trajectory = trajectoryName , filename = trajectoryFileName , use_pool = False , multiproc = True , ncores = ncores , complevel = 9 , log_config = paths . PYPET_LOGGING_CONFIG , ) # Get the trajectory from the environment traj = env . traj # Sanity check if everything went ok assert ( trajectoryName == traj . v_name ), f \"Pypet trajectory has a different name than trajectoryName { trajectoryName } \" # trajectoryName = traj.v_name self . model = model self . evalFunction = evalFunction self . weightList = weightList self . NGEN = NGEN assert POP_SIZE % 2 == 0 , \"Please chose an even number for POP_SIZE!\" self . POP_SIZE = POP_SIZE assert POP_INIT_SIZE % 2 == 0 , \"Please chose an even number for POP_INIT_SIZE!\" self . POP_INIT_SIZE = POP_INIT_SIZE self . ncores = ncores # comment string for storing info self . comments = \"no comments\" self . traj = env . traj self . env = env self . trajectoryName = trajectoryName self . trajectoryFileName = trajectoryFileName self . _initialPopulationSimulated = False # -------- settings self . verbose = False self . plotColor = \"C0\" # -------- simulation self . parameterSpace = parameterSpace self . ParametersInterval = self . parameterSpace . named_tuple_constructor self . paramInterval = self . parameterSpace . named_tuple self . toolbox = deap . base . Toolbox () # -------- algorithms if algorithm == \"adaptive\" : logging . info ( f \"Evolution: Using algorithm: { algorithm } \" ) self . matingOperator = tools . cxBlend self . MATE_P = { \"alpha\" : 0.5 } or MATE_P self . mutationOperator = du . gaussianAdaptiveMutation_nStepSizes self . selectionOperator = du . selBest_multiObj self . parentSelectionOperator = du . selRank self . PARENT_SELECT_P = { \"s\" : 1.5 } or PARENT_SELECT_P self . individualGenerator = du . randomParametersAdaptive elif algorithm == \"nsga2\" : logging . info ( f \"Evolution: Using algorithm: { algorithm } \" ) self . matingOperator = tools . cxSimulatedBinaryBounded self . MATE_P = { \"low\" : self . parameterSpace . lowerBound , \"up\" : self . parameterSpace . upperBound , \"eta\" : 20.0 , } or MATE_P self . mutationOperator = tools . mutPolynomialBounded self . MUTATE_P = { \"low\" : self . parameterSpace . lowerBound , \"up\" : self . parameterSpace . upperBound , \"eta\" : 20.0 , \"indpb\" : 1.0 / len ( self . weightList ), } or MUTATE_P self . selectionOperator = tools . selNSGA2 self . parentSelectionOperator = tools . selTournamentDCD self . individualGenerator = du . randomParameters else : raise ValueError ( \"Evolution: algorithm must be one of the following: ['adaptive', 'nsga2']\" ) # if the operators are set manually, then overwrite them self . matingOperator = self . matingOperator if hasattr ( self , \"matingOperator\" ) else matingOperator self . mutationOperator = self . mutationOperator if hasattr ( self , \"mutationOperator\" ) else mutationOperator self . selectionOperator = self . selectionOperator if hasattr ( self , \"selectionOperator\" ) else selectionOperator self . parentSelectionOperator = ( self . parentSelectionOperator if hasattr ( self , \"parentSelectionOperator\" ) else parentSelectionOperator ) self . individualGenerator = ( self . individualGenerator if hasattr ( self , \"individualGenerator\" ) else individualGenerator ) # let's also make sure that the parameters are set correctly self . MATE_P = self . MATE_P if hasattr ( self , \"MATE_P\" ) else {} self . PARENT_SELECT_P = self . PARENT_SELECT_P if hasattr ( self , \"PARENT_SELECT_P\" ) else {} self . MUTATE_P = self . MUTATE_P if hasattr ( self , \"MUTATE_P\" ) else {} self . SELECT_P = self . SELECT_P if hasattr ( self , \"SELECT_P\" ) else {} self . _initDEAP ( self . toolbox , self . env , self . paramInterval , self . evalFunction , weightList = self . weightList , matingOperator = self . matingOperator , mutationOperator = self . mutationOperator , selectionOperator = self . selectionOperator , parentSelectionOperator = self . parentSelectionOperator , individualGenerator = self . individualGenerator , ) # set up pypet trajectory self . _initPypetTrajectory ( self . traj , self . paramInterval , self . POP_SIZE , self . NGEN , self . model , ) # population history: dict of all valid individuals per generation self . history = {} # initialize population self . evaluationCounter = 0 self . last_id = 0 dfEvolution ( self , outputs = False ) Returns a pandas DataFrame with the individuals of the the whole evolution. This method can be usef after loading an evolution from disk using loadEvolution() Returns: Type Description Union[`pandas.c,e.frame.DataFrame`] Pandas DataFrame with all individuals and their parameters Source code in neurolib/optimize/evolution/evolution.py def dfEvolution ( self , outputs = False ): \"\"\"Returns a `pandas` DataFrame with the individuals of the the whole evolution. This method can be usef after loading an evolution from disk using loadEvolution() :return: Pandas DataFrame with all individuals and their parameters :rtype: `pandas.core.frame.DataFrame` \"\"\" parameters = self . parameterSpace . parameterNames allIndividuals = [ p for gen , pop in self . history . items () for p in pop ] popArray = np . array ([ p [ 0 : len ( self . paramInterval . _fields )] for p in allIndividuals ]) . T dfEvolution = pd . DataFrame ( popArray , index = parameters ) . T # add more information to the dataframe scores = [ float ( p . fitness . score ) for p in allIndividuals ] indIds = [ p . id for p in allIndividuals ] dfEvolution [ \"score\" ] = scores dfEvolution [ \"id\" ] = indIds dfEvolution [ \"gen\" ] = [ p . gIdx for p in allIndividuals ] if outputs : dfEvolution = self . _outputToDf ( allIndividuals , dfEvolution ) # add fitness columns # NOTE: have to do this with wvalues and divide by weights later, why? # Because after loading the evolution with dill, somehow multiple fitnesses # dissappear and only the first one is left. However, wvalues still has all # fitnesses, and we have acces to weightList, so this hack kind of helps n_fitnesses = len ( self . pop [ 0 ] . fitness . wvalues ) for i in range ( n_fitnesses ): for ip , p in enumerate ( allIndividuals ): dfEvolution . loc [ ip , f \"f { i } \" ] = p . fitness . wvalues [ i ] / self . weightList [ i ] # the history keeps all individuals of all generations # there can be duplicates (in elitism for example), which we filter # out for the dataframe dfEvolution = self . _dropDuplicatesFromDf ( dfEvolution ) dfEvolution = dfEvolution . reset_index ( drop = True ) return dfEvolution dfPop ( self , outputs = False ) Returns a pandas DataFrame of the current generation's population parameters. This object can be further used to easily analyse the population. Returns: Type Description Union[`pandas.c,e.frame.DataFrame`] Pandas DataFrame with all individuals and their parameters Source code in neurolib/optimize/evolution/evolution.py def dfPop ( self , outputs = False ): \"\"\"Returns a `pandas` DataFrame of the current generation's population parameters. This object can be further used to easily analyse the population. :return: Pandas DataFrame with all individuals and their parameters :rtype: `pandas.core.frame.DataFrame` \"\"\" # add the current population to the dataframe validPop = self . getValidPopulation ( self . pop ) indIds = [ p . id for p in validPop ] popArray = np . array ([ p [ 0 : len ( self . paramInterval . _fields )] for p in validPop ]) . T dfPop = pd . DataFrame ( popArray , index = self . parameterSpace . parameterNames ) . T # add more information to the dataframe scores = self . getScores () dfPop [ \"score\" ] = scores dfPop [ \"id\" ] = indIds dfPop [ \"gen\" ] = [ p . gIdx for p in validPop ] if outputs : dfPop = self . _outputToDf ( validPop , dfPop ) # add fitness columns # NOTE: when loading an evolution with dill using loadingEvolution # MultiFitness values dissappear and only one is left. # See dfEvolution() for a solution using wvalues n_fitnesses = len ( validPop [ 0 ] . fitness . values ) for i in range ( n_fitnesses ): for ip , p in enumerate ( validPop ): column_name = \"f\" + str ( i ) dfPop . loc [ ip , column_name ] = p . fitness . values [ i ] return dfPop getIndividualFromHistory ( self , id ) Searches the entire evolution history for an individual with a specific id and returns it. Parameters: Name Type Description Default id int Individual id required Returns: Type Description Union[`deap.creat,.Individual`] Individual ( DEAP type) Source code in neurolib/optimize/evolution/evolution.py def getIndividualFromHistory ( self , id ): \"\"\"Searches the entire evolution history for an individual with a specific id and returns it. :param id: Individual id :type id: int :return: Individual (`DEAP` type) :rtype: `deap.creator.Individual` \"\"\" for key , value in self . history . items (): for p in value : if p . id == id : return p logging . warning ( f \"No individual with id= { id } found. Returning `None`\" ) return None getIndividualFromTraj ( self , traj ) Get individual from pypet trajectory Parameters: Name Type Description Default traj Union[`pypet.traject,y.Traject,y`] Pypet trajectory required Returns: Type Description Union[`deap.creat,.Individual`] Individual ( DEAP type) Source code in neurolib/optimize/evolution/evolution.py def getIndividualFromTraj ( self , traj ): \"\"\"Get individual from pypet trajectory :param traj: Pypet trajectory :type traj: `pypet.trajectory.Trajectory` :return: Individual (`DEAP` type) :rtype: `deap.creator.Individual` \"\"\" # either pass an individual or a pypet trajectory with the attribute individual if type ( traj ) . __name__ == \"Individual\" : individual = traj else : individual = traj . individual ind_id = traj . id individual = [ p for p in self . pop if p . id == ind_id ] if len ( individual ) > 0 : individual = individual [ 0 ] return individual getInvalidPopulation ( self , pop = None ) Returns a list of the invalid population. Parameters: Name Type Description Default pop deap population Population to check, defaults to self.pop None Returns: Type Description list List of invalid population Source code in neurolib/optimize/evolution/evolution.py def getInvalidPopulation ( self , pop = None ): \"\"\"Returns a list of the invalid population. :params pop: Population to check, defaults to self.pop :type pop: deap population :return: List of invalid population :rtype: list \"\"\" pop = pop or self . pop return [ p for p in pop if np . isnan ( p . fitness . values ) . any () or np . isinf ( p . fitness . values ) . any ()] getModelFromTraj ( self , traj ) Return the appropriate model with parameters for this individual Parameters: Name Type Description Default traj Union[`pypet.traject,y.Traject,y`] Pypet trajectory with individual (traj.individual) or directly a deap.Individual required Returns: Type Description `neurolib.models.model.Model` Model with the parameters of this individual. Source code in neurolib/optimize/evolution/evolution.py def getModelFromTraj ( self , traj ): \"\"\"Return the appropriate model with parameters for this individual :params traj: Pypet trajectory with individual (traj.individual) or directly a deap.Individual :returns model: Model with the parameters of this individual. :param traj: Pypet trajectory with individual (traj.individual) or directly a deap.Individual :type traj: `pypet.trajectory.Trajectory` :return: Model with the parameters of this individual. :rtype: `neurolib.models.model.Model` \"\"\" model = self . model # resolve star notation - MultiModel individual_params = self . individualToDict ( self . getIndividualFromTraj ( traj )) if self . parameterSpace . star : individual_params = unwrap_star_dotdict ( individual_params , self . model , replaced_dict = BACKWARD_REPLACE ) model . params . update ( individual_params ) return model getScores ( self ) Returns the scores of the current valid population Source code in neurolib/optimize/evolution/evolution.py def getScores ( self ): \"\"\"Returns the scores of the current valid population\"\"\" validPop = self . getValidPopulation ( self . pop ) return np . array ([ pop . fitness . score for pop in validPop ]) getScoresDuringEvolution ( self , traj = None , drop_first = True , reverse = False ) Get the scores of each generation's population. Parameters: Name Type Description Default traj Union[`pypet.traject,y.Traject,y`, optional] Pypet trajectory. If not given, the current trajectory is used, defaults to None None drop_first bool, optional Drop the first (initial) generation. This can be usefull because it can have a different size ( POP_INIT_SIZE ) than the succeeding populations ( POP_SIZE ) which can make data handling tricky, defaults to True True reverse bool, optional Reverse the order of each generation. This is a necessary workaraound because loading from the an hdf file returns the generations in a reversed order compared to loading each generation from the pypet trajectory in memory, defaults to False False Returns: Type Description tuple[list, numpy.ndarray] Tuple of list of all generations and an array of the scores of all individuals Source code in neurolib/optimize/evolution/evolution.py def getScoresDuringEvolution ( self , traj = None , drop_first = True , reverse = False ): \"\"\"Get the scores of each generation's population. :param traj: Pypet trajectory. If not given, the current trajectory is used, defaults to None :type traj: `pypet.trajectory.Trajectory`, optional :param drop_first: Drop the first (initial) generation. This can be usefull because it can have a different size (`POP_INIT_SIZE`) than the succeeding populations (`POP_SIZE`) which can make data handling tricky, defaults to True :type drop_first: bool, optional :param reverse: Reverse the order of each generation. This is a necessary workaraound because loading from the an hdf file returns the generations in a reversed order compared to loading each generation from the pypet trajectory in memory, defaults to False :type reverse: bool, optional :return: Tuple of list of all generations and an array of the scores of all individuals :rtype: tuple[list, numpy.ndarray] \"\"\" if traj == None : traj = self . traj generation_names = list ( traj . results . evolution . f_to_dict ( nested = True ) . keys ()) if reverse : generation_names = generation_names [:: - 1 ] if drop_first and \"gen_000000\" in generation_names : generation_names . remove ( \"gen_000000\" ) npop = len ( traj . results . evolution [ generation_names [ 0 ]] . scores ) gens = [] all_scores = np . empty (( len ( generation_names ), npop )) for i , r in enumerate ( generation_names ): gens . append ( i ) scores = traj . results . evolution [ r ] . scores all_scores [ i ] = scores if drop_first : gens = np . add ( gens , 1 ) return gens , all_scores getValidPopulation ( self , pop = None ) Returns a list of the valid population. Parameters: Name Type Description Default pop deap population Population to check, defaults to self.pop None Returns: Type Description list List of valid population Source code in neurolib/optimize/evolution/evolution.py def getValidPopulation ( self , pop = None ): \"\"\"Returns a list of the valid population. :params pop: Population to check, defaults to self.pop :type pop: deap population :return: List of valid population :rtype: list \"\"\" pop = pop or self . pop return [ p for p in pop if not ( np . isnan ( p . fitness . values ) . any () or np . isinf ( p . fitness . values ) . any ())] individualToDict ( self , individual ) Convert an individual to a parameter dictionary. Parameters: Name Type Description Default individual Union[`deap.creat,.Individual`] Individual ( DEAP type) required Returns: Type Description dict Parameter dictionary of this individual Source code in neurolib/optimize/evolution/evolution.py def individualToDict ( self , individual ): \"\"\"Convert an individual to a parameter dictionary. :param individual: Individual (`DEAP` type) :type individual: `deap.creator.Individual` :return: Parameter dictionary of this individual :rtype: dict \"\"\" return self . ParametersInterval ( * ( individual [: len ( self . paramInterval )])) . _asdict () . copy () info ( self , plot = True , bestN = 5 , info = True , reverse = False ) Print and plot information about the evolution and the current population Parameters: Name Type Description Default plot bool, optional plot a plot using matplotlib , defaults to True True bestN int, optional Print summary of bestN best individuals, defaults to 5 5 info bool, optional Print information about the evolution environment True Source code in neurolib/optimize/evolution/evolution.py def info ( self , plot = True , bestN = 5 , info = True , reverse = False ): \"\"\"Print and plot information about the evolution and the current population :param plot: plot a plot using `matplotlib`, defaults to True :type plot: bool, optional :param bestN: Print summary of `bestN` best individuals, defaults to 5 :type bestN: int, optional :param info: Print information about the evolution environment :type info: bool, optional \"\"\" if info : eu . printEvolutionInfo ( self ) validPop = self . getValidPopulation ( self . pop ) scores = self . getScores () # Text output print ( \"--- Info summary ---\" ) print ( \"Valid: {} \" . format ( len ( validPop ))) print ( \"Mean score (weighted fitness): {:.2} \" . format ( np . mean ( scores ))) eu . printParamDist ( self . pop , self . paramInterval , self . gIdx ) print ( \"--------------------\" ) print ( f \"Best { bestN } individuals:\" ) eu . printIndividuals ( self . toolbox . selBest ( self . pop , bestN ), self . paramInterval ) print ( \"--------------------\" ) # Plotting if plot : # hack: during the evolution we need to use reverse=True # after the evolution (with evolution.info()), we need False try : self . plotProgress ( reverse = reverse ) except : logging . warning ( \"Could not plot progress, is this a previously saved simulation?\" ) eu . plotPopulation ( self , plotScattermatrix = True , save_plots = self . trajectoryName , color = self . plotColor , ) loadEvolution ( self , fname ) Load evolution from previously saved simulatoins. Example usage: evaluateSimulation = lambda x: x # the funciton can be ommited, that's why we define a lambda here pars = ParameterSpace(['a', 'b'], # should be same as previously saved evolution [[0.0, 4.0], [0.0, 5.0]]) evolution = Evolution(evaluateSimulation, pars, weightList = [1.0]) evolution = evolution.loadEvolution(\"data/evolution-results-2020-05-15-00H-24M-48S.dill\") Parameters: Name Type Description Default fname str Filename, defaults to a path in ./data/ required Returns: Type Description self Evolution Source code in neurolib/optimize/evolution/evolution.py def loadEvolution ( self , fname ): \"\"\"Load evolution from previously saved simulatoins. Example usage: ``` evaluateSimulation = lambda x: x # the funciton can be ommited, that's why we define a lambda here pars = ParameterSpace(['a', 'b'], # should be same as previously saved evolution [[0.0, 4.0], [0.0, 5.0]]) evolution = Evolution(evaluateSimulation, pars, weightList = [1.0]) evolution = evolution.loadEvolution(\"data/evolution-results-2020-05-15-00H-24M-48S.dill\") ``` :param fname: Filename, defaults to a path in ./data/ :type fname: str :return: Evolution :rtype: self \"\"\" import dill evolution = dill . load ( open ( fname , \"rb\" )) # parameter space is not saved correctly in dill, don't know why # that is why we recreate it using the values of # the parameter space in the dill pars = ParameterSpace ( evolution . parameterSpace . parameterNames , evolution . parameterSpace . parameterValues , ) evolution . parameterSpace = pars evolution . paramInterval = evolution . parameterSpace . named_tuple evolution . ParametersInterval = evolution . parameterSpace . named_tuple_constructor return evolution loadResults ( self , filename = None , trajectoryName = None ) Load results from a hdf file of a previous evolution and store the pypet trajectory in self.traj Parameters: Name Type Description Default filename str, optional hdf filename of the previous run, defaults to None None trajectoryName str, optional Name of the trajectory in the hdf file to load. If not given, the last one will be loaded, defaults to None None Source code in neurolib/optimize/evolution/evolution.py def loadResults ( self , filename = None , trajectoryName = None ): \"\"\"Load results from a hdf file of a previous evolution and store the pypet trajectory in `self.traj` :param filename: hdf filename of the previous run, defaults to None :type filename: str, optional :param trajectoryName: Name of the trajectory in the hdf file to load. If not given, the last one will be loaded, defaults to None :type trajectoryName: str, optional \"\"\" if filename == None : filename = self . HDF_FILE self . traj = pu . loadPypetTrajectory ( filename , trajectoryName ) plotProgress ( self , reverse = False ) Plots progress of fitnesses of current evolution run Source code in neurolib/optimize/evolution/evolution.py def plotProgress ( self , reverse = False ): \"\"\"Plots progress of fitnesses of current evolution run\"\"\" eu . plotProgress ( self , reverse = reverse ) run ( self , verbose = False ) Run the evolution or continue previous evolution. If evolution was not initialized first using runInitial() , this will be done. Parameters: Name Type Description Default verbose bool, optional Print and plot state of evolution during run, defaults to False False Source code in neurolib/optimize/evolution/evolution.py def run ( self , verbose = False ): \"\"\"Run the evolution or continue previous evolution. If evolution was not initialized first using `runInitial()`, this will be done. :param verbose: Print and plot state of evolution during run, defaults to False :type verbose: bool, optional \"\"\" self . verbose = verbose if not self . _initialPopulationSimulated : self . runInitial () self . runEvolution () runEvolution ( self ) Run the evolutionary optimization process for NGEN generations. Source code in neurolib/optimize/evolution/evolution.py def runEvolution ( self ): \"\"\"Run the evolutionary optimization process for `NGEN` generations.\"\"\" # Start evolution logging . info ( \"Start of evolution\" ) self . _t_start_evolution = datetime . datetime . now () for self . gIdx in range ( self . gIdx + 1 , self . gIdx + self . traj . NGEN ): # ------- Weed out the invalid individuals and replace them by random new indivuals -------- # validpop = self . getValidPopulation ( self . pop ) # replace invalid individuals invalidpop = self . getInvalidPopulation ( self . pop ) logging . info ( \"Replacing {} invalid individuals.\" . format ( len ( invalidpop ))) newpop = self . toolbox . population ( n = len ( invalidpop )) newpop = self . _tagPopulation ( newpop ) # ------- Create the next generation by crossover and mutation -------- # ### Select parents using rank selection and clone them ### offspring = list ( map ( self . toolbox . clone , self . toolbox . selectParents ( self . pop , self . POP_SIZE , ** self . PARENT_SELECT_P ), ) ) ##### cross-over #### for i in range ( 1 , len ( offspring ), 2 ): offspring [ i - 1 ], offspring [ i ] = self . toolbox . mate ( offspring [ i - 1 ], offspring [ i ], ** self . MATE_P ) # delete fitness inherited from parents del offspring [ i - 1 ] . fitness . values , offspring [ i ] . fitness . values del offspring [ i - 1 ] . fitness . wvalues , offspring [ i ] . fitness . wvalues # assign parent IDs to new offspring offspring [ i - 1 ] . parentIds = offspring [ i - 1 ] . id , offspring [ i ] . id offspring [ i ] . parentIds = offspring [ i - 1 ] . id , offspring [ i ] . id # delete id originally set from parents, needs to be deleted here! # will be set later in _tagPopulation() del offspring [ i - 1 ] . id , offspring [ i ] . id ##### Mutation #### # Apply mutation du . mutateUntilValid ( offspring , self . paramInterval , self . toolbox , MUTATE_P = self . MUTATE_P ) offspring = self . _tagPopulation ( offspring ) # ------- Evaluate next generation -------- # self . pop = offspring + newpop self . _evalPopulationUsingPypet ( self . traj , self . toolbox , offspring + newpop , self . gIdx ) # log individuals self . history [ self . gIdx ] = validpop + offspring + newpop # self.getValidPopulation(self.pop) # ------- Select surviving population -------- # # select next generation self . pop = self . toolbox . select ( validpop + offspring + newpop , k = self . traj . popsize , ** self . SELECT_P ) # ------- END OF ROUND ------- # save all simulation data to pypet self . pop = eu . saveToPypet ( self . traj , self . pop , self . gIdx ) # select best individual for logging self . best_ind = self . toolbox . selBest ( self . pop , 1 )[ 0 ] # text log next_print = print if self . verbose else logging . info next_print ( \"----------- Generation %i -----------\" % self . gIdx ) next_print ( \"Best individual is {} \" . format ( self . best_ind )) next_print ( \"Score: {} \" . format ( self . best_ind . fitness . score )) next_print ( \"Fitness: {} \" . format ( self . best_ind . fitness . values )) next_print ( \"--- Population statistics ---\" ) # verbose output if self . verbose : self . info ( plot = True , info = True ) logging . info ( \"--- End of evolution ---\" ) logging . info ( \"Best individual is %s , %s \" % ( self . best_ind , self . best_ind . fitness . values )) logging . info ( \"--- End of evolution ---\" ) self . traj . f_store () # We switched off automatic storing, so we need to store manually self . _t_end_evolution = datetime . datetime . now () self . _buildEvolutionTree () runInitial ( self ) Run the first round of evolution with the initial population of size POP_INIT_SIZE and select the best POP_SIZE for the following evolution. This needs to be run before runEvolution() Source code in neurolib/optimize/evolution/evolution.py def runInitial ( self ): \"\"\"Run the first round of evolution with the initial population of size `POP_INIT_SIZE` and select the best `POP_SIZE` for the following evolution. This needs to be run before `runEvolution()` \"\"\" self . _t_start_initial_population = datetime . datetime . now () # Create the initial population self . pop = self . toolbox . population ( n = self . POP_INIT_SIZE ) ### Evaluate the initial population logging . info ( \"Evaluating initial population of size %i ...\" % len ( self . pop )) self . gIdx = 0 # set generation index self . pop = self . _tagPopulation ( self . pop ) # evaluate self . pop = self . _evalPopulationUsingPypet ( self . traj , self . toolbox , self . pop , self . gIdx ) if self . verbose : eu . printParamDist ( self . pop , self . paramInterval , self . gIdx ) # save all simulation data to pypet self . pop = eu . saveToPypet ( self . traj , self . pop , self . gIdx ) # reduce initial population to popsize self . pop = self . toolbox . select ( self . pop , k = self . traj . popsize , ** self . SELECT_P ) self . _initialPopulationSimulated = True # populate history for tracking self . history [ self . gIdx ] = self . pop # self.getValidPopulation(self.pop) self . _t_end_initial_population = datetime . datetime . now () saveEvolution ( self , fname = None ) Save evolution to file using dill. Parameters: Name Type Description Default fname str, optional Filename, defaults to a path in ./data/ None Source code in neurolib/optimize/evolution/evolution.py def saveEvolution ( self , fname = None ): \"\"\"Save evolution to file using dill. :param fname: Filename, defaults to a path in ./data/ :type fname: str, optional \"\"\" import dill fname = fname or os . path . join ( \"data/\" , \"evolution-\" + self . trajectoryName + \".dill\" ) dill . dump ( self , open ( fname , \"wb\" )) logging . info ( f \"Saving evolution to { fname } \" )","title":"Evolution"},{"location":"optimization/evolution/#evolution","text":"Evolutionary parameter optimization. This class helps you to optimize any function or model using an evlutionary algorithm. It uses the package deap and supports its builtin mating and selection functions as well as custom ones.","title":"Evolution"},{"location":"optimization/evolution/#neurolib.optimize.evolution.evolution.Evolution.__init__","text":"Initialize evolutionary optimization. Parameters: Name Type Description Default evalFunction function Evaluation function of a run that provides a fitness vector and simulation outputs required parameterSpace `neurolib.utils.parameterSpace.ParameterSpace` Parameter space to run evolution in. required weightList list[float], optional List of floats that defines the dimensionality of the fitness vector returned from evalFunction and the weights of each component for multiobjective optimization (positive = maximize, negative = minimize). If not given, then a single positive weight will be used, defaults to None None model `neurolib.models.model.Model`, optional Model to simulate, defaults to None None filename str, optional HDF file to store all results in, defaults to \"evolution.hdf\" 'evolution.hdf' ncores int, optional Number of cores to simulate on (max cores default), defaults to None None POP_INIT_SIZE int, optional Size of first population to initialize evolution with (random, uniformly distributed), defaults to 100 100 POP_SIZE int, optional Size of the population during evolution, defaults to 20 20 NGEN int, optional Numbers of generations to evaluate, defaults to 10 10 matingOperator Union[deap operat,, optional] Custom mating operator, defaults to deap.tools.cxBlend None MATE_P dict, optional Mating operator keyword arguments (for the default crossover operator cxBlend, this defaults alpha = 0.5) None mutationOperator Union[deap operat,, optional] Custom mutation operator, defaults to du.gaussianAdaptiveMutation_nStepSizes None MUTATE_P dict, optional Mutation operator keyword arguments None selectionOperator Union[deap operat,, optional] Custom selection operator, defaults to du.selBest_multiObj None SELECT_P dict, optional Selection operator keyword arguments None parentSelectionOperator Operator for parent selection, defaults to du.selRank None PARENT_SELECT_P dict, optional Parent selection operator keyword arguments (for the default operator selRank, this defaults to s = 1.5 in Eiben&Smith p.81) None individualGenerator Function to generate initial individuals, defaults to du.randomParametersAdaptive None Source code in neurolib/optimize/evolution/evolution.py def __init__ ( self , evalFunction , parameterSpace , weightList = None , model = None , filename = \"evolution.hdf\" , ncores = None , POP_INIT_SIZE = 100 , POP_SIZE = 20 , NGEN = 10 , algorithm = \"adaptive\" , matingOperator = None , MATE_P = None , mutationOperator = None , MUTATE_P = None , selectionOperator = None , SELECT_P = None , parentSelectionOperator = None , PARENT_SELECT_P = None , individualGenerator = None , IND_GENERATOR_P = None , ): \"\"\"Initialize evolutionary optimization. :param evalFunction: Evaluation function of a run that provides a fitness vector and simulation outputs :type evalFunction: function :param parameterSpace: Parameter space to run evolution in. :type parameterSpace: `neurolib.utils.parameterSpace.ParameterSpace` :param weightList: List of floats that defines the dimensionality of the fitness vector returned from evalFunction and the weights of each component for multiobjective optimization (positive = maximize, negative = minimize). If not given, then a single positive weight will be used, defaults to None :type weightList: list[float], optional :param model: Model to simulate, defaults to None :type model: `neurolib.models.model.Model`, optional :param filename: HDF file to store all results in, defaults to \"evolution.hdf\" :type filename: str, optional :param ncores: Number of cores to simulate on (max cores default), defaults to None :type ncores: int, optional :param POP_INIT_SIZE: Size of first population to initialize evolution with (random, uniformly distributed), defaults to 100 :type POP_INIT_SIZE: int, optional :param POP_SIZE: Size of the population during evolution, defaults to 20 :type POP_SIZE: int, optional :param NGEN: Numbers of generations to evaluate, defaults to 10 :type NGEN: int, optional :param matingOperator: Custom mating operator, defaults to deap.tools.cxBlend :type matingOperator: deap operator, optional :param MATE_P: Mating operator keyword arguments (for the default crossover operator cxBlend, this defaults `alpha` = 0.5) :type MATE_P: dict, optional :param mutationOperator: Custom mutation operator, defaults to du.gaussianAdaptiveMutation_nStepSizes :type mutationOperator: deap operator, optional :param MUTATE_P: Mutation operator keyword arguments :type MUTATE_P: dict, optional :param selectionOperator: Custom selection operator, defaults to du.selBest_multiObj :type selectionOperator: deap operator, optional :param SELECT_P: Selection operator keyword arguments :type SELECT_P: dict, optional :param parentSelectionOperator: Operator for parent selection, defaults to du.selRank :param PARENT_SELECT_P: Parent selection operator keyword arguments (for the default operator selRank, this defaults to `s` = 1.5 in Eiben&Smith p.81) :type PARENT_SELECT_P: dict, optional :param individualGenerator: Function to generate initial individuals, defaults to du.randomParametersAdaptive \"\"\" if weightList is None : logging . info ( \"weightList not set, assuming single fitness value to be maximized.\" ) weightList = [ 1.0 ] trajectoryName = \"results\" + datetime . datetime . now () . strftime ( \"-%Y-%m- %d -%HH-%MM-%SS\" ) logging . info ( f \"Trajectory Name: { trajectoryName } \" ) self . HDF_FILE = os . path . join ( paths . HDF_DIR , filename ) trajectoryFileName = self . HDF_FILE logging . info ( \"Storing data to: {} \" . format ( trajectoryFileName )) logging . info ( \"Trajectory Name: {} \" . format ( trajectoryName )) if ncores is None : ncores = multiprocessing . cpu_count () logging . info ( \"Number of cores: {} \" . format ( ncores )) # initialize pypet environment # env = pp.Environment(trajectory=trajectoryName, filename=trajectoryFileName) env = pp . Environment ( trajectory = trajectoryName , filename = trajectoryFileName , use_pool = False , multiproc = True , ncores = ncores , complevel = 9 , log_config = paths . PYPET_LOGGING_CONFIG , ) # Get the trajectory from the environment traj = env . traj # Sanity check if everything went ok assert ( trajectoryName == traj . v_name ), f \"Pypet trajectory has a different name than trajectoryName { trajectoryName } \" # trajectoryName = traj.v_name self . model = model self . evalFunction = evalFunction self . weightList = weightList self . NGEN = NGEN assert POP_SIZE % 2 == 0 , \"Please chose an even number for POP_SIZE!\" self . POP_SIZE = POP_SIZE assert POP_INIT_SIZE % 2 == 0 , \"Please chose an even number for POP_INIT_SIZE!\" self . POP_INIT_SIZE = POP_INIT_SIZE self . ncores = ncores # comment string for storing info self . comments = \"no comments\" self . traj = env . traj self . env = env self . trajectoryName = trajectoryName self . trajectoryFileName = trajectoryFileName self . _initialPopulationSimulated = False # -------- settings self . verbose = False self . plotColor = \"C0\" # -------- simulation self . parameterSpace = parameterSpace self . ParametersInterval = self . parameterSpace . named_tuple_constructor self . paramInterval = self . parameterSpace . named_tuple self . toolbox = deap . base . Toolbox () # -------- algorithms if algorithm == \"adaptive\" : logging . info ( f \"Evolution: Using algorithm: { algorithm } \" ) self . matingOperator = tools . cxBlend self . MATE_P = { \"alpha\" : 0.5 } or MATE_P self . mutationOperator = du . gaussianAdaptiveMutation_nStepSizes self . selectionOperator = du . selBest_multiObj self . parentSelectionOperator = du . selRank self . PARENT_SELECT_P = { \"s\" : 1.5 } or PARENT_SELECT_P self . individualGenerator = du . randomParametersAdaptive elif algorithm == \"nsga2\" : logging . info ( f \"Evolution: Using algorithm: { algorithm } \" ) self . matingOperator = tools . cxSimulatedBinaryBounded self . MATE_P = { \"low\" : self . parameterSpace . lowerBound , \"up\" : self . parameterSpace . upperBound , \"eta\" : 20.0 , } or MATE_P self . mutationOperator = tools . mutPolynomialBounded self . MUTATE_P = { \"low\" : self . parameterSpace . lowerBound , \"up\" : self . parameterSpace . upperBound , \"eta\" : 20.0 , \"indpb\" : 1.0 / len ( self . weightList ), } or MUTATE_P self . selectionOperator = tools . selNSGA2 self . parentSelectionOperator = tools . selTournamentDCD self . individualGenerator = du . randomParameters else : raise ValueError ( \"Evolution: algorithm must be one of the following: ['adaptive', 'nsga2']\" ) # if the operators are set manually, then overwrite them self . matingOperator = self . matingOperator if hasattr ( self , \"matingOperator\" ) else matingOperator self . mutationOperator = self . mutationOperator if hasattr ( self , \"mutationOperator\" ) else mutationOperator self . selectionOperator = self . selectionOperator if hasattr ( self , \"selectionOperator\" ) else selectionOperator self . parentSelectionOperator = ( self . parentSelectionOperator if hasattr ( self , \"parentSelectionOperator\" ) else parentSelectionOperator ) self . individualGenerator = ( self . individualGenerator if hasattr ( self , \"individualGenerator\" ) else individualGenerator ) # let's also make sure that the parameters are set correctly self . MATE_P = self . MATE_P if hasattr ( self , \"MATE_P\" ) else {} self . PARENT_SELECT_P = self . PARENT_SELECT_P if hasattr ( self , \"PARENT_SELECT_P\" ) else {} self . MUTATE_P = self . MUTATE_P if hasattr ( self , \"MUTATE_P\" ) else {} self . SELECT_P = self . SELECT_P if hasattr ( self , \"SELECT_P\" ) else {} self . _initDEAP ( self . toolbox , self . env , self . paramInterval , self . evalFunction , weightList = self . weightList , matingOperator = self . matingOperator , mutationOperator = self . mutationOperator , selectionOperator = self . selectionOperator , parentSelectionOperator = self . parentSelectionOperator , individualGenerator = self . individualGenerator , ) # set up pypet trajectory self . _initPypetTrajectory ( self . traj , self . paramInterval , self . POP_SIZE , self . NGEN , self . model , ) # population history: dict of all valid individuals per generation self . history = {} # initialize population self . evaluationCounter = 0 self . last_id = 0","title":"__init__()"},{"location":"optimization/evolution/#neurolib.optimize.evolution.evolution.Evolution.dfEvolution","text":"Returns a pandas DataFrame with the individuals of the the whole evolution. This method can be usef after loading an evolution from disk using loadEvolution() Returns: Type Description Union[`pandas.c,e.frame.DataFrame`] Pandas DataFrame with all individuals and their parameters Source code in neurolib/optimize/evolution/evolution.py def dfEvolution ( self , outputs = False ): \"\"\"Returns a `pandas` DataFrame with the individuals of the the whole evolution. This method can be usef after loading an evolution from disk using loadEvolution() :return: Pandas DataFrame with all individuals and their parameters :rtype: `pandas.core.frame.DataFrame` \"\"\" parameters = self . parameterSpace . parameterNames allIndividuals = [ p for gen , pop in self . history . items () for p in pop ] popArray = np . array ([ p [ 0 : len ( self . paramInterval . _fields )] for p in allIndividuals ]) . T dfEvolution = pd . DataFrame ( popArray , index = parameters ) . T # add more information to the dataframe scores = [ float ( p . fitness . score ) for p in allIndividuals ] indIds = [ p . id for p in allIndividuals ] dfEvolution [ \"score\" ] = scores dfEvolution [ \"id\" ] = indIds dfEvolution [ \"gen\" ] = [ p . gIdx for p in allIndividuals ] if outputs : dfEvolution = self . _outputToDf ( allIndividuals , dfEvolution ) # add fitness columns # NOTE: have to do this with wvalues and divide by weights later, why? # Because after loading the evolution with dill, somehow multiple fitnesses # dissappear and only the first one is left. However, wvalues still has all # fitnesses, and we have acces to weightList, so this hack kind of helps n_fitnesses = len ( self . pop [ 0 ] . fitness . wvalues ) for i in range ( n_fitnesses ): for ip , p in enumerate ( allIndividuals ): dfEvolution . loc [ ip , f \"f { i } \" ] = p . fitness . wvalues [ i ] / self . weightList [ i ] # the history keeps all individuals of all generations # there can be duplicates (in elitism for example), which we filter # out for the dataframe dfEvolution = self . _dropDuplicatesFromDf ( dfEvolution ) dfEvolution = dfEvolution . reset_index ( drop = True ) return dfEvolution","title":"dfEvolution()"},{"location":"optimization/evolution/#neurolib.optimize.evolution.evolution.Evolution.dfPop","text":"Returns a pandas DataFrame of the current generation's population parameters. This object can be further used to easily analyse the population. Returns: Type Description Union[`pandas.c,e.frame.DataFrame`] Pandas DataFrame with all individuals and their parameters Source code in neurolib/optimize/evolution/evolution.py def dfPop ( self , outputs = False ): \"\"\"Returns a `pandas` DataFrame of the current generation's population parameters. This object can be further used to easily analyse the population. :return: Pandas DataFrame with all individuals and their parameters :rtype: `pandas.core.frame.DataFrame` \"\"\" # add the current population to the dataframe validPop = self . getValidPopulation ( self . pop ) indIds = [ p . id for p in validPop ] popArray = np . array ([ p [ 0 : len ( self . paramInterval . _fields )] for p in validPop ]) . T dfPop = pd . DataFrame ( popArray , index = self . parameterSpace . parameterNames ) . T # add more information to the dataframe scores = self . getScores () dfPop [ \"score\" ] = scores dfPop [ \"id\" ] = indIds dfPop [ \"gen\" ] = [ p . gIdx for p in validPop ] if outputs : dfPop = self . _outputToDf ( validPop , dfPop ) # add fitness columns # NOTE: when loading an evolution with dill using loadingEvolution # MultiFitness values dissappear and only one is left. # See dfEvolution() for a solution using wvalues n_fitnesses = len ( validPop [ 0 ] . fitness . values ) for i in range ( n_fitnesses ): for ip , p in enumerate ( validPop ): column_name = \"f\" + str ( i ) dfPop . loc [ ip , column_name ] = p . fitness . values [ i ] return dfPop","title":"dfPop()"},{"location":"optimization/evolution/#neurolib.optimize.evolution.evolution.Evolution.getIndividualFromHistory","text":"Searches the entire evolution history for an individual with a specific id and returns it. Parameters: Name Type Description Default id int Individual id required Returns: Type Description Union[`deap.creat,.Individual`] Individual ( DEAP type) Source code in neurolib/optimize/evolution/evolution.py def getIndividualFromHistory ( self , id ): \"\"\"Searches the entire evolution history for an individual with a specific id and returns it. :param id: Individual id :type id: int :return: Individual (`DEAP` type) :rtype: `deap.creator.Individual` \"\"\" for key , value in self . history . items (): for p in value : if p . id == id : return p logging . warning ( f \"No individual with id= { id } found. Returning `None`\" ) return None","title":"getIndividualFromHistory()"},{"location":"optimization/evolution/#neurolib.optimize.evolution.evolution.Evolution.getIndividualFromTraj","text":"Get individual from pypet trajectory Parameters: Name Type Description Default traj Union[`pypet.traject,y.Traject,y`] Pypet trajectory required Returns: Type Description Union[`deap.creat,.Individual`] Individual ( DEAP type) Source code in neurolib/optimize/evolution/evolution.py def getIndividualFromTraj ( self , traj ): \"\"\"Get individual from pypet trajectory :param traj: Pypet trajectory :type traj: `pypet.trajectory.Trajectory` :return: Individual (`DEAP` type) :rtype: `deap.creator.Individual` \"\"\" # either pass an individual or a pypet trajectory with the attribute individual if type ( traj ) . __name__ == \"Individual\" : individual = traj else : individual = traj . individual ind_id = traj . id individual = [ p for p in self . pop if p . id == ind_id ] if len ( individual ) > 0 : individual = individual [ 0 ] return individual","title":"getIndividualFromTraj()"},{"location":"optimization/evolution/#neurolib.optimize.evolution.evolution.Evolution.getInvalidPopulation","text":"Returns a list of the invalid population. Parameters: Name Type Description Default pop deap population Population to check, defaults to self.pop None Returns: Type Description list List of invalid population Source code in neurolib/optimize/evolution/evolution.py def getInvalidPopulation ( self , pop = None ): \"\"\"Returns a list of the invalid population. :params pop: Population to check, defaults to self.pop :type pop: deap population :return: List of invalid population :rtype: list \"\"\" pop = pop or self . pop return [ p for p in pop if np . isnan ( p . fitness . values ) . any () or np . isinf ( p . fitness . values ) . any ()]","title":"getInvalidPopulation()"},{"location":"optimization/evolution/#neurolib.optimize.evolution.evolution.Evolution.getModelFromTraj","text":"Return the appropriate model with parameters for this individual Parameters: Name Type Description Default traj Union[`pypet.traject,y.Traject,y`] Pypet trajectory with individual (traj.individual) or directly a deap.Individual required Returns: Type Description `neurolib.models.model.Model` Model with the parameters of this individual. Source code in neurolib/optimize/evolution/evolution.py def getModelFromTraj ( self , traj ): \"\"\"Return the appropriate model with parameters for this individual :params traj: Pypet trajectory with individual (traj.individual) or directly a deap.Individual :returns model: Model with the parameters of this individual. :param traj: Pypet trajectory with individual (traj.individual) or directly a deap.Individual :type traj: `pypet.trajectory.Trajectory` :return: Model with the parameters of this individual. :rtype: `neurolib.models.model.Model` \"\"\" model = self . model # resolve star notation - MultiModel individual_params = self . individualToDict ( self . getIndividualFromTraj ( traj )) if self . parameterSpace . star : individual_params = unwrap_star_dotdict ( individual_params , self . model , replaced_dict = BACKWARD_REPLACE ) model . params . update ( individual_params ) return model","title":"getModelFromTraj()"},{"location":"optimization/evolution/#neurolib.optimize.evolution.evolution.Evolution.getScores","text":"Returns the scores of the current valid population Source code in neurolib/optimize/evolution/evolution.py def getScores ( self ): \"\"\"Returns the scores of the current valid population\"\"\" validPop = self . getValidPopulation ( self . pop ) return np . array ([ pop . fitness . score for pop in validPop ])","title":"getScores()"},{"location":"optimization/evolution/#neurolib.optimize.evolution.evolution.Evolution.getScoresDuringEvolution","text":"Get the scores of each generation's population. Parameters: Name Type Description Default traj Union[`pypet.traject,y.Traject,y`, optional] Pypet trajectory. If not given, the current trajectory is used, defaults to None None drop_first bool, optional Drop the first (initial) generation. This can be usefull because it can have a different size ( POP_INIT_SIZE ) than the succeeding populations ( POP_SIZE ) which can make data handling tricky, defaults to True True reverse bool, optional Reverse the order of each generation. This is a necessary workaraound because loading from the an hdf file returns the generations in a reversed order compared to loading each generation from the pypet trajectory in memory, defaults to False False Returns: Type Description tuple[list, numpy.ndarray] Tuple of list of all generations and an array of the scores of all individuals Source code in neurolib/optimize/evolution/evolution.py def getScoresDuringEvolution ( self , traj = None , drop_first = True , reverse = False ): \"\"\"Get the scores of each generation's population. :param traj: Pypet trajectory. If not given, the current trajectory is used, defaults to None :type traj: `pypet.trajectory.Trajectory`, optional :param drop_first: Drop the first (initial) generation. This can be usefull because it can have a different size (`POP_INIT_SIZE`) than the succeeding populations (`POP_SIZE`) which can make data handling tricky, defaults to True :type drop_first: bool, optional :param reverse: Reverse the order of each generation. This is a necessary workaraound because loading from the an hdf file returns the generations in a reversed order compared to loading each generation from the pypet trajectory in memory, defaults to False :type reverse: bool, optional :return: Tuple of list of all generations and an array of the scores of all individuals :rtype: tuple[list, numpy.ndarray] \"\"\" if traj == None : traj = self . traj generation_names = list ( traj . results . evolution . f_to_dict ( nested = True ) . keys ()) if reverse : generation_names = generation_names [:: - 1 ] if drop_first and \"gen_000000\" in generation_names : generation_names . remove ( \"gen_000000\" ) npop = len ( traj . results . evolution [ generation_names [ 0 ]] . scores ) gens = [] all_scores = np . empty (( len ( generation_names ), npop )) for i , r in enumerate ( generation_names ): gens . append ( i ) scores = traj . results . evolution [ r ] . scores all_scores [ i ] = scores if drop_first : gens = np . add ( gens , 1 ) return gens , all_scores","title":"getScoresDuringEvolution()"},{"location":"optimization/evolution/#neurolib.optimize.evolution.evolution.Evolution.getValidPopulation","text":"Returns a list of the valid population. Parameters: Name Type Description Default pop deap population Population to check, defaults to self.pop None Returns: Type Description list List of valid population Source code in neurolib/optimize/evolution/evolution.py def getValidPopulation ( self , pop = None ): \"\"\"Returns a list of the valid population. :params pop: Population to check, defaults to self.pop :type pop: deap population :return: List of valid population :rtype: list \"\"\" pop = pop or self . pop return [ p for p in pop if not ( np . isnan ( p . fitness . values ) . any () or np . isinf ( p . fitness . values ) . any ())]","title":"getValidPopulation()"},{"location":"optimization/evolution/#neurolib.optimize.evolution.evolution.Evolution.individualToDict","text":"Convert an individual to a parameter dictionary. Parameters: Name Type Description Default individual Union[`deap.creat,.Individual`] Individual ( DEAP type) required Returns: Type Description dict Parameter dictionary of this individual Source code in neurolib/optimize/evolution/evolution.py def individualToDict ( self , individual ): \"\"\"Convert an individual to a parameter dictionary. :param individual: Individual (`DEAP` type) :type individual: `deap.creator.Individual` :return: Parameter dictionary of this individual :rtype: dict \"\"\" return self . ParametersInterval ( * ( individual [: len ( self . paramInterval )])) . _asdict () . copy ()","title":"individualToDict()"},{"location":"optimization/evolution/#neurolib.optimize.evolution.evolution.Evolution.info","text":"Print and plot information about the evolution and the current population Parameters: Name Type Description Default plot bool, optional plot a plot using matplotlib , defaults to True True bestN int, optional Print summary of bestN best individuals, defaults to 5 5 info bool, optional Print information about the evolution environment True Source code in neurolib/optimize/evolution/evolution.py def info ( self , plot = True , bestN = 5 , info = True , reverse = False ): \"\"\"Print and plot information about the evolution and the current population :param plot: plot a plot using `matplotlib`, defaults to True :type plot: bool, optional :param bestN: Print summary of `bestN` best individuals, defaults to 5 :type bestN: int, optional :param info: Print information about the evolution environment :type info: bool, optional \"\"\" if info : eu . printEvolutionInfo ( self ) validPop = self . getValidPopulation ( self . pop ) scores = self . getScores () # Text output print ( \"--- Info summary ---\" ) print ( \"Valid: {} \" . format ( len ( validPop ))) print ( \"Mean score (weighted fitness): {:.2} \" . format ( np . mean ( scores ))) eu . printParamDist ( self . pop , self . paramInterval , self . gIdx ) print ( \"--------------------\" ) print ( f \"Best { bestN } individuals:\" ) eu . printIndividuals ( self . toolbox . selBest ( self . pop , bestN ), self . paramInterval ) print ( \"--------------------\" ) # Plotting if plot : # hack: during the evolution we need to use reverse=True # after the evolution (with evolution.info()), we need False try : self . plotProgress ( reverse = reverse ) except : logging . warning ( \"Could not plot progress, is this a previously saved simulation?\" ) eu . plotPopulation ( self , plotScattermatrix = True , save_plots = self . trajectoryName , color = self . plotColor , )","title":"info()"},{"location":"optimization/evolution/#neurolib.optimize.evolution.evolution.Evolution.loadEvolution","text":"Load evolution from previously saved simulatoins. Example usage: evaluateSimulation = lambda x: x # the funciton can be ommited, that's why we define a lambda here pars = ParameterSpace(['a', 'b'], # should be same as previously saved evolution [[0.0, 4.0], [0.0, 5.0]]) evolution = Evolution(evaluateSimulation, pars, weightList = [1.0]) evolution = evolution.loadEvolution(\"data/evolution-results-2020-05-15-00H-24M-48S.dill\") Parameters: Name Type Description Default fname str Filename, defaults to a path in ./data/ required Returns: Type Description self Evolution Source code in neurolib/optimize/evolution/evolution.py def loadEvolution ( self , fname ): \"\"\"Load evolution from previously saved simulatoins. Example usage: ``` evaluateSimulation = lambda x: x # the funciton can be ommited, that's why we define a lambda here pars = ParameterSpace(['a', 'b'], # should be same as previously saved evolution [[0.0, 4.0], [0.0, 5.0]]) evolution = Evolution(evaluateSimulation, pars, weightList = [1.0]) evolution = evolution.loadEvolution(\"data/evolution-results-2020-05-15-00H-24M-48S.dill\") ``` :param fname: Filename, defaults to a path in ./data/ :type fname: str :return: Evolution :rtype: self \"\"\" import dill evolution = dill . load ( open ( fname , \"rb\" )) # parameter space is not saved correctly in dill, don't know why # that is why we recreate it using the values of # the parameter space in the dill pars = ParameterSpace ( evolution . parameterSpace . parameterNames , evolution . parameterSpace . parameterValues , ) evolution . parameterSpace = pars evolution . paramInterval = evolution . parameterSpace . named_tuple evolution . ParametersInterval = evolution . parameterSpace . named_tuple_constructor return evolution","title":"loadEvolution()"},{"location":"optimization/evolution/#neurolib.optimize.evolution.evolution.Evolution.loadResults","text":"Load results from a hdf file of a previous evolution and store the pypet trajectory in self.traj Parameters: Name Type Description Default filename str, optional hdf filename of the previous run, defaults to None None trajectoryName str, optional Name of the trajectory in the hdf file to load. If not given, the last one will be loaded, defaults to None None Source code in neurolib/optimize/evolution/evolution.py def loadResults ( self , filename = None , trajectoryName = None ): \"\"\"Load results from a hdf file of a previous evolution and store the pypet trajectory in `self.traj` :param filename: hdf filename of the previous run, defaults to None :type filename: str, optional :param trajectoryName: Name of the trajectory in the hdf file to load. If not given, the last one will be loaded, defaults to None :type trajectoryName: str, optional \"\"\" if filename == None : filename = self . HDF_FILE self . traj = pu . loadPypetTrajectory ( filename , trajectoryName )","title":"loadResults()"},{"location":"optimization/evolution/#neurolib.optimize.evolution.evolution.Evolution.plotProgress","text":"Plots progress of fitnesses of current evolution run Source code in neurolib/optimize/evolution/evolution.py def plotProgress ( self , reverse = False ): \"\"\"Plots progress of fitnesses of current evolution run\"\"\" eu . plotProgress ( self , reverse = reverse )","title":"plotProgress()"},{"location":"optimization/evolution/#neurolib.optimize.evolution.evolution.Evolution.run","text":"Run the evolution or continue previous evolution. If evolution was not initialized first using runInitial() , this will be done. Parameters: Name Type Description Default verbose bool, optional Print and plot state of evolution during run, defaults to False False Source code in neurolib/optimize/evolution/evolution.py def run ( self , verbose = False ): \"\"\"Run the evolution or continue previous evolution. If evolution was not initialized first using `runInitial()`, this will be done. :param verbose: Print and plot state of evolution during run, defaults to False :type verbose: bool, optional \"\"\" self . verbose = verbose if not self . _initialPopulationSimulated : self . runInitial () self . runEvolution ()","title":"run()"},{"location":"optimization/evolution/#neurolib.optimize.evolution.evolution.Evolution.runEvolution","text":"Run the evolutionary optimization process for NGEN generations. Source code in neurolib/optimize/evolution/evolution.py def runEvolution ( self ): \"\"\"Run the evolutionary optimization process for `NGEN` generations.\"\"\" # Start evolution logging . info ( \"Start of evolution\" ) self . _t_start_evolution = datetime . datetime . now () for self . gIdx in range ( self . gIdx + 1 , self . gIdx + self . traj . NGEN ): # ------- Weed out the invalid individuals and replace them by random new indivuals -------- # validpop = self . getValidPopulation ( self . pop ) # replace invalid individuals invalidpop = self . getInvalidPopulation ( self . pop ) logging . info ( \"Replacing {} invalid individuals.\" . format ( len ( invalidpop ))) newpop = self . toolbox . population ( n = len ( invalidpop )) newpop = self . _tagPopulation ( newpop ) # ------- Create the next generation by crossover and mutation -------- # ### Select parents using rank selection and clone them ### offspring = list ( map ( self . toolbox . clone , self . toolbox . selectParents ( self . pop , self . POP_SIZE , ** self . PARENT_SELECT_P ), ) ) ##### cross-over #### for i in range ( 1 , len ( offspring ), 2 ): offspring [ i - 1 ], offspring [ i ] = self . toolbox . mate ( offspring [ i - 1 ], offspring [ i ], ** self . MATE_P ) # delete fitness inherited from parents del offspring [ i - 1 ] . fitness . values , offspring [ i ] . fitness . values del offspring [ i - 1 ] . fitness . wvalues , offspring [ i ] . fitness . wvalues # assign parent IDs to new offspring offspring [ i - 1 ] . parentIds = offspring [ i - 1 ] . id , offspring [ i ] . id offspring [ i ] . parentIds = offspring [ i - 1 ] . id , offspring [ i ] . id # delete id originally set from parents, needs to be deleted here! # will be set later in _tagPopulation() del offspring [ i - 1 ] . id , offspring [ i ] . id ##### Mutation #### # Apply mutation du . mutateUntilValid ( offspring , self . paramInterval , self . toolbox , MUTATE_P = self . MUTATE_P ) offspring = self . _tagPopulation ( offspring ) # ------- Evaluate next generation -------- # self . pop = offspring + newpop self . _evalPopulationUsingPypet ( self . traj , self . toolbox , offspring + newpop , self . gIdx ) # log individuals self . history [ self . gIdx ] = validpop + offspring + newpop # self.getValidPopulation(self.pop) # ------- Select surviving population -------- # # select next generation self . pop = self . toolbox . select ( validpop + offspring + newpop , k = self . traj . popsize , ** self . SELECT_P ) # ------- END OF ROUND ------- # save all simulation data to pypet self . pop = eu . saveToPypet ( self . traj , self . pop , self . gIdx ) # select best individual for logging self . best_ind = self . toolbox . selBest ( self . pop , 1 )[ 0 ] # text log next_print = print if self . verbose else logging . info next_print ( \"----------- Generation %i -----------\" % self . gIdx ) next_print ( \"Best individual is {} \" . format ( self . best_ind )) next_print ( \"Score: {} \" . format ( self . best_ind . fitness . score )) next_print ( \"Fitness: {} \" . format ( self . best_ind . fitness . values )) next_print ( \"--- Population statistics ---\" ) # verbose output if self . verbose : self . info ( plot = True , info = True ) logging . info ( \"--- End of evolution ---\" ) logging . info ( \"Best individual is %s , %s \" % ( self . best_ind , self . best_ind . fitness . values )) logging . info ( \"--- End of evolution ---\" ) self . traj . f_store () # We switched off automatic storing, so we need to store manually self . _t_end_evolution = datetime . datetime . now () self . _buildEvolutionTree ()","title":"runEvolution()"},{"location":"optimization/evolution/#neurolib.optimize.evolution.evolution.Evolution.runInitial","text":"Run the first round of evolution with the initial population of size POP_INIT_SIZE and select the best POP_SIZE for the following evolution. This needs to be run before runEvolution() Source code in neurolib/optimize/evolution/evolution.py def runInitial ( self ): \"\"\"Run the first round of evolution with the initial population of size `POP_INIT_SIZE` and select the best `POP_SIZE` for the following evolution. This needs to be run before `runEvolution()` \"\"\" self . _t_start_initial_population = datetime . datetime . now () # Create the initial population self . pop = self . toolbox . population ( n = self . POP_INIT_SIZE ) ### Evaluate the initial population logging . info ( \"Evaluating initial population of size %i ...\" % len ( self . pop )) self . gIdx = 0 # set generation index self . pop = self . _tagPopulation ( self . pop ) # evaluate self . pop = self . _evalPopulationUsingPypet ( self . traj , self . toolbox , self . pop , self . gIdx ) if self . verbose : eu . printParamDist ( self . pop , self . paramInterval , self . gIdx ) # save all simulation data to pypet self . pop = eu . saveToPypet ( self . traj , self . pop , self . gIdx ) # reduce initial population to popsize self . pop = self . toolbox . select ( self . pop , k = self . traj . popsize , ** self . SELECT_P ) self . _initialPopulationSimulated = True # populate history for tracking self . history [ self . gIdx ] = self . pop # self.getValidPopulation(self.pop) self . _t_end_initial_population = datetime . datetime . now ()","title":"runInitial()"},{"location":"optimization/evolution/#neurolib.optimize.evolution.evolution.Evolution.saveEvolution","text":"Save evolution to file using dill. Parameters: Name Type Description Default fname str, optional Filename, defaults to a path in ./data/ None Source code in neurolib/optimize/evolution/evolution.py def saveEvolution ( self , fname = None ): \"\"\"Save evolution to file using dill. :param fname: Filename, defaults to a path in ./data/ :type fname: str, optional \"\"\" import dill fname = fname or os . path . join ( \"data/\" , \"evolution-\" + self . trajectoryName + \".dill\" ) dill . dump ( self , open ( fname , \"wb\" )) logging . info ( f \"Saving evolution to { fname } \" )","title":"saveEvolution()"},{"location":"utils/dataset/","text":"Dataset This class is for loading empirical Datasets. Datasets are stored as matrices and can include functional (e.g. fMRI) and structural (e.g. DTI) data. Format Empirical datasets are stored in the neurolib/data/datasets directory. In each dataset, subject-wise functional and structural data is stored as MATLAB .mat matrices that can be opened in Python using SciPy's loadmat function. Structural data are \\(N \\times N\\) , and functional time series are \\(N \\times t\\) matrices, \\(N\\) being the number of brain regions and \\(t\\) the number of time steps. Example datasets are included in neurolib and custom datasets can be added by placing them in the dataset directory. Structural DTI data To simulate a whole-brain network model, first we need to load the structural connectivity matrices from a DTI data set. The matrices are usually a result of processing DTI data and performing fiber tractography using software like FSL or DSIStudio . The handling of the datasets is done by the Dataset class, and the attributes in the following refer to its instances. Upon initialization, the subject-wise data set is loaded from disk. For all examples in this paper, we use freely available data from the ConnectomeDB of the Human Connectome Project (HCP). For a given parcellation of the brain into \\(N\\) brain regions, these matrices are the \\(N \\times N\\) adjacency matrix self.Cmat , i.e. the structural connectivity matrix, which determines the coupling strengths between brain areas, and the fiber length matrix Dmat which determines the signal transmission delays. The two example datasets currently included in neurolib use the the 80 cortical regions of the AAL2 atlas to define the brain areas and are sorted in a LRLR-ordering. Connectivity matrix normalization The elements of the structural connectivity matrix Cmat are typically the number of reconstructed fibers from DTI tractography. Since the number of fibers depends on the method and the parameters of the (probabilistic or deterministic) tractography, they need to be normalized using one of the three implemented methods. The first method max is to simply divide the entries of Cmat by the largest entry, such that the the largest entry becomes 1. The second method waytotal divides the entries of each column of Cmat by the number fiber tracts generated from the respective brain region during probabilistic tractography in FSL, which is contained in the waytotal.txt file. The third method nvoxel divides the entries of each column of Cmat by the size, e.g., the number of voxels of the corresponding brain area. The last two methods yield an asymmetric connectivity matrix, while the first one keeps Cmat symmetric. All normalization steps are done on the subject-wise matrices Cmats and Dmats . In a final step, all matrices can also be averaged across all subjects to yield one Cmat and Dmat per dataset. Functional MRI data Subject-wise fMRI time series must be in a \\((N \\times t)\\) -dimensional format, where \\(N\\) is the number of brain regions and \\(t\\) the length of the time series. Each region-wise time series represents the BOLD activity averaged across all voxels of that region, which can be also obtained from software like FSL. Functional connectivity (FC) captures the spatial correlation structure of the BOLD time series averaged across the entire time of the recording. FC matrices are accessible via the attribute FCs and are generated by computing the Pearson correlation of the time series between all regions, yielding a \\(N \\times N\\) matrix for each subject. To capture the temporal fluctuations of time-dependent FC(t), which are lost when averaging across the entire recording time, functional connectivity dynamics matrices ( FCDs ) are computed as the element-wise Pearson correlation of time-dependent FC(t) matrices in a moving window across the BOLD time series of a chosen window length of, for example, 1 min. This yields a \\(t_{FCD} \\times t_{FCD}\\) FCD matrix for each subject, with \\(t_{FCD}\\) being the number of steps the window was moved. __init__ ( self , datasetName = None , normalizeCmats = 'max' , fcd = False , subcortical = False ) special Load the empirical data sets that are provided with neurolib . Right now, datasets work on a per-subject base. A dataset must be located in the neurolib/data/datasets/ directory. Each subject's dataset must be in the subjects subdirectory of that folder. In each subject folder there is a directory called functional for time series data and structural the structural connectivity data. See loadData.loadSubjectFiles() for more details on which files are being loaded. The structural connectivity data (accessible using the attribute loadData.Cmat), can be normalized using the normalizeCmats flag. This defaults to \"max\" which normalizes the Cmat by its maxmimum. Other options are waytotal or nvoxel , which normalizes the Cmat by dividing every row of the matrix by the waytotal or nvoxel files that are provided in the datasets. Info: the waytotal.txt and the nvoxel.txt are files extracted from the tractography of DTI data using probtrackX from the fsl pipeline. Individual subject data is provided with the class attributes: self.BOLDs: BOLD timeseries of each individual self.FCs: Functional connectivity of BOLD timeseries Mean data is provided with the class attributes: self.Cmat: Structural connectivity matrix (for coupling strenghts between areas) self.Dmat: Fiber length matrix (for delays) self.BOLDs: BOLD timeseries of each area self.FCs: Functional connectiviy matrices of each BOLD timeseries Parameters: Name Type Description Default datasetName str Name of the dataset to load None normalizeCmats str Normalization method for the structural connectivity matrix. normalizationMethods = [\"max\", \"waytotal\", \"nvoxel\"] 'max' fcd bool Compute FCD matrices of BOLD data, defaults to False False subcortical bool Include subcortical areas from the atlas or not, defaults to False False Source code in neurolib/utils/loadData.py def __init__ ( self , datasetName = None , normalizeCmats = \"max\" , fcd = False , subcortical = False ): \"\"\" Load the empirical data sets that are provided with `neurolib`. Right now, datasets work on a per-subject base. A dataset must be located in the `neurolib/data/datasets/` directory. Each subject's dataset must be in the `subjects` subdirectory of that folder. In each subject folder there is a directory called `functional` for time series data and `structural` the structural connectivity data. See `loadData.loadSubjectFiles()` for more details on which files are being loaded. The structural connectivity data (accessible using the attribute loadData.Cmat), can be normalized using the `normalizeCmats` flag. This defaults to \"max\" which normalizes the Cmat by its maxmimum. Other options are `waytotal` or `nvoxel`, which normalizes the Cmat by dividing every row of the matrix by the waytotal or nvoxel files that are provided in the datasets. Info: the waytotal.txt and the nvoxel.txt are files extracted from the tractography of DTI data using `probtrackX` from the `fsl` pipeline. Individual subject data is provided with the class attributes: self.BOLDs: BOLD timeseries of each individual self.FCs: Functional connectivity of BOLD timeseries Mean data is provided with the class attributes: self.Cmat: Structural connectivity matrix (for coupling strenghts between areas) self.Dmat: Fiber length matrix (for delays) self.BOLDs: BOLD timeseries of each area self.FCs: Functional connectiviy matrices of each BOLD timeseries :param datasetName: Name of the dataset to load :type datasetName: str :param normalizeCmats: Normalization method for the structural connectivity matrix. normalizationMethods = [\"max\", \"waytotal\", \"nvoxel\"] :type normalizeCmats: str :param fcd: Compute FCD matrices of BOLD data, defaults to False :type fcd: bool :param subcortical: Include subcortical areas from the atlas or not, defaults to False :type subcortical: bool \"\"\" self . has_subjects = None if datasetName : self . loadDataset ( datasetName , normalizeCmats = normalizeCmats , fcd = fcd , subcortical = subcortical ) getDataPerSubject ( self , name , apply = 'single' , apply_function = None , apply_function_kwargs = {}, normalizeCmats = 'max' ) Load data of a certain kind for all users of the current dataset Parameters: Name Type Description Default name str Name of data type, i.e. \"bold\" or \"cm\" required apply str, optional Apply function per subject (\"single\") or on all subjects (\"all\"), defaults to \"single\" 'single' apply_function function, optional Apply function on data, defaults to None None apply_function_kwargs dict, optional Keyword arguments of fuction, defaults to {} {} Returns: Type Description list[np.ndarray] Subjectwise data, after function apply Source code in neurolib/utils/loadData.py def getDataPerSubject ( self , name , apply = \"single\" , apply_function = None , apply_function_kwargs = {}, normalizeCmats = \"max\" , ): \"\"\"Load data of a certain kind for all users of the current dataset :param name: Name of data type, i.e. \"bold\" or \"cm\" :type name: str :param apply: Apply function per subject (\"single\") or on all subjects (\"all\"), defaults to \"single\" :type apply: str, optional :param apply_function: Apply function on data, defaults to None :type apply_function: function, optional :param apply_function_kwargs: Keyword arguments of fuction, defaults to {} :type apply_function_kwargs: dict, optional :return: Subjectwise data, after function apply :rtype: list[np.ndarray] \"\"\" values = [] for subject , value in self . data [ \"subjects\" ] . items (): assert name in value , f \"Data type { name } not found in dataset of subject { subject } .\" val = value [ name ] if apply_function and apply == \"single\" : val = apply_function ( val , ** apply_function_kwargs ) values . append ( val ) if apply_function and apply == \"all\" : values = apply_function ( values , ** apply_function_kwargs ) return values loadDataset ( self , datasetName , normalizeCmats = 'max' , fcd = False , subcortical = False ) Load data into accessible class attributes. Parameters: Name Type Description Default datasetName str Name of the dataset (must be in datasets directory) required normalizeCmats str, optional Normalization method for Cmats, defaults to \"max\" 'max' Exceptions: Type Description NotImplementedError If unknown normalization method is used Source code in neurolib/utils/loadData.py def loadDataset ( self , datasetName , normalizeCmats = \"max\" , fcd = False , subcortical = False ): \"\"\"Load data into accessible class attributes. :param datasetName: Name of the dataset (must be in `datasets` directory) :type datasetName: str :param normalizeCmats: Normalization method for Cmats, defaults to \"max\" :type normalizeCmats: str, optional :raises NotImplementedError: If unknown normalization method is used \"\"\" # the base directory of the dataset dsBaseDirectory = os . path . join ( os . path . dirname ( __file__ ), \"..\" , \"data\" , \"datasets\" , datasetName ) assert os . path . exists ( dsBaseDirectory ), f \"Dataset { datasetName } not found in { dsBaseDirectory } .\" self . dsBaseDirectory = dsBaseDirectory self . data = dotdict ({}) # load all available subject data from disk to memory logging . info ( f \"Loading dataset { datasetName } from { self . dsBaseDirectory } .\" ) self . _loadSubjectFiles ( self . dsBaseDirectory , subcortical = subcortical ) assert len ( self . data ) > 0 , \"No data loaded.\" assert self . has_subjects self . Cmats = self . _normalizeCmats ( self . getDataPerSubject ( \"cm\" ), method = normalizeCmats ) self . Dmats = self . getDataPerSubject ( \"len\" ) # take the average of all self . Cmat = np . mean ( self . Cmats , axis = 0 ) self . Dmat = self . getDataPerSubject ( \"len\" , apply = \"all\" , apply_function = np . mean , apply_function_kwargs = { \"axis\" : 0 }, ) self . BOLDs = self . getDataPerSubject ( \"bold\" ) self . FCs = self . getDataPerSubject ( \"bold\" , apply_function = func . fc ) if fcd : self . computeFCD () logging . info ( f \"Dataset { datasetName } loaded.\" ) loadMatrix ( self , matFileName , key = '' , verbose = False ) Function to furiously load .mat files with scipy.io.loadmat. Info: More formats are supported but commented out in the code. Parameters: Name Type Description Default matFileName str Filename of matrix to load required key str .mat file key in which data is stored (example: \"sc\") '' Returns: Type Description numpy.ndarray Loaded matrix Source code in neurolib/utils/loadData.py def loadMatrix ( self , matFileName , key = \"\" , verbose = False ): \"\"\"Function to furiously load .mat files with scipy.io.loadmat. Info: More formats are supported but commented out in the code. :param matFileName: Filename of matrix to load :type matFileName: str :param key: .mat file key in which data is stored (example: \"sc\") :type key: str :return: Loaded matrix :rtype: numpy.ndarray \"\"\" if verbose : print ( f \"Loading { matFileName } \" ) matrix = scipy . io . loadmat ( matFileName ) if verbose : print ( \" \\t Loading using scipy.io.loadmat...\" ) print ( f \"Keys: { list ( matrix . keys ()) } \" ) if key != \"\" and key in list ( matrix . keys ()): matrix = matrix [ key ] if verbose : print ( f ' \\t Loaded key \" { key } \"' ) elif type ( matrix ) is dict : raise ValueError ( f \"Object is still a dict. Here are the keys: { matrix . keys () } \" ) return matrix return 0","title":"Dataset"},{"location":"utils/dataset/#dataset","text":"This class is for loading empirical Datasets. Datasets are stored as matrices and can include functional (e.g. fMRI) and structural (e.g. DTI) data.","title":"Dataset"},{"location":"utils/dataset/#neurolib.utils.loadData.Dataset--format","text":"Empirical datasets are stored in the neurolib/data/datasets directory. In each dataset, subject-wise functional and structural data is stored as MATLAB .mat matrices that can be opened in Python using SciPy's loadmat function. Structural data are \\(N \\times N\\) , and functional time series are \\(N \\times t\\) matrices, \\(N\\) being the number of brain regions and \\(t\\) the number of time steps. Example datasets are included in neurolib and custom datasets can be added by placing them in the dataset directory.","title":"Format"},{"location":"utils/dataset/#neurolib.utils.loadData.Dataset--structural-dti-data","text":"To simulate a whole-brain network model, first we need to load the structural connectivity matrices from a DTI data set. The matrices are usually a result of processing DTI data and performing fiber tractography using software like FSL or DSIStudio . The handling of the datasets is done by the Dataset class, and the attributes in the following refer to its instances. Upon initialization, the subject-wise data set is loaded from disk. For all examples in this paper, we use freely available data from the ConnectomeDB of the Human Connectome Project (HCP). For a given parcellation of the brain into \\(N\\) brain regions, these matrices are the \\(N \\times N\\) adjacency matrix self.Cmat , i.e. the structural connectivity matrix, which determines the coupling strengths between brain areas, and the fiber length matrix Dmat which determines the signal transmission delays. The two example datasets currently included in neurolib use the the 80 cortical regions of the AAL2 atlas to define the brain areas and are sorted in a LRLR-ordering.","title":"Structural DTI data"},{"location":"utils/dataset/#neurolib.utils.loadData.Dataset--connectivity-matrix-normalization","text":"The elements of the structural connectivity matrix Cmat are typically the number of reconstructed fibers from DTI tractography. Since the number of fibers depends on the method and the parameters of the (probabilistic or deterministic) tractography, they need to be normalized using one of the three implemented methods. The first method max is to simply divide the entries of Cmat by the largest entry, such that the the largest entry becomes 1. The second method waytotal divides the entries of each column of Cmat by the number fiber tracts generated from the respective brain region during probabilistic tractography in FSL, which is contained in the waytotal.txt file. The third method nvoxel divides the entries of each column of Cmat by the size, e.g., the number of voxels of the corresponding brain area. The last two methods yield an asymmetric connectivity matrix, while the first one keeps Cmat symmetric. All normalization steps are done on the subject-wise matrices Cmats and Dmats . In a final step, all matrices can also be averaged across all subjects to yield one Cmat and Dmat per dataset.","title":"Connectivity matrix normalization"},{"location":"utils/dataset/#neurolib.utils.loadData.Dataset--functional-mri-data","text":"Subject-wise fMRI time series must be in a \\((N \\times t)\\) -dimensional format, where \\(N\\) is the number of brain regions and \\(t\\) the length of the time series. Each region-wise time series represents the BOLD activity averaged across all voxels of that region, which can be also obtained from software like FSL. Functional connectivity (FC) captures the spatial correlation structure of the BOLD time series averaged across the entire time of the recording. FC matrices are accessible via the attribute FCs and are generated by computing the Pearson correlation of the time series between all regions, yielding a \\(N \\times N\\) matrix for each subject. To capture the temporal fluctuations of time-dependent FC(t), which are lost when averaging across the entire recording time, functional connectivity dynamics matrices ( FCDs ) are computed as the element-wise Pearson correlation of time-dependent FC(t) matrices in a moving window across the BOLD time series of a chosen window length of, for example, 1 min. This yields a \\(t_{FCD} \\times t_{FCD}\\) FCD matrix for each subject, with \\(t_{FCD}\\) being the number of steps the window was moved.","title":"Functional MRI data"},{"location":"utils/dataset/#neurolib.utils.loadData.Dataset.__init__","text":"Load the empirical data sets that are provided with neurolib . Right now, datasets work on a per-subject base. A dataset must be located in the neurolib/data/datasets/ directory. Each subject's dataset must be in the subjects subdirectory of that folder. In each subject folder there is a directory called functional for time series data and structural the structural connectivity data. See loadData.loadSubjectFiles() for more details on which files are being loaded. The structural connectivity data (accessible using the attribute loadData.Cmat), can be normalized using the normalizeCmats flag. This defaults to \"max\" which normalizes the Cmat by its maxmimum. Other options are waytotal or nvoxel , which normalizes the Cmat by dividing every row of the matrix by the waytotal or nvoxel files that are provided in the datasets. Info: the waytotal.txt and the nvoxel.txt are files extracted from the tractography of DTI data using probtrackX from the fsl pipeline. Individual subject data is provided with the class attributes: self.BOLDs: BOLD timeseries of each individual self.FCs: Functional connectivity of BOLD timeseries Mean data is provided with the class attributes: self.Cmat: Structural connectivity matrix (for coupling strenghts between areas) self.Dmat: Fiber length matrix (for delays) self.BOLDs: BOLD timeseries of each area self.FCs: Functional connectiviy matrices of each BOLD timeseries Parameters: Name Type Description Default datasetName str Name of the dataset to load None normalizeCmats str Normalization method for the structural connectivity matrix. normalizationMethods = [\"max\", \"waytotal\", \"nvoxel\"] 'max' fcd bool Compute FCD matrices of BOLD data, defaults to False False subcortical bool Include subcortical areas from the atlas or not, defaults to False False Source code in neurolib/utils/loadData.py def __init__ ( self , datasetName = None , normalizeCmats = \"max\" , fcd = False , subcortical = False ): \"\"\" Load the empirical data sets that are provided with `neurolib`. Right now, datasets work on a per-subject base. A dataset must be located in the `neurolib/data/datasets/` directory. Each subject's dataset must be in the `subjects` subdirectory of that folder. In each subject folder there is a directory called `functional` for time series data and `structural` the structural connectivity data. See `loadData.loadSubjectFiles()` for more details on which files are being loaded. The structural connectivity data (accessible using the attribute loadData.Cmat), can be normalized using the `normalizeCmats` flag. This defaults to \"max\" which normalizes the Cmat by its maxmimum. Other options are `waytotal` or `nvoxel`, which normalizes the Cmat by dividing every row of the matrix by the waytotal or nvoxel files that are provided in the datasets. Info: the waytotal.txt and the nvoxel.txt are files extracted from the tractography of DTI data using `probtrackX` from the `fsl` pipeline. Individual subject data is provided with the class attributes: self.BOLDs: BOLD timeseries of each individual self.FCs: Functional connectivity of BOLD timeseries Mean data is provided with the class attributes: self.Cmat: Structural connectivity matrix (for coupling strenghts between areas) self.Dmat: Fiber length matrix (for delays) self.BOLDs: BOLD timeseries of each area self.FCs: Functional connectiviy matrices of each BOLD timeseries :param datasetName: Name of the dataset to load :type datasetName: str :param normalizeCmats: Normalization method for the structural connectivity matrix. normalizationMethods = [\"max\", \"waytotal\", \"nvoxel\"] :type normalizeCmats: str :param fcd: Compute FCD matrices of BOLD data, defaults to False :type fcd: bool :param subcortical: Include subcortical areas from the atlas or not, defaults to False :type subcortical: bool \"\"\" self . has_subjects = None if datasetName : self . loadDataset ( datasetName , normalizeCmats = normalizeCmats , fcd = fcd , subcortical = subcortical )","title":"__init__()"},{"location":"utils/dataset/#neurolib.utils.loadData.Dataset.getDataPerSubject","text":"Load data of a certain kind for all users of the current dataset Parameters: Name Type Description Default name str Name of data type, i.e. \"bold\" or \"cm\" required apply str, optional Apply function per subject (\"single\") or on all subjects (\"all\"), defaults to \"single\" 'single' apply_function function, optional Apply function on data, defaults to None None apply_function_kwargs dict, optional Keyword arguments of fuction, defaults to {} {} Returns: Type Description list[np.ndarray] Subjectwise data, after function apply Source code in neurolib/utils/loadData.py def getDataPerSubject ( self , name , apply = \"single\" , apply_function = None , apply_function_kwargs = {}, normalizeCmats = \"max\" , ): \"\"\"Load data of a certain kind for all users of the current dataset :param name: Name of data type, i.e. \"bold\" or \"cm\" :type name: str :param apply: Apply function per subject (\"single\") or on all subjects (\"all\"), defaults to \"single\" :type apply: str, optional :param apply_function: Apply function on data, defaults to None :type apply_function: function, optional :param apply_function_kwargs: Keyword arguments of fuction, defaults to {} :type apply_function_kwargs: dict, optional :return: Subjectwise data, after function apply :rtype: list[np.ndarray] \"\"\" values = [] for subject , value in self . data [ \"subjects\" ] . items (): assert name in value , f \"Data type { name } not found in dataset of subject { subject } .\" val = value [ name ] if apply_function and apply == \"single\" : val = apply_function ( val , ** apply_function_kwargs ) values . append ( val ) if apply_function and apply == \"all\" : values = apply_function ( values , ** apply_function_kwargs ) return values","title":"getDataPerSubject()"},{"location":"utils/dataset/#neurolib.utils.loadData.Dataset.loadDataset","text":"Load data into accessible class attributes. Parameters: Name Type Description Default datasetName str Name of the dataset (must be in datasets directory) required normalizeCmats str, optional Normalization method for Cmats, defaults to \"max\" 'max' Exceptions: Type Description NotImplementedError If unknown normalization method is used Source code in neurolib/utils/loadData.py def loadDataset ( self , datasetName , normalizeCmats = \"max\" , fcd = False , subcortical = False ): \"\"\"Load data into accessible class attributes. :param datasetName: Name of the dataset (must be in `datasets` directory) :type datasetName: str :param normalizeCmats: Normalization method for Cmats, defaults to \"max\" :type normalizeCmats: str, optional :raises NotImplementedError: If unknown normalization method is used \"\"\" # the base directory of the dataset dsBaseDirectory = os . path . join ( os . path . dirname ( __file__ ), \"..\" , \"data\" , \"datasets\" , datasetName ) assert os . path . exists ( dsBaseDirectory ), f \"Dataset { datasetName } not found in { dsBaseDirectory } .\" self . dsBaseDirectory = dsBaseDirectory self . data = dotdict ({}) # load all available subject data from disk to memory logging . info ( f \"Loading dataset { datasetName } from { self . dsBaseDirectory } .\" ) self . _loadSubjectFiles ( self . dsBaseDirectory , subcortical = subcortical ) assert len ( self . data ) > 0 , \"No data loaded.\" assert self . has_subjects self . Cmats = self . _normalizeCmats ( self . getDataPerSubject ( \"cm\" ), method = normalizeCmats ) self . Dmats = self . getDataPerSubject ( \"len\" ) # take the average of all self . Cmat = np . mean ( self . Cmats , axis = 0 ) self . Dmat = self . getDataPerSubject ( \"len\" , apply = \"all\" , apply_function = np . mean , apply_function_kwargs = { \"axis\" : 0 }, ) self . BOLDs = self . getDataPerSubject ( \"bold\" ) self . FCs = self . getDataPerSubject ( \"bold\" , apply_function = func . fc ) if fcd : self . computeFCD () logging . info ( f \"Dataset { datasetName } loaded.\" )","title":"loadDataset()"},{"location":"utils/dataset/#neurolib.utils.loadData.Dataset.loadMatrix","text":"Function to furiously load .mat files with scipy.io.loadmat. Info: More formats are supported but commented out in the code. Parameters: Name Type Description Default matFileName str Filename of matrix to load required key str .mat file key in which data is stored (example: \"sc\") '' Returns: Type Description numpy.ndarray Loaded matrix Source code in neurolib/utils/loadData.py def loadMatrix ( self , matFileName , key = \"\" , verbose = False ): \"\"\"Function to furiously load .mat files with scipy.io.loadmat. Info: More formats are supported but commented out in the code. :param matFileName: Filename of matrix to load :type matFileName: str :param key: .mat file key in which data is stored (example: \"sc\") :type key: str :return: Loaded matrix :rtype: numpy.ndarray \"\"\" if verbose : print ( f \"Loading { matFileName } \" ) matrix = scipy . io . loadmat ( matFileName ) if verbose : print ( \" \\t Loading using scipy.io.loadmat...\" ) print ( f \"Keys: { list ( matrix . keys ()) } \" ) if key != \"\" and key in list ( matrix . keys ()): matrix = matrix [ key ] if verbose : print ( f ' \\t Loaded key \" { key } \"' ) elif type ( matrix ) is dict : raise ValueError ( f \"Object is still a dict. Here are the keys: { matrix . keys () } \" ) return matrix return 0","title":"loadMatrix()"},{"location":"utils/functions/","text":"Functions fc ( ts ) Functional connectivity matrix of timeseries multidimensional ts (Nxt). Pearson correlation (from np.corrcoef() is used). Parameters: Name Type Description Default ts numpy.ndarray Nxt timeseries required Returns: Type Description numpy.ndarray N x N functional connectivity matrix Source code in neurolib/utils/functions.py def fc ( ts ): \"\"\"Functional connectivity matrix of timeseries multidimensional `ts` (Nxt). Pearson correlation (from `np.corrcoef()` is used). :param ts: Nxt timeseries :type ts: numpy.ndarray :return: N x N functional connectivity matrix :rtype: numpy.ndarray \"\"\" fc = np . corrcoef ( ts ) fc = np . nan_to_num ( fc ) # remove NaNs return fc fcd ( ts , windowsize = 30 , stepsize = 5 ) Computes FCD (functional connectivity dynamics) matrix, as described in Deco's whole-brain model papers. Default paramters are suited for computing FCS matrices of BOLD timeseries: A windowsize of 30 at the BOLD sampling rate of 0.5 Hz equals 60s and stepsize = 5 equals 10s. Parameters: Name Type Description Default ts numpy.ndarray Nxt timeseries required windowsize int, optional Size of each rolling window in timesteps, defaults to 30 30 stepsize int, optional Stepsize between each rolling window, defaults to 5 5 Returns: Type Description numpy.ndarray T x T FCD matrix Source code in neurolib/utils/functions.py def fcd ( ts , windowsize = 30 , stepsize = 5 ): \"\"\"Computes FCD (functional connectivity dynamics) matrix, as described in Deco's whole-brain model papers. Default paramters are suited for computing FCS matrices of BOLD timeseries: A windowsize of 30 at the BOLD sampling rate of 0.5 Hz equals 60s and stepsize = 5 equals 10s. :param ts: Nxt timeseries :type ts: numpy.ndarray :param windowsize: Size of each rolling window in timesteps, defaults to 30 :type windowsize: int, optional :param stepsize: Stepsize between each rolling window, defaults to 5 :type stepsize: int, optional :return: T x T FCD matrix :rtype: numpy.ndarray \"\"\" t_window_width = int ( windowsize ) # int(windowsize * 30) # x minutes stepsize = stepsize # ts.shape[1]/N corrFCs = [] try : counter = range ( 0 , ts . shape [ 1 ] - t_window_width , stepsize ) for t in counter : ts_slice = ts [:, t : t + t_window_width ] corrFCs . append ( np . corrcoef ( ts_slice )) FCd = np . empty ([ len ( corrFCs ), len ( corrFCs )]) f1i = 0 for f1 in corrFCs : f2i = 0 for f2 in corrFCs : FCd [ f1i , f2i ] = np . corrcoef ( f1 . reshape (( 1 , f1 . size )), f2 . reshape (( 1 , f2 . size )))[ 0 , 1 ] f2i += 1 f1i += 1 return FCd except : return 0 getMeanPowerSpectrum ( activities , dt , maxfr = 70 , spectrum_windowsize = 1.0 , normalize = False ) Returns the mean power spectrum of multiple timeseries. Parameters: Name Type Description Default activities np.ndarray N-dimensional timeseries required dt float Simulation time step required maxfr int, optional Maximum frequency in Hz to cutoff from return, defaults to 70 70 spectrum_windowsize float, optional Length of the window used in Welch's method (in seconds), defaults to 1.0 1.0 normalize bool, optional Maximum power is normalized to 1 if True, defaults to False False Returns: Type Description [np.ndarray, np.ndarray] Frquencies and the power of each frequency Source code in neurolib/utils/functions.py def getMeanPowerSpectrum ( activities , dt , maxfr = 70 , spectrum_windowsize = 1.0 , normalize = False ): \"\"\"Returns the mean power spectrum of multiple timeseries. :param activities: N-dimensional timeseries :type activities: np.ndarray :param dt: Simulation time step :type dt: float :param maxfr: Maximum frequency in Hz to cutoff from return, defaults to 70 :type maxfr: int, optional :param spectrum_windowsize: Length of the window used in Welch's method (in seconds), defaults to 1.0 :type spectrum_windowsize: float, optional :param normalize: Maximum power is normalized to 1 if True, defaults to False :type normalize: bool, optional :return: Frquencies and the power of each frequency :rtype: [np.ndarray, np.ndarray] \"\"\" powers = np . zeros ( getPowerSpectrum ( activities [ 0 ], dt , maxfr , spectrum_windowsize )[ 0 ] . shape ) ps = [] for rate in activities : f , Pxx_spec = getPowerSpectrum ( rate , dt , maxfr , spectrum_windowsize ) ps . append ( Pxx_spec ) powers += Pxx_spec powers /= len ( ps ) if normalize : powers /= np . max ( powers ) return f , powers getPowerSpectrum ( activity , dt , maxfr = 70 , spectrum_windowsize = 1.0 , normalize = False ) Returns a power spectrum using Welch's method. Parameters: Name Type Description Default activity np.ndarray One-dimensional timeseries required dt float Simulation time step required maxfr int, optional Maximum frequency in Hz to cutoff from return, defaults to 70 70 spectrum_windowsize float, optional Length of the window used in Welch's method (in seconds), defaults to 1.0 1.0 normalize bool, optional Maximum power is normalized to 1 if True, defaults to False False Returns: Type Description [np.ndarray, np.ndarray] Frquencies and the power of each frequency Source code in neurolib/utils/functions.py def getPowerSpectrum ( activity , dt , maxfr = 70 , spectrum_windowsize = 1.0 , normalize = False ): \"\"\"Returns a power spectrum using Welch's method. :param activity: One-dimensional timeseries :type activity: np.ndarray :param dt: Simulation time step :type dt: float :param maxfr: Maximum frequency in Hz to cutoff from return, defaults to 70 :type maxfr: int, optional :param spectrum_windowsize: Length of the window used in Welch's method (in seconds), defaults to 1.0 :type spectrum_windowsize: float, optional :param normalize: Maximum power is normalized to 1 if True, defaults to False :type normalize: bool, optional :return: Frquencies and the power of each frequency :rtype: [np.ndarray, np.ndarray] \"\"\" # convert to one-dimensional array if it is an (1xn)-D array if activity . shape [ 0 ] == 1 and activity . shape [ 1 ] > 1 : activity = activity [ 0 ] assert len ( activity . shape ) == 1 , \"activity is not one-dimensional!\" f , Pxx_spec = scipy . signal . welch ( activity , 1000 / dt , window = \"hanning\" , nperseg = int ( spectrum_windowsize * 1000 / dt ), scaling = \"spectrum\" , ) f = f [ f < maxfr ] Pxx_spec = Pxx_spec [ 0 : len ( f )] if normalize : Pxx_spec /= np . max ( Pxx_spec ) return f , Pxx_spec kuramoto ( traces , dt = 0.1 , smoothing = 0.0 , peakrange = [ 0.1 , 0.2 ]) Computes the Kuramoto order parameter of a timeseries which is a measure for synchrony. Can smooth timeseries if there is noise. Peaks are then detected using a peakfinder. From these peaks a phase is derived and then the amount of phase synchrony (the Kuramoto order parameter) is computed. Parameters: Name Type Description Default traces numpy.ndarray Multidimensional timeseries array required dt float Integration time step 0.1 smoothing float, optional Gaussian smoothing strength 0.0 peakrange list[float], length 2 Width range of peaks for peak detection with scipy.signal.find_peaks_cwt [0.1, 0.2] Returns: Type Description numpy.ndarray Timeseries of Kuramoto order paramter Source code in neurolib/utils/functions.py def kuramoto ( traces , dt = 0.1 , smoothing = 0.0 , peakrange = [ 0.1 , 0.2 ]): \"\"\" Computes the Kuramoto order parameter of a timeseries which is a measure for synchrony. Can smooth timeseries if there is noise. Peaks are then detected using a peakfinder. From these peaks a phase is derived and then the amount of phase synchrony (the Kuramoto order parameter) is computed. :param traces: Multidimensional timeseries array :type traces: numpy.ndarray :param dt: Integration time step :type dt: float :param smoothing: Gaussian smoothing strength :type smoothing: float, optional :param peakrange: Width range of peaks for peak detection with `scipy.signal.find_peaks_cwt` :type peakrange: list[float], length 2 :return: Timeseries of Kuramoto order paramter :rtype: numpy.ndarray \"\"\" phases = [] nTraces = len ( traces ) for n in range ( nTraces ): tList = np . dot ( range ( len ( traces [ n ])), dt / 1000 ) a = traces [ n ] # find peaks if smoothing > 0 : a = scipy . ndimage . filters . gaussian_filter ( traces [ n ], smoothing ) # smooth data maximalist = scipy . signal . find_peaks_cwt ( a , np . arange ( peakrange [ 0 ], peakrange [ 1 ])) maximalist = np . append ( maximalist , len ( traces [ n ]) - 1 ) . astype ( int ) if len ( maximalist ) > 1 : phases . append ([]) lastMax = 0 for m in maximalist : for t in range ( lastMax , m ): # compute instantaneous phase phi = 2 * np . pi * float ( t - lastMax ) / float ( m - lastMax ) phases [ n ] . append ( phi ) lastMax = m phases [ n ] . append ( 2 * np . pi ) else : logging . warning ( \"Kuramoto: No peaks found, returning 0.\" ) return 0 # determine kuramoto order paramter kuramoto = [] for t in range ( len ( tList )): R = 1 j * 0 for n in range ( nTraces ): R += np . exp ( 1 j * phases [ n ][ t ]) R /= nTraces kuramoto . append ( np . absolute ( R )) return kuramoto matrix_correlation ( M1 , M2 ) Pearson correlation of the lower triagonal of two matrices. The triangular matrix is offset by k = 1 in order to ignore the diagonal line Parameters: Name Type Description Default M1 numpy.ndarray First matrix required M2 numpy.ndarray Second matrix required Returns: Type Description float Correlation coefficient Source code in neurolib/utils/functions.py def matrix_correlation ( M1 , M2 ): \"\"\"Pearson correlation of the lower triagonal of two matrices. The triangular matrix is offset by k = 1 in order to ignore the diagonal line :param M1: First matrix :type M1: numpy.ndarray :param M2: Second matrix :type M2: numpy.ndarray :return: Correlation coefficient :rtype: float \"\"\" cc = np . corrcoef ( M1 [ np . triu_indices_from ( M1 , k = 1 )], M2 [ np . triu_indices_from ( M2 , k = 1 )])[ 0 , 1 ] return cc matrix_kolmogorov ( m1 , m2 ) Computes the Kolmogorov distance between the distributions of lower-triangular entries of two matrices See: https://en.wikipedia.org/wiki/Kolmogorov%E2%80%93Smirnov_test#Two-sample_Kolmogorov%E2%80%93Smirnov_test Parameters: Name Type Description Default m1 np.ndarray matrix 1 required m2 np.ndarray matrix 2 required Returns: Type Description float 2-sample KS statistics Source code in neurolib/utils/functions.py def matrix_kolmogorov ( m1 , m2 ): \"\"\"Computes the Kolmogorov distance between the distributions of lower-triangular entries of two matrices See: https://en.wikipedia.org/wiki/Kolmogorov%E2%80%93Smirnov_test#Two-sample_Kolmogorov%E2%80%93Smirnov_test :param m1: matrix 1 :type m1: np.ndarray :param m2: matrix 2 :type m2: np.ndarray :return: 2-sample KS statistics :rtype: float \"\"\" # get the values of the lower triangle triu_ind1 = np . triu_indices ( m1 . shape [ 0 ], k = 1 ) m1_vals = m1 [ triu_ind1 ] triu_ind2 = np . triu_indices ( m2 . shape [ 0 ], k = 1 ) m2_vals = m2 [ triu_ind2 ] # return the distance, omit p-value return scipy . stats . ks_2samp ( m1_vals , m2_vals )[ 0 ] ts_kolmogorov ( ts1 , ts2 , ** fcd_kwargs ) Computes kolmogorov distance between two timeseries. This is done by first computing two FCD matrices (one for each timeseries) and then measuring the Kolmogorov distance of the upper triangle of these matrices. Parameters: Name Type Description Default ts1 np.ndarray Timeseries 1 required ts2 np.ndarray Timeseries 2 required Returns: Type Description float 2-sample KS statistics Source code in neurolib/utils/functions.py def ts_kolmogorov ( ts1 , ts2 , ** fcd_kwargs ): \"\"\"Computes kolmogorov distance between two timeseries. This is done by first computing two FCD matrices (one for each timeseries) and then measuring the Kolmogorov distance of the upper triangle of these matrices. :param ts1: Timeseries 1 :type ts1: np.ndarray :param ts2: Timeseries 2 :type ts2: np.ndarray :return: 2-sample KS statistics :rtype: float \"\"\" fcd1 = fcd ( ts1 , ** fcd_kwargs ) fcd2 = fcd ( ts2 , ** fcd_kwargs ) return matrix_kolmogorov ( fcd1 , fcd2 ) weighted_correlation ( x , y , w ) Weighted Pearson correlation of two series. Parameters: Name Type Description Default x list, np.array Timeseries 1 required y list, np.array Timeseries 2, must have same length as x required w list, np.array Weight vector, must have same length as x and y required Returns: Type Description float Weighted correlation coefficient Source code in neurolib/utils/functions.py def weighted_correlation ( x , y , w ): \"\"\"Weighted Pearson correlation of two series. :param x: Timeseries 1 :type x: list, np.array :param y: Timeseries 2, must have same length as x :type y: list, np.array :param w: Weight vector, must have same length as x and y :type w: list, np.array :return: Weighted correlation coefficient :rtype: float \"\"\" def weighted_mean ( x , w ): \"\"\"Weighted Mean\"\"\" return np . sum ( x * w ) / np . sum ( w ) def weighted_cov ( x , y , w ): \"\"\"Weighted Covariance\"\"\" return np . sum ( w * ( x - weighted_mean ( x , w )) * ( y - weighted_mean ( y , w ))) / np . sum ( w ) return weighted_cov ( x , y , w ) / np . sqrt ( weighted_cov ( x , x , w ) * weighted_cov ( y , y , w ))","title":"Functions"},{"location":"utils/functions/#functions","text":"","title":"Functions"},{"location":"utils/functions/#neurolib.utils.functions.fc","text":"Functional connectivity matrix of timeseries multidimensional ts (Nxt). Pearson correlation (from np.corrcoef() is used). Parameters: Name Type Description Default ts numpy.ndarray Nxt timeseries required Returns: Type Description numpy.ndarray N x N functional connectivity matrix Source code in neurolib/utils/functions.py def fc ( ts ): \"\"\"Functional connectivity matrix of timeseries multidimensional `ts` (Nxt). Pearson correlation (from `np.corrcoef()` is used). :param ts: Nxt timeseries :type ts: numpy.ndarray :return: N x N functional connectivity matrix :rtype: numpy.ndarray \"\"\" fc = np . corrcoef ( ts ) fc = np . nan_to_num ( fc ) # remove NaNs return fc","title":"fc()"},{"location":"utils/functions/#neurolib.utils.functions.fcd","text":"Computes FCD (functional connectivity dynamics) matrix, as described in Deco's whole-brain model papers. Default paramters are suited for computing FCS matrices of BOLD timeseries: A windowsize of 30 at the BOLD sampling rate of 0.5 Hz equals 60s and stepsize = 5 equals 10s. Parameters: Name Type Description Default ts numpy.ndarray Nxt timeseries required windowsize int, optional Size of each rolling window in timesteps, defaults to 30 30 stepsize int, optional Stepsize between each rolling window, defaults to 5 5 Returns: Type Description numpy.ndarray T x T FCD matrix Source code in neurolib/utils/functions.py def fcd ( ts , windowsize = 30 , stepsize = 5 ): \"\"\"Computes FCD (functional connectivity dynamics) matrix, as described in Deco's whole-brain model papers. Default paramters are suited for computing FCS matrices of BOLD timeseries: A windowsize of 30 at the BOLD sampling rate of 0.5 Hz equals 60s and stepsize = 5 equals 10s. :param ts: Nxt timeseries :type ts: numpy.ndarray :param windowsize: Size of each rolling window in timesteps, defaults to 30 :type windowsize: int, optional :param stepsize: Stepsize between each rolling window, defaults to 5 :type stepsize: int, optional :return: T x T FCD matrix :rtype: numpy.ndarray \"\"\" t_window_width = int ( windowsize ) # int(windowsize * 30) # x minutes stepsize = stepsize # ts.shape[1]/N corrFCs = [] try : counter = range ( 0 , ts . shape [ 1 ] - t_window_width , stepsize ) for t in counter : ts_slice = ts [:, t : t + t_window_width ] corrFCs . append ( np . corrcoef ( ts_slice )) FCd = np . empty ([ len ( corrFCs ), len ( corrFCs )]) f1i = 0 for f1 in corrFCs : f2i = 0 for f2 in corrFCs : FCd [ f1i , f2i ] = np . corrcoef ( f1 . reshape (( 1 , f1 . size )), f2 . reshape (( 1 , f2 . size )))[ 0 , 1 ] f2i += 1 f1i += 1 return FCd except : return 0","title":"fcd()"},{"location":"utils/functions/#neurolib.utils.functions.getMeanPowerSpectrum","text":"Returns the mean power spectrum of multiple timeseries. Parameters: Name Type Description Default activities np.ndarray N-dimensional timeseries required dt float Simulation time step required maxfr int, optional Maximum frequency in Hz to cutoff from return, defaults to 70 70 spectrum_windowsize float, optional Length of the window used in Welch's method (in seconds), defaults to 1.0 1.0 normalize bool, optional Maximum power is normalized to 1 if True, defaults to False False Returns: Type Description [np.ndarray, np.ndarray] Frquencies and the power of each frequency Source code in neurolib/utils/functions.py def getMeanPowerSpectrum ( activities , dt , maxfr = 70 , spectrum_windowsize = 1.0 , normalize = False ): \"\"\"Returns the mean power spectrum of multiple timeseries. :param activities: N-dimensional timeseries :type activities: np.ndarray :param dt: Simulation time step :type dt: float :param maxfr: Maximum frequency in Hz to cutoff from return, defaults to 70 :type maxfr: int, optional :param spectrum_windowsize: Length of the window used in Welch's method (in seconds), defaults to 1.0 :type spectrum_windowsize: float, optional :param normalize: Maximum power is normalized to 1 if True, defaults to False :type normalize: bool, optional :return: Frquencies and the power of each frequency :rtype: [np.ndarray, np.ndarray] \"\"\" powers = np . zeros ( getPowerSpectrum ( activities [ 0 ], dt , maxfr , spectrum_windowsize )[ 0 ] . shape ) ps = [] for rate in activities : f , Pxx_spec = getPowerSpectrum ( rate , dt , maxfr , spectrum_windowsize ) ps . append ( Pxx_spec ) powers += Pxx_spec powers /= len ( ps ) if normalize : powers /= np . max ( powers ) return f , powers","title":"getMeanPowerSpectrum()"},{"location":"utils/functions/#neurolib.utils.functions.getPowerSpectrum","text":"Returns a power spectrum using Welch's method. Parameters: Name Type Description Default activity np.ndarray One-dimensional timeseries required dt float Simulation time step required maxfr int, optional Maximum frequency in Hz to cutoff from return, defaults to 70 70 spectrum_windowsize float, optional Length of the window used in Welch's method (in seconds), defaults to 1.0 1.0 normalize bool, optional Maximum power is normalized to 1 if True, defaults to False False Returns: Type Description [np.ndarray, np.ndarray] Frquencies and the power of each frequency Source code in neurolib/utils/functions.py def getPowerSpectrum ( activity , dt , maxfr = 70 , spectrum_windowsize = 1.0 , normalize = False ): \"\"\"Returns a power spectrum using Welch's method. :param activity: One-dimensional timeseries :type activity: np.ndarray :param dt: Simulation time step :type dt: float :param maxfr: Maximum frequency in Hz to cutoff from return, defaults to 70 :type maxfr: int, optional :param spectrum_windowsize: Length of the window used in Welch's method (in seconds), defaults to 1.0 :type spectrum_windowsize: float, optional :param normalize: Maximum power is normalized to 1 if True, defaults to False :type normalize: bool, optional :return: Frquencies and the power of each frequency :rtype: [np.ndarray, np.ndarray] \"\"\" # convert to one-dimensional array if it is an (1xn)-D array if activity . shape [ 0 ] == 1 and activity . shape [ 1 ] > 1 : activity = activity [ 0 ] assert len ( activity . shape ) == 1 , \"activity is not one-dimensional!\" f , Pxx_spec = scipy . signal . welch ( activity , 1000 / dt , window = \"hanning\" , nperseg = int ( spectrum_windowsize * 1000 / dt ), scaling = \"spectrum\" , ) f = f [ f < maxfr ] Pxx_spec = Pxx_spec [ 0 : len ( f )] if normalize : Pxx_spec /= np . max ( Pxx_spec ) return f , Pxx_spec","title":"getPowerSpectrum()"},{"location":"utils/functions/#neurolib.utils.functions.kuramoto","text":"Computes the Kuramoto order parameter of a timeseries which is a measure for synchrony. Can smooth timeseries if there is noise. Peaks are then detected using a peakfinder. From these peaks a phase is derived and then the amount of phase synchrony (the Kuramoto order parameter) is computed. Parameters: Name Type Description Default traces numpy.ndarray Multidimensional timeseries array required dt float Integration time step 0.1 smoothing float, optional Gaussian smoothing strength 0.0 peakrange list[float], length 2 Width range of peaks for peak detection with scipy.signal.find_peaks_cwt [0.1, 0.2] Returns: Type Description numpy.ndarray Timeseries of Kuramoto order paramter Source code in neurolib/utils/functions.py def kuramoto ( traces , dt = 0.1 , smoothing = 0.0 , peakrange = [ 0.1 , 0.2 ]): \"\"\" Computes the Kuramoto order parameter of a timeseries which is a measure for synchrony. Can smooth timeseries if there is noise. Peaks are then detected using a peakfinder. From these peaks a phase is derived and then the amount of phase synchrony (the Kuramoto order parameter) is computed. :param traces: Multidimensional timeseries array :type traces: numpy.ndarray :param dt: Integration time step :type dt: float :param smoothing: Gaussian smoothing strength :type smoothing: float, optional :param peakrange: Width range of peaks for peak detection with `scipy.signal.find_peaks_cwt` :type peakrange: list[float], length 2 :return: Timeseries of Kuramoto order paramter :rtype: numpy.ndarray \"\"\" phases = [] nTraces = len ( traces ) for n in range ( nTraces ): tList = np . dot ( range ( len ( traces [ n ])), dt / 1000 ) a = traces [ n ] # find peaks if smoothing > 0 : a = scipy . ndimage . filters . gaussian_filter ( traces [ n ], smoothing ) # smooth data maximalist = scipy . signal . find_peaks_cwt ( a , np . arange ( peakrange [ 0 ], peakrange [ 1 ])) maximalist = np . append ( maximalist , len ( traces [ n ]) - 1 ) . astype ( int ) if len ( maximalist ) > 1 : phases . append ([]) lastMax = 0 for m in maximalist : for t in range ( lastMax , m ): # compute instantaneous phase phi = 2 * np . pi * float ( t - lastMax ) / float ( m - lastMax ) phases [ n ] . append ( phi ) lastMax = m phases [ n ] . append ( 2 * np . pi ) else : logging . warning ( \"Kuramoto: No peaks found, returning 0.\" ) return 0 # determine kuramoto order paramter kuramoto = [] for t in range ( len ( tList )): R = 1 j * 0 for n in range ( nTraces ): R += np . exp ( 1 j * phases [ n ][ t ]) R /= nTraces kuramoto . append ( np . absolute ( R )) return kuramoto","title":"kuramoto()"},{"location":"utils/functions/#neurolib.utils.functions.matrix_correlation","text":"Pearson correlation of the lower triagonal of two matrices. The triangular matrix is offset by k = 1 in order to ignore the diagonal line Parameters: Name Type Description Default M1 numpy.ndarray First matrix required M2 numpy.ndarray Second matrix required Returns: Type Description float Correlation coefficient Source code in neurolib/utils/functions.py def matrix_correlation ( M1 , M2 ): \"\"\"Pearson correlation of the lower triagonal of two matrices. The triangular matrix is offset by k = 1 in order to ignore the diagonal line :param M1: First matrix :type M1: numpy.ndarray :param M2: Second matrix :type M2: numpy.ndarray :return: Correlation coefficient :rtype: float \"\"\" cc = np . corrcoef ( M1 [ np . triu_indices_from ( M1 , k = 1 )], M2 [ np . triu_indices_from ( M2 , k = 1 )])[ 0 , 1 ] return cc","title":"matrix_correlation()"},{"location":"utils/functions/#neurolib.utils.functions.matrix_kolmogorov","text":"Computes the Kolmogorov distance between the distributions of lower-triangular entries of two matrices See: https://en.wikipedia.org/wiki/Kolmogorov%E2%80%93Smirnov_test#Two-sample_Kolmogorov%E2%80%93Smirnov_test Parameters: Name Type Description Default m1 np.ndarray matrix 1 required m2 np.ndarray matrix 2 required Returns: Type Description float 2-sample KS statistics Source code in neurolib/utils/functions.py def matrix_kolmogorov ( m1 , m2 ): \"\"\"Computes the Kolmogorov distance between the distributions of lower-triangular entries of two matrices See: https://en.wikipedia.org/wiki/Kolmogorov%E2%80%93Smirnov_test#Two-sample_Kolmogorov%E2%80%93Smirnov_test :param m1: matrix 1 :type m1: np.ndarray :param m2: matrix 2 :type m2: np.ndarray :return: 2-sample KS statistics :rtype: float \"\"\" # get the values of the lower triangle triu_ind1 = np . triu_indices ( m1 . shape [ 0 ], k = 1 ) m1_vals = m1 [ triu_ind1 ] triu_ind2 = np . triu_indices ( m2 . shape [ 0 ], k = 1 ) m2_vals = m2 [ triu_ind2 ] # return the distance, omit p-value return scipy . stats . ks_2samp ( m1_vals , m2_vals )[ 0 ]","title":"matrix_kolmogorov()"},{"location":"utils/functions/#neurolib.utils.functions.ts_kolmogorov","text":"Computes kolmogorov distance between two timeseries. This is done by first computing two FCD matrices (one for each timeseries) and then measuring the Kolmogorov distance of the upper triangle of these matrices. Parameters: Name Type Description Default ts1 np.ndarray Timeseries 1 required ts2 np.ndarray Timeseries 2 required Returns: Type Description float 2-sample KS statistics Source code in neurolib/utils/functions.py def ts_kolmogorov ( ts1 , ts2 , ** fcd_kwargs ): \"\"\"Computes kolmogorov distance between two timeseries. This is done by first computing two FCD matrices (one for each timeseries) and then measuring the Kolmogorov distance of the upper triangle of these matrices. :param ts1: Timeseries 1 :type ts1: np.ndarray :param ts2: Timeseries 2 :type ts2: np.ndarray :return: 2-sample KS statistics :rtype: float \"\"\" fcd1 = fcd ( ts1 , ** fcd_kwargs ) fcd2 = fcd ( ts2 , ** fcd_kwargs ) return matrix_kolmogorov ( fcd1 , fcd2 )","title":"ts_kolmogorov()"},{"location":"utils/functions/#neurolib.utils.functions.weighted_correlation","text":"Weighted Pearson correlation of two series. Parameters: Name Type Description Default x list, np.array Timeseries 1 required y list, np.array Timeseries 2, must have same length as x required w list, np.array Weight vector, must have same length as x and y required Returns: Type Description float Weighted correlation coefficient Source code in neurolib/utils/functions.py def weighted_correlation ( x , y , w ): \"\"\"Weighted Pearson correlation of two series. :param x: Timeseries 1 :type x: list, np.array :param y: Timeseries 2, must have same length as x :type y: list, np.array :param w: Weight vector, must have same length as x and y :type w: list, np.array :return: Weighted correlation coefficient :rtype: float \"\"\" def weighted_mean ( x , w ): \"\"\"Weighted Mean\"\"\" return np . sum ( x * w ) / np . sum ( w ) def weighted_cov ( x , y , w ): \"\"\"Weighted Covariance\"\"\" return np . sum ( w * ( x - weighted_mean ( x , w )) * ( y - weighted_mean ( y , w ))) / np . sum ( w ) return weighted_cov ( x , y , w ) / np . sqrt ( weighted_cov ( x , x , w ) * weighted_cov ( y , y , w ))","title":"weighted_correlation()"},{"location":"utils/parameterspace/","text":"ParameterSpace Parameter space lowerBound property readonly Returns lower bound of all parameters as a list ndims property readonly Number of dimensions (parameters) upperBound property readonly Returns upper bound of all parameters as a list __init__ ( self , parameters , parameterValues = None , kind = None , allow_star_notation = False ) special Initialize parameter space. Parameter space can be initialized in two ways: Either a parameters is a dictionary of the form {\"parName1\" : [0, 1, 2], \"parName2\" : [3, 4]} , or parameters is a list of names and parameterValues are values of each parameter. Parameters: Name Type Description Default parameters `dict, list[str, str]` parameter dictionary or list of names of parameters e.g. ['x', 'y'] required parameterValues `list[list[float, float]]` list of parameter values (must be floats) e.g. [[x_min, x_max], [y_min, y_max], ...] None kind str string describing the kind of parameter space. Supports \"point\", \"bound\", \"grid\" None allow_star_notation bool whether to allow star notation in parameter names - MultiModel False Source code in neurolib/utils/parameterSpace.py def __init__ ( self , parameters , parameterValues = None , kind = None , allow_star_notation = False ): \"\"\" Initialize parameter space. Parameter space can be initialized in two ways: Either a `parameters` is a dictionary of the form `{\"parName1\" : [0, 1, 2], \"parName2\" : [3, 4]}`, or `parameters` is a list of names and `parameterValues` are values of each parameter. :param parameters: parameter dictionary or list of names of parameters e.g. `['x', 'y']` :type parameters: `dict, list[str, str]` :param parameterValues: list of parameter values (must be floats) e.g. `[[x_min, x_max], [y_min, y_max], ...]` :type parameterValues: `list[list[float, float]]` :param kind: string describing the kind of parameter space. Supports \"point\", \"bound\", \"grid\" :type kind: str :param allow_star_notation: whether to allow star notation in parameter names - MultiModel :type allow_star_notation: bool \"\"\" self . kind = kind self . parameters = parameters self . star = allow_star_notation # in case a parameter dictionary was given if parameterValues is None : assert isinstance ( parameters , dict ), \"Parameters must be a dict, if no values are given in `parameterValues`\" processedParameters = self . _processParameterDict ( parameters ) else : # check if all names are strings assert np . all ([ isinstance ( pn , str ) for pn in parameters ]), \"Parameter names must all be strings.\" # check if all parameter values are lists assert np . all ([ isinstance ( pv , ( list , tuple )) for pv in parameterValues ]), \"Parameter values must be a list.\" parameters = self . _parameterListsToDict ( parameters , parameterValues ) processedParameters = self . _processParameterDict ( parameters ) self . parameters = processedParameters self . parameterNames = list ( self . parameters . keys ()) self . parameterValues = list ( self . parameters . values ()) # let's create a named tuple of the parameters # Note: evolution.py implementation relies on named tuples self . named_tuple_constructor = namedtuple ( \"ParameterSpace\" , sanitize_dot_dict ( parameters )) self . named_tuple = self . named_tuple_constructor ( * self . parameterValues ) # set attributes of this class to make it accessible for i , p in enumerate ( self . parameters ): setattr ( self , p , self . parameterValues [ i ]) __str__ ( self ) special Print the named_tuple object Source code in neurolib/utils/parameterSpace.py def __str__ ( self ): \"\"\"Print the named_tuple object\"\"\" return str ( self . parameters ) dict ( self ) Returns the parameter space as a dicitonary of lists. Source code in neurolib/utils/parameterSpace.py def dict ( self ): \"\"\"Returns the parameter space as a dicitonary of lists. :rtype: dict \"\"\" return self . parameters getRandom ( self , safe = False ) This function returns a random single parameter from the whole space in the form of { \"par1\" : 1, \"par2\" : 2}. This function is used by neurolib/optimize/exploarion.py to add parameters of the space to pypet (for initialization) Parameters: Name Type Description Default safe Return a \"safe\" parameter or the original. Safe refers to returning python floats, not, for example numpy.float64 (necessary for pypet). ;type safe: bool False Source code in neurolib/utils/parameterSpace.py def getRandom ( self , safe = False ): \"\"\"This function returns a random single parameter from the whole space in the form of { \"par1\" : 1, \"par2\" : 2}. This function is used by neurolib/optimize/exploarion.py to add parameters of the space to pypet (for initialization) :param safe: Return a \"safe\" parameter or the original. Safe refers to returning python floats, not, for example numpy.float64 (necessary for pypet). ;type safe: bool \"\"\" randomPar = {} if safe : for key , value in self . parameters . items (): random_value = np . random . choice ( value ) if isinstance ( random_value , np . float64 ): random_value = float ( random_value ) elif isinstance ( random_value , np . int64 ): random_value = int ( random_value ) randomPar [ key ] = random_value else : for key , value in self . parameters . items (): randomPar [ key ] = np . random . choice ( value ) return randomPar","title":"ParameterSpace"},{"location":"utils/parameterspace/#parameterspace","text":"Parameter space","title":"ParameterSpace"},{"location":"utils/parameterspace/#neurolib.utils.parameterSpace.ParameterSpace.lowerBound","text":"Returns lower bound of all parameters as a list","title":"lowerBound"},{"location":"utils/parameterspace/#neurolib.utils.parameterSpace.ParameterSpace.ndims","text":"Number of dimensions (parameters)","title":"ndims"},{"location":"utils/parameterspace/#neurolib.utils.parameterSpace.ParameterSpace.upperBound","text":"Returns upper bound of all parameters as a list","title":"upperBound"},{"location":"utils/parameterspace/#neurolib.utils.parameterSpace.ParameterSpace.__init__","text":"Initialize parameter space. Parameter space can be initialized in two ways: Either a parameters is a dictionary of the form {\"parName1\" : [0, 1, 2], \"parName2\" : [3, 4]} , or parameters is a list of names and parameterValues are values of each parameter. Parameters: Name Type Description Default parameters `dict, list[str, str]` parameter dictionary or list of names of parameters e.g. ['x', 'y'] required parameterValues `list[list[float, float]]` list of parameter values (must be floats) e.g. [[x_min, x_max], [y_min, y_max], ...] None kind str string describing the kind of parameter space. Supports \"point\", \"bound\", \"grid\" None allow_star_notation bool whether to allow star notation in parameter names - MultiModel False Source code in neurolib/utils/parameterSpace.py def __init__ ( self , parameters , parameterValues = None , kind = None , allow_star_notation = False ): \"\"\" Initialize parameter space. Parameter space can be initialized in two ways: Either a `parameters` is a dictionary of the form `{\"parName1\" : [0, 1, 2], \"parName2\" : [3, 4]}`, or `parameters` is a list of names and `parameterValues` are values of each parameter. :param parameters: parameter dictionary or list of names of parameters e.g. `['x', 'y']` :type parameters: `dict, list[str, str]` :param parameterValues: list of parameter values (must be floats) e.g. `[[x_min, x_max], [y_min, y_max], ...]` :type parameterValues: `list[list[float, float]]` :param kind: string describing the kind of parameter space. Supports \"point\", \"bound\", \"grid\" :type kind: str :param allow_star_notation: whether to allow star notation in parameter names - MultiModel :type allow_star_notation: bool \"\"\" self . kind = kind self . parameters = parameters self . star = allow_star_notation # in case a parameter dictionary was given if parameterValues is None : assert isinstance ( parameters , dict ), \"Parameters must be a dict, if no values are given in `parameterValues`\" processedParameters = self . _processParameterDict ( parameters ) else : # check if all names are strings assert np . all ([ isinstance ( pn , str ) for pn in parameters ]), \"Parameter names must all be strings.\" # check if all parameter values are lists assert np . all ([ isinstance ( pv , ( list , tuple )) for pv in parameterValues ]), \"Parameter values must be a list.\" parameters = self . _parameterListsToDict ( parameters , parameterValues ) processedParameters = self . _processParameterDict ( parameters ) self . parameters = processedParameters self . parameterNames = list ( self . parameters . keys ()) self . parameterValues = list ( self . parameters . values ()) # let's create a named tuple of the parameters # Note: evolution.py implementation relies on named tuples self . named_tuple_constructor = namedtuple ( \"ParameterSpace\" , sanitize_dot_dict ( parameters )) self . named_tuple = self . named_tuple_constructor ( * self . parameterValues ) # set attributes of this class to make it accessible for i , p in enumerate ( self . parameters ): setattr ( self , p , self . parameterValues [ i ])","title":"__init__()"},{"location":"utils/parameterspace/#neurolib.utils.parameterSpace.ParameterSpace.__str__","text":"Print the named_tuple object Source code in neurolib/utils/parameterSpace.py def __str__ ( self ): \"\"\"Print the named_tuple object\"\"\" return str ( self . parameters )","title":"__str__()"},{"location":"utils/parameterspace/#neurolib.utils.parameterSpace.ParameterSpace.dict","text":"Returns the parameter space as a dicitonary of lists. Source code in neurolib/utils/parameterSpace.py def dict ( self ): \"\"\"Returns the parameter space as a dicitonary of lists. :rtype: dict \"\"\" return self . parameters","title":"dict()"},{"location":"utils/parameterspace/#neurolib.utils.parameterSpace.ParameterSpace.getRandom","text":"This function returns a random single parameter from the whole space in the form of { \"par1\" : 1, \"par2\" : 2}. This function is used by neurolib/optimize/exploarion.py to add parameters of the space to pypet (for initialization) Parameters: Name Type Description Default safe Return a \"safe\" parameter or the original. Safe refers to returning python floats, not, for example numpy.float64 (necessary for pypet). ;type safe: bool False Source code in neurolib/utils/parameterSpace.py def getRandom ( self , safe = False ): \"\"\"This function returns a random single parameter from the whole space in the form of { \"par1\" : 1, \"par2\" : 2}. This function is used by neurolib/optimize/exploarion.py to add parameters of the space to pypet (for initialization) :param safe: Return a \"safe\" parameter or the original. Safe refers to returning python floats, not, for example numpy.float64 (necessary for pypet). ;type safe: bool \"\"\" randomPar = {} if safe : for key , value in self . parameters . items (): random_value = np . random . choice ( value ) if isinstance ( random_value , np . float64 ): random_value = float ( random_value ) elif isinstance ( random_value , np . int64 ): random_value = int ( random_value ) randomPar [ key ] = random_value else : for key , value in self . parameters . items (): randomPar [ key ] = np . random . choice ( value ) return randomPar","title":"getRandom()"},{"location":"utils/signal/","text":"Signal __constructor__ property readonly special Return constructor, so that each child class would initiate a new instance of the correct class, i.e. first in the method resolution order. coords_not_time property readonly Return dict with all coordinates except time. dims_not_time property readonly Return list of dimensions that are not time. end_time property readonly Return ending time of the signal. preprocessing_steps property readonly Return preprocessing steps done on the data. shape property readonly Return shape of the data. Time axis is the first one. start_time property readonly Return starting time of the signal. __eq__ ( self , other ) special Comparison operator. Parameters: Name Type Description Default other `Signal` other Signal to compare with required Returns: Type Description bool whether two Signals are the same Source code in neurolib/utils/signal.py def __eq__ ( self , other ): \"\"\" Comparison operator. :param other: other `Signal` to compare with :type other: `Signal` :return: whether two `Signals` are the same :rtype: bool \"\"\" assert isinstance ( other , Signal ) # assert data are the same try : xr . testing . assert_allclose ( self . data , other . data ) eq = True except AssertionError : eq = False # check attributes, but if not equal, only warn the user for attr in self . _copy_attributes : if getattr ( self , attr ) != getattr ( other , attr ): logging . warning ( f \"` { attr } ` not equal between signals.\" ) return eq __finalize__ ( self , other , add_steps = None ) special Copy attrbutes from other to self. Used when constructing class instance with different data, but same metadata. Parameters: Name Type Description Default other `Signal` other instance of Signal required add_steps list|None add steps to preprocessing None Source code in neurolib/utils/signal.py def __finalize__ ( self , other , add_steps = None ): \"\"\" Copy attrbutes from other to self. Used when constructing class instance with different data, but same metadata. :param other: other instance of `Signal` :type other: `Signal` :param add_steps: add steps to preprocessing :type add_steps: list|None \"\"\" assert isinstance ( other , Signal ) for attr in self . _copy_attributes : setattr ( self , attr , deepcopy ( getattr ( other , attr ))) if add_steps is not None : self . process_steps += add_steps return self __getitem__ ( self , pos ) special Get item selectes in output dimension. Source code in neurolib/utils/signal.py def __getitem__ ( self , pos ): \"\"\" Get item selectes in output dimension. \"\"\" add_steps = [ f \"select ` { pos } ` output\" ] return self . __constructor__ ( self . data . sel ( output = pos )) . __finalize__ ( self , add_steps ) __init__ ( self , data , time_in_ms = False ) special Parameters: Name Type Description Default data xr.DataArray data for the signal, assumes time dimension with time in seconds required time_in_ms bool whether time dimension is in ms False Source code in neurolib/utils/signal.py def __init__ ( self , data , time_in_ms = False ): \"\"\" :param data: data for the signal, assumes time dimension with time in seconds :type data: xr.DataArray :param time_in_ms: whether time dimension is in ms :type time_in_ms: bool \"\"\" assert isinstance ( data , xr . DataArray ) data = deepcopy ( data ) assert \"time\" in data . dims , \"DataArray must have time axis\" if time_in_ms : data [ \"time\" ] = data [ \"time\" ] / 1000.0 data [ \"time\" ] = np . around ( data [ \"time\" ], 6 ) self . data = data # compute dt and sampling frequency self . dt = np . around ( np . diff ( data . time ) . mean (), 6 ) self . sampling_frequency = 1.0 / self . dt self . process_steps = list () __repr__ ( self ) special Representation. Source code in neurolib/utils/signal.py def __repr__ ( self ): \"\"\" Representation. \"\"\" return self . __str__ () __str__ ( self ) special String representation. Source code in neurolib/utils/signal.py def __str__ ( self ): \"\"\" String representation. \"\"\" return ( f \" { self . name } representing { self . signal_type } signal with unit of \" f \" { self . unit } with user-provided description: ` { self . description } `. \" f \"Shape of the signal is { self . shape } with dimensions { self . data . dims } .\" ) apply ( self , func , inplace = True ) Apply func for each timeseries. Parameters: Name Type Description Default func callable function to be applied for each 1D timeseries required inplace bool whether to do the operation in place or return True Source code in neurolib/utils/signal.py def apply ( self , func , inplace = True ): \"\"\" Apply func for each timeseries. :param func: function to be applied for each 1D timeseries :type func: callable :param inplace: whether to do the operation in place or return :type inplace: bool \"\"\" assert callable ( func ) try : # this will work for element-wise function that does not reduces dimensions processed = xr . apply_ufunc ( func , self . data , input_core_dims = [[ \"time\" ]], output_core_dims = [[ \"time\" ]]) add_steps = [ f \"apply ` { func . __name__ } ` function over time dim\" ] if inplace : self . data = processed self . process_steps += add_steps else : return self . __constructor__ ( processed ) . __finalize__ ( self , add_steps ) except ValueError : # this works for functions that reduce time dimension processed = xr . apply_ufunc ( func , self . data , input_core_dims = [[ \"time\" ]]) logging . warning ( f \"Shape changed after operation! Old shape: { self . shape } , new \" f \"shape: { processed . shape } ; Cannot cast to Signal class, \" \"returing as `xr.DataArray`\" ) return processed detrend ( self , segments = None , inplace = True ) Linearly detrend signal. If segments are given, detrending will be performed in each part. Parameters: Name Type Description Default segments list|None segments for detrening, if None will detrend whole signal, given as indices of the time array None inplace bool whether to do the operation in place or return True Source code in neurolib/utils/signal.py def detrend ( self , segments = None , inplace = True ): \"\"\" Linearly detrend signal. If segments are given, detrending will be performed in each part. :param segments: segments for detrening, if None will detrend whole signal, given as indices of the time array :type segments: list|None :param inplace: whether to do the operation in place or return :type inplace: bool \"\"\" segments = segments or 0 detrended = detrend ( self . data , type = \"linear\" , bp = segments , axis =- 1 ) detrended = xr . DataArray ( detrended , dims = self . data . dims , coords = self . data . coords ) segments_text = f \" with segments: { segments } \" if segments != 0 else \"\" add_steps = [ f \"detrend { segments_text } \" ] if inplace : self . data = detrended self . process_steps += add_steps else : return self . __constructor__ ( detrended ) . __finalize__ ( self , add_steps ) filter ( self , low_freq , high_freq , l_trans_bandwidth = 'auto' , h_trans_bandwidth = 'auto' , inplace = True , ** kwargs ) Filter data. Can be: low-pass (low_freq is None, high_freq is not None), high-pass (high_freq is None, low_freq is not None), band-pass (l_freq < h_freq), band-stop (l_freq > h_freq) filter type :**kwargs: possible keywords to mne.filter.create_filter : filter_length =\"auto\", method =\"fir\", iir_params =None phase =\"zero\", fir_window =\"hamming\", fir_design =\"firwin\" Parameters: Name Type Description Default low_freq float|None frequency below which to filter the data required high_freq float|None frequency above which to filter the data required l_trans_bandwidth float|str transition band width for low frequency 'auto' h_trans_bandwidth float|str transition band width for high frequency 'auto' inplace bool whether to do the operation in place or return True Source code in neurolib/utils/signal.py def filter ( self , low_freq , high_freq , l_trans_bandwidth = \"auto\" , h_trans_bandwidth = \"auto\" , inplace = True , ** kwargs , ): \"\"\" Filter data. Can be: low-pass (low_freq is None, high_freq is not None), high-pass (high_freq is None, low_freq is not None), band-pass (l_freq < h_freq), band-stop (l_freq > h_freq) filter type :param low_freq: frequency below which to filter the data :type low_freq: float|None :param high_freq: frequency above which to filter the data :type high_freq: float|None :param l_trans_bandwidth: transition band width for low frequency :type l_trans_bandwidth: float|str :param h_trans_bandwidth: transition band width for high frequency :type h_trans_bandwidth: float|str :param inplace: whether to do the operation in place or return :type inplace: bool :**kwargs: possible keywords to `mne.filter.create_filter`: `filter_length`=\"auto\", `method`=\"fir\", `iir_params`=None `phase`=\"zero\", `fir_window`=\"hamming\", `fir_design`=\"firwin\" \"\"\" try : from mne.filter import filter_data except ImportError : logging . warning ( \"`mne` module not found, falling back to basic scipy's function\" ) filter_data = scipy_iir_filter_data filtered = filter_data ( self . data . values , # times has to be the last axis sfreq = self . sampling_frequency , l_freq = low_freq , h_freq = high_freq , l_trans_bandwidth = l_trans_bandwidth , h_trans_bandwidth = h_trans_bandwidth , ** kwargs , ) add_steps = [ f \"filter: low { low_freq or 'x' } Hz - high { high_freq or 'x' } Hz\" ] # to dataframe filtered = xr . DataArray ( filtered , dims = self . data . dims , coords = self . data . coords ) if inplace : self . data = filtered self . process_steps += add_steps else : return self . __constructor__ ( filtered ) . __finalize__ ( self , add_steps ) from_file ( filename ) classmethod Load signal from saved file. Parameters: Name Type Description Default filename str filename for the Signal required Source code in neurolib/utils/signal.py @classmethod def from_file ( cls , filename ): \"\"\" Load signal from saved file. :param filename: filename for the Signal :type filename: str \"\"\" if not filename . endswith ( NC_EXT ): filename += NC_EXT # load NC file xarray = xr . load_dataarray ( filename ) # init class signal = cls ( xarray ) # if nc file has atrributes, copy them to signal class process_steps = [] if xarray . attrs : for k , v in xarray . attrs . items (): if cls . PROCESS_STEPS_KEY in k : idx = int ( k [ len ( cls . PROCESS_STEPS_KEY ) + 1 :]) process_steps . insert ( idx , v ) else : setattr ( signal , k , v ) if len ( process_steps ) > 0 : setattr ( signal , cls . PROCESS_STEPS_KEY , process_steps ) else : logging . warning ( \"No metadata found, setting empty...\" ) return signal from_model_output ( model , group = '' , time_in_ms = True ) classmethod Initial Signal from modelling output. Source code in neurolib/utils/signal.py @classmethod def from_model_output ( cls , model , group = \"\" , time_in_ms = True ): \"\"\" Initial Signal from modelling output. \"\"\" assert isinstance ( model , Model ) return cls ( model . xr ( group = group ), time_in_ms = time_in_ms ) functional_connectivity ( self , fc_function =< function corrcoef at 0x7f97869ed710 > ) Compute and return functional connectivity from the data. Parameters: Name Type Description Default fc_function function which to use for FC computation, should take 2D array as space x time and convert it to space x space with desired measure <function corrcoef at 0x7f97869ed710> Source code in neurolib/utils/signal.py def functional_connectivity ( self , fc_function = np . corrcoef ): \"\"\" Compute and return functional connectivity from the data. :param fc_function: function which to use for FC computation, should take 2D array as space x time and convert it to space x space with desired measure \"\"\" if len ( self . data [ \"space\" ]) <= 1 : logging . error ( \"Cannot compute functional connectivity from one timeseries.\" ) return None if self . data . ndim == 3 : assert callable ( fc_function ) fcs = [] for output in self . data [ \"output\" ]: current_slice = self . data . sel ({ \"output\" : output }) assert current_slice . ndim == 2 fcs . append ( fc_function ( current_slice . values )) return xr . DataArray ( np . array ( fcs ), dims = [ \"output\" , \"space\" , \"space\" ], coords = { \"output\" : self . data . coords [ \"output\" ], \"space\" : self . data . coords [ \"space\" ]}, ) if self . data . ndim == 2 : return xr . DataArray ( fc_function ( self . data . values ), dims = [ \"space\" , \"space\" ], coords = { \"space\" : self . data . coords [ \"space\" ]}, ) hilbert_transform ( self , return_as = 'complex' , inplace = True ) Perform hilbert transform on the signal resulting in analytic signal. Parameters: Name Type Description Default return_as what to return complex will compute only analytical signal amplitude will compute amplitude, hence abs(H(x)) phase_wrapped will compute phase, hence angle(H(x)), in -pi,pi phase_unwrapped will compute phase in a continuous sense, hence monotonic 'complex' inplace bool whether to do the operation in place or return True Source code in neurolib/utils/signal.py def hilbert_transform ( self , return_as = \"complex\" , inplace = True ): \"\"\" Perform hilbert transform on the signal resulting in analytic signal. :param return_as: what to return `complex` will compute only analytical signal `amplitude` will compute amplitude, hence abs(H(x)) `phase_wrapped` will compute phase, hence angle(H(x)), in -pi,pi `phase_unwrapped` will compute phase in a continuous sense, hence monotonic :param inplace: whether to do the operation in place or return :type inplace: bool \"\"\" analytic = hilbert ( self . data , axis =- 1 ) if return_as == \"amplitude\" : analytic = np . abs ( analytic ) add_steps = [ \"Hilbert - amplitude\" ] elif return_as == \"phase_unwrapped\" : analytic = np . unwrap ( np . angle ( analytic )) add_steps = [ \"Hilbert - unwrapped phase\" ] elif return_as == \"phase_wrapped\" : analytic = np . angle ( analytic ) add_steps = [ \"Hilbert - wrapped phase\" ] elif return_as == \"complex\" : add_steps = [ \"Hilbert - complex\" ] else : raise ValueError ( f \"Do not know how to return: { return_as } \" ) analytic = xr . DataArray ( analytic , dims = self . data . dims , coords = self . data . coords ) if inplace : self . data = analytic self . process_steps += add_steps else : return self . __constructor__ ( analytic ) . __finalize__ ( self , add_steps ) isel ( self , isel_args , inplace = True ) Subselect part of signal using pandas' isel , i.e. selecting by index, hence integers. Parameters: Name Type Description Default loc_args tuple|list arguments you'd give to df.lioc[], i.e. slice of indices you want to select, in seconds as a len=2 list or tuple required inplace bool whether to do the operation in place or return True Source code in neurolib/utils/signal.py def isel ( self , isel_args , inplace = True ): \"\"\" Subselect part of signal using pandas' `isel`, i.e. selecting by index, hence integers. :param loc_args: arguments you'd give to df.lioc[], i.e. slice of indices you want to select, in seconds as a len=2 list or tuple :type loc_args: tuple|list :param inplace: whether to do the operation in place or return :type inplace: bool \"\"\" assert len ( isel_args ) == 2 , \"Must provide 2 arguments\" selected = self . data . isel ( time = slice ( isel_args [ 0 ], isel_args [ 1 ])) start = isel_args [ 0 ] * self . dt if isel_args [ 0 ] is not None else \"x\" end = isel_args [ 1 ] * self . dt if isel_args [ 1 ] is not None else \"x\" add_steps = [ f \"select { start } : { end } s\" ] if inplace : self . data = selected self . process_steps += add_steps else : return self . __constructor__ ( selected ) . __finalize__ ( self , add_steps ) iterate ( self , return_as = 'signal' ) Return iterator over columns, so univariate measures can be computed per column. Loops over tuples as (variable name, timeseries). Parameters: Name Type Description Default return_as str how to return columns: xr as xr.DataArray, signal as instance of NeuroSignal with the same attributes as the mother signal 'signal' Source code in neurolib/utils/signal.py def iterate ( self , return_as = \"signal\" ): \"\"\" Return iterator over columns, so univariate measures can be computed per column. Loops over tuples as (variable name, timeseries). :param return_as: how to return columns: `xr` as xr.DataArray, `signal` as instance of NeuroSignal with the same attributes as the mother signal :type return_as: str \"\"\" if return_as == \"xr\" : yield from self . data . stack ({ \"all\" : self . dims_not_time }) . groupby ( \"all\" ) elif return_as == \"signal\" : for name , column in self . data . stack ({ \"all\" : self . dims_not_time }) . groupby ( \"all\" ): yield name , self . __constructor__ ( column ) . __finalize__ ( self , [ f \"select { column . name } \" ]) else : raise ValueError ( f \"Data type not understood: { return_as } \" ) normalize ( self , std = False , inplace = True ) De-mean the timeseries. Optionally also standardise. Parameters: Name Type Description Default std bool normalize by std, i.e. to unit variance False inplace bool whether to do the operation in place or return True Source code in neurolib/utils/signal.py def normalize ( self , std = False , inplace = True ): \"\"\" De-mean the timeseries. Optionally also standardise. :param std: normalize by std, i.e. to unit variance :type std: bool :param inplace: whether to do the operation in place or return :type inplace: bool \"\"\" def norm_func ( x , dim ): demeaned = x - x . mean ( dim = dim ) if std : return demeaned / x . std ( dim = dim ) else : return demeaned normalized = norm_func ( self . data , dim = \"time\" ) add_steps = [ \"normalize\" , \"standardize\" ] if std else [ \"normalize\" ] if inplace : self . data = normalized self . process_steps += add_steps else : return self . __constructor__ ( normalized ) . __finalize__ ( self , add_steps ) pad ( self , how_much , in_seconds = False , padding_type = 'constant' , side = 'both' , inplace = True , ** kwargs ) Pad signal by how_much on given side of given type. :kwargs: passed to np.pad Parameters: Name Type Description Default how_much float|int how much we should pad, can be time points, or seconds, see in_seconds required in_seconds bool whether how_much is in seconds, if False, it is number of time points False padding_type str how to pad the signal, see np.pad documentation 'constant' side str which side to pad - \"before\", \"after\", or \"both\" 'both' inplace bool whether to do the operation in place or return True Source code in neurolib/utils/signal.py def pad ( self , how_much , in_seconds = False , padding_type = \"constant\" , side = \"both\" , inplace = True , ** kwargs , ): \"\"\" Pad signal by `how_much` on given side of given type. :param how_much: how much we should pad, can be time points, or seconds, see `in_seconds` :type how_much: float|int :param in_seconds: whether `how_much` is in seconds, if False, it is number of time points :type in_seconds: bool :param padding_type: how to pad the signal, see `np.pad` documentation :type padding_type: str :param side: which side to pad - \"before\", \"after\", or \"both\" :type side: str :param inplace: whether to do the operation in place or return :type inplace: bool :kwargs: passed to `np.pad` \"\"\" if in_seconds : how_much = int ( np . around ( how_much / self . dt )) if side == \"before\" : pad_width = ( how_much , 0 ) pad_times = np . arange ( - how_much , 0 ) * self . dt + self . data . time . values [ 0 ] new_times = np . concatenate ([ pad_times , self . data . time . values ], axis = 0 ) elif side == \"after\" : pad_width = ( 0 , how_much ) pad_times = np . arange ( 1 , how_much + 1 ) * self . dt + self . data . time . values [ - 1 ] new_times = np . concatenate ([ self . data . time . values , pad_times ], axis = 0 ) elif side == \"both\" : pad_width = ( how_much , how_much ) pad_before = np . arange ( - how_much , 0 ) * self . dt + self . data . time . values [ 0 ] pad_after = np . arange ( 1 , how_much + 1 ) * self . dt + self . data . time . values [ - 1 ] new_times = np . concatenate ([ pad_before , self . data . time . values , pad_after ], axis = 0 ) side += \" sides\" else : raise ValueError ( f \"Unknown padding side: { side } \" ) # add padding for other axes than time - zeroes pad_width = [( 0 , 0 )] * len ( self . dims_not_time ) + [ pad_width ] padded = np . pad ( self . data . values , pad_width , mode = padding_type , ** kwargs ) # to dataframe padded = xr . DataArray ( padded , dims = self . data . dims , coords = { ** self . coords_not_time , \"time\" : new_times }) add_steps = [ f \" { how_much * self . dt } s { padding_type } { side } padding\" ] if inplace : self . data = padded self . process_steps += add_steps else : return self . __constructor__ ( padded ) . __finalize__ ( self , add_steps ) resample ( self , to_frequency , inplace = True ) Resample signal to target frequency. Parameters: Name Type Description Default to_frequency float target frequency of the signal, in Hz required inplace bool whether to do the operation in place or return True Source code in neurolib/utils/signal.py def resample ( self , to_frequency , inplace = True ): \"\"\" Resample signal to target frequency. :param to_frequency: target frequency of the signal, in Hz :type to_frequency: float :param inplace: whether to do the operation in place or return :type inplace: bool \"\"\" to_frequency = float ( to_frequency ) try : from mne.filter import resample resample_func = partial ( resample , up = to_frequency , down = self . sampling_frequency , npad = \"auto\" , axis =- 1 , pad = \"edge\" ) except ImportError : logging . warning ( \"`mne` module not found, falling back to basic scipy's function\" ) def resample_func ( x ): return scipy_resample ( x , num = int ( round (( to_frequency / self . sampling_frequency ) * self . data . shape [ - 1 ])), axis =- 1 , window = \"boxcar\" , ) resampled = resample_func ( self . data . values ) # construct new times new_times = ( np . arange ( resampled . shape [ - 1 ], dtype = np . float ) / to_frequency ) + self . data . time . values [ 0 ] # to dataframe resampled = xr . DataArray ( resampled , dims = self . data . dims , coords = { ** self . coords_not_time , \"time\" : new_times }) add_steps = [ f \"resample to { to_frequency } Hz\" ] if inplace : self . data = resampled self . sampling_frequency = to_frequency self . dt = np . around ( np . diff ( resampled . time ) . mean (), 6 ) self . process_steps += add_steps else : return self . __constructor__ ( resampled ) . __finalize__ ( self , add_steps ) save ( self , filename ) Save signal. Parameters: Name Type Description Default filename str filename to save, currently saves to netCDF file, which is natively supported by xarray required Source code in neurolib/utils/signal.py def save ( self , filename ): \"\"\" Save signal. :param filename: filename to save, currently saves to netCDF file, which is natively supported by xarray :type filename: str \"\"\" self . _write_attrs_to_xr () if not filename . endswith ( NC_EXT ): filename += NC_EXT self . data . to_netcdf ( filename ) sel ( self , sel_args , inplace = True ) Subselect part of signal using pandas' sel , i.e. selecting by actual physical index, hence time in seconds. Parameters: Name Type Description Default sel_args tuple|list arguments you'd give to df.sel[], i.e. slice of times you want to select, in seconds as a len=2 list or tuple required inplace bool whether to do the operation in place or return True Source code in neurolib/utils/signal.py def sel ( self , sel_args , inplace = True ): \"\"\" Subselect part of signal using pandas' `sel`, i.e. selecting by actual physical index, hence time in seconds. :param sel_args: arguments you'd give to df.sel[], i.e. slice of times you want to select, in seconds as a len=2 list or tuple :type sel_args: tuple|list :param inplace: whether to do the operation in place or return :type inplace: bool \"\"\" assert len ( sel_args ) == 2 , \"Must provide 2 arguments\" selected = self . data . sel ( time = slice ( sel_args [ 0 ], sel_args [ 1 ])) add_steps = [ f \"select { sel_args [ 0 ] or 'x' } : { sel_args [ 1 ] or 'x' } s\" ] if inplace : self . data = selected self . process_steps += add_steps else : return self . __constructor__ ( selected ) . __finalize__ ( self , add_steps ) sliding_window ( self , length , step = 1 , window_function = 'boxcar' , lengths_in_seconds = False ) Return iterator over sliding windows with windowing function applied. Each window has length length and each is translated by step steps. For no windowing function use \"boxcar\". If the last window would have the same length as other, it is omitted, i.e. last window does not have to end with the final timeseries point! :yield: generator with windowed Signals Parameters: Name Type Description Default length int|float length of the window, can be index or time in seconds, see lengths_in_seconds required step int|float how much to translate window in the temporal sense, can be index or time in seconds, see lengths_in_seconds 1 window_function str|tuple|float windowing function to use, this is passed to get_window() ; see scipy.signal.windows.get_window documentation 'boxcar' lengths_in_seconds bool if True, length and step are interpreted in seconds, if False they are indices False Source code in neurolib/utils/signal.py def sliding_window ( self , length , step = 1 , window_function = \"boxcar\" , lengths_in_seconds = False ): \"\"\" Return iterator over sliding windows with windowing function applied. Each window has length `length` and each is translated by `step` steps. For no windowing function use \"boxcar\". If the last window would have the same length as other, it is omitted, i.e. last window does not have to end with the final timeseries point! :param length: length of the window, can be index or time in seconds, see `lengths_in_seconds` :type length: int|float :param step: how much to translate window in the temporal sense, can be index or time in seconds, see `lengths_in_seconds` :type step: int|float :param window_function: windowing function to use, this is passed to `get_window()`; see `scipy.signal.windows.get_window` documentation :type window_function: str|tuple|float :param lengths_in_seconds: if True, `length` and `step` are interpreted in seconds, if False they are indices :type lengths_in_seconds: bool :yield: generator with windowed Signals \"\"\" if lengths_in_seconds : length = int ( length / self . dt ) step = int ( step / self . dt ) assert ( length < self . data . time . shape [ 0 ] ), f \"Length must be smaller than time span of the timeseries: { self . data . time . shape [ 0 ] } \" assert step <= length , \"Step cannot be larger than length, some part of timeseries would be omitted!\" current_idx = 0 add_steps = f \" { str ( window_function ) } window: \" windowing_function = get_window ( window_function , Nx = length ) while current_idx <= ( self . data . time . shape [ 0 ] - length ): yield self . __constructor__ ( self . data . isel ( time = slice ( current_idx , current_idx + length )) * windowing_function ) . __finalize__ ( self , [ add_steps + f \" { current_idx } : { current_idx + length } \" ]) current_idx += step","title":"Signal"},{"location":"utils/signal/#signal","text":"","title":"Signal"},{"location":"utils/signal/#neurolib.utils.signal.Signal.__constructor__","text":"Return constructor, so that each child class would initiate a new instance of the correct class, i.e. first in the method resolution order.","title":"__constructor__"},{"location":"utils/signal/#neurolib.utils.signal.Signal.coords_not_time","text":"Return dict with all coordinates except time.","title":"coords_not_time"},{"location":"utils/signal/#neurolib.utils.signal.Signal.dims_not_time","text":"Return list of dimensions that are not time.","title":"dims_not_time"},{"location":"utils/signal/#neurolib.utils.signal.Signal.end_time","text":"Return ending time of the signal.","title":"end_time"},{"location":"utils/signal/#neurolib.utils.signal.Signal.preprocessing_steps","text":"Return preprocessing steps done on the data.","title":"preprocessing_steps"},{"location":"utils/signal/#neurolib.utils.signal.Signal.shape","text":"Return shape of the data. Time axis is the first one.","title":"shape"},{"location":"utils/signal/#neurolib.utils.signal.Signal.start_time","text":"Return starting time of the signal.","title":"start_time"},{"location":"utils/signal/#neurolib.utils.signal.Signal.__eq__","text":"Comparison operator. Parameters: Name Type Description Default other `Signal` other Signal to compare with required Returns: Type Description bool whether two Signals are the same Source code in neurolib/utils/signal.py def __eq__ ( self , other ): \"\"\" Comparison operator. :param other: other `Signal` to compare with :type other: `Signal` :return: whether two `Signals` are the same :rtype: bool \"\"\" assert isinstance ( other , Signal ) # assert data are the same try : xr . testing . assert_allclose ( self . data , other . data ) eq = True except AssertionError : eq = False # check attributes, but if not equal, only warn the user for attr in self . _copy_attributes : if getattr ( self , attr ) != getattr ( other , attr ): logging . warning ( f \"` { attr } ` not equal between signals.\" ) return eq","title":"__eq__()"},{"location":"utils/signal/#neurolib.utils.signal.Signal.__finalize__","text":"Copy attrbutes from other to self. Used when constructing class instance with different data, but same metadata. Parameters: Name Type Description Default other `Signal` other instance of Signal required add_steps list|None add steps to preprocessing None Source code in neurolib/utils/signal.py def __finalize__ ( self , other , add_steps = None ): \"\"\" Copy attrbutes from other to self. Used when constructing class instance with different data, but same metadata. :param other: other instance of `Signal` :type other: `Signal` :param add_steps: add steps to preprocessing :type add_steps: list|None \"\"\" assert isinstance ( other , Signal ) for attr in self . _copy_attributes : setattr ( self , attr , deepcopy ( getattr ( other , attr ))) if add_steps is not None : self . process_steps += add_steps return self","title":"__finalize__()"},{"location":"utils/signal/#neurolib.utils.signal.Signal.__getitem__","text":"Get item selectes in output dimension. Source code in neurolib/utils/signal.py def __getitem__ ( self , pos ): \"\"\" Get item selectes in output dimension. \"\"\" add_steps = [ f \"select ` { pos } ` output\" ] return self . __constructor__ ( self . data . sel ( output = pos )) . __finalize__ ( self , add_steps )","title":"__getitem__()"},{"location":"utils/signal/#neurolib.utils.signal.Signal.__init__","text":"Parameters: Name Type Description Default data xr.DataArray data for the signal, assumes time dimension with time in seconds required time_in_ms bool whether time dimension is in ms False Source code in neurolib/utils/signal.py def __init__ ( self , data , time_in_ms = False ): \"\"\" :param data: data for the signal, assumes time dimension with time in seconds :type data: xr.DataArray :param time_in_ms: whether time dimension is in ms :type time_in_ms: bool \"\"\" assert isinstance ( data , xr . DataArray ) data = deepcopy ( data ) assert \"time\" in data . dims , \"DataArray must have time axis\" if time_in_ms : data [ \"time\" ] = data [ \"time\" ] / 1000.0 data [ \"time\" ] = np . around ( data [ \"time\" ], 6 ) self . data = data # compute dt and sampling frequency self . dt = np . around ( np . diff ( data . time ) . mean (), 6 ) self . sampling_frequency = 1.0 / self . dt self . process_steps = list ()","title":"__init__()"},{"location":"utils/signal/#neurolib.utils.signal.Signal.__repr__","text":"Representation. Source code in neurolib/utils/signal.py def __repr__ ( self ): \"\"\" Representation. \"\"\" return self . __str__ ()","title":"__repr__()"},{"location":"utils/signal/#neurolib.utils.signal.Signal.__str__","text":"String representation. Source code in neurolib/utils/signal.py def __str__ ( self ): \"\"\" String representation. \"\"\" return ( f \" { self . name } representing { self . signal_type } signal with unit of \" f \" { self . unit } with user-provided description: ` { self . description } `. \" f \"Shape of the signal is { self . shape } with dimensions { self . data . dims } .\" )","title":"__str__()"},{"location":"utils/signal/#neurolib.utils.signal.Signal.apply","text":"Apply func for each timeseries. Parameters: Name Type Description Default func callable function to be applied for each 1D timeseries required inplace bool whether to do the operation in place or return True Source code in neurolib/utils/signal.py def apply ( self , func , inplace = True ): \"\"\" Apply func for each timeseries. :param func: function to be applied for each 1D timeseries :type func: callable :param inplace: whether to do the operation in place or return :type inplace: bool \"\"\" assert callable ( func ) try : # this will work for element-wise function that does not reduces dimensions processed = xr . apply_ufunc ( func , self . data , input_core_dims = [[ \"time\" ]], output_core_dims = [[ \"time\" ]]) add_steps = [ f \"apply ` { func . __name__ } ` function over time dim\" ] if inplace : self . data = processed self . process_steps += add_steps else : return self . __constructor__ ( processed ) . __finalize__ ( self , add_steps ) except ValueError : # this works for functions that reduce time dimension processed = xr . apply_ufunc ( func , self . data , input_core_dims = [[ \"time\" ]]) logging . warning ( f \"Shape changed after operation! Old shape: { self . shape } , new \" f \"shape: { processed . shape } ; Cannot cast to Signal class, \" \"returing as `xr.DataArray`\" ) return processed","title":"apply()"},{"location":"utils/signal/#neurolib.utils.signal.Signal.detrend","text":"Linearly detrend signal. If segments are given, detrending will be performed in each part. Parameters: Name Type Description Default segments list|None segments for detrening, if None will detrend whole signal, given as indices of the time array None inplace bool whether to do the operation in place or return True Source code in neurolib/utils/signal.py def detrend ( self , segments = None , inplace = True ): \"\"\" Linearly detrend signal. If segments are given, detrending will be performed in each part. :param segments: segments for detrening, if None will detrend whole signal, given as indices of the time array :type segments: list|None :param inplace: whether to do the operation in place or return :type inplace: bool \"\"\" segments = segments or 0 detrended = detrend ( self . data , type = \"linear\" , bp = segments , axis =- 1 ) detrended = xr . DataArray ( detrended , dims = self . data . dims , coords = self . data . coords ) segments_text = f \" with segments: { segments } \" if segments != 0 else \"\" add_steps = [ f \"detrend { segments_text } \" ] if inplace : self . data = detrended self . process_steps += add_steps else : return self . __constructor__ ( detrended ) . __finalize__ ( self , add_steps )","title":"detrend()"},{"location":"utils/signal/#neurolib.utils.signal.Signal.filter","text":"Filter data. Can be: low-pass (low_freq is None, high_freq is not None), high-pass (high_freq is None, low_freq is not None), band-pass (l_freq < h_freq), band-stop (l_freq > h_freq) filter type :**kwargs: possible keywords to mne.filter.create_filter : filter_length =\"auto\", method =\"fir\", iir_params =None phase =\"zero\", fir_window =\"hamming\", fir_design =\"firwin\" Parameters: Name Type Description Default low_freq float|None frequency below which to filter the data required high_freq float|None frequency above which to filter the data required l_trans_bandwidth float|str transition band width for low frequency 'auto' h_trans_bandwidth float|str transition band width for high frequency 'auto' inplace bool whether to do the operation in place or return True Source code in neurolib/utils/signal.py def filter ( self , low_freq , high_freq , l_trans_bandwidth = \"auto\" , h_trans_bandwidth = \"auto\" , inplace = True , ** kwargs , ): \"\"\" Filter data. Can be: low-pass (low_freq is None, high_freq is not None), high-pass (high_freq is None, low_freq is not None), band-pass (l_freq < h_freq), band-stop (l_freq > h_freq) filter type :param low_freq: frequency below which to filter the data :type low_freq: float|None :param high_freq: frequency above which to filter the data :type high_freq: float|None :param l_trans_bandwidth: transition band width for low frequency :type l_trans_bandwidth: float|str :param h_trans_bandwidth: transition band width for high frequency :type h_trans_bandwidth: float|str :param inplace: whether to do the operation in place or return :type inplace: bool :**kwargs: possible keywords to `mne.filter.create_filter`: `filter_length`=\"auto\", `method`=\"fir\", `iir_params`=None `phase`=\"zero\", `fir_window`=\"hamming\", `fir_design`=\"firwin\" \"\"\" try : from mne.filter import filter_data except ImportError : logging . warning ( \"`mne` module not found, falling back to basic scipy's function\" ) filter_data = scipy_iir_filter_data filtered = filter_data ( self . data . values , # times has to be the last axis sfreq = self . sampling_frequency , l_freq = low_freq , h_freq = high_freq , l_trans_bandwidth = l_trans_bandwidth , h_trans_bandwidth = h_trans_bandwidth , ** kwargs , ) add_steps = [ f \"filter: low { low_freq or 'x' } Hz - high { high_freq or 'x' } Hz\" ] # to dataframe filtered = xr . DataArray ( filtered , dims = self . data . dims , coords = self . data . coords ) if inplace : self . data = filtered self . process_steps += add_steps else : return self . __constructor__ ( filtered ) . __finalize__ ( self , add_steps )","title":"filter()"},{"location":"utils/signal/#neurolib.utils.signal.Signal.from_file","text":"Load signal from saved file. Parameters: Name Type Description Default filename str filename for the Signal required Source code in neurolib/utils/signal.py @classmethod def from_file ( cls , filename ): \"\"\" Load signal from saved file. :param filename: filename for the Signal :type filename: str \"\"\" if not filename . endswith ( NC_EXT ): filename += NC_EXT # load NC file xarray = xr . load_dataarray ( filename ) # init class signal = cls ( xarray ) # if nc file has atrributes, copy them to signal class process_steps = [] if xarray . attrs : for k , v in xarray . attrs . items (): if cls . PROCESS_STEPS_KEY in k : idx = int ( k [ len ( cls . PROCESS_STEPS_KEY ) + 1 :]) process_steps . insert ( idx , v ) else : setattr ( signal , k , v ) if len ( process_steps ) > 0 : setattr ( signal , cls . PROCESS_STEPS_KEY , process_steps ) else : logging . warning ( \"No metadata found, setting empty...\" ) return signal","title":"from_file()"},{"location":"utils/signal/#neurolib.utils.signal.Signal.from_model_output","text":"Initial Signal from modelling output. Source code in neurolib/utils/signal.py @classmethod def from_model_output ( cls , model , group = \"\" , time_in_ms = True ): \"\"\" Initial Signal from modelling output. \"\"\" assert isinstance ( model , Model ) return cls ( model . xr ( group = group ), time_in_ms = time_in_ms )","title":"from_model_output()"},{"location":"utils/signal/#neurolib.utils.signal.Signal.functional_connectivity","text":"Compute and return functional connectivity from the data. Parameters: Name Type Description Default fc_function function which to use for FC computation, should take 2D array as space x time and convert it to space x space with desired measure <function corrcoef at 0x7f97869ed710> Source code in neurolib/utils/signal.py def functional_connectivity ( self , fc_function = np . corrcoef ): \"\"\" Compute and return functional connectivity from the data. :param fc_function: function which to use for FC computation, should take 2D array as space x time and convert it to space x space with desired measure \"\"\" if len ( self . data [ \"space\" ]) <= 1 : logging . error ( \"Cannot compute functional connectivity from one timeseries.\" ) return None if self . data . ndim == 3 : assert callable ( fc_function ) fcs = [] for output in self . data [ \"output\" ]: current_slice = self . data . sel ({ \"output\" : output }) assert current_slice . ndim == 2 fcs . append ( fc_function ( current_slice . values )) return xr . DataArray ( np . array ( fcs ), dims = [ \"output\" , \"space\" , \"space\" ], coords = { \"output\" : self . data . coords [ \"output\" ], \"space\" : self . data . coords [ \"space\" ]}, ) if self . data . ndim == 2 : return xr . DataArray ( fc_function ( self . data . values ), dims = [ \"space\" , \"space\" ], coords = { \"space\" : self . data . coords [ \"space\" ]}, )","title":"functional_connectivity()"},{"location":"utils/signal/#neurolib.utils.signal.Signal.hilbert_transform","text":"Perform hilbert transform on the signal resulting in analytic signal. Parameters: Name Type Description Default return_as what to return complex will compute only analytical signal amplitude will compute amplitude, hence abs(H(x)) phase_wrapped will compute phase, hence angle(H(x)), in -pi,pi phase_unwrapped will compute phase in a continuous sense, hence monotonic 'complex' inplace bool whether to do the operation in place or return True Source code in neurolib/utils/signal.py def hilbert_transform ( self , return_as = \"complex\" , inplace = True ): \"\"\" Perform hilbert transform on the signal resulting in analytic signal. :param return_as: what to return `complex` will compute only analytical signal `amplitude` will compute amplitude, hence abs(H(x)) `phase_wrapped` will compute phase, hence angle(H(x)), in -pi,pi `phase_unwrapped` will compute phase in a continuous sense, hence monotonic :param inplace: whether to do the operation in place or return :type inplace: bool \"\"\" analytic = hilbert ( self . data , axis =- 1 ) if return_as == \"amplitude\" : analytic = np . abs ( analytic ) add_steps = [ \"Hilbert - amplitude\" ] elif return_as == \"phase_unwrapped\" : analytic = np . unwrap ( np . angle ( analytic )) add_steps = [ \"Hilbert - unwrapped phase\" ] elif return_as == \"phase_wrapped\" : analytic = np . angle ( analytic ) add_steps = [ \"Hilbert - wrapped phase\" ] elif return_as == \"complex\" : add_steps = [ \"Hilbert - complex\" ] else : raise ValueError ( f \"Do not know how to return: { return_as } \" ) analytic = xr . DataArray ( analytic , dims = self . data . dims , coords = self . data . coords ) if inplace : self . data = analytic self . process_steps += add_steps else : return self . __constructor__ ( analytic ) . __finalize__ ( self , add_steps )","title":"hilbert_transform()"},{"location":"utils/signal/#neurolib.utils.signal.Signal.isel","text":"Subselect part of signal using pandas' isel , i.e. selecting by index, hence integers. Parameters: Name Type Description Default loc_args tuple|list arguments you'd give to df.lioc[], i.e. slice of indices you want to select, in seconds as a len=2 list or tuple required inplace bool whether to do the operation in place or return True Source code in neurolib/utils/signal.py def isel ( self , isel_args , inplace = True ): \"\"\" Subselect part of signal using pandas' `isel`, i.e. selecting by index, hence integers. :param loc_args: arguments you'd give to df.lioc[], i.e. slice of indices you want to select, in seconds as a len=2 list or tuple :type loc_args: tuple|list :param inplace: whether to do the operation in place or return :type inplace: bool \"\"\" assert len ( isel_args ) == 2 , \"Must provide 2 arguments\" selected = self . data . isel ( time = slice ( isel_args [ 0 ], isel_args [ 1 ])) start = isel_args [ 0 ] * self . dt if isel_args [ 0 ] is not None else \"x\" end = isel_args [ 1 ] * self . dt if isel_args [ 1 ] is not None else \"x\" add_steps = [ f \"select { start } : { end } s\" ] if inplace : self . data = selected self . process_steps += add_steps else : return self . __constructor__ ( selected ) . __finalize__ ( self , add_steps )","title":"isel()"},{"location":"utils/signal/#neurolib.utils.signal.Signal.iterate","text":"Return iterator over columns, so univariate measures can be computed per column. Loops over tuples as (variable name, timeseries). Parameters: Name Type Description Default return_as str how to return columns: xr as xr.DataArray, signal as instance of NeuroSignal with the same attributes as the mother signal 'signal' Source code in neurolib/utils/signal.py def iterate ( self , return_as = \"signal\" ): \"\"\" Return iterator over columns, so univariate measures can be computed per column. Loops over tuples as (variable name, timeseries). :param return_as: how to return columns: `xr` as xr.DataArray, `signal` as instance of NeuroSignal with the same attributes as the mother signal :type return_as: str \"\"\" if return_as == \"xr\" : yield from self . data . stack ({ \"all\" : self . dims_not_time }) . groupby ( \"all\" ) elif return_as == \"signal\" : for name , column in self . data . stack ({ \"all\" : self . dims_not_time }) . groupby ( \"all\" ): yield name , self . __constructor__ ( column ) . __finalize__ ( self , [ f \"select { column . name } \" ]) else : raise ValueError ( f \"Data type not understood: { return_as } \" )","title":"iterate()"},{"location":"utils/signal/#neurolib.utils.signal.Signal.normalize","text":"De-mean the timeseries. Optionally also standardise. Parameters: Name Type Description Default std bool normalize by std, i.e. to unit variance False inplace bool whether to do the operation in place or return True Source code in neurolib/utils/signal.py def normalize ( self , std = False , inplace = True ): \"\"\" De-mean the timeseries. Optionally also standardise. :param std: normalize by std, i.e. to unit variance :type std: bool :param inplace: whether to do the operation in place or return :type inplace: bool \"\"\" def norm_func ( x , dim ): demeaned = x - x . mean ( dim = dim ) if std : return demeaned / x . std ( dim = dim ) else : return demeaned normalized = norm_func ( self . data , dim = \"time\" ) add_steps = [ \"normalize\" , \"standardize\" ] if std else [ \"normalize\" ] if inplace : self . data = normalized self . process_steps += add_steps else : return self . __constructor__ ( normalized ) . __finalize__ ( self , add_steps )","title":"normalize()"},{"location":"utils/signal/#neurolib.utils.signal.Signal.pad","text":"Pad signal by how_much on given side of given type. :kwargs: passed to np.pad Parameters: Name Type Description Default how_much float|int how much we should pad, can be time points, or seconds, see in_seconds required in_seconds bool whether how_much is in seconds, if False, it is number of time points False padding_type str how to pad the signal, see np.pad documentation 'constant' side str which side to pad - \"before\", \"after\", or \"both\" 'both' inplace bool whether to do the operation in place or return True Source code in neurolib/utils/signal.py def pad ( self , how_much , in_seconds = False , padding_type = \"constant\" , side = \"both\" , inplace = True , ** kwargs , ): \"\"\" Pad signal by `how_much` on given side of given type. :param how_much: how much we should pad, can be time points, or seconds, see `in_seconds` :type how_much: float|int :param in_seconds: whether `how_much` is in seconds, if False, it is number of time points :type in_seconds: bool :param padding_type: how to pad the signal, see `np.pad` documentation :type padding_type: str :param side: which side to pad - \"before\", \"after\", or \"both\" :type side: str :param inplace: whether to do the operation in place or return :type inplace: bool :kwargs: passed to `np.pad` \"\"\" if in_seconds : how_much = int ( np . around ( how_much / self . dt )) if side == \"before\" : pad_width = ( how_much , 0 ) pad_times = np . arange ( - how_much , 0 ) * self . dt + self . data . time . values [ 0 ] new_times = np . concatenate ([ pad_times , self . data . time . values ], axis = 0 ) elif side == \"after\" : pad_width = ( 0 , how_much ) pad_times = np . arange ( 1 , how_much + 1 ) * self . dt + self . data . time . values [ - 1 ] new_times = np . concatenate ([ self . data . time . values , pad_times ], axis = 0 ) elif side == \"both\" : pad_width = ( how_much , how_much ) pad_before = np . arange ( - how_much , 0 ) * self . dt + self . data . time . values [ 0 ] pad_after = np . arange ( 1 , how_much + 1 ) * self . dt + self . data . time . values [ - 1 ] new_times = np . concatenate ([ pad_before , self . data . time . values , pad_after ], axis = 0 ) side += \" sides\" else : raise ValueError ( f \"Unknown padding side: { side } \" ) # add padding for other axes than time - zeroes pad_width = [( 0 , 0 )] * len ( self . dims_not_time ) + [ pad_width ] padded = np . pad ( self . data . values , pad_width , mode = padding_type , ** kwargs ) # to dataframe padded = xr . DataArray ( padded , dims = self . data . dims , coords = { ** self . coords_not_time , \"time\" : new_times }) add_steps = [ f \" { how_much * self . dt } s { padding_type } { side } padding\" ] if inplace : self . data = padded self . process_steps += add_steps else : return self . __constructor__ ( padded ) . __finalize__ ( self , add_steps )","title":"pad()"},{"location":"utils/signal/#neurolib.utils.signal.Signal.resample","text":"Resample signal to target frequency. Parameters: Name Type Description Default to_frequency float target frequency of the signal, in Hz required inplace bool whether to do the operation in place or return True Source code in neurolib/utils/signal.py def resample ( self , to_frequency , inplace = True ): \"\"\" Resample signal to target frequency. :param to_frequency: target frequency of the signal, in Hz :type to_frequency: float :param inplace: whether to do the operation in place or return :type inplace: bool \"\"\" to_frequency = float ( to_frequency ) try : from mne.filter import resample resample_func = partial ( resample , up = to_frequency , down = self . sampling_frequency , npad = \"auto\" , axis =- 1 , pad = \"edge\" ) except ImportError : logging . warning ( \"`mne` module not found, falling back to basic scipy's function\" ) def resample_func ( x ): return scipy_resample ( x , num = int ( round (( to_frequency / self . sampling_frequency ) * self . data . shape [ - 1 ])), axis =- 1 , window = \"boxcar\" , ) resampled = resample_func ( self . data . values ) # construct new times new_times = ( np . arange ( resampled . shape [ - 1 ], dtype = np . float ) / to_frequency ) + self . data . time . values [ 0 ] # to dataframe resampled = xr . DataArray ( resampled , dims = self . data . dims , coords = { ** self . coords_not_time , \"time\" : new_times }) add_steps = [ f \"resample to { to_frequency } Hz\" ] if inplace : self . data = resampled self . sampling_frequency = to_frequency self . dt = np . around ( np . diff ( resampled . time ) . mean (), 6 ) self . process_steps += add_steps else : return self . __constructor__ ( resampled ) . __finalize__ ( self , add_steps )","title":"resample()"},{"location":"utils/signal/#neurolib.utils.signal.Signal.save","text":"Save signal. Parameters: Name Type Description Default filename str filename to save, currently saves to netCDF file, which is natively supported by xarray required Source code in neurolib/utils/signal.py def save ( self , filename ): \"\"\" Save signal. :param filename: filename to save, currently saves to netCDF file, which is natively supported by xarray :type filename: str \"\"\" self . _write_attrs_to_xr () if not filename . endswith ( NC_EXT ): filename += NC_EXT self . data . to_netcdf ( filename )","title":"save()"},{"location":"utils/signal/#neurolib.utils.signal.Signal.sel","text":"Subselect part of signal using pandas' sel , i.e. selecting by actual physical index, hence time in seconds. Parameters: Name Type Description Default sel_args tuple|list arguments you'd give to df.sel[], i.e. slice of times you want to select, in seconds as a len=2 list or tuple required inplace bool whether to do the operation in place or return True Source code in neurolib/utils/signal.py def sel ( self , sel_args , inplace = True ): \"\"\" Subselect part of signal using pandas' `sel`, i.e. selecting by actual physical index, hence time in seconds. :param sel_args: arguments you'd give to df.sel[], i.e. slice of times you want to select, in seconds as a len=2 list or tuple :type sel_args: tuple|list :param inplace: whether to do the operation in place or return :type inplace: bool \"\"\" assert len ( sel_args ) == 2 , \"Must provide 2 arguments\" selected = self . data . sel ( time = slice ( sel_args [ 0 ], sel_args [ 1 ])) add_steps = [ f \"select { sel_args [ 0 ] or 'x' } : { sel_args [ 1 ] or 'x' } s\" ] if inplace : self . data = selected self . process_steps += add_steps else : return self . __constructor__ ( selected ) . __finalize__ ( self , add_steps )","title":"sel()"},{"location":"utils/signal/#neurolib.utils.signal.Signal.sliding_window","text":"Return iterator over sliding windows with windowing function applied. Each window has length length and each is translated by step steps. For no windowing function use \"boxcar\". If the last window would have the same length as other, it is omitted, i.e. last window does not have to end with the final timeseries point! :yield: generator with windowed Signals Parameters: Name Type Description Default length int|float length of the window, can be index or time in seconds, see lengths_in_seconds required step int|float how much to translate window in the temporal sense, can be index or time in seconds, see lengths_in_seconds 1 window_function str|tuple|float windowing function to use, this is passed to get_window() ; see scipy.signal.windows.get_window documentation 'boxcar' lengths_in_seconds bool if True, length and step are interpreted in seconds, if False they are indices False Source code in neurolib/utils/signal.py def sliding_window ( self , length , step = 1 , window_function = \"boxcar\" , lengths_in_seconds = False ): \"\"\" Return iterator over sliding windows with windowing function applied. Each window has length `length` and each is translated by `step` steps. For no windowing function use \"boxcar\". If the last window would have the same length as other, it is omitted, i.e. last window does not have to end with the final timeseries point! :param length: length of the window, can be index or time in seconds, see `lengths_in_seconds` :type length: int|float :param step: how much to translate window in the temporal sense, can be index or time in seconds, see `lengths_in_seconds` :type step: int|float :param window_function: windowing function to use, this is passed to `get_window()`; see `scipy.signal.windows.get_window` documentation :type window_function: str|tuple|float :param lengths_in_seconds: if True, `length` and `step` are interpreted in seconds, if False they are indices :type lengths_in_seconds: bool :yield: generator with windowed Signals \"\"\" if lengths_in_seconds : length = int ( length / self . dt ) step = int ( step / self . dt ) assert ( length < self . data . time . shape [ 0 ] ), f \"Length must be smaller than time span of the timeseries: { self . data . time . shape [ 0 ] } \" assert step <= length , \"Step cannot be larger than length, some part of timeseries would be omitted!\" current_idx = 0 add_steps = f \" { str ( window_function ) } window: \" windowing_function = get_window ( window_function , Nx = length ) while current_idx <= ( self . data . time . shape [ 0 ] - length ): yield self . __constructor__ ( self . data . isel ( time = slice ( current_idx , current_idx + length )) * windowing_function ) . __finalize__ ( self , [ add_steps + f \" { current_idx } : { current_idx + length } \" ]) current_idx += step","title":"sliding_window()"},{"location":"utils/stimulus/","text":"Stimulus Functions for creating stimuli and noise inputs for models. ConcatenatedInput Represents concatenation of inputs - typically for stimulus plus noise. Supports concatenation of arbitrary many objects. __init__ ( self , noise_processes ) special Parameters: Name Type Description Default noise_processes list[`ModelInput`] list of noise/stimulation processes to concatinate required Source code in neurolib/utils/stimulus.py def __init__ ( self , noise_processes ): \"\"\" :param noise_processes: list of noise/stimulation processes to concatinate :type noise_processes: list[`ModelInput`] \"\"\" assert all ( isinstance ( process , ModelInput ) for process in noise_processes ) self . noise_processes = noise_processes as_array ( self , duration , dt ) Return sum of all processes as numpy array. Source code in neurolib/utils/stimulus.py def as_array ( self , duration , dt ): \"\"\" Return sum of all processes as numpy array. \"\"\" return np . sum ( np . stack ([ process . as_array ( duration , dt ) for process in self . noise_processes ]), axis = 0 , ) as_cubic_splines ( self , duration , dt ) Return sum of all processes as cubic Hermite splines. Source code in neurolib/utils/stimulus.py def as_cubic_splines ( self , duration , dt ): \"\"\" Return sum of all processes as cubic Hermite splines. \"\"\" result = self . noise_processes [ 0 ] . as_cubic_splines ( duration , dt ) for process in self . noise_processes [ 1 :]: result . plus ( process . as_cubic_splines ( duration , dt )) return result get_params ( self ) Get parameters recursively from all input processes. Source code in neurolib/utils/stimulus.py def get_params ( self ): \"\"\" Get parameters recursively from all input processes. \"\"\" return { \"type\" : self . __class__ . __name__ , ** { f \"noise_ { i } \" : process . get_params () for i , process in enumerate ( self . noise_processes )}, } update_params ( self , params_dict ) Update all parameters recursively. Source code in neurolib/utils/stimulus.py def update_params ( self , params_dict ): \"\"\" Update all parameters recursively. \"\"\" for i , process in enumerate ( self . noise_processes ): process . update_params ( params_dict . get ( f \"noise_ { i } \" , {})) ExponentialInput Exponential rise or decay input. __init__ ( self , inp_max , exp_coef = 30.0 , exp_type = 'rise' , stim_start = None , stim_end = None , num_iid = 1 , seed = None ) special Parameters: Name Type Description Default inp_max float maximum of stimulus required exp_coeficient float coeffiecent for exponential, the higher the coefficient is, the faster it rises or decays required exp_type str whether its rise or decay 'rise' Source code in neurolib/utils/stimulus.py def __init__ ( self , inp_max , exp_coef = 30.0 , exp_type = \"rise\" , stim_start = None , stim_end = None , num_iid = 1 , seed = None , ): \"\"\" :param inp_max: maximum of stimulus :type inp_max: float :param exp_coeficient: coeffiecent for exponential, the higher the coefficient is, the faster it rises or decays :type exp_coeficient: float :param exp_type: whether its rise or decay :type exp_type: str \"\"\" self . inp_max = inp_max self . exp_coef = exp_coef assert exp_type in [ \"rise\" , \"decay\" ] self . exp_type = exp_type super () . __init__ ( stim_start = stim_start , stim_end = stim_end , num_iid = num_iid , seed = seed , ) generate_input ( self , duration , dt ) Function to generate input. Parameters: Name Type Description Default duration float duration of the input, in miliseconds required dt float dt of input, in miliseconds required Source code in neurolib/utils/stimulus.py def generate_input ( self , duration , dt ): self . _get_times ( duration = duration , dt = dt ) exponential = np . exp ( - ( self . exp_coef / self . times [ - 1 ]) * self . times ) * self . inp_max if self . exp_type == \"rise\" : exponential = - exponential + self . inp_max return self . _trim_stim_input ( np . vstack ([ exponential ] * self . num_iid ) . T ) LinearRampInput Linear ramp input. __init__ ( self , inp_max , ramp_length , stim_start = None , stim_end = None , num_iid = 1 , seed = None ) special Parameters: Name Type Description Default inp_max float maximum of stimulus required ramp_length float length of linear ramp, in miliseconds required Source code in neurolib/utils/stimulus.py def __init__ ( self , inp_max , ramp_length , stim_start = None , stim_end = None , num_iid = 1 , seed = None , ): \"\"\" :param inp_max: maximum of stimulus :type inp_max: float :param ramp_length: length of linear ramp, in miliseconds :type ramp_length: float \"\"\" self . inp_max = inp_max self . ramp_length = ramp_length super () . __init__ ( stim_start = stim_start , stim_end = stim_end , num_iid = num_iid , seed = seed , ) generate_input ( self , duration , dt ) Function to generate input. Parameters: Name Type Description Default duration float duration of the input, in miliseconds required dt float dt of input, in miliseconds required Source code in neurolib/utils/stimulus.py def generate_input ( self , duration , dt ): self . _get_times ( duration = duration , dt = dt ) # need to adjust times for stimulus start times = self . times - self . stim_start linear_inp = ( self . inp_max / self . ramp_length ) * times * ( times < self . ramp_length ) + self . inp_max * ( times >= self . ramp_length ) return self . _trim_stim_input ( np . vstack ([ linear_inp ] * self . num_iid ) . T ) ModelInput Generates input to model. Base class for other input types. __add__ ( self , other ) special Concatenate two processes. Source code in neurolib/utils/stimulus.py def __add__ ( self , other ): \"\"\" Concatenate two processes. \"\"\" assert isinstance ( other , ModelInput ) assert self . num_iid == other . num_iid if isinstance ( other , ConcatenatedInput ): return ConcatenatedInput ( noise_processes = [ self ] + other . noise_processes ) else : return ConcatenatedInput ( noise_processes = [ self , other ]) __init__ ( self , num_iid = 1 , seed = None ) special Parameters: Name Type Description Default num_iid int how many independent realisation of the input we want - for constant inputs the array is just copied, for noise this means independent realisation 1 seed int|None optional seed for noise generator None Source code in neurolib/utils/stimulus.py def __init__ ( self , num_iid = 1 , seed = None ): \"\"\" :param num_iid: how many independent realisation of the input we want - for constant inputs the array is just copied, for noise this means independent realisation :type num_iid: int :param seed: optional seed for noise generator :type seed: int|None \"\"\" self . num_iid = num_iid self . seed = seed # seed the generator np . random . seed ( seed ) # get parameter names self . param_names = inspect . getfullargspec ( self . __init__ ) . args self . param_names . remove ( \"self\" ) as_array ( self , duration , dt ) Return input as numpy array. Parameters: Name Type Description Default duration float duration of the input, in miliseconds required dt float some reasonable \"speed\" of input, in miliseconds required Source code in neurolib/utils/stimulus.py def as_array ( self , duration , dt ): \"\"\" Return input as numpy array. :param duration: duration of the input, in miliseconds :type duration: float :param dt: some reasonable \"speed\" of input, in miliseconds :type dt: float \"\"\" return self . generate_input ( duration , dt ) as_cubic_splines ( self , duration , dt ) Return as cubic Hermite splines. Parameters: Name Type Description Default duration float duration of the input, in miliseconds required dt float some reasonable \"speed\" of input, in miliseconds required Source code in neurolib/utils/stimulus.py def as_cubic_splines ( self , duration , dt ): \"\"\" Return as cubic Hermite splines. :param duration: duration of the input, in miliseconds :type duration: float :param dt: some reasonable \"speed\" of input, in miliseconds :type dt: float \"\"\" self . _get_times ( duration , dt ) return CubicHermiteSpline . from_data ( self . times , self . generate_input ( duration , dt )) generate_input ( self , duration , dt ) Function to generate input. Parameters: Name Type Description Default duration float duration of the input, in miliseconds required dt float dt of input, in miliseconds required Source code in neurolib/utils/stimulus.py def generate_input ( self , duration , dt ): \"\"\" Function to generate input. :param duration: duration of the input, in miliseconds :type duration: float :param dt: dt of input, in miliseconds :type dt: float \"\"\" raise NotImplementedError get_params ( self ) Return model input parameters as dict. Source code in neurolib/utils/stimulus.py def get_params ( self ): \"\"\" Return model input parameters as dict. \"\"\" assert all ( hasattr ( self , name ) for name in self . param_names ), self . param_names params = { name : getattr ( self , name ) for name in self . param_names } return { \"type\" : self . __class__ . __name__ , ** params } update_params ( self , params_dict ) Update model input parameters. Parameters: Name Type Description Default params_dict dict new parameters for this model input required Source code in neurolib/utils/stimulus.py def update_params ( self , params_dict ): \"\"\" Update model input parameters. :param params_dict: new parameters for this model input :type params_dict: dict \"\"\" for param , value in params_dict . items (): if hasattr ( self , param ): setattr ( self , param , value ) OrnsteinUhlenbeckProcess Ornstein\u2013Uhlenbeck process, i.e. dX = (mu - X)/tau * dt + sigma*dW __init__ ( self , mu , sigma , tau , num_iid = 1 , seed = None ) special Parameters: Name Type Description Default mu float drift of the O-U process required sigma float scale of the Wiener process required tau float O-U process timescale, same unit as time required Source code in neurolib/utils/stimulus.py def __init__ ( self , mu , sigma , tau , num_iid = 1 , seed = None , ): \"\"\" :param mu: drift of the O-U process :type mu: float :param sigma: scale of the Wiener process :type sigma: float :param tau: O-U process timescale, same unit as time :type tau: float \"\"\" self . mu = mu self . sigma = sigma self . tau = tau super () . __init__ ( num_iid = num_iid , seed = seed , ) generate_input ( self , duration , dt ) Function to generate input. Parameters: Name Type Description Default duration float duration of the input, in miliseconds required dt float dt of input, in miliseconds required Source code in neurolib/utils/stimulus.py def generate_input ( self , duration , dt ): self . _get_times ( duration = duration , dt = dt ) x = np . random . rand ( self . times . shape [ 0 ], self . num_iid ) * self . mu return self . numba_ou ( x , self . times , dt , self . mu , self . sigma , self . tau , self . num_iid ) numba_ou ( x , times , dt , mu , sigma , tau , num_iid ) staticmethod Generation of Ornstein-Uhlenback process - wrapped in numba's jit for speed. Source code in neurolib/utils/stimulus.py @staticmethod @numba . njit () def numba_ou ( x , times , dt , mu , sigma , tau , num_iid ): \"\"\" Generation of Ornstein-Uhlenback process - wrapped in numba's jit for speed. \"\"\" for i in range ( times . shape [ 0 ] - 1 ): x [ i + 1 , :] = x [ i , :] + dt * (( mu - x [ i , :]) / tau ) + sigma * np . sqrt ( dt ) * np . random . randn ( num_iid ) return x SinusoidalInput Sinusoidal input. __init__ ( self , amplitude , period , nonnegative = True , stim_start = None , stim_end = None , num_iid = 1 , seed = None ) special Parameters: Name Type Description Default amplitude float amplitude of the sinusoid required period float period of the sinusoid, in miliseconds required nonnegative bool whether the sinusoid oscillates around 0 point (False), or around its amplitude, thus is nonnegative (True) True Source code in neurolib/utils/stimulus.py def __init__ ( self , amplitude , period , nonnegative = True , stim_start = None , stim_end = None , num_iid = 1 , seed = None , ): \"\"\" :param amplitude: amplitude of the sinusoid :type amplitude: float :param period: period of the sinusoid, in miliseconds :type period: float :param nonnegative: whether the sinusoid oscillates around 0 point (False), or around its amplitude, thus is nonnegative (True) :type nonnegative: bool \"\"\" self . amplitude = amplitude self . period = period self . nonnegative = nonnegative super () . __init__ ( stim_start = stim_start , stim_end = stim_end , num_iid = num_iid , seed = seed , ) generate_input ( self , duration , dt ) Function to generate input. Parameters: Name Type Description Default duration float duration of the input, in miliseconds required dt float dt of input, in miliseconds required Source code in neurolib/utils/stimulus.py def generate_input ( self , duration , dt ): self . _get_times ( duration = duration , dt = dt ) sinusoid = self . amplitude * np . sin ( 2 * np . pi * self . times * ( 1.0 / self . period )) if self . nonnegative : sinusoid += self . amplitude return self . _trim_stim_input ( np . vstack ([ sinusoid ] * self . num_iid ) . T ) SquareInput Square input. __init__ ( self , amplitude , period , nonnegative = True , stim_start = None , stim_end = None , num_iid = 1 , seed = None ) special Parameters: Name Type Description Default amplitude float amplitude of the square required period float period of the square, in miliseconds required nonnegative bool whether the square oscillates around 0 point (False), or around its amplitude, thus is nonnegative (True) True Source code in neurolib/utils/stimulus.py def __init__ ( self , amplitude , period , nonnegative = True , stim_start = None , stim_end = None , num_iid = 1 , seed = None , ): \"\"\" :param amplitude: amplitude of the square :type amplitude: float :param period: period of the square, in miliseconds :type period: float :param nonnegative: whether the square oscillates around 0 point (False), or around its amplitude, thus is nonnegative (True) :type nonnegative: bool \"\"\" self . amplitude = amplitude self . period = period self . nonnegative = nonnegative super () . __init__ ( stim_start = stim_start , stim_end = stim_end , num_iid = num_iid , seed = seed , ) generate_input ( self , duration , dt ) Function to generate input. Parameters: Name Type Description Default duration float duration of the input, in miliseconds required dt float dt of input, in miliseconds required Source code in neurolib/utils/stimulus.py def generate_input ( self , duration , dt ): self . _get_times ( duration = duration , dt = dt ) square_inp = self . amplitude * square ( 2 * np . pi * self . times * ( 1.0 / self . period )) if self . nonnegative : square_inp += self . amplitude return self . _trim_stim_input ( np . vstack ([ square_inp ] * self . num_iid ) . T ) StepInput Basic step process. __init__ ( self , step_size , stim_start = None , stim_end = None , num_iid = 1 , seed = None ) special Parameters: Name Type Description Default step_size float size of the stimulus required Source code in neurolib/utils/stimulus.py def __init__ ( self , step_size , stim_start = None , stim_end = None , num_iid = 1 , seed = None , ): \"\"\" :param step_size: size of the stimulus :type step_size: float \"\"\" self . step_size = step_size super () . __init__ ( stim_start = stim_start , stim_end = stim_end , num_iid = num_iid , seed = seed , ) generate_input ( self , duration , dt ) Function to generate input. Parameters: Name Type Description Default duration float duration of the input, in miliseconds required dt float dt of input, in miliseconds required Source code in neurolib/utils/stimulus.py def generate_input ( self , duration , dt ): self . _get_times ( duration = duration , dt = dt ) return self . _trim_stim_input ( np . ones (( self . times . shape [ 0 ], self . num_iid )) * self . step_size ) StimulusInput Generates stimulus input with optional start and end times. __init__ ( self , stim_start = None , stim_end = None , num_iid = 1 , seed = None ) special Parameters: Name Type Description Default stim_start float start of the stimulus, in miliseconds None stim_end float end of the stimulus, in miliseconds None Source code in neurolib/utils/stimulus.py def __init__ ( self , stim_start = None , stim_end = None , num_iid = 1 , seed = None , ): \"\"\" :param stim_start: start of the stimulus, in miliseconds :type stim_start: float :param stim_end: end of the stimulus, in miliseconds :type stim_end: float \"\"\" self . stim_start = stim_start self . stim_end = stim_end super () . __init__ ( num_iid = num_iid , seed = seed , ) WienerProcess Basic Wiener process, dW, i.e. drawn from standard normal N(0, sqrt(dt)). generate_input ( self , duration , dt ) Function to generate input. Parameters: Name Type Description Default duration float duration of the input, in miliseconds required dt float dt of input, in miliseconds required Source code in neurolib/utils/stimulus.py def generate_input ( self , duration , dt ): self . _get_times ( duration = duration , dt = dt ) return np . random . normal ( 0.0 , np . sqrt ( dt ), ( self . times . shape [ 0 ], self . num_iid )) ZeroInput No noise input, i.e. all zeros. For convenience. generate_input ( self , duration , dt ) Function to generate input. Parameters: Name Type Description Default duration float duration of the input, in miliseconds required dt float dt of input, in miliseconds required Source code in neurolib/utils/stimulus.py def generate_input ( self , duration , dt ): self . _get_times ( duration = duration , dt = dt ) return np . zeros (( self . times . shape [ 0 ], self . num_iid )) construct_stimulus ( stim = 'dc' , duration = 6000 , dt = 0.1 , stim_amp = 0.2 , stim_freq = 1 , stim_bias = 0 , n_periods = None , nostim_before = 0 , nostim_after = 0 ) Constructs a stimulus that can be applied to a model Parameters: Name Type Description Default stim str, optional Stimulation type: 'ac':oscillatory stimulus, 'dc': stimple step current, 'rect': step current in negative then positive direction with slowly decaying amplitude, used for bistability detection, defaults to 'dc' 'dc' duration int, optional Duration of stimulus in ms, defaults to 6000 6000 dt float, optional Integration time step in ms, defaults to 0.1 0.1 stim_amp float, optional Amplitude of stimulus (for AdEx: in mV/ms, multiply by conductance C to get current in pA), defaults to 0.2 0.2 stim_freq int, optional Stimulation frequency, defaults to 1 1 stim_bias int, optional Stimulation offset (bias), defaults to 0 0 n_periods [type], optional Numer of periods of stimulus, defaults to None None nostim_before int, optional Time before stimulation, defaults to 0 0 nostim_after int, optional Time after stimulation, defaults to 0 0 Returns: Type Description numpy.ndarray Stimulus timeseries Exceptions: Type Description ValueError Raises error if unsupported stimulus type is chosen. Source code in neurolib/utils/stimulus.py def construct_stimulus ( stim = \"dc\" , duration = 6000 , dt = 0.1 , stim_amp = 0.2 , stim_freq = 1 , stim_bias = 0 , n_periods = None , nostim_before = 0 , nostim_after = 0 , ): \"\"\"Constructs a stimulus that can be applied to a model :param stim: Stimulation type: 'ac':oscillatory stimulus, 'dc': stimple step current, 'rect': step current in negative then positive direction with slowly decaying amplitude, used for bistability detection, defaults to 'dc' :type stim: str, optional :param duration: Duration of stimulus in ms, defaults to 6000 :type duration: int, optional :param dt: Integration time step in ms, defaults to 0.1 :type dt: float, optional :param stim_amp: Amplitude of stimulus (for AdEx: in mV/ms, multiply by conductance C to get current in pA), defaults to 0.2 :type stim_amp: float, optional :param stim_freq: Stimulation frequency, defaults to 1 :type stim_freq: int, optional :param stim_bias: Stimulation offset (bias), defaults to 0 :type stim_bias: int, optional :param n_periods: Numer of periods of stimulus, defaults to None :type n_periods: [type], optional :param nostim_before: Time before stimulation, defaults to 0 :type nostim_before: int, optional :param nostim_after: Time after stimulation, defaults to 0 :type nostim_after: int, optional :raises ValueError: Raises error if unsupported stimulus type is chosen. :return: Stimulus timeseries :rtype: numpy.ndarray \"\"\" \"\"\"Constructs a sitmulus that can be applied as input to a model TODO: rewrite stim: Stimulus type: 'ac':oscillatory stimulus, 'dc': stimple step current, 'rect': step current in negative then positive direction with slowly decaying amplitude, used for bistability detection stim_amp: Amplitude of stimulus (for AdEx: in mV/ms, multiply by conductance C to get current in pA) \"\"\" def sinus_stim ( f = 1 , amplitude = 0.2 , positive = 0 , phase = 0 , cycles = 1 , t_pause = 0 ): x = np . linspace ( np . pi , - np . pi , int ( 1000 / dt / f )) sinus_function = np . hstack ((( np . sin ( x + phase ) + positive ), np . tile ( 0 , t_pause ))) sinus_function *= amplitude return np . tile ( sinus_function , cycles ) if stim == \"ac\" : \"\"\"Oscillatory stimulus\"\"\" n_periods = n_periods or int ( stim_freq ) stimulus = np . hstack ( ( [ stim_bias ] * int ( nostim_before / dt ), np . tile ( sinus_stim ( stim_freq , stim_amp ) + stim_bias , n_periods ), ) ) stimulus = np . hstack (( stimulus , [ stim_bias ] * int ( nostim_after / dt ))) elif stim == \"dc\" : \"\"\"Simple DC input and return to baseline\"\"\" stimulus = np . hstack (([ stim_bias ] * int ( nostim_before / dt ), [ stim_bias + stim_amp ] * int ( 1000 / dt ))) stimulus = np . hstack (( stimulus , [ stim_bias ] * int ( nostim_after / dt ))) stimulus [ stimulus < 0 ] = 0 elif stim == \"rect\" : \"\"\"Rectified step current with slow decay\"\"\" # construct input stimulus = np . zeros ( int ( duration / dt )) tot_len = int ( duration / dt ) stim_epoch = tot_len / 6 stim_increase_counter = 0 stim_decrease_counter = 0 stim_step_increase = 5.0 / stim_epoch for i , m in enumerate ( stimulus ): if 0 * stim_epoch <= i < 0.5 * stim_epoch : stimulus [ i ] -= stim_amp elif 0.5 * stim_epoch <= i < 3.0 * stim_epoch : stimulus [ i ] = - np . exp ( - stim_increase_counter ) * stim_amp stim_increase_counter += stim_step_increase elif 3.0 * stim_epoch <= i < 3.5 * stim_epoch : stimulus [ i ] += stim_amp elif 3.5 * stim_epoch <= i < 5 * stim_epoch : stimulus [ i ] = np . exp ( - stim_decrease_counter ) * stim_amp stim_decrease_counter += stim_step_increase else : raise ValueError ( f 'Stimulus { stim } not found. Use \"ac\", \"dc\" or \"rect\".' ) # repeat stimulus until full length steps = int ( duration / dt ) stimlength = int ( len ( stimulus )) stimulus = np . tile ( stimulus , int ( steps / stimlength + 2 )) stimulus = stimulus [: steps ] return stimulus","title":"Stimulus"},{"location":"utils/stimulus/#stimulus","text":"Functions for creating stimuli and noise inputs for models.","title":"Stimulus"},{"location":"utils/stimulus/#neurolib.utils.stimulus.ConcatenatedInput","text":"Represents concatenation of inputs - typically for stimulus plus noise. Supports concatenation of arbitrary many objects.","title":"ConcatenatedInput"},{"location":"utils/stimulus/#neurolib.utils.stimulus.ConcatenatedInput.__init__","text":"Parameters: Name Type Description Default noise_processes list[`ModelInput`] list of noise/stimulation processes to concatinate required Source code in neurolib/utils/stimulus.py def __init__ ( self , noise_processes ): \"\"\" :param noise_processes: list of noise/stimulation processes to concatinate :type noise_processes: list[`ModelInput`] \"\"\" assert all ( isinstance ( process , ModelInput ) for process in noise_processes ) self . noise_processes = noise_processes","title":"__init__()"},{"location":"utils/stimulus/#neurolib.utils.stimulus.ConcatenatedInput.as_array","text":"Return sum of all processes as numpy array. Source code in neurolib/utils/stimulus.py def as_array ( self , duration , dt ): \"\"\" Return sum of all processes as numpy array. \"\"\" return np . sum ( np . stack ([ process . as_array ( duration , dt ) for process in self . noise_processes ]), axis = 0 , )","title":"as_array()"},{"location":"utils/stimulus/#neurolib.utils.stimulus.ConcatenatedInput.as_cubic_splines","text":"Return sum of all processes as cubic Hermite splines. Source code in neurolib/utils/stimulus.py def as_cubic_splines ( self , duration , dt ): \"\"\" Return sum of all processes as cubic Hermite splines. \"\"\" result = self . noise_processes [ 0 ] . as_cubic_splines ( duration , dt ) for process in self . noise_processes [ 1 :]: result . plus ( process . as_cubic_splines ( duration , dt )) return result","title":"as_cubic_splines()"},{"location":"utils/stimulus/#neurolib.utils.stimulus.ConcatenatedInput.get_params","text":"Get parameters recursively from all input processes. Source code in neurolib/utils/stimulus.py def get_params ( self ): \"\"\" Get parameters recursively from all input processes. \"\"\" return { \"type\" : self . __class__ . __name__ , ** { f \"noise_ { i } \" : process . get_params () for i , process in enumerate ( self . noise_processes )}, }","title":"get_params()"},{"location":"utils/stimulus/#neurolib.utils.stimulus.ConcatenatedInput.update_params","text":"Update all parameters recursively. Source code in neurolib/utils/stimulus.py def update_params ( self , params_dict ): \"\"\" Update all parameters recursively. \"\"\" for i , process in enumerate ( self . noise_processes ): process . update_params ( params_dict . get ( f \"noise_ { i } \" , {}))","title":"update_params()"},{"location":"utils/stimulus/#neurolib.utils.stimulus.ExponentialInput","text":"Exponential rise or decay input.","title":"ExponentialInput"},{"location":"utils/stimulus/#neurolib.utils.stimulus.ExponentialInput.__init__","text":"Parameters: Name Type Description Default inp_max float maximum of stimulus required exp_coeficient float coeffiecent for exponential, the higher the coefficient is, the faster it rises or decays required exp_type str whether its rise or decay 'rise' Source code in neurolib/utils/stimulus.py def __init__ ( self , inp_max , exp_coef = 30.0 , exp_type = \"rise\" , stim_start = None , stim_end = None , num_iid = 1 , seed = None , ): \"\"\" :param inp_max: maximum of stimulus :type inp_max: float :param exp_coeficient: coeffiecent for exponential, the higher the coefficient is, the faster it rises or decays :type exp_coeficient: float :param exp_type: whether its rise or decay :type exp_type: str \"\"\" self . inp_max = inp_max self . exp_coef = exp_coef assert exp_type in [ \"rise\" , \"decay\" ] self . exp_type = exp_type super () . __init__ ( stim_start = stim_start , stim_end = stim_end , num_iid = num_iid , seed = seed , )","title":"__init__()"},{"location":"utils/stimulus/#neurolib.utils.stimulus.ExponentialInput.generate_input","text":"Function to generate input. Parameters: Name Type Description Default duration float duration of the input, in miliseconds required dt float dt of input, in miliseconds required Source code in neurolib/utils/stimulus.py def generate_input ( self , duration , dt ): self . _get_times ( duration = duration , dt = dt ) exponential = np . exp ( - ( self . exp_coef / self . times [ - 1 ]) * self . times ) * self . inp_max if self . exp_type == \"rise\" : exponential = - exponential + self . inp_max return self . _trim_stim_input ( np . vstack ([ exponential ] * self . num_iid ) . T )","title":"generate_input()"},{"location":"utils/stimulus/#neurolib.utils.stimulus.LinearRampInput","text":"Linear ramp input.","title":"LinearRampInput"},{"location":"utils/stimulus/#neurolib.utils.stimulus.LinearRampInput.__init__","text":"Parameters: Name Type Description Default inp_max float maximum of stimulus required ramp_length float length of linear ramp, in miliseconds required Source code in neurolib/utils/stimulus.py def __init__ ( self , inp_max , ramp_length , stim_start = None , stim_end = None , num_iid = 1 , seed = None , ): \"\"\" :param inp_max: maximum of stimulus :type inp_max: float :param ramp_length: length of linear ramp, in miliseconds :type ramp_length: float \"\"\" self . inp_max = inp_max self . ramp_length = ramp_length super () . __init__ ( stim_start = stim_start , stim_end = stim_end , num_iid = num_iid , seed = seed , )","title":"__init__()"},{"location":"utils/stimulus/#neurolib.utils.stimulus.LinearRampInput.generate_input","text":"Function to generate input. Parameters: Name Type Description Default duration float duration of the input, in miliseconds required dt float dt of input, in miliseconds required Source code in neurolib/utils/stimulus.py def generate_input ( self , duration , dt ): self . _get_times ( duration = duration , dt = dt ) # need to adjust times for stimulus start times = self . times - self . stim_start linear_inp = ( self . inp_max / self . ramp_length ) * times * ( times < self . ramp_length ) + self . inp_max * ( times >= self . ramp_length ) return self . _trim_stim_input ( np . vstack ([ linear_inp ] * self . num_iid ) . T )","title":"generate_input()"},{"location":"utils/stimulus/#neurolib.utils.stimulus.ModelInput","text":"Generates input to model. Base class for other input types.","title":"ModelInput"},{"location":"utils/stimulus/#neurolib.utils.stimulus.ModelInput.__add__","text":"Concatenate two processes. Source code in neurolib/utils/stimulus.py def __add__ ( self , other ): \"\"\" Concatenate two processes. \"\"\" assert isinstance ( other , ModelInput ) assert self . num_iid == other . num_iid if isinstance ( other , ConcatenatedInput ): return ConcatenatedInput ( noise_processes = [ self ] + other . noise_processes ) else : return ConcatenatedInput ( noise_processes = [ self , other ])","title":"__add__()"},{"location":"utils/stimulus/#neurolib.utils.stimulus.ModelInput.__init__","text":"Parameters: Name Type Description Default num_iid int how many independent realisation of the input we want - for constant inputs the array is just copied, for noise this means independent realisation 1 seed int|None optional seed for noise generator None Source code in neurolib/utils/stimulus.py def __init__ ( self , num_iid = 1 , seed = None ): \"\"\" :param num_iid: how many independent realisation of the input we want - for constant inputs the array is just copied, for noise this means independent realisation :type num_iid: int :param seed: optional seed for noise generator :type seed: int|None \"\"\" self . num_iid = num_iid self . seed = seed # seed the generator np . random . seed ( seed ) # get parameter names self . param_names = inspect . getfullargspec ( self . __init__ ) . args self . param_names . remove ( \"self\" )","title":"__init__()"},{"location":"utils/stimulus/#neurolib.utils.stimulus.ModelInput.as_array","text":"Return input as numpy array. Parameters: Name Type Description Default duration float duration of the input, in miliseconds required dt float some reasonable \"speed\" of input, in miliseconds required Source code in neurolib/utils/stimulus.py def as_array ( self , duration , dt ): \"\"\" Return input as numpy array. :param duration: duration of the input, in miliseconds :type duration: float :param dt: some reasonable \"speed\" of input, in miliseconds :type dt: float \"\"\" return self . generate_input ( duration , dt )","title":"as_array()"},{"location":"utils/stimulus/#neurolib.utils.stimulus.ModelInput.as_cubic_splines","text":"Return as cubic Hermite splines. Parameters: Name Type Description Default duration float duration of the input, in miliseconds required dt float some reasonable \"speed\" of input, in miliseconds required Source code in neurolib/utils/stimulus.py def as_cubic_splines ( self , duration , dt ): \"\"\" Return as cubic Hermite splines. :param duration: duration of the input, in miliseconds :type duration: float :param dt: some reasonable \"speed\" of input, in miliseconds :type dt: float \"\"\" self . _get_times ( duration , dt ) return CubicHermiteSpline . from_data ( self . times , self . generate_input ( duration , dt ))","title":"as_cubic_splines()"},{"location":"utils/stimulus/#neurolib.utils.stimulus.ModelInput.generate_input","text":"Function to generate input. Parameters: Name Type Description Default duration float duration of the input, in miliseconds required dt float dt of input, in miliseconds required Source code in neurolib/utils/stimulus.py def generate_input ( self , duration , dt ): \"\"\" Function to generate input. :param duration: duration of the input, in miliseconds :type duration: float :param dt: dt of input, in miliseconds :type dt: float \"\"\" raise NotImplementedError","title":"generate_input()"},{"location":"utils/stimulus/#neurolib.utils.stimulus.ModelInput.get_params","text":"Return model input parameters as dict. Source code in neurolib/utils/stimulus.py def get_params ( self ): \"\"\" Return model input parameters as dict. \"\"\" assert all ( hasattr ( self , name ) for name in self . param_names ), self . param_names params = { name : getattr ( self , name ) for name in self . param_names } return { \"type\" : self . __class__ . __name__ , ** params }","title":"get_params()"},{"location":"utils/stimulus/#neurolib.utils.stimulus.ModelInput.update_params","text":"Update model input parameters. Parameters: Name Type Description Default params_dict dict new parameters for this model input required Source code in neurolib/utils/stimulus.py def update_params ( self , params_dict ): \"\"\" Update model input parameters. :param params_dict: new parameters for this model input :type params_dict: dict \"\"\" for param , value in params_dict . items (): if hasattr ( self , param ): setattr ( self , param , value )","title":"update_params()"},{"location":"utils/stimulus/#neurolib.utils.stimulus.OrnsteinUhlenbeckProcess","text":"Ornstein\u2013Uhlenbeck process, i.e. dX = (mu - X)/tau * dt + sigma*dW","title":"OrnsteinUhlenbeckProcess"},{"location":"utils/stimulus/#neurolib.utils.stimulus.OrnsteinUhlenbeckProcess.__init__","text":"Parameters: Name Type Description Default mu float drift of the O-U process required sigma float scale of the Wiener process required tau float O-U process timescale, same unit as time required Source code in neurolib/utils/stimulus.py def __init__ ( self , mu , sigma , tau , num_iid = 1 , seed = None , ): \"\"\" :param mu: drift of the O-U process :type mu: float :param sigma: scale of the Wiener process :type sigma: float :param tau: O-U process timescale, same unit as time :type tau: float \"\"\" self . mu = mu self . sigma = sigma self . tau = tau super () . __init__ ( num_iid = num_iid , seed = seed , )","title":"__init__()"},{"location":"utils/stimulus/#neurolib.utils.stimulus.OrnsteinUhlenbeckProcess.generate_input","text":"Function to generate input. Parameters: Name Type Description Default duration float duration of the input, in miliseconds required dt float dt of input, in miliseconds required Source code in neurolib/utils/stimulus.py def generate_input ( self , duration , dt ): self . _get_times ( duration = duration , dt = dt ) x = np . random . rand ( self . times . shape [ 0 ], self . num_iid ) * self . mu return self . numba_ou ( x , self . times , dt , self . mu , self . sigma , self . tau , self . num_iid )","title":"generate_input()"},{"location":"utils/stimulus/#neurolib.utils.stimulus.OrnsteinUhlenbeckProcess.numba_ou","text":"Generation of Ornstein-Uhlenback process - wrapped in numba's jit for speed. Source code in neurolib/utils/stimulus.py @staticmethod @numba . njit () def numba_ou ( x , times , dt , mu , sigma , tau , num_iid ): \"\"\" Generation of Ornstein-Uhlenback process - wrapped in numba's jit for speed. \"\"\" for i in range ( times . shape [ 0 ] - 1 ): x [ i + 1 , :] = x [ i , :] + dt * (( mu - x [ i , :]) / tau ) + sigma * np . sqrt ( dt ) * np . random . randn ( num_iid ) return x","title":"numba_ou()"},{"location":"utils/stimulus/#neurolib.utils.stimulus.SinusoidalInput","text":"Sinusoidal input.","title":"SinusoidalInput"},{"location":"utils/stimulus/#neurolib.utils.stimulus.SinusoidalInput.__init__","text":"Parameters: Name Type Description Default amplitude float amplitude of the sinusoid required period float period of the sinusoid, in miliseconds required nonnegative bool whether the sinusoid oscillates around 0 point (False), or around its amplitude, thus is nonnegative (True) True Source code in neurolib/utils/stimulus.py def __init__ ( self , amplitude , period , nonnegative = True , stim_start = None , stim_end = None , num_iid = 1 , seed = None , ): \"\"\" :param amplitude: amplitude of the sinusoid :type amplitude: float :param period: period of the sinusoid, in miliseconds :type period: float :param nonnegative: whether the sinusoid oscillates around 0 point (False), or around its amplitude, thus is nonnegative (True) :type nonnegative: bool \"\"\" self . amplitude = amplitude self . period = period self . nonnegative = nonnegative super () . __init__ ( stim_start = stim_start , stim_end = stim_end , num_iid = num_iid , seed = seed , )","title":"__init__()"},{"location":"utils/stimulus/#neurolib.utils.stimulus.SinusoidalInput.generate_input","text":"Function to generate input. Parameters: Name Type Description Default duration float duration of the input, in miliseconds required dt float dt of input, in miliseconds required Source code in neurolib/utils/stimulus.py def generate_input ( self , duration , dt ): self . _get_times ( duration = duration , dt = dt ) sinusoid = self . amplitude * np . sin ( 2 * np . pi * self . times * ( 1.0 / self . period )) if self . nonnegative : sinusoid += self . amplitude return self . _trim_stim_input ( np . vstack ([ sinusoid ] * self . num_iid ) . T )","title":"generate_input()"},{"location":"utils/stimulus/#neurolib.utils.stimulus.SquareInput","text":"Square input.","title":"SquareInput"},{"location":"utils/stimulus/#neurolib.utils.stimulus.SquareInput.__init__","text":"Parameters: Name Type Description Default amplitude float amplitude of the square required period float period of the square, in miliseconds required nonnegative bool whether the square oscillates around 0 point (False), or around its amplitude, thus is nonnegative (True) True Source code in neurolib/utils/stimulus.py def __init__ ( self , amplitude , period , nonnegative = True , stim_start = None , stim_end = None , num_iid = 1 , seed = None , ): \"\"\" :param amplitude: amplitude of the square :type amplitude: float :param period: period of the square, in miliseconds :type period: float :param nonnegative: whether the square oscillates around 0 point (False), or around its amplitude, thus is nonnegative (True) :type nonnegative: bool \"\"\" self . amplitude = amplitude self . period = period self . nonnegative = nonnegative super () . __init__ ( stim_start = stim_start , stim_end = stim_end , num_iid = num_iid , seed = seed , )","title":"__init__()"},{"location":"utils/stimulus/#neurolib.utils.stimulus.SquareInput.generate_input","text":"Function to generate input. Parameters: Name Type Description Default duration float duration of the input, in miliseconds required dt float dt of input, in miliseconds required Source code in neurolib/utils/stimulus.py def generate_input ( self , duration , dt ): self . _get_times ( duration = duration , dt = dt ) square_inp = self . amplitude * square ( 2 * np . pi * self . times * ( 1.0 / self . period )) if self . nonnegative : square_inp += self . amplitude return self . _trim_stim_input ( np . vstack ([ square_inp ] * self . num_iid ) . T )","title":"generate_input()"},{"location":"utils/stimulus/#neurolib.utils.stimulus.StepInput","text":"Basic step process.","title":"StepInput"},{"location":"utils/stimulus/#neurolib.utils.stimulus.StepInput.__init__","text":"Parameters: Name Type Description Default step_size float size of the stimulus required Source code in neurolib/utils/stimulus.py def __init__ ( self , step_size , stim_start = None , stim_end = None , num_iid = 1 , seed = None , ): \"\"\" :param step_size: size of the stimulus :type step_size: float \"\"\" self . step_size = step_size super () . __init__ ( stim_start = stim_start , stim_end = stim_end , num_iid = num_iid , seed = seed , )","title":"__init__()"},{"location":"utils/stimulus/#neurolib.utils.stimulus.StepInput.generate_input","text":"Function to generate input. Parameters: Name Type Description Default duration float duration of the input, in miliseconds required dt float dt of input, in miliseconds required Source code in neurolib/utils/stimulus.py def generate_input ( self , duration , dt ): self . _get_times ( duration = duration , dt = dt ) return self . _trim_stim_input ( np . ones (( self . times . shape [ 0 ], self . num_iid )) * self . step_size )","title":"generate_input()"},{"location":"utils/stimulus/#neurolib.utils.stimulus.StimulusInput","text":"Generates stimulus input with optional start and end times.","title":"StimulusInput"},{"location":"utils/stimulus/#neurolib.utils.stimulus.StimulusInput.__init__","text":"Parameters: Name Type Description Default stim_start float start of the stimulus, in miliseconds None stim_end float end of the stimulus, in miliseconds None Source code in neurolib/utils/stimulus.py def __init__ ( self , stim_start = None , stim_end = None , num_iid = 1 , seed = None , ): \"\"\" :param stim_start: start of the stimulus, in miliseconds :type stim_start: float :param stim_end: end of the stimulus, in miliseconds :type stim_end: float \"\"\" self . stim_start = stim_start self . stim_end = stim_end super () . __init__ ( num_iid = num_iid , seed = seed , )","title":"__init__()"},{"location":"utils/stimulus/#neurolib.utils.stimulus.WienerProcess","text":"Basic Wiener process, dW, i.e. drawn from standard normal N(0, sqrt(dt)).","title":"WienerProcess"},{"location":"utils/stimulus/#neurolib.utils.stimulus.WienerProcess.generate_input","text":"Function to generate input. Parameters: Name Type Description Default duration float duration of the input, in miliseconds required dt float dt of input, in miliseconds required Source code in neurolib/utils/stimulus.py def generate_input ( self , duration , dt ): self . _get_times ( duration = duration , dt = dt ) return np . random . normal ( 0.0 , np . sqrt ( dt ), ( self . times . shape [ 0 ], self . num_iid ))","title":"generate_input()"},{"location":"utils/stimulus/#neurolib.utils.stimulus.ZeroInput","text":"No noise input, i.e. all zeros. For convenience.","title":"ZeroInput"},{"location":"utils/stimulus/#neurolib.utils.stimulus.ZeroInput.generate_input","text":"Function to generate input. Parameters: Name Type Description Default duration float duration of the input, in miliseconds required dt float dt of input, in miliseconds required Source code in neurolib/utils/stimulus.py def generate_input ( self , duration , dt ): self . _get_times ( duration = duration , dt = dt ) return np . zeros (( self . times . shape [ 0 ], self . num_iid ))","title":"generate_input()"},{"location":"utils/stimulus/#neurolib.utils.stimulus.construct_stimulus","text":"Constructs a stimulus that can be applied to a model Parameters: Name Type Description Default stim str, optional Stimulation type: 'ac':oscillatory stimulus, 'dc': stimple step current, 'rect': step current in negative then positive direction with slowly decaying amplitude, used for bistability detection, defaults to 'dc' 'dc' duration int, optional Duration of stimulus in ms, defaults to 6000 6000 dt float, optional Integration time step in ms, defaults to 0.1 0.1 stim_amp float, optional Amplitude of stimulus (for AdEx: in mV/ms, multiply by conductance C to get current in pA), defaults to 0.2 0.2 stim_freq int, optional Stimulation frequency, defaults to 1 1 stim_bias int, optional Stimulation offset (bias), defaults to 0 0 n_periods [type], optional Numer of periods of stimulus, defaults to None None nostim_before int, optional Time before stimulation, defaults to 0 0 nostim_after int, optional Time after stimulation, defaults to 0 0 Returns: Type Description numpy.ndarray Stimulus timeseries Exceptions: Type Description ValueError Raises error if unsupported stimulus type is chosen. Source code in neurolib/utils/stimulus.py def construct_stimulus ( stim = \"dc\" , duration = 6000 , dt = 0.1 , stim_amp = 0.2 , stim_freq = 1 , stim_bias = 0 , n_periods = None , nostim_before = 0 , nostim_after = 0 , ): \"\"\"Constructs a stimulus that can be applied to a model :param stim: Stimulation type: 'ac':oscillatory stimulus, 'dc': stimple step current, 'rect': step current in negative then positive direction with slowly decaying amplitude, used for bistability detection, defaults to 'dc' :type stim: str, optional :param duration: Duration of stimulus in ms, defaults to 6000 :type duration: int, optional :param dt: Integration time step in ms, defaults to 0.1 :type dt: float, optional :param stim_amp: Amplitude of stimulus (for AdEx: in mV/ms, multiply by conductance C to get current in pA), defaults to 0.2 :type stim_amp: float, optional :param stim_freq: Stimulation frequency, defaults to 1 :type stim_freq: int, optional :param stim_bias: Stimulation offset (bias), defaults to 0 :type stim_bias: int, optional :param n_periods: Numer of periods of stimulus, defaults to None :type n_periods: [type], optional :param nostim_before: Time before stimulation, defaults to 0 :type nostim_before: int, optional :param nostim_after: Time after stimulation, defaults to 0 :type nostim_after: int, optional :raises ValueError: Raises error if unsupported stimulus type is chosen. :return: Stimulus timeseries :rtype: numpy.ndarray \"\"\" \"\"\"Constructs a sitmulus that can be applied as input to a model TODO: rewrite stim: Stimulus type: 'ac':oscillatory stimulus, 'dc': stimple step current, 'rect': step current in negative then positive direction with slowly decaying amplitude, used for bistability detection stim_amp: Amplitude of stimulus (for AdEx: in mV/ms, multiply by conductance C to get current in pA) \"\"\" def sinus_stim ( f = 1 , amplitude = 0.2 , positive = 0 , phase = 0 , cycles = 1 , t_pause = 0 ): x = np . linspace ( np . pi , - np . pi , int ( 1000 / dt / f )) sinus_function = np . hstack ((( np . sin ( x + phase ) + positive ), np . tile ( 0 , t_pause ))) sinus_function *= amplitude return np . tile ( sinus_function , cycles ) if stim == \"ac\" : \"\"\"Oscillatory stimulus\"\"\" n_periods = n_periods or int ( stim_freq ) stimulus = np . hstack ( ( [ stim_bias ] * int ( nostim_before / dt ), np . tile ( sinus_stim ( stim_freq , stim_amp ) + stim_bias , n_periods ), ) ) stimulus = np . hstack (( stimulus , [ stim_bias ] * int ( nostim_after / dt ))) elif stim == \"dc\" : \"\"\"Simple DC input and return to baseline\"\"\" stimulus = np . hstack (([ stim_bias ] * int ( nostim_before / dt ), [ stim_bias + stim_amp ] * int ( 1000 / dt ))) stimulus = np . hstack (( stimulus , [ stim_bias ] * int ( nostim_after / dt ))) stimulus [ stimulus < 0 ] = 0 elif stim == \"rect\" : \"\"\"Rectified step current with slow decay\"\"\" # construct input stimulus = np . zeros ( int ( duration / dt )) tot_len = int ( duration / dt ) stim_epoch = tot_len / 6 stim_increase_counter = 0 stim_decrease_counter = 0 stim_step_increase = 5.0 / stim_epoch for i , m in enumerate ( stimulus ): if 0 * stim_epoch <= i < 0.5 * stim_epoch : stimulus [ i ] -= stim_amp elif 0.5 * stim_epoch <= i < 3.0 * stim_epoch : stimulus [ i ] = - np . exp ( - stim_increase_counter ) * stim_amp stim_increase_counter += stim_step_increase elif 3.0 * stim_epoch <= i < 3.5 * stim_epoch : stimulus [ i ] += stim_amp elif 3.5 * stim_epoch <= i < 5 * stim_epoch : stimulus [ i ] = np . exp ( - stim_decrease_counter ) * stim_amp stim_decrease_counter += stim_step_increase else : raise ValueError ( f 'Stimulus { stim } not found. Use \"ac\", \"dc\" or \"rect\".' ) # repeat stimulus until full length steps = int ( duration / dt ) stimlength = int ( len ( stimulus )) stimulus = np . tile ( stimulus , int ( steps / stimlength + 2 )) stimulus = stimulus [: steps ] return stimulus","title":"construct_stimulus()"}]}