{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Introduction Getting started To browse the source code of neurolib visit out GitHub repository . Read the gentle introduction to neurolib for an overview of the basic functionality and some background information on the science behind whole-brain simulations. What is neurolib? neurolib is a simulation and optimization framework for whole-brain modeling. It allows you to implement your own neural mass models which can simulate fMRI BOLD activity. neurolib helps you to analyse your simulations, to load and handle structural and functional brain data, and to use powerful evolutionary algorithms to tune your model's parameters and fit it to empirical data. You can chose from different neural mass models to simulate the activity of each brain area. The main implementation is a mean-field model of spiking adaptive exponential integrate-and-fire neurons (AdEx) called ALNModel where each brain area contains two populations of excitatory and inhibitory neurons. An analysis and validation of the ALNModel model can be found in our paper . \ud83d\udcda Please read the gentle introduction to neurolib for an overview of the basic functionality and the science behind whole-brain simulations or read the documentation for getting started. \ud83d\udcdd Cite the following paper if you use neurolib for your own research: Cakan, C., Jajcay, N. & Obermayer, K. neurolib: A Simulation Framework for Whole-Brain Neural Mass Modeling. Cogn. Comput. (2021) . The figure below shows a schematic of how a brain network is constructed: Examples: Single node simulation \u00b7 Whole-brain network \u00b7 Parameter exploration \u00b7 Evolutionary optimization Whole-brain modeling Typically, in whole-brain modeling, diffusion tensor imaging (DTI) is used to infer the structural connectivity (the connection strengths) between different brain areas. In a DTI scan, the direction of the diffusion of molecules is measured across the whole brain. Using tractography , this information can yield the distribution of axonal fibers in the brain that connect distant brain areas, called the connectome. Together with an atlas that divides the brain into distinct areas, a matrix can be computed that encodes how many fibers go from one area to another, the so-called structural connectivity (SC) matrix. This matrix defines the coupling strengths between brain areas and acts as an adjacency matrix of the brain network. The fiber length determines the signal transmission delay between all brain areas. Combining the structural data with a computational model of the neuronal activity of each brain area, we can create a dynamical model of the whole brain. The resulting whole-brain model consists of interconnected brain areas, with each brain area having their internal neural dynamics. The neural activity can also be used to simulate hemodynamic BOLD activity using the Balloon-Windkessel model, which can be compared to empirical fMRI data. Often, BOLD activity is used to compute correlations of activity between brain areas, the so called resting state functional connectivity , resulting in a matrix with correlations between each brain area. This matrix can then be fitted to empirical fMRI recordings of the resting-state activity of the brain. Below is an animation of the neuronal activity of a whole-brain model plotted on a brain. Installation The easiest way to get going is to install the pypi package using pip : pip install neurolib Alternatively, you can also clone this repository and install all dependencies with git clone https://github.com/neurolib-dev/neurolib.git cd neurolib/ pip install -r requirements.txt pip install . It is recommended to clone or fork the entire repository since it will also include all examples and tests. Project layout neurolib/ # Main module \u251c\u2500\u2500 models/ # Neural mass models \u251c\u2500\u2500model.py # Base model class \u2514\u2500\u2500 /.../ # Implemented mass models \u251c\u2500\u2500 optimize/ # Optimization submodule \u251c\u2500\u2500 evolution/ # Evolutionary optimization \u2514\u2500\u2500 exploration/ # Parameter exploration \u251c\u2500\u2500 data/ # Empirical datasets (structural, functional) \u251c\u2500\u2500 utils/ # Utility belt \u251c\u2500\u2500 atlases.py # Atlases (Region names, coordinates) \u251c\u2500\u2500 collections.py # Custom data types \u251c\u2500\u2500 functions.py # Useful functions \u251c\u2500\u2500 loadData.py # Dataset loader \u251c\u2500\u2500 parameterSpace.py # Parameter space \u251c\u2500\u2500 saver.py # Save simulation outputs \u251c\u2500\u2500 signal.py # Signal processing functions \u2514\u2500\u2500 stimulus.py # Stimulus construction \u251c\u2500\u2500 examples/ # Example Jupyter notebooks \u251c\u2500\u2500 docs/ # Documentation \u2514\u2500\u2500 tests/ # Automated tests Examples Example IPython Notebooks on how to use the library can be found in the ./examples/ directory, don't forget to check them out! You can run the examples in your browser using Binder by clicking here or one of the following links: Example 0.0 - Basic use of the aln model Example 0.3 - Fitz-Hugh Nagumo model fhn on a brain network Example 0.6 - Minimal example of how to implement your own model in neurolib Example 1.2 - Parameter exploration of a brain network and fitting to BOLD data Example 2.0 - A simple example of the evolutionary optimization framework A basic overview of the functionality of neurolib is also given in the following. Single node This example is available in detail as a IPython Notebook . To create a single aln model with the default parameters, simply run from neurolib.models.aln import ALNModel model = ALNModel () model . params [ 'sigma_ou' ] = 0.1 # add some noise model . run () The results from this small simulation can be plotted easily: import matplotlib.pyplot as plt plt . plot ( model . t , model . output . T ) Whole-brain network A detailed example is available as a IPython Notebook . To simulate a whole-brain network model, first we need to load a DTI and a resting-state fMRI dataset. neurolib already provides some example data for you: from neurolib.utils.loadData import Dataset ds = Dataset ( \"gw\" ) The dataset that we just loaded, looks like this: We initialize a model with the dataset and run it: model = ALNModel ( Cmat = ds . Cmat , Dmat = ds . Dmat ) model . params [ 'duration' ] = 5 * 60 * 1000 # in ms, simulates for 5 minutes model . run ( bold = True ) This can take several minutes to compute, since we are simulating 80 brain regions for 5 minutes realtime. Note that we specified bold=True which simulates the BOLD model in parallel to the neuronal model. The resulting firing rates and BOLD functional connectivity looks like this: The quality of the fit of this simulation can be computed by correlating the simulated functional connectivity matrix above to the empirical resting-state functional connectivity for each subject of the dataset. This gives us an estimate of how well the model reproduces inter-areal BOLD correlations. As a rule of thumb, a value above 0.5 is considered good. We can compute the quality of the fit of the simulated data using func.fc() which calculates a functional connectivity matrix of N ( N = number of brain regions) time series. We use func.matrix_correlation() to compare this matrix to empirical data. scores = [ func . matrix_correlation ( func . fc ( model . BOLD . BOLD [:, 5 :]), fcemp ) for fcemp in ds . FCs ] print ( \"Correlation per subject:\" , [ f \" { s : .2 } \" for s in scores ]) print ( f \"Mean FC/FC correlation: { np . mean ( scores ) : .2 } \" ) Correlation per subject: ['0.34', '0.61', '0.54', '0.7', '0.54', '0.64', '0.69', '0.47', '0.59', '0.72', '0.58'] Mean FC/FC correlation: 0.58 Parameter exploration A detailed example of a single-node exploration is available as a IPython Notebook . For an example of a brain network exploration, see this Notebook . Whenever you work with a model, it is of great importance to know what kind of dynamics it exhibits given a certain set of parameters. It is often useful to get an overview of the state space of a given model of interest. For example in the case of aln , the dynamics depends a lot on the mean inputs to the excitatory and the inhibitory population. neurolib makes it very easy to quickly explore parameter spaces of a given model: # create model model = ALNModel () # define the parameter space to explore parameters = ParameterSpace ({ \"mue_ext_mean\" : np . linspace ( 0 , 3 , 21 ), # input to E \"mui_ext_mean\" : np . linspace ( 0 , 3 , 21 )}) # input to I # define exploration search = BoxSearch ( model , parameters ) search . run () That's it!. You can now use the builtin functions to load the simulation results from disk and perform your analysis: search . loadResults () # calculate maximum firing rate for each parameter for i in search . dfResults . index : search . dfResults . loc [ i , 'max_r' ] = np . max ( search . results [ i ][ 'rates_exc' ][:, - int ( 1000 / model . params [ 'dt' ]):]) We can plot the results to get something close to a bifurcation diagram! Evolutionary optimization A detailed example is available as a IPython Notebook . neurolib also implements evolutionary parameter optimization, which works particularly well with brain networks. In an evolutionary algorithm, each simulation is represented as an individual and the parameters of the simulation, for example coupling strengths or noise level values, are represented as the genes of each individual. An individual is a part of a population. In each generation, individuals are evaluated and ranked according to a fitness criterion. For whole-brain network simulations, this could be the fit of the simulated activity to empirical data. Then, individuals with a high fitness value are selected as parents and mate to create offspring. These offspring undergo random mutations of their genes. After all offspring are evaluated, the best individuals of the population are selected to transition into the next generation. This process goes on for a given amount generations until a stopping criterion is reached. This could be a predefined maximum number of generations or when a large enough population with high fitness values is found. An example genealogy tree is shown below. You can see the evolution starting at the top and individuals reproducing generation by generation. The color indicates the fitness. neurolib makes it very easy to set up your own evolutionary optimization and everything else is handled under the hood. You can chose between two implemented evolutionary algorithms: adaptive is a gaussian mutation and rank selection algorithm with adaptive step size that ensures convergence (a schematic is shown in the image below). nsga2 is an implementation of the popular multi-objective optimization algorithm by Deb et al. 2002. Of course, if you like, you can dig deeper, define your own selection, mutation and mating operators. In the following demonstration, we will simply evaluate the fitness of each individual as the distance to the unit circle. After a couple of generations of mating, mutating and selecting, only individuals who are close to the circle should survive: from neurolib.utils.parameterSpace import ParameterSpace from neurolib.optimize.evolution import Evolution def optimize_me ( traj ): ind = evolution . getIndividualFromTraj ( traj ) # let's make a circle fitness_result = abs (( ind . x ** 2 + ind . y ** 2 ) - 1 ) # gather results fitness_tuple = ( fitness_result ,) result_dict = { \"result\" : [ fitness_result ]} return fitness_tuple , result_dict # we define a parameter space and its boundaries pars = ParameterSpace ([ 'x' , 'y' ], [[ - 5.0 , 5.0 ], [ - 5.0 , 5.0 ]]) # initialize the evolution and go evolution = Evolution ( optimize_me , pars , weightList = [ - 1.0 ], POP_INIT_SIZE = 100 , POP_SIZE = 50 , NGEN = 10 ) evolution . run () That's it! Now we can check the results: evolution . loadResults () evolution . info ( plot = True ) This will gives us a summary of the last generation and plots a distribution of the individuals (and their parameters). Below is an animation of 10 generations of the evolutionary process. Ass you can see, after a couple of generations, all remaining individuals lie very close to the unit circle. More information Built With neurolib is built using other amazing open source projects: pypet - Python parameter exploration toolbox deap - Distributed Evolutionary Algorithms in Python numpy - The fundamental package for scientific computing with Python numba - NumPy aware dynamic Python compiler using LLVM Jupyter - Jupyter Interactive Notebook How to cite Cakan, C., Jajcay, N. & Obermayer, K. neurolib: A Simulation Framework for Whole-Brain Neural Mass Modeling. Cogn. Comput. (2021). https://doi.org/10.1007/s12559-021-09931-9 @article { cakan2021 , author = {Cakan, Caglar and Jajcay, Nikola and Obermayer, Klaus} , title = {neurolib: A Simulation Framework for Whole-Brain Neural Mass Modeling} , journal = {Cognitive Computation} , year = {2021} , month = {Oct} , issn = {1866-9964} , doi = {10.1007/s12559-021-09931-9} , url = {https://doi.org/10.1007/s12559-021-09931-9} } Get in touch Caglar Cakan (cakan@ni.tu-berlin.de) Department of Software Engineering and Theoretical Computer Science, Technische Universit\u00e4t Berlin, Germany Bernstein Center for Computational Neuroscience Berlin, Germany Acknowledgments This work was supported by the Deutsche Forschungsgemeinschaft (DFG, German Research Foundation) with the project number 327654276 (SFB 1315) and the Research Training Group GRK1589/2.","title":"Introduction"},{"location":"#introduction","text":"","title":"Introduction"},{"location":"#getting-started","text":"To browse the source code of neurolib visit out GitHub repository . Read the gentle introduction to neurolib for an overview of the basic functionality and some background information on the science behind whole-brain simulations.","title":"Getting started"},{"location":"#what-is-neurolib","text":"neurolib is a simulation and optimization framework for whole-brain modeling. It allows you to implement your own neural mass models which can simulate fMRI BOLD activity. neurolib helps you to analyse your simulations, to load and handle structural and functional brain data, and to use powerful evolutionary algorithms to tune your model's parameters and fit it to empirical data. You can chose from different neural mass models to simulate the activity of each brain area. The main implementation is a mean-field model of spiking adaptive exponential integrate-and-fire neurons (AdEx) called ALNModel where each brain area contains two populations of excitatory and inhibitory neurons. An analysis and validation of the ALNModel model can be found in our paper . \ud83d\udcda Please read the gentle introduction to neurolib for an overview of the basic functionality and the science behind whole-brain simulations or read the documentation for getting started. \ud83d\udcdd Cite the following paper if you use neurolib for your own research: Cakan, C., Jajcay, N. & Obermayer, K. neurolib: A Simulation Framework for Whole-Brain Neural Mass Modeling. Cogn. Comput. (2021) . The figure below shows a schematic of how a brain network is constructed: Examples: Single node simulation \u00b7 Whole-brain network \u00b7 Parameter exploration \u00b7 Evolutionary optimization","title":"What is neurolib?"},{"location":"#whole-brain-modeling","text":"Typically, in whole-brain modeling, diffusion tensor imaging (DTI) is used to infer the structural connectivity (the connection strengths) between different brain areas. In a DTI scan, the direction of the diffusion of molecules is measured across the whole brain. Using tractography , this information can yield the distribution of axonal fibers in the brain that connect distant brain areas, called the connectome. Together with an atlas that divides the brain into distinct areas, a matrix can be computed that encodes how many fibers go from one area to another, the so-called structural connectivity (SC) matrix. This matrix defines the coupling strengths between brain areas and acts as an adjacency matrix of the brain network. The fiber length determines the signal transmission delay between all brain areas. Combining the structural data with a computational model of the neuronal activity of each brain area, we can create a dynamical model of the whole brain. The resulting whole-brain model consists of interconnected brain areas, with each brain area having their internal neural dynamics. The neural activity can also be used to simulate hemodynamic BOLD activity using the Balloon-Windkessel model, which can be compared to empirical fMRI data. Often, BOLD activity is used to compute correlations of activity between brain areas, the so called resting state functional connectivity , resulting in a matrix with correlations between each brain area. This matrix can then be fitted to empirical fMRI recordings of the resting-state activity of the brain. Below is an animation of the neuronal activity of a whole-brain model plotted on a brain.","title":"Whole-brain modeling"},{"location":"#installation","text":"The easiest way to get going is to install the pypi package using pip : pip install neurolib Alternatively, you can also clone this repository and install all dependencies with git clone https://github.com/neurolib-dev/neurolib.git cd neurolib/ pip install -r requirements.txt pip install . It is recommended to clone or fork the entire repository since it will also include all examples and tests.","title":"Installation"},{"location":"#project-layout","text":"neurolib/ # Main module \u251c\u2500\u2500 models/ # Neural mass models \u251c\u2500\u2500model.py # Base model class \u2514\u2500\u2500 /.../ # Implemented mass models \u251c\u2500\u2500 optimize/ # Optimization submodule \u251c\u2500\u2500 evolution/ # Evolutionary optimization \u2514\u2500\u2500 exploration/ # Parameter exploration \u251c\u2500\u2500 data/ # Empirical datasets (structural, functional) \u251c\u2500\u2500 utils/ # Utility belt \u251c\u2500\u2500 atlases.py # Atlases (Region names, coordinates) \u251c\u2500\u2500 collections.py # Custom data types \u251c\u2500\u2500 functions.py # Useful functions \u251c\u2500\u2500 loadData.py # Dataset loader \u251c\u2500\u2500 parameterSpace.py # Parameter space \u251c\u2500\u2500 saver.py # Save simulation outputs \u251c\u2500\u2500 signal.py # Signal processing functions \u2514\u2500\u2500 stimulus.py # Stimulus construction \u251c\u2500\u2500 examples/ # Example Jupyter notebooks \u251c\u2500\u2500 docs/ # Documentation \u2514\u2500\u2500 tests/ # Automated tests","title":"Project layout"},{"location":"#examples","text":"Example IPython Notebooks on how to use the library can be found in the ./examples/ directory, don't forget to check them out! You can run the examples in your browser using Binder by clicking here or one of the following links: Example 0.0 - Basic use of the aln model Example 0.3 - Fitz-Hugh Nagumo model fhn on a brain network Example 0.6 - Minimal example of how to implement your own model in neurolib Example 1.2 - Parameter exploration of a brain network and fitting to BOLD data Example 2.0 - A simple example of the evolutionary optimization framework A basic overview of the functionality of neurolib is also given in the following.","title":"Examples"},{"location":"#single-node","text":"This example is available in detail as a IPython Notebook . To create a single aln model with the default parameters, simply run from neurolib.models.aln import ALNModel model = ALNModel () model . params [ 'sigma_ou' ] = 0.1 # add some noise model . run () The results from this small simulation can be plotted easily: import matplotlib.pyplot as plt plt . plot ( model . t , model . output . T )","title":"Single node"},{"location":"#whole-brain-network","text":"A detailed example is available as a IPython Notebook . To simulate a whole-brain network model, first we need to load a DTI and a resting-state fMRI dataset. neurolib already provides some example data for you: from neurolib.utils.loadData import Dataset ds = Dataset ( \"gw\" ) The dataset that we just loaded, looks like this: We initialize a model with the dataset and run it: model = ALNModel ( Cmat = ds . Cmat , Dmat = ds . Dmat ) model . params [ 'duration' ] = 5 * 60 * 1000 # in ms, simulates for 5 minutes model . run ( bold = True ) This can take several minutes to compute, since we are simulating 80 brain regions for 5 minutes realtime. Note that we specified bold=True which simulates the BOLD model in parallel to the neuronal model. The resulting firing rates and BOLD functional connectivity looks like this: The quality of the fit of this simulation can be computed by correlating the simulated functional connectivity matrix above to the empirical resting-state functional connectivity for each subject of the dataset. This gives us an estimate of how well the model reproduces inter-areal BOLD correlations. As a rule of thumb, a value above 0.5 is considered good. We can compute the quality of the fit of the simulated data using func.fc() which calculates a functional connectivity matrix of N ( N = number of brain regions) time series. We use func.matrix_correlation() to compare this matrix to empirical data. scores = [ func . matrix_correlation ( func . fc ( model . BOLD . BOLD [:, 5 :]), fcemp ) for fcemp in ds . FCs ] print ( \"Correlation per subject:\" , [ f \" { s : .2 } \" for s in scores ]) print ( f \"Mean FC/FC correlation: { np . mean ( scores ) : .2 } \" ) Correlation per subject: ['0.34', '0.61', '0.54', '0.7', '0.54', '0.64', '0.69', '0.47', '0.59', '0.72', '0.58'] Mean FC/FC correlation: 0.58","title":"Whole-brain network"},{"location":"#parameter-exploration","text":"A detailed example of a single-node exploration is available as a IPython Notebook . For an example of a brain network exploration, see this Notebook . Whenever you work with a model, it is of great importance to know what kind of dynamics it exhibits given a certain set of parameters. It is often useful to get an overview of the state space of a given model of interest. For example in the case of aln , the dynamics depends a lot on the mean inputs to the excitatory and the inhibitory population. neurolib makes it very easy to quickly explore parameter spaces of a given model: # create model model = ALNModel () # define the parameter space to explore parameters = ParameterSpace ({ \"mue_ext_mean\" : np . linspace ( 0 , 3 , 21 ), # input to E \"mui_ext_mean\" : np . linspace ( 0 , 3 , 21 )}) # input to I # define exploration search = BoxSearch ( model , parameters ) search . run () That's it!. You can now use the builtin functions to load the simulation results from disk and perform your analysis: search . loadResults () # calculate maximum firing rate for each parameter for i in search . dfResults . index : search . dfResults . loc [ i , 'max_r' ] = np . max ( search . results [ i ][ 'rates_exc' ][:, - int ( 1000 / model . params [ 'dt' ]):]) We can plot the results to get something close to a bifurcation diagram!","title":"Parameter exploration"},{"location":"#evolutionary-optimization","text":"A detailed example is available as a IPython Notebook . neurolib also implements evolutionary parameter optimization, which works particularly well with brain networks. In an evolutionary algorithm, each simulation is represented as an individual and the parameters of the simulation, for example coupling strengths or noise level values, are represented as the genes of each individual. An individual is a part of a population. In each generation, individuals are evaluated and ranked according to a fitness criterion. For whole-brain network simulations, this could be the fit of the simulated activity to empirical data. Then, individuals with a high fitness value are selected as parents and mate to create offspring. These offspring undergo random mutations of their genes. After all offspring are evaluated, the best individuals of the population are selected to transition into the next generation. This process goes on for a given amount generations until a stopping criterion is reached. This could be a predefined maximum number of generations or when a large enough population with high fitness values is found. An example genealogy tree is shown below. You can see the evolution starting at the top and individuals reproducing generation by generation. The color indicates the fitness. neurolib makes it very easy to set up your own evolutionary optimization and everything else is handled under the hood. You can chose between two implemented evolutionary algorithms: adaptive is a gaussian mutation and rank selection algorithm with adaptive step size that ensures convergence (a schematic is shown in the image below). nsga2 is an implementation of the popular multi-objective optimization algorithm by Deb et al. 2002. Of course, if you like, you can dig deeper, define your own selection, mutation and mating operators. In the following demonstration, we will simply evaluate the fitness of each individual as the distance to the unit circle. After a couple of generations of mating, mutating and selecting, only individuals who are close to the circle should survive: from neurolib.utils.parameterSpace import ParameterSpace from neurolib.optimize.evolution import Evolution def optimize_me ( traj ): ind = evolution . getIndividualFromTraj ( traj ) # let's make a circle fitness_result = abs (( ind . x ** 2 + ind . y ** 2 ) - 1 ) # gather results fitness_tuple = ( fitness_result ,) result_dict = { \"result\" : [ fitness_result ]} return fitness_tuple , result_dict # we define a parameter space and its boundaries pars = ParameterSpace ([ 'x' , 'y' ], [[ - 5.0 , 5.0 ], [ - 5.0 , 5.0 ]]) # initialize the evolution and go evolution = Evolution ( optimize_me , pars , weightList = [ - 1.0 ], POP_INIT_SIZE = 100 , POP_SIZE = 50 , NGEN = 10 ) evolution . run () That's it! Now we can check the results: evolution . loadResults () evolution . info ( plot = True ) This will gives us a summary of the last generation and plots a distribution of the individuals (and their parameters). Below is an animation of 10 generations of the evolutionary process. Ass you can see, after a couple of generations, all remaining individuals lie very close to the unit circle.","title":"Evolutionary optimization"},{"location":"#more-information","text":"","title":"More information"},{"location":"#built-with","text":"neurolib is built using other amazing open source projects: pypet - Python parameter exploration toolbox deap - Distributed Evolutionary Algorithms in Python numpy - The fundamental package for scientific computing with Python numba - NumPy aware dynamic Python compiler using LLVM Jupyter - Jupyter Interactive Notebook","title":"Built With"},{"location":"#how-to-cite","text":"Cakan, C., Jajcay, N. & Obermayer, K. neurolib: A Simulation Framework for Whole-Brain Neural Mass Modeling. Cogn. Comput. (2021). https://doi.org/10.1007/s12559-021-09931-9 @article { cakan2021 , author = {Cakan, Caglar and Jajcay, Nikola and Obermayer, Klaus} , title = {neurolib: A Simulation Framework for Whole-Brain Neural Mass Modeling} , journal = {Cognitive Computation} , year = {2021} , month = {Oct} , issn = {1866-9964} , doi = {10.1007/s12559-021-09931-9} , url = {https://doi.org/10.1007/s12559-021-09931-9} }","title":"How to cite"},{"location":"#get-in-touch","text":"Caglar Cakan (cakan@ni.tu-berlin.de) Department of Software Engineering and Theoretical Computer Science, Technische Universit\u00e4t Berlin, Germany Bernstein Center for Computational Neuroscience Berlin, Germany","title":"Get in touch"},{"location":"#acknowledgments","text":"This work was supported by the Deutsche Forschungsgemeinschaft (DFG, German Research Foundation) with the project number 327654276 (SFB 1315) and the Research Training Group GRK1589/2.","title":"Acknowledgments"},{"location":"contributing/","text":"Contributing to neurolib Thank you for your interest in contributing to neurolib . We welcome bug reports through the issues tab and pull requests for fixes or improvements. You are warlmy invited to join our development efforts and make brain network modeling easier and more useful for all researchers. Pull requests To propose a change to neurolib 's code, you should first clone the repository to your own Github account. Then, create a branch and make some changes. You can then send a pull request to neurolib's own repository and we will review and discuss your proposed changes. More information on how to make pull requests can be found in the Github help pages. Maintaining code Please be aware that we have a conservative policy for implementing new functionality. All new features need to be maintained, sometimes forever. We are a small team of developers and can only maintain a limited amount of code. Therefore, ideally, you should also feel responsible for the changes you have proposed and maintain it after it becomes part of neurolib . Code style We are using the black code formatter with the additional argument --line-length=120 . It's called the \"uncompromising formatter\" because it is completely deterministic and you have literally no control over how your code will look like. We like that! We recommend using black directly in your IDE, for example in VSCode . Commenting Code We are using the sphinx format for commenting code. Comments are incredibly important to us since neurolib is supposed to be a library of user-facing code. It's encouraged to read the code, change it and build something on top of it. Our users are coders. Please write as many comments as you can, including a description of each function and method and its arguments but also single-line comments for the code itself. Implementing a neural mass model You are very welcome to implement your favorite neural mass model and contribute it to neurolib . The easiest way of implementing a model is to copy a model directory and adapt the relevant parts of it to your own model. Please have a look of how other models are implemented. We recommend having a look at the HopfModel which is a fairly simple model. All models inherit from the Model base class which can be found in neurolib/models/model.py . You can also check out the model implementation example to find out how a model is implemented. All models need to pass tests. Tests are located in the tests/ directory of the project. A model should be added to the test files tests/test_models.py and tests/test_autochunk.py . However, you should also make sure that your model supports as many neurolib features as possible, such as exploration and optimization. If you did everything right, this should be the case. As of now, models consist of three parts: The model.py file which contains the class of the model. Here the model specifies attributes like its name, its state variables, its initial value parameters. Additionally, in the constructor (the __init__() method), the model loads its default parameters. The loadDefaultParams.py file contains a function ( loadDefaultParams() ) which has the arguments Cmat for the structural connectivity matrix, Dmat for the delay matrix and seed for the seed of the random number generator. This function returns a dictionary (or dotdict , see neurolib/utils/collections.py ) with all parrameters inside. The timeIntegration.py file which contains a timeIntegration() function which has the argument params coming from the previous step. Here, we need to prepare the numerical integration. We load all relevant parameters from the params dictionary and pass it to the main integration loop. The integration loop is written such that it can be accelerated by numba ( numba's page ) which speeds up the integration by a factor of around 1000. Contributing examples We very much welcome example contributions since they help new users to learn how to make use of neurolib . They can include basic usage examples or tutorials of neurolib 's features, or a demonstration of how to solve a specific scientific task using neural mass models or whole-brain networks. Examples are provided as Jupyter Notebooks in the /examples/ directory of the project repository. Notebooks should have a brief description of what they are trying to accomplish at the beginning. It is recommended to change the working directory to the root directory at the very beginning of the notebook ( os.chdir('..') ). Notebooks should be structured with different subheadings (Markdown style). Please also describe in words what you are doing in code. Contributing brain data We have a few small datasets already in neurolib so everyone can start simulating right away. If you'd like to contribute more data to the project, please feel invited to do so. We're looking for more structural connectivity matrices and fiber length matrices in the MATLAB matrix .mat format (which can be loaded by scipy.loadmat ). We also appreciate BOLD data, EEG data, or MEG data. Other modalities could be useful as well. Please be aware that the data has to be in a parcellated form, i.e., the brain areas need to be organized according to an atlas like the AAL2 atlas (or others).","title":"Contributing to neurolib"},{"location":"contributing/#contributing-to-neurolib","text":"Thank you for your interest in contributing to neurolib . We welcome bug reports through the issues tab and pull requests for fixes or improvements. You are warlmy invited to join our development efforts and make brain network modeling easier and more useful for all researchers.","title":"Contributing to neurolib"},{"location":"contributing/#pull-requests","text":"To propose a change to neurolib 's code, you should first clone the repository to your own Github account. Then, create a branch and make some changes. You can then send a pull request to neurolib's own repository and we will review and discuss your proposed changes. More information on how to make pull requests can be found in the Github help pages.","title":"Pull requests"},{"location":"contributing/#maintaining-code","text":"Please be aware that we have a conservative policy for implementing new functionality. All new features need to be maintained, sometimes forever. We are a small team of developers and can only maintain a limited amount of code. Therefore, ideally, you should also feel responsible for the changes you have proposed and maintain it after it becomes part of neurolib .","title":"Maintaining code"},{"location":"contributing/#code-style","text":"We are using the black code formatter with the additional argument --line-length=120 . It's called the \"uncompromising formatter\" because it is completely deterministic and you have literally no control over how your code will look like. We like that! We recommend using black directly in your IDE, for example in VSCode .","title":"Code style"},{"location":"contributing/#commenting-code","text":"We are using the sphinx format for commenting code. Comments are incredibly important to us since neurolib is supposed to be a library of user-facing code. It's encouraged to read the code, change it and build something on top of it. Our users are coders. Please write as many comments as you can, including a description of each function and method and its arguments but also single-line comments for the code itself.","title":"Commenting Code"},{"location":"contributing/#implementing-a-neural-mass-model","text":"You are very welcome to implement your favorite neural mass model and contribute it to neurolib . The easiest way of implementing a model is to copy a model directory and adapt the relevant parts of it to your own model. Please have a look of how other models are implemented. We recommend having a look at the HopfModel which is a fairly simple model. All models inherit from the Model base class which can be found in neurolib/models/model.py . You can also check out the model implementation example to find out how a model is implemented. All models need to pass tests. Tests are located in the tests/ directory of the project. A model should be added to the test files tests/test_models.py and tests/test_autochunk.py . However, you should also make sure that your model supports as many neurolib features as possible, such as exploration and optimization. If you did everything right, this should be the case. As of now, models consist of three parts: The model.py file which contains the class of the model. Here the model specifies attributes like its name, its state variables, its initial value parameters. Additionally, in the constructor (the __init__() method), the model loads its default parameters. The loadDefaultParams.py file contains a function ( loadDefaultParams() ) which has the arguments Cmat for the structural connectivity matrix, Dmat for the delay matrix and seed for the seed of the random number generator. This function returns a dictionary (or dotdict , see neurolib/utils/collections.py ) with all parrameters inside. The timeIntegration.py file which contains a timeIntegration() function which has the argument params coming from the previous step. Here, we need to prepare the numerical integration. We load all relevant parameters from the params dictionary and pass it to the main integration loop. The integration loop is written such that it can be accelerated by numba ( numba's page ) which speeds up the integration by a factor of around 1000.","title":"Implementing a neural mass model"},{"location":"contributing/#contributing-examples","text":"We very much welcome example contributions since they help new users to learn how to make use of neurolib . They can include basic usage examples or tutorials of neurolib 's features, or a demonstration of how to solve a specific scientific task using neural mass models or whole-brain networks. Examples are provided as Jupyter Notebooks in the /examples/ directory of the project repository. Notebooks should have a brief description of what they are trying to accomplish at the beginning. It is recommended to change the working directory to the root directory at the very beginning of the notebook ( os.chdir('..') ). Notebooks should be structured with different subheadings (Markdown style). Please also describe in words what you are doing in code.","title":"Contributing examples"},{"location":"contributing/#contributing-brain-data","text":"We have a few small datasets already in neurolib so everyone can start simulating right away. If you'd like to contribute more data to the project, please feel invited to do so. We're looking for more structural connectivity matrices and fiber length matrices in the MATLAB matrix .mat format (which can be loaded by scipy.loadmat ). We also appreciate BOLD data, EEG data, or MEG data. Other modalities could be useful as well. Please be aware that the data has to be in a parcellated form, i.e., the brain areas need to be organized according to an atlas like the AAL2 atlas (or others).","title":"Contributing brain data"},{"location":"examples/example-0-aln-minimal/","text":"(function() { function addWidgetsRenderer() { var requireJsScript = document.createElement('script'); requireJsScript.src = 'https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js'; var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var jupyterWidgetsScript = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} jupyterWidgetsScript.src = widgetRendererSrc; document.body.appendChild(requireJsScript); document.body.appendChild(jupyterWidgetsScript); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); The neural mass model In this example, we will learn about the basic of neurolib . We will create a two-population mean-field model of exponential integrate-and-fire neurons called the aln model. We will learn how to create a Model , set some parameters and run a simulation. We will also see how we can easily access the output of each simulation. aln - the adaptive linear-nonlinear cascade model The adaptive linear-nonlinear ( aln ) cascade model is a low-dimensional population model of spiking neural networks. Mathematically, it is a dynamical system of non-linear ODEs. The dynamical variables of the system simulated in the aln model describe the average firing rate and other macroscopic variables of a randomly connected, delay-coupled network of excitatory and inhibitory adative exponential integrate-and-fire neurons (AdEx) with non-linear synaptic currents. Ultimately, the model is a result of various steps of model reduction starting from the Fokker-Planck equation of the AdEx neuron subject to white noise input at many steps of input means \\(\\mu\\) and variances \\(\\sigma\\) . The resulting mean firing rates and mean membrane potentials are then stored in a lookup table and serve as the nonlinear firing rate transfer function, \\(r = \\Phi(\\mu, \\sigma)\\) . Basic use # change to the root directory of the project import os if os . getcwd () . split ( \"/\" )[ - 1 ] == \"examples\" : os . chdir ( '..' ) # This will reload all imports as soon as the code changes % load_ext autoreload % autoreload 2 try : import matplotlib.pyplot as plt except ImportError : import sys ! { sys . executable } - m pip install matplotlib import matplotlib.pyplot as plt import numpy as np import scipy # Let's import the aln model from neurolib.models.aln import ALNModel # Some useful functions are provided here import neurolib.utils.functions as func # a nice color map plt . rcParams [ 'image.cmap' ] = 'plasma' Simulating a single aln node To create a single node, we simply instanciate the model without any arguments. # Create the model aln = ALNModel () # Each model comes with a set of default parameters which are are a dictionary. # Let's change the parameter that controls the duration of a simulation to 10s. aln . params [ 'duration' ] = 10.0 * 1000 # For convenience, we could also use: aln . params . duration = 10.0 * 1000 # In the aln model an Ornstein-Uhlenbeck process is simulated in parallel # as the source of input noise fluctuations. Here we can set the variance # of the process. # For more info: https://en.wikipedia.org/wiki/Ornstein%E2%80%93Uhlenbeck_process # Let's add some noise. aln . params [ 'sigma_ou' ] = 0.1 # Finally, we run the model aln . run () Accessing the outputs Accessing the outputs is straight-forward. Every model's outputs are stored in the model.outputs attribute. According to the specific name of each of the model's outputs, they can also be accessed as a key of the Model object, i.e. aln['rates_exc'] . plt . plot ( aln [ 't' ], aln [ 'rates_exc' ] . T , lw = 2 , c = 'k' ) plt . xlabel ( \"t [ms]\" ) plt . ylabel ( \"Rate [Hz]\" ) plt . xlim ( 1000 , 2000 ); # Outputs are also available as an xr DataArray xr = aln . xr () print ( xr . dims ) # outputs can also be accessed via attributes in dot.notation print ( \"rates_exc\" , aln . rates_exc ) ('output', 'space', 'time') rates_exc [[0.54644307 0.48676051 0.43664265 ... 0.06910043 0.06969732 0.07031085]] Bifurcation diagram Bifurcation diagrams can give us an overview of how different parameters of the model affect its dynamics. The simplest method for drawing a bifurcation diagram is to simply change relevant parameters step by step and record the model's behavior in response to these changes. In this example, we want to see how the model's dynamics changes with respect to the external input currents to the excitatory population. These input currents could be due to couplings with other nodes in a brain network or we could model other factors like external electrical stimulation. Below, you can see a schematic of the aln model. As you can see, a single node consists of one excitatory (red) and one inhibitory population (blue). The parameter that controls the mean input to the excitatory population is \\(\\mu_{E}\\) or aln.params[\"mue_ext_mean\"] . Let's first decrease the duration of a single run so we can scan the parameter space a bit faster and let's also disable the noisy input. aln . params [ 'duration' ] = 2.0 * 1000 aln . params [ 'sigma_ou' ] = 0.0 Let's fix the input to the inhibitory population: aln . params [ 'mui_ext_mean' ] = 0.5 We draw a one-dimensional bifurcation diagram, so it is enough to loop through different values of mue_ext_mean and record the minimum and maximum of the rate for each parameter. max_rate_e = [] min_rate_e = [] # these are the different input values that we want to scan mue_inputs = np . linspace ( 0 , 2 , 50 ) for mue in mue_inputs : # Note: this has to be a vector since it is input for all nodes # (but we have only one node in this example) aln . params [ 'mue_ext_mean' ] = mue aln . run () # we add the maximum and the minimum of the last second of the # simulation to a list max_rate_e . append ( np . max ( aln . output [ 0 , - int ( 1000 / aln . params [ 'dt' ]):])) min_rate_e . append ( np . min ( aln . output [ 0 , - int ( 1000 / aln . params [ 'dt' ]):])) Let's plot the results! plt . plot ( mue_inputs , max_rate_e , c = 'k' , lw = 2 ) plt . plot ( mue_inputs , min_rate_e , c = 'k' , lw = 2 ) plt . title ( \"Bifurcation diagram of the aln model\" ) plt . xlabel ( \"Input to excitatory population\" ) plt . ylabel ( \"Min / max firing rate\" ) Text(0, 0.5, 'Min / max firing rate') Whole-brain model neurolib comes with some example datasets for exploring its functionality. Please be aware that these datasets are not tested and should not be used for your research, only for experimentation with the software. A dataset for whole-brain modeling can consists of the following parts: A structural connectivity matrix capturing the synaptic connection strengths between brain areas, often derived from DTI tractography of the whole brain. The connectome is then typically parcellated in a preferred atlas (for exapmle the AAL2 atlas) and the number of axonal fibers connecting each brain area with every other area is counted. This number serves as a indication of the synaptic coupling strengths between the areas of the brain. A delay matrix which can be calculated from the average length of the axonal fibers connecting each brain area with another. A set of functional data that can act as a target for model optimization. Resting-state fMRI offers an easy and fairly unbiased way for calibrating whole-brain models. EEG data could be used as well. We can load a Dataset by passing the name of it in the constructor. from neurolib.utils.loadData import Dataset ds = Dataset ( \"gw\" ) We now create the aln model with a structural connectivity matrix and a delay matrix. In order to achieve a good fit of the BOLD activity to the empirical data, the model has to run for quite a while. A a rule of thumb, a simulation of resting-state BOLD activity should not be shorter than 3 minutes and preferrably longer than 5 minutes real time. If the empirical recordings are for example 10 minues long, ideally, a simulation of 10 minutes would be used to compare the output of the model to the resting state recording. aln = ALNModel ( Cmat = ds . Cmat , Dmat = ds . Dmat ) aln . params [ 'duration' ] = 0.2 * 60 * 1000 # Info: value 0.2*60*1000 is low for testing # use 5*60*1000 for real simulation After some optimization to the resting-state fMRI data of the dataset, we found a set of parameters that creates interesting whole-brain dynamics. We set the mean input of the excitatory and the inhibitory population to be close to the E-I limit cycle. aln . params [ 'mue_ext_mean' ] = 1.57 aln . params [ 'mui_ext_mean' ] = 1.6 # We set an appropriate level of noise aln . params [ 'sigma_ou' ] = 0.09 # And turn on adaptation with a low value of spike-triggered adaptation currents. aln . params [ 'b' ] = 5.0 Let's have a look what the data looks like. We can access the data of each model by calling its internal attrivbutes. Here, we plot the structural connectivity matrix by calling aln.params['Cmat'] and fiber length matrix by calling aln.params['lengthMat'] . Of course, we can also access the dataset using the Dataset object itself. For example the functional conencity matrices of the BOLD timeseries in the datasets are given as list with ds.FCs . from matplotlib.colors import LogNorm fig , axs = plt . subplots ( 1 , 3 , figsize = ( 12 , 8 ), dpi = 75 ) fig . subplots_adjust ( wspace = 0.28 ) im = axs [ 0 ] . imshow ( aln . params [ 'Cmat' ], norm = LogNorm ( vmin = 10e-5 , vmax = np . max ( aln . params [ 'Cmat' ]))) axs [ 0 ] . set_title ( \"Cmat\" ) fig . colorbar ( im , ax = axs [ 0 ], fraction = 0.046 , pad = 0.04 ) im = axs [ 1 ] . imshow ( aln . params [ 'lengthMat' ], cmap = 'inferno' ) axs [ 1 ] . set_title ( \"Dmat\" ) fig . colorbar ( im , ax = axs [ 1 ], fraction = 0.046 , pad = 0.04 ) im = axs [ 2 ] . imshow ( ds . FCs [ 0 ], cmap = 'inferno' ) axs [ 2 ] . set_title ( \"Empirical FC\" ) fig . colorbar ( im , ax = axs [ 2 ], fraction = 0.046 , pad = 0.04 ) <matplotlib.colorbar.Colorbar at 0x12c0ac5c0> Run model We run the model with bold simulation by using bold=True . This simulates the Balloon-Windkessel BOLD model in parallel to the neural population model in order to estimate the blood oxigen levels of the underlying neural activity. The output of the bold model can be used to compare the simulated data to empirical fMRI data (resting-state fMRI for example). To save (a lot of) RAM, we can run the simulation in chunkwise mode. In this mode, the model will be simulated for a length of chunksize steps (not time in ms, but actual integration steps!), and the output of that chunk will be used to automatically reinitiate the model with the appropriate initial conditions. This allows for a serial continuation of the model without having to store all the data in memory and is particularly useful for very long and many parallel simulations. aln . run ( chunkwise = True , chunksize = 100000 , bold = True ) Results The outputs of the model can be accessed using the attribute model.outputs aln . outputs {'t': array([0.000e+00, 1.000e-01, 2.000e-01, ..., 9.598e+02, 9.599e+02, 9.600e+02]), 'rates_exc': array([[0.00835719, 0.00840018, 0.008441 , ..., 0.07789972, 0.07678947, 0.07575822]]), 'rates_inh': array([[6.67987791, 6.74212832, 6.82498266, ..., 9.74761859, 9.76436539, 9.75417725]]), 'BOLD': {'t': array([1.00000e-01, 2.00010e+03, 4.00010e+03, 6.00010e+03, 8.00010e+03, 1.00001e+04, 1.20001e+04, 1.40001e+04, 1.60001e+04, 1.80001e+04, 2.00001e+04, 2.20001e+04, 2.40001e+04]), 'BOLD': array([[1.37324205e-10, 2.32894551e-02, 2.52461497e-02, 1.57354848e-02, 9.56109432e-03, 1.05825534e-02, 1.12229272e-02, 1.22928019e-02, 1.53881680e-02, 1.50792887e-02, 1.27970412e-02, 1.30106312e-02, 1.40587017e-02]])}} For convenience, they can also be accessed directly using attributes of the model with the outputs name, like aln.rates_exc . The outputs are also available as xr DataArrays as aln.xr() . The since we used bold=True to simulate BOLD, we can also access aln.BOLD.BOLD for the actual BOLD activity, and aln.BOLD.t for the time steps of the BOLD simulation (which are downsampled to 0.5 Hz by default). Plot simulated activity # Plot functional connectivity and BOLD timeseries (z-scored) fig , axs = plt . subplots ( 1 , 2 , figsize = ( 6 , 2 ), dpi = 75 , gridspec_kw = { 'width_ratios' : [ 1 , 2 ]}) axs [ 0 ] . imshow ( func . fc ( aln . BOLD . BOLD [:, 5 :])) axs [ 1 ] . imshow ( scipy . stats . mstats . zscore ( aln . BOLD . BOLD [:, aln . BOLD . t_BOLD > 10000 ], axis = 1 ), aspect = 'auto' , extent = [ aln . BOLD . t_BOLD [ aln . BOLD . t_BOLD > 10000 ][ 0 ], aln . BOLD . t_BOLD [ - 1 ], 0 , aln . params [ 'N' ]]); axs [ 0 ] . set_title ( \"FC\" ) axs [ 0 ] . set_xlabel ( \"Node\" ) axs [ 0 ] . set_ylabel ( \"Node\" ) axs [ 1 ] . set_xlabel ( \"t [ms]\" ) # the results of the model are also accesible through an xarray DataArray fig , axs = plt . subplots ( 1 , 1 , figsize = ( 6 , 2 ), dpi = 75 ) plt . plot ( aln . xr () . time , aln . xr () . loc [ 'rates_exc' ] . T ); Correlation of simulated BOLD to empirical data We can compute the element-wise Pearson correlation of the functional connectivity matrices of the simulated data to the empirical data to estimate how well the model captures the inter-areal BOLD correlations found in empirical resting-state recordings. scores = [ func . matrix_correlation ( func . fc ( aln . BOLD . BOLD [:, 5 :]), fcemp ) for fcemp in ds . FCs ] print ( \"Correlation per subject:\" , [ f \" { s : .2 } \" for s in scores ]) print ( f \"Mean FC/FC correlation: { np . mean ( scores ) : .2 } \" ) Correlation per subject: ['0.52', '0.54', '0.67', '0.49', '0.69'] Mean FC/FC correlation: 0.58","title":"Example 0 aln minimal"},{"location":"examples/example-0-aln-minimal/#the-neural-mass-model","text":"In this example, we will learn about the basic of neurolib . We will create a two-population mean-field model of exponential integrate-and-fire neurons called the aln model. We will learn how to create a Model , set some parameters and run a simulation. We will also see how we can easily access the output of each simulation.","title":"The neural mass model"},{"location":"examples/example-0-aln-minimal/#aln-the-adaptive-linear-nonlinear-cascade-model","text":"The adaptive linear-nonlinear ( aln ) cascade model is a low-dimensional population model of spiking neural networks. Mathematically, it is a dynamical system of non-linear ODEs. The dynamical variables of the system simulated in the aln model describe the average firing rate and other macroscopic variables of a randomly connected, delay-coupled network of excitatory and inhibitory adative exponential integrate-and-fire neurons (AdEx) with non-linear synaptic currents. Ultimately, the model is a result of various steps of model reduction starting from the Fokker-Planck equation of the AdEx neuron subject to white noise input at many steps of input means \\(\\mu\\) and variances \\(\\sigma\\) . The resulting mean firing rates and mean membrane potentials are then stored in a lookup table and serve as the nonlinear firing rate transfer function, \\(r = \\Phi(\\mu, \\sigma)\\) .","title":"aln - the adaptive linear-nonlinear cascade model"},{"location":"examples/example-0-aln-minimal/#basic-use","text":"# change to the root directory of the project import os if os . getcwd () . split ( \"/\" )[ - 1 ] == \"examples\" : os . chdir ( '..' ) # This will reload all imports as soon as the code changes % load_ext autoreload % autoreload 2 try : import matplotlib.pyplot as plt except ImportError : import sys ! { sys . executable } - m pip install matplotlib import matplotlib.pyplot as plt import numpy as np import scipy # Let's import the aln model from neurolib.models.aln import ALNModel # Some useful functions are provided here import neurolib.utils.functions as func # a nice color map plt . rcParams [ 'image.cmap' ] = 'plasma'","title":"Basic use"},{"location":"examples/example-0-aln-minimal/#simulating-a-single-aln-node","text":"To create a single node, we simply instanciate the model without any arguments. # Create the model aln = ALNModel () # Each model comes with a set of default parameters which are are a dictionary. # Let's change the parameter that controls the duration of a simulation to 10s. aln . params [ 'duration' ] = 10.0 * 1000 # For convenience, we could also use: aln . params . duration = 10.0 * 1000 # In the aln model an Ornstein-Uhlenbeck process is simulated in parallel # as the source of input noise fluctuations. Here we can set the variance # of the process. # For more info: https://en.wikipedia.org/wiki/Ornstein%E2%80%93Uhlenbeck_process # Let's add some noise. aln . params [ 'sigma_ou' ] = 0.1 # Finally, we run the model aln . run ()","title":"Simulating a single aln node"},{"location":"examples/example-0-aln-minimal/#accessing-the-outputs","text":"Accessing the outputs is straight-forward. Every model's outputs are stored in the model.outputs attribute. According to the specific name of each of the model's outputs, they can also be accessed as a key of the Model object, i.e. aln['rates_exc'] . plt . plot ( aln [ 't' ], aln [ 'rates_exc' ] . T , lw = 2 , c = 'k' ) plt . xlabel ( \"t [ms]\" ) plt . ylabel ( \"Rate [Hz]\" ) plt . xlim ( 1000 , 2000 ); # Outputs are also available as an xr DataArray xr = aln . xr () print ( xr . dims ) # outputs can also be accessed via attributes in dot.notation print ( \"rates_exc\" , aln . rates_exc ) ('output', 'space', 'time') rates_exc [[0.54644307 0.48676051 0.43664265 ... 0.06910043 0.06969732 0.07031085]]","title":"Accessing the outputs"},{"location":"examples/example-0-aln-minimal/#bifurcation-diagram","text":"Bifurcation diagrams can give us an overview of how different parameters of the model affect its dynamics. The simplest method for drawing a bifurcation diagram is to simply change relevant parameters step by step and record the model's behavior in response to these changes. In this example, we want to see how the model's dynamics changes with respect to the external input currents to the excitatory population. These input currents could be due to couplings with other nodes in a brain network or we could model other factors like external electrical stimulation. Below, you can see a schematic of the aln model. As you can see, a single node consists of one excitatory (red) and one inhibitory population (blue). The parameter that controls the mean input to the excitatory population is \\(\\mu_{E}\\) or aln.params[\"mue_ext_mean\"] . Let's first decrease the duration of a single run so we can scan the parameter space a bit faster and let's also disable the noisy input. aln . params [ 'duration' ] = 2.0 * 1000 aln . params [ 'sigma_ou' ] = 0.0 Let's fix the input to the inhibitory population: aln . params [ 'mui_ext_mean' ] = 0.5 We draw a one-dimensional bifurcation diagram, so it is enough to loop through different values of mue_ext_mean and record the minimum and maximum of the rate for each parameter. max_rate_e = [] min_rate_e = [] # these are the different input values that we want to scan mue_inputs = np . linspace ( 0 , 2 , 50 ) for mue in mue_inputs : # Note: this has to be a vector since it is input for all nodes # (but we have only one node in this example) aln . params [ 'mue_ext_mean' ] = mue aln . run () # we add the maximum and the minimum of the last second of the # simulation to a list max_rate_e . append ( np . max ( aln . output [ 0 , - int ( 1000 / aln . params [ 'dt' ]):])) min_rate_e . append ( np . min ( aln . output [ 0 , - int ( 1000 / aln . params [ 'dt' ]):])) Let's plot the results! plt . plot ( mue_inputs , max_rate_e , c = 'k' , lw = 2 ) plt . plot ( mue_inputs , min_rate_e , c = 'k' , lw = 2 ) plt . title ( \"Bifurcation diagram of the aln model\" ) plt . xlabel ( \"Input to excitatory population\" ) plt . ylabel ( \"Min / max firing rate\" ) Text(0, 0.5, 'Min / max firing rate')","title":"Bifurcation diagram"},{"location":"examples/example-0-aln-minimal/#whole-brain-model","text":"neurolib comes with some example datasets for exploring its functionality. Please be aware that these datasets are not tested and should not be used for your research, only for experimentation with the software. A dataset for whole-brain modeling can consists of the following parts: A structural connectivity matrix capturing the synaptic connection strengths between brain areas, often derived from DTI tractography of the whole brain. The connectome is then typically parcellated in a preferred atlas (for exapmle the AAL2 atlas) and the number of axonal fibers connecting each brain area with every other area is counted. This number serves as a indication of the synaptic coupling strengths between the areas of the brain. A delay matrix which can be calculated from the average length of the axonal fibers connecting each brain area with another. A set of functional data that can act as a target for model optimization. Resting-state fMRI offers an easy and fairly unbiased way for calibrating whole-brain models. EEG data could be used as well. We can load a Dataset by passing the name of it in the constructor. from neurolib.utils.loadData import Dataset ds = Dataset ( \"gw\" ) We now create the aln model with a structural connectivity matrix and a delay matrix. In order to achieve a good fit of the BOLD activity to the empirical data, the model has to run for quite a while. A a rule of thumb, a simulation of resting-state BOLD activity should not be shorter than 3 minutes and preferrably longer than 5 minutes real time. If the empirical recordings are for example 10 minues long, ideally, a simulation of 10 minutes would be used to compare the output of the model to the resting state recording. aln = ALNModel ( Cmat = ds . Cmat , Dmat = ds . Dmat ) aln . params [ 'duration' ] = 0.2 * 60 * 1000 # Info: value 0.2*60*1000 is low for testing # use 5*60*1000 for real simulation After some optimization to the resting-state fMRI data of the dataset, we found a set of parameters that creates interesting whole-brain dynamics. We set the mean input of the excitatory and the inhibitory population to be close to the E-I limit cycle. aln . params [ 'mue_ext_mean' ] = 1.57 aln . params [ 'mui_ext_mean' ] = 1.6 # We set an appropriate level of noise aln . params [ 'sigma_ou' ] = 0.09 # And turn on adaptation with a low value of spike-triggered adaptation currents. aln . params [ 'b' ] = 5.0 Let's have a look what the data looks like. We can access the data of each model by calling its internal attrivbutes. Here, we plot the structural connectivity matrix by calling aln.params['Cmat'] and fiber length matrix by calling aln.params['lengthMat'] . Of course, we can also access the dataset using the Dataset object itself. For example the functional conencity matrices of the BOLD timeseries in the datasets are given as list with ds.FCs . from matplotlib.colors import LogNorm fig , axs = plt . subplots ( 1 , 3 , figsize = ( 12 , 8 ), dpi = 75 ) fig . subplots_adjust ( wspace = 0.28 ) im = axs [ 0 ] . imshow ( aln . params [ 'Cmat' ], norm = LogNorm ( vmin = 10e-5 , vmax = np . max ( aln . params [ 'Cmat' ]))) axs [ 0 ] . set_title ( \"Cmat\" ) fig . colorbar ( im , ax = axs [ 0 ], fraction = 0.046 , pad = 0.04 ) im = axs [ 1 ] . imshow ( aln . params [ 'lengthMat' ], cmap = 'inferno' ) axs [ 1 ] . set_title ( \"Dmat\" ) fig . colorbar ( im , ax = axs [ 1 ], fraction = 0.046 , pad = 0.04 ) im = axs [ 2 ] . imshow ( ds . FCs [ 0 ], cmap = 'inferno' ) axs [ 2 ] . set_title ( \"Empirical FC\" ) fig . colorbar ( im , ax = axs [ 2 ], fraction = 0.046 , pad = 0.04 ) <matplotlib.colorbar.Colorbar at 0x12c0ac5c0>","title":"Whole-brain model"},{"location":"examples/example-0-aln-minimal/#run-model","text":"We run the model with bold simulation by using bold=True . This simulates the Balloon-Windkessel BOLD model in parallel to the neural population model in order to estimate the blood oxigen levels of the underlying neural activity. The output of the bold model can be used to compare the simulated data to empirical fMRI data (resting-state fMRI for example). To save (a lot of) RAM, we can run the simulation in chunkwise mode. In this mode, the model will be simulated for a length of chunksize steps (not time in ms, but actual integration steps!), and the output of that chunk will be used to automatically reinitiate the model with the appropriate initial conditions. This allows for a serial continuation of the model without having to store all the data in memory and is particularly useful for very long and many parallel simulations. aln . run ( chunkwise = True , chunksize = 100000 , bold = True )","title":"Run model"},{"location":"examples/example-0-aln-minimal/#results","text":"The outputs of the model can be accessed using the attribute model.outputs aln . outputs {'t': array([0.000e+00, 1.000e-01, 2.000e-01, ..., 9.598e+02, 9.599e+02, 9.600e+02]), 'rates_exc': array([[0.00835719, 0.00840018, 0.008441 , ..., 0.07789972, 0.07678947, 0.07575822]]), 'rates_inh': array([[6.67987791, 6.74212832, 6.82498266, ..., 9.74761859, 9.76436539, 9.75417725]]), 'BOLD': {'t': array([1.00000e-01, 2.00010e+03, 4.00010e+03, 6.00010e+03, 8.00010e+03, 1.00001e+04, 1.20001e+04, 1.40001e+04, 1.60001e+04, 1.80001e+04, 2.00001e+04, 2.20001e+04, 2.40001e+04]), 'BOLD': array([[1.37324205e-10, 2.32894551e-02, 2.52461497e-02, 1.57354848e-02, 9.56109432e-03, 1.05825534e-02, 1.12229272e-02, 1.22928019e-02, 1.53881680e-02, 1.50792887e-02, 1.27970412e-02, 1.30106312e-02, 1.40587017e-02]])}} For convenience, they can also be accessed directly using attributes of the model with the outputs name, like aln.rates_exc . The outputs are also available as xr DataArrays as aln.xr() . The since we used bold=True to simulate BOLD, we can also access aln.BOLD.BOLD for the actual BOLD activity, and aln.BOLD.t for the time steps of the BOLD simulation (which are downsampled to 0.5 Hz by default).","title":"Results"},{"location":"examples/example-0-aln-minimal/#plot-simulated-activity","text":"# Plot functional connectivity and BOLD timeseries (z-scored) fig , axs = plt . subplots ( 1 , 2 , figsize = ( 6 , 2 ), dpi = 75 , gridspec_kw = { 'width_ratios' : [ 1 , 2 ]}) axs [ 0 ] . imshow ( func . fc ( aln . BOLD . BOLD [:, 5 :])) axs [ 1 ] . imshow ( scipy . stats . mstats . zscore ( aln . BOLD . BOLD [:, aln . BOLD . t_BOLD > 10000 ], axis = 1 ), aspect = 'auto' , extent = [ aln . BOLD . t_BOLD [ aln . BOLD . t_BOLD > 10000 ][ 0 ], aln . BOLD . t_BOLD [ - 1 ], 0 , aln . params [ 'N' ]]); axs [ 0 ] . set_title ( \"FC\" ) axs [ 0 ] . set_xlabel ( \"Node\" ) axs [ 0 ] . set_ylabel ( \"Node\" ) axs [ 1 ] . set_xlabel ( \"t [ms]\" ) # the results of the model are also accesible through an xarray DataArray fig , axs = plt . subplots ( 1 , 1 , figsize = ( 6 , 2 ), dpi = 75 ) plt . plot ( aln . xr () . time , aln . xr () . loc [ 'rates_exc' ] . T );","title":"Plot simulated activity"},{"location":"examples/example-0-aln-minimal/#correlation-of-simulated-bold-to-empirical-data","text":"We can compute the element-wise Pearson correlation of the functional connectivity matrices of the simulated data to the empirical data to estimate how well the model captures the inter-areal BOLD correlations found in empirical resting-state recordings. scores = [ func . matrix_correlation ( func . fc ( aln . BOLD . BOLD [:, 5 :]), fcemp ) for fcemp in ds . FCs ] print ( \"Correlation per subject:\" , [ f \" { s : .2 } \" for s in scores ]) print ( f \"Mean FC/FC correlation: { np . mean ( scores ) : .2 } \" ) Correlation per subject: ['0.52', '0.54', '0.67', '0.49', '0.69'] Mean FC/FC correlation: 0.58","title":"Correlation of simulated BOLD to empirical data"},{"location":"examples/example-0.1-hopf-minimal/","text":"(function() { function addWidgetsRenderer() { var requireJsScript = document.createElement('script'); requireJsScript.src = 'https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js'; var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var jupyterWidgetsScript = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} jupyterWidgetsScript.src = widgetRendererSrc; document.body.appendChild(requireJsScript); document.body.appendChild(jupyterWidgetsScript); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); # change to the root directory of the project import os if os . getcwd () . split ( \"/\" )[ - 1 ] == \"examples\" : os . chdir ( '..' ) % load_ext autoreload % autoreload 2 try : import matplotlib.pyplot as plt except ImportError : import sys ! { sys . executable } - m pip install matplotlib import matplotlib.pyplot as plt import numpy as np # Let's import the hopf model from neurolib.models.hopf import HopfModel # Some useful functions are provided here import neurolib.utils.functions as func # a nice color map plt . rcParams [ 'image.cmap' ] = 'plasma' Single node simulation hopf = HopfModel () hopf . params [ 'duration' ] = 1.0 * 1000 hopf . params [ 'sigma_ou' ] = 0.03 hopf . run () plt . plot ( hopf . t , hopf . x . T , c = 'k' , lw = 2 ) # alternatively plot the results in the xarray: # plt.plot(hopfModel.xr[0, 0].time, hopfModel.xr[0, 0].values) plt . xlabel ( \"t [ms]\" ) plt . ylabel ( \"Activity\" ) Text(0, 0.5, 'Activity') Bifurcation diagram hopf = HopfModel () hopf . params [ 'duration' ] = 2.0 * 1000 max_x = [] min_x = [] # these are the different input values that we want to scan a_s = np . linspace ( - 2 , 2 , 50 ) for a in a_s : hopf . params [ 'a' ] = a hopf . run () # we add the maximum and the minimum of the last second of the # simulation to a list max_x . append ( np . max ( hopf . x [ 0 , - int ( 1000 / hopf . params [ 'dt' ]):])) min_x . append ( np . min ( hopf . x [ 0 , - int ( 1000 / hopf . params [ 'dt' ]):])) plt . plot ( a_s , max_x , c = 'k' , lw = 2 ) plt . plot ( a_s , min_x , c = 'k' , lw = 2 ) plt . title ( \"Bifurcation diagram of the Hopf oscillator\" ) plt . xlabel ( \"a\" ) plt . ylabel ( \"Min / max x\" ) Text(0, 0.5, 'Min / max x') Brain network from neurolib.utils.loadData import Dataset ds = Dataset ( \"hcp\" ) hopf = HopfModel ( Cmat = ds . Cmat , Dmat = ds . Dmat ) hopf . params [ 'w' ] = 1.0 hopf . params [ 'signalV' ] = 0 hopf . params [ 'duration' ] = 20 * 1000 hopf . params [ 'sigma_ou' ] = 0.14 hopf . params [ 'K_gl' ] = 0.6 hopf . run ( chunkwise = True ) plt . plot ( hopf . t , hopf . x [:: 5 , :] . T , alpha = 0.8 ); plt . xlim ( 0 , 200 ) plt . xlabel ( \"t [ms]\" ) Text(0.5, 0, 't [ms]') fig , axs = plt . subplots ( 1 , 2 , figsize = ( 8 , 2 )) axs [ 0 ] . imshow ( func . fc ( hopf . x [:, - 10000 :])) axs [ 1 ] . plot ( hopf . t , hopf . x [:: 5 , :] . T , alpha = 0.8 ); scores = [ func . matrix_correlation ( func . fc ( hopf . x [:, - int ( 5000 / hopf . params [ 'dt' ]):]), fcemp ) for fcemp in ds . FCs ] print ( \"Correlation per subject:\" , [ f \" { s : .2 } \" for s in scores ]) print ( \"Mean FC/FC correlation: {:.2f} \" . format ( np . mean ( scores ))) Correlation per subject: ['0.54', '0.63', '0.66', '0.53', '0.55', '0.55', '0.69'] Mean FC/FC correlation: 0.59","title":"Example 0.1 hopf minimal"},{"location":"examples/example-0.1-hopf-minimal/#single-node-simulation","text":"hopf = HopfModel () hopf . params [ 'duration' ] = 1.0 * 1000 hopf . params [ 'sigma_ou' ] = 0.03 hopf . run () plt . plot ( hopf . t , hopf . x . T , c = 'k' , lw = 2 ) # alternatively plot the results in the xarray: # plt.plot(hopfModel.xr[0, 0].time, hopfModel.xr[0, 0].values) plt . xlabel ( \"t [ms]\" ) plt . ylabel ( \"Activity\" ) Text(0, 0.5, 'Activity')","title":"Single node simulation"},{"location":"examples/example-0.1-hopf-minimal/#bifurcation-diagram","text":"hopf = HopfModel () hopf . params [ 'duration' ] = 2.0 * 1000 max_x = [] min_x = [] # these are the different input values that we want to scan a_s = np . linspace ( - 2 , 2 , 50 ) for a in a_s : hopf . params [ 'a' ] = a hopf . run () # we add the maximum and the minimum of the last second of the # simulation to a list max_x . append ( np . max ( hopf . x [ 0 , - int ( 1000 / hopf . params [ 'dt' ]):])) min_x . append ( np . min ( hopf . x [ 0 , - int ( 1000 / hopf . params [ 'dt' ]):])) plt . plot ( a_s , max_x , c = 'k' , lw = 2 ) plt . plot ( a_s , min_x , c = 'k' , lw = 2 ) plt . title ( \"Bifurcation diagram of the Hopf oscillator\" ) plt . xlabel ( \"a\" ) plt . ylabel ( \"Min / max x\" ) Text(0, 0.5, 'Min / max x')","title":"Bifurcation diagram"},{"location":"examples/example-0.1-hopf-minimal/#brain-network","text":"from neurolib.utils.loadData import Dataset ds = Dataset ( \"hcp\" ) hopf = HopfModel ( Cmat = ds . Cmat , Dmat = ds . Dmat ) hopf . params [ 'w' ] = 1.0 hopf . params [ 'signalV' ] = 0 hopf . params [ 'duration' ] = 20 * 1000 hopf . params [ 'sigma_ou' ] = 0.14 hopf . params [ 'K_gl' ] = 0.6 hopf . run ( chunkwise = True ) plt . plot ( hopf . t , hopf . x [:: 5 , :] . T , alpha = 0.8 ); plt . xlim ( 0 , 200 ) plt . xlabel ( \"t [ms]\" ) Text(0.5, 0, 't [ms]') fig , axs = plt . subplots ( 1 , 2 , figsize = ( 8 , 2 )) axs [ 0 ] . imshow ( func . fc ( hopf . x [:, - 10000 :])) axs [ 1 ] . plot ( hopf . t , hopf . x [:: 5 , :] . T , alpha = 0.8 ); scores = [ func . matrix_correlation ( func . fc ( hopf . x [:, - int ( 5000 / hopf . params [ 'dt' ]):]), fcemp ) for fcemp in ds . FCs ] print ( \"Correlation per subject:\" , [ f \" { s : .2 } \" for s in scores ]) print ( \"Mean FC/FC correlation: {:.2f} \" . format ( np . mean ( scores ))) Correlation per subject: ['0.54', '0.63', '0.66', '0.53', '0.55', '0.55', '0.69'] Mean FC/FC correlation: 0.59","title":"Brain network"},{"location":"examples/example-0.2-basic_analysis/","text":"(function() { function addWidgetsRenderer() { var requireJsScript = document.createElement('script'); requireJsScript.src = 'https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js'; var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var jupyterWidgetsScript = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} jupyterWidgetsScript.src = widgetRendererSrc; document.body.appendChild(requireJsScript); document.body.appendChild(jupyterWidgetsScript); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); Introduction # change to the root directory of the project import os if os . getcwd () . split ( \"/\" )[ - 1 ] == \"examples\" : os . chdir ( '..' ) # This will reload all imports as soon as the code changes % load_ext autoreload % autoreload 2 try : import matplotlib.pyplot as plt except ImportError : import sys ! { sys . executable } - m pip install matplotlib import matplotlib.pyplot as plt from functools import partial import numpy as np from neurolib.models.aln import ALNModel from neurolib.utils.loadData import Dataset from neurolib.utils.signal import RatesSignal , BOLDSignal plt . rcParams [ 'image.cmap' ] = 'plasma' Run the ALN model Firstly, let us run a network model given the structural connectivity and fiber lengths. ds = Dataset ( \"gw\" ) # simulates the whole-brain model aln = ALNModel ( Cmat = ds . Cmat , Dmat = ds . Dmat ) # Resting state fits aln . params [ 'mue_ext_mean' ] = 1.57 aln . params [ 'mui_ext_mean' ] = 1.6 aln . params [ 'sigma_ou' ] = 0.09 aln . params [ 'b' ] = 5.0 aln . params [ 'duration' ] = 0.2 * 60 * 1000 # info: value 0.2*60*1000 is low for testing # use 5*60*1000 for real simulation aln . run ( chunkwise = True , bold = True ) WARNING:root:aln: BOLD simulation is supported only with chunkwise integration. Enabling chunkwise integration. Now we can cast the modelling result into our Signal class. Signal is a parent base class for any neuro signal. We also provide three child class for particular signals: RatesSignal (for firing rate of the populations), VoltageSignal (for average membrane potential of the populations), and BOLDSignal (for simulated BOLD). They only differ in name, labels and units. Nothing fancy. Of course, you can implement your own class for your particular results very easily as: from neurolib.utils.signal import Signal class PostSynapticCurrentSignal ( Signal ): name = \"Population post-synaptic current signal\" label = \"I_syn\" signal_type = \"post_current\" unit = \"mA\" and that's it. All useful methods and attributes are directly inhereted from the Signal parent. # Create Signal out of firing rates fr = RatesSignal . from_model_output ( aln , group = \"\" , time_in_ms = True ) # optional description fr . description = \"Output of the ALN model with default SC and fiber lengths\" # Create Signal out of BOLD simulated timeseries bold = BOLDSignal . from_model_output ( aln , group = \"BOLD\" , time_in_ms = True ) bold . description = \"Simulated BOLD of the ALN model with default SC and fiber lengths\" # let's check what's inside print ( fr ) print ( bold ) Population firing rate representing rate signal with unit of Hz with user-provided description: `Output of the ALN model with default SC and fiber lengths`. Shape of the signal is (2, 80, 8831) with dimensions ('output', 'space', 'time'). Population blood oxygen level-dependent signal representing bold signal with unit of % with user-provided description: `Simulated BOLD of the ALN model with default SC and fiber lengths`. Shape of the signal is (1, 80, 7) with dimensions ('output', 'space', 'time'). Signal automatically computes useful attributes like dt , sampling rate, starting and ending times. # inherent attributes print ( \"Inherent attributes:\" ) print ( fr . name ) print ( fr . label ) print ( fr . unit ) print ( fr . signal_type ) print ( fr . description ) # computed attributes print ( \" \\n Computed attributes:\" ) print ( fr . dt ) print ( fr . sampling_frequency ) print ( fr . start_time ) print ( fr . end_time ) print ( fr . shape ) Inherent attributes: Population firing rate q Hz rate Output of the ALN model with default SC and fiber lengths Computed attributes: 0.0001 10000.0 0.0 0.883 (2, 80, 8831) # internal representation of the signal is just xarray's DataArray print ( fr . data ) # xarray is just pandas on steroids, i.e. it supports multi-dimensional arrays, not only 2D # if you'd need simple numpy array just call .values on signal's data print ( type ( fr . data . values )) print ( fr . data . values . shape ) <xarray.DataArray (output: 2, space: 80, time: 8831)> array([[[1.33261450e-02, 1.36917651e-02, 1.40695947e-02, ..., 3.48158384e-03, 3.46784876e-03, 3.46133411e-03], [6.13965587e-01, 6.25356604e-01, 6.34768740e-01, ..., 3.59993904e-01, 3.54528049e-01, 3.49018287e-01], [6.36038906e-02, 6.35557804e-02, 6.33770702e-02, ..., 4.42949449e-02, 4.37566338e-02, 4.32171260e-02], ..., [2.50859629e-03, 2.52563325e-03, 2.54037707e-03, ..., 8.00547429e-03, 7.78636724e-03, 7.61333390e-03], [5.95617787e-02, 6.07513850e-02, 6.20942706e-02, ..., 3.26872805e-02, 3.33536801e-02, 3.40569905e-02], [4.96090615e-02, 4.84730168e-02, 4.73428175e-02, ..., 1.05820581e-01, 1.05724932e-01, 1.05846529e-01]], [[4.17821712e+00, 4.21196680e+00, 4.23883558e+00, ..., 1.01836901e+01, 1.00264571e+01, 9.86191716e+00], [6.83616353e+00, 6.91560104e+00, 6.97566672e+00, ..., 8.07743197e+00, 8.08297235e+00, 8.07994833e+00], [6.57108005e+00, 6.49135703e+00, 6.43050397e+00, ..., 8.93701663e+00, 8.95484465e+00, 8.97588108e+00], ..., [8.75902323e+00, 8.81787556e+00, 8.89506320e+00, ..., 7.48694404e+00, 7.41863238e+00, 7.35970182e+00], [4.15841271e+00, 4.15037911e+00, 4.15057015e+00, ..., 6.61282248e+00, 6.60115808e+00, 6.58597805e+00], [9.52609773e+00, 9.39861579e+00, 9.28794497e+00, ..., 5.83291993e+00, 5.90070345e+00, 5.94592106e+00]]]) Coordinates: * output (output) <U9 'rates_exc' 'rates_inh' * space (space) int64 0 1 2 3 4 5 6 7 8 9 ... 70 71 72 73 74 75 76 77 78 79 * time (time) float64 0.0 0.0001 0.0002 0.0003 ... 0.8828 0.8829 0.883 <class 'numpy.ndarray'> (2, 80, 8831) Now let's see what Signal can do... Just a side note, all operations can be done inplace (everything happens inside signal class), or altered signal is returned with the same attributes as the original one # basic operations norm = fr . normalize ( std = True , inplace = False ) # so, are all temporal means close to zero? print ( np . allclose ( norm . data . mean ( dim = \"time\" ), 0. )) # aand, are all temporal std close to 1? print ( np . allclose ( norm . data . std ( dim = \"time\" ), 1.0 )) plt . plot ( fr [ \"rates_exc\" ] . data . sel ({ \"space\" : 0 }), label = \"original\" ) plt . plot ( norm [ \"rates_exc\" ] . data . sel ({ \"space\" : 0 }), label = \"normalised\" ) # you can detrend the signal, all of it, or by segments (as indices within the signal) # let's first normalise (so inplace=False), then detrend (we can inplace=True) detrended = fr . normalize ( std = True , inplace = False ) detrended . detrend ( inplace = True ) plt . plot ( detrended [ \"rates_exc\" ] . data . sel ({ \"space\" : 0 }), label = \"normalised & detrended\" ) detrended_segments = fr . detrend ( segments = np . arange ( 20000 , 1000 ), inplace = False ) plt . legend () True True <matplotlib.legend.Legend at 0x1301a4320> so, the sampling frequency is too high, let's resample print ( fr . sampling_frequency ) plt . plot ( fr . data . time , fr [ \"rates_exc\" ] . data . sel ({ \"space\" : 0 }), label = \"original\" ) fr . resample ( to_frequency = 1000. , inplace = True ) print ( fr . sampling_frequency ) plt . plot ( fr . data . time , fr [ \"rates_exc\" ] . data . sel ({ \"space\" : 0 }), label = \"resampled\" ) plt . legend () 10000.0 1000.0 <matplotlib.legend.Legend at 0x131e0e940> More complete example Let's do a more complete example. Let's say, you run the model and want to extract phase and amplitude of the \\(\\alpha\\) band (i.e. 8-12Hz) for some phase-amplitude coupling analyses. # init again to start fresh fr = RatesSignal . from_model_output ( aln , group = \"\" , time_in_ms = True ) plt . plot ( fr . data . time , fr [ \"rates_exc\" ] . data . sel ({ \"space\" : 0 }), label = \"original\" ) # first resample fr . resample ( to_frequency = 1000. , inplace = True ) # next detrend fr . detrend ( inplace = True ) print ( fr . start_time , fr . end_time ) # next pad with 0s for 0.5 seconds in order to suppress edge effect when filtering padded = fr . pad ( how_much = 0.5 , in_seconds = True , padding_type = \"constant\" , side = \"both\" , constant_values = 0. , inplace = False ) print ( padded . start_time , padded . end_time ) # now filter - by default uses mne, if not installed, falls back to scipy basic IIR filter padded . filter ( low_freq = 8. , high_freq = 12. , inplace = True ) # now cut back the original length filtered = padded . sel ([ fr . start_time , fr . end_time ], inplace = False ) print ( filtered . start_time , filtered . end_time ) plt . plot ( filtered . data . time , filtered [ \"rates_exc\" ] . data . sel ({ \"space\" : 0 }), label = r \"filtered $\\alpha$\" ) # finally, get phase and amplitude via Hilbert transform phase = filtered . hilbert_transform ( return_as = \"phase_wrapped\" , inplace = False ) plt . plot ( phase . data . time , phase [ \"rates_exc\" ] . data . sel ({ \"space\" : 0 }), label = r \"phase $\\alpha$\" ) amplitude = filtered . hilbert_transform ( return_as = \"amplitude\" , inplace = False ) plt . plot ( amplitude . data . time , amplitude [ \"rates_exc\" ] . data . sel ({ \"space\" : 0 }), label = r \"amplitude $\\alpha$\" ) plt . legend () 0.0 0.882 -0.5 1.382 Setting up band-pass filter from 8 - 12 Hz FIR filter parameters --------------------- Designing a one-pass, zero-phase, non-causal bandpass filter: - Windowed time-domain design (firwin) method - Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation - Lower passband edge: 8.00 - Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 7.00 Hz) - Upper passband edge: 12.00 Hz - Upper transition bandwidth: 3.00 Hz (-6 dB cutoff frequency: 13.50 Hz) - Filter length: 1651 samples (1.651 sec) 0.0 0.882 <matplotlib.legend.Legend at 0x1322e6e80> # in case you forget that happened in the processing, you can easily check all steps: print ( phase . preprocessing_steps ) print ( amplitude . preprocessing_steps ) resample to 1000.0Hz -> detrend -> 0.5s constant both sides padding -> filter: low 8.0Hz - high 12.0Hz -> select x:0.882s -> Hilbert - wrapped phase resample to 1000.0Hz -> detrend -> 0.5s constant both sides padding -> filter: low 8.0Hz - high 12.0Hz -> select x:0.882s -> Hilbert - amplitude Saving / loading # and you can save your signal for future generations! (saved as netCDF file) phase . save ( \"phase_from_some_experiment\" ) # and then load it phase_loaded = RatesSignal . from_file ( \"phase_from_some_experiment\" ) # compare whether it is the same print ( phase == phase_loaded ) # the attributes are saved/loaded as well print ( phase_loaded . name ) print ( phase_loaded . unit ) print ( phase_loaded . preprocessing_steps ) # delete file os . remove ( \"phase_from_some_experiment.nc\" ) True Population firing rate Hz resample to 1000.0Hz -> detrend -> 0.5s constant both sides padding -> filter: low 8.0Hz - high 12.0Hz -> select x:0.882s -> Hilbert - wrapped phase Iterators Sometimes it is useful to apply or see something in a loop. That's why Signal supports both: iterating over space / outputs variables and applying some 1D function over temporal dimensions. # this will iterate over whole data and return one 1D temporal slice at the time, each slice is Signal class for name , ts in fr . iterate ( return_as = \"signal\" ): print ( name , type ( ts ), ts . start_time , ts . end_time ) # this will iterate over whole data and return one 1D temporal slice at the time, each slice is DataArray for name , ts in fr . iterate ( return_as = \"xr\" ): print ( name , type ( ts ), ts . shape , ts . shape ) ('rates_exc', 0) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 1) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 2) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 3) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 4) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 5) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 6) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 7) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 8) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 9) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 10) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 11) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 12) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 13) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 14) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 15) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 16) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 17) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 18) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 19) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 20) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 21) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 22) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 23) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 24) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 25) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 26) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 27) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 28) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 29) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 30) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 31) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 32) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 33) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 34) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 35) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 36) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 37) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 38) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 39) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 40) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 41) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 42) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 43) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 44) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 45) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 46) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 47) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 48) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 49) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 50) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 51) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 52) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 53) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 54) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 55) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 56) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 57) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 58) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 59) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 60) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 61) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 62) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 63) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 64) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 65) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 66) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 67) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 68) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 69) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 70) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 71) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 72) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 73) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 74) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 75) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 76) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 77) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 78) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 79) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 0) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 1) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 2) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 3) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 4) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 5) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 6) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 7) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 8) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 9) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 10) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 11) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 12) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 13) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 14) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 15) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 16) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 17) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 18) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 19) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 20) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 21) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 22) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 23) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 24) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 25) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 26) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 27) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 28) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 29) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 30) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 31) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 32) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 33) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 34) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 35) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 36) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 37) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 38) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 39) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 40) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 41) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 42) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 43) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 44) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 45) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 46) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 47) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 48) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 49) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 50) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 51) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 52) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 53) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 54) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 55) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 56) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 57) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 58) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 59) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 60) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 61) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 62) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 63) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 64) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 65) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 66) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 67) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 68) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 69) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 70) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 71) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 72) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 73) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 74) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 75) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 76) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 77) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 78) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 79) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 0) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 1) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 2) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 3) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 4) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 5) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 6) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 7) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 8) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 9) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 10) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 11) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 12) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 13) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 14) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 15) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 16) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 17) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 18) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 19) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 20) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 21) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 22) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 23) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 24) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 25) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 26) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 27) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 28) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 29) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 30) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 31) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 32) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 33) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 34) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 35) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 36) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 37) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 38) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 39) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 40) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 41) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 42) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 43) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 44) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 45) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 46) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 47) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 48) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 49) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 50) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 51) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 52) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 53) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 54) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 55) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 56) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 57) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 58) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 59) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 60) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 61) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 62) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 63) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 64) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 65) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 66) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 67) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 68) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 69) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 70) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 71) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 72) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 73) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 74) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 75) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 76) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 77) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 78) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 79) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 0) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 1) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 2) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 3) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 4) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 5) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 6) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 7) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 8) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 9) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 10) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 11) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 12) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 13) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 14) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 15) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 16) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 17) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 18) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 19) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 20) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 21) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 22) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 23) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 24) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 25) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 26) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 27) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 28) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 29) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 30) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 31) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 32) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 33) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 34) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 35) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 36) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 37) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 38) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 39) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 40) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 41) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 42) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 43) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 44) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 45) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 46) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 47) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 48) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 49) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 50) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 51) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 52) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 53) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 54) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 55) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 56) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 57) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 58) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 59) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 60) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 61) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 62) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 63) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 64) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 65) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 66) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 67) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 68) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 69) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 70) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 71) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 72) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 73) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 74) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 75) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 76) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 77) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 78) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 79) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) # sliding window - let's iterate over temporal windows of 0.5seconds, with 0.1s translation and boxcar window function for window in fr . sliding_window ( length = 0.5 , step = 0.1 , window_function = \"boxcar\" , lengths_in_seconds = True ): print ( type ( window ), window . shape , window . start_time , window . end_time ) <class 'neurolib.utils.signal.RatesSignal'> (2, 80, 500) 0.0 0.499 <class 'neurolib.utils.signal.RatesSignal'> (2, 80, 500) 0.1 0.599 <class 'neurolib.utils.signal.RatesSignal'> (2, 80, 500) 0.2 0.699 <class 'neurolib.utils.signal.RatesSignal'> (2, 80, 500) 0.3 0.799 # apply 1D function - Signal supports applying 1D function per temporal slice # both are supported: function that reduces temporal dimension (e.g. mean which reduces timeseries of length N to one number), # and functions that preserve shape # reduce mean = fr . apply ( partial ( np . mean , axis =- 1 ), inplace = False ) # mean is now xr.DataArray, not Signal; but the coordinates except time are preserved print ( type ( mean ), mean . shape , mean . coords ) # preserve shape absolute_value = fr . apply ( np . abs , inplace = False ) # still Signal print ( absolute_value . shape ) WARNING:root:Shape changed after operation! Old shape: (2, 80, 883), new shape: (2, 80); Cannot cast to Signal class, returing as `xr.DataArray` <class 'xarray.core.dataarray.DataArray'> (2, 80) Coordinates: * output (output) <U9 'rates_exc' 'rates_inh' * space (space) int64 0 1 2 3 4 5 6 7 8 9 ... 70 71 72 73 74 75 76 77 78 79 (2, 80, 883) Functional connectivity Lot of modelling effort actually goes to fitting the experimental functional connectivity with the modelled one. That's why Signal class supports functional connectivity computation and with other methods (like filtering and iterating over temporal windows) we can even do timeseries of FC or band-specific FC very easily within the couple of lines. # basic FC from excitatory rates - using correlation fc_exc = fr [ \"rates_exc\" ] . functional_connectivity ( fc_function = np . corrcoef ) # results is DataArray with space coordinates print ( type ( fc_exc ), fc_exc . shape , fc_exc . coords ) plt . subplot ( 1 , 2 , 1 ) plt . title ( \"Correlation FC\" ) plt . imshow ( fc_exc . values ) # FC from covariance fc_cov_exc = fr [ \"rates_exc\" ] . functional_connectivity ( fc_function = np . cov ) plt . subplot ( 1 , 2 , 2 ) plt . title ( \"Covariance FC\" ) plt . imshow ( fc_cov_exc . values ) # so fc_function can be any function that can take (nodes x time) array and transform it to (nodes x nodes) connectivity matrix <class 'xarray.core.dataarray.DataArray'> (80, 80) Coordinates: * space (space) int64 0 1 2 3 4 5 6 7 8 9 ... 70 71 72 73 74 75 76 77 78 79 <matplotlib.image.AxesImage at 0x131f1db70> # band-specific FC BANDS = { \"delta\" : { \"low_freq\" : 2 , \"high_freq\" : 4 }, \"theta\" : { \"low_freq\" : 4 , \"high_freq\" : 8 }, \"alpha\" : { \"low_freq\" : 8 , \"high_freq\" : 12 }, \"beta\" : { \"low_freq\" : 12 , \"high_freq\" : 30 }, \"low_gamma\" : { \"low_freq\" : 30 , \"high_freq\" : 60 }, \"high_gamma\" : { \"low_freq\" : 60 , \"high_freq\" : 120 }, } padded = fr . pad ( how_much = 0.5 , in_seconds = True , padding_type = \"constant\" , side = \"both\" , constant_values = 0. , inplace = False ) plt . figure ( figsize = ( 20 , 4 )) for ii , ( band , filt_spec ) in enumerate ( BANDS . items ()): print ( f \"Processing { band } ...\" ) filtered = padded . filter ( ** filt_spec , inplace = False ) filtered . sel ([ fr . start_time , fr . end_time ], inplace = True ) plt . subplot ( 1 , len ( BANDS ), ii + 1 ) fc = filtered [ \"rates_exc\" ] . functional_connectivity ( fc_function = np . corrcoef ) print ( filtered . preprocessing_steps ) plt . imshow ( fc ) plt . title ( f \" { band } : { filt_spec [ 'low_freq' ] } - { filt_spec [ 'high_freq' ] } Hz\" ) plt . show () Processing delta... Setting up band-pass filter from 2 - 4 Hz FIR filter parameters --------------------- Designing a one-pass, zero-phase, non-causal bandpass filter: - Windowed time-domain design (firwin) method - Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation - Lower passband edge: 2.00 - Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 1.00 Hz) - Upper passband edge: 4.00 Hz - Upper transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 5.00 Hz) - Filter length: 1651 samples (1.651 sec) resample to 1000.0Hz -> detrend -> 0.5s constant both sides padding -> filter: low 2Hz - high 4Hz -> select x:0.882s Processing theta... Setting up band-pass filter from 4 - 8 Hz FIR filter parameters --------------------- Designing a one-pass, zero-phase, non-causal bandpass filter: - Windowed time-domain design (firwin) method - Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation - Lower passband edge: 4.00 - Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz) - Upper passband edge: 8.00 Hz - Upper transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 9.00 Hz) - Filter length: 1651 samples (1.651 sec) resample to 1000.0Hz -> detrend -> 0.5s constant both sides padding -> filter: low 4Hz - high 8Hz -> select x:0.882s Processing alpha... Setting up band-pass filter from 8 - 12 Hz FIR filter parameters --------------------- Designing a one-pass, zero-phase, non-causal bandpass filter: - Windowed time-domain design (firwin) method - Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation - Lower passband edge: 8.00 - Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 7.00 Hz) - Upper passband edge: 12.00 Hz - Upper transition bandwidth: 3.00 Hz (-6 dB cutoff frequency: 13.50 Hz) - Filter length: 1651 samples (1.651 sec) resample to 1000.0Hz -> detrend -> 0.5s constant both sides padding -> filter: low 8Hz - high 12Hz -> select x:0.882s Processing beta... Setting up band-pass filter from 12 - 30 Hz FIR filter parameters --------------------- Designing a one-pass, zero-phase, non-causal bandpass filter: - Windowed time-domain design (firwin) method - Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation - Lower passband edge: 12.00 - Lower transition bandwidth: 3.00 Hz (-6 dB cutoff frequency: 10.50 Hz) - Upper passband edge: 30.00 Hz - Upper transition bandwidth: 7.50 Hz (-6 dB cutoff frequency: 33.75 Hz) - Filter length: 1101 samples (1.101 sec) resample to 1000.0Hz -> detrend -> 0.5s constant both sides padding -> filter: low 12Hz - high 30Hz -> select x:0.882s Processing low_gamma... Setting up band-pass filter from 30 - 60 Hz FIR filter parameters --------------------- Designing a one-pass, zero-phase, non-causal bandpass filter: - Windowed time-domain design (firwin) method - Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation - Lower passband edge: 30.00 - Lower transition bandwidth: 7.50 Hz (-6 dB cutoff frequency: 26.25 Hz) - Upper passband edge: 60.00 Hz - Upper transition bandwidth: 15.00 Hz (-6 dB cutoff frequency: 67.50 Hz) - Filter length: 441 samples (0.441 sec) resample to 1000.0Hz -> detrend -> 0.5s constant both sides padding -> filter: low 30Hz - high 60Hz -> select x:0.882s Processing high_gamma... Setting up band-pass filter from 60 - 1.2e+02 Hz FIR filter parameters --------------------- Designing a one-pass, zero-phase, non-causal bandpass filter: - Windowed time-domain design (firwin) method - Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation - Lower passband edge: 60.00 - Lower transition bandwidth: 15.00 Hz (-6 dB cutoff frequency: 52.50 Hz) - Upper passband edge: 120.00 Hz - Upper transition bandwidth: 30.00 Hz (-6 dB cutoff frequency: 135.00 Hz) - Filter length: 221 samples (0.221 sec) resample to 1000.0Hz -> detrend -> 0.5s constant both sides padding -> filter: low 60Hz - high 120Hz -> select x:0.882s # time-varying FC for window in fr . sliding_window ( length = 0.5 , step = 0.2 , window_function = \"boxcar\" , lengths_in_seconds = True ): fc = window [ \"rates_exc\" ] . functional_connectivity ( fc_function = np . corrcoef ) plt . imshow ( fc ) plt . title ( f \"FC: { window . start_time } - { window . end_time } s\" ) plt . show ()","title":"Example 0.2 basic analysis"},{"location":"examples/example-0.2-basic_analysis/#introduction","text":"# change to the root directory of the project import os if os . getcwd () . split ( \"/\" )[ - 1 ] == \"examples\" : os . chdir ( '..' ) # This will reload all imports as soon as the code changes % load_ext autoreload % autoreload 2 try : import matplotlib.pyplot as plt except ImportError : import sys ! { sys . executable } - m pip install matplotlib import matplotlib.pyplot as plt from functools import partial import numpy as np from neurolib.models.aln import ALNModel from neurolib.utils.loadData import Dataset from neurolib.utils.signal import RatesSignal , BOLDSignal plt . rcParams [ 'image.cmap' ] = 'plasma'","title":"Introduction"},{"location":"examples/example-0.2-basic_analysis/#run-the-aln-model","text":"Firstly, let us run a network model given the structural connectivity and fiber lengths. ds = Dataset ( \"gw\" ) # simulates the whole-brain model aln = ALNModel ( Cmat = ds . Cmat , Dmat = ds . Dmat ) # Resting state fits aln . params [ 'mue_ext_mean' ] = 1.57 aln . params [ 'mui_ext_mean' ] = 1.6 aln . params [ 'sigma_ou' ] = 0.09 aln . params [ 'b' ] = 5.0 aln . params [ 'duration' ] = 0.2 * 60 * 1000 # info: value 0.2*60*1000 is low for testing # use 5*60*1000 for real simulation aln . run ( chunkwise = True , bold = True ) WARNING:root:aln: BOLD simulation is supported only with chunkwise integration. Enabling chunkwise integration. Now we can cast the modelling result into our Signal class. Signal is a parent base class for any neuro signal. We also provide three child class for particular signals: RatesSignal (for firing rate of the populations), VoltageSignal (for average membrane potential of the populations), and BOLDSignal (for simulated BOLD). They only differ in name, labels and units. Nothing fancy. Of course, you can implement your own class for your particular results very easily as: from neurolib.utils.signal import Signal class PostSynapticCurrentSignal ( Signal ): name = \"Population post-synaptic current signal\" label = \"I_syn\" signal_type = \"post_current\" unit = \"mA\" and that's it. All useful methods and attributes are directly inhereted from the Signal parent. # Create Signal out of firing rates fr = RatesSignal . from_model_output ( aln , group = \"\" , time_in_ms = True ) # optional description fr . description = \"Output of the ALN model with default SC and fiber lengths\" # Create Signal out of BOLD simulated timeseries bold = BOLDSignal . from_model_output ( aln , group = \"BOLD\" , time_in_ms = True ) bold . description = \"Simulated BOLD of the ALN model with default SC and fiber lengths\" # let's check what's inside print ( fr ) print ( bold ) Population firing rate representing rate signal with unit of Hz with user-provided description: `Output of the ALN model with default SC and fiber lengths`. Shape of the signal is (2, 80, 8831) with dimensions ('output', 'space', 'time'). Population blood oxygen level-dependent signal representing bold signal with unit of % with user-provided description: `Simulated BOLD of the ALN model with default SC and fiber lengths`. Shape of the signal is (1, 80, 7) with dimensions ('output', 'space', 'time'). Signal automatically computes useful attributes like dt , sampling rate, starting and ending times. # inherent attributes print ( \"Inherent attributes:\" ) print ( fr . name ) print ( fr . label ) print ( fr . unit ) print ( fr . signal_type ) print ( fr . description ) # computed attributes print ( \" \\n Computed attributes:\" ) print ( fr . dt ) print ( fr . sampling_frequency ) print ( fr . start_time ) print ( fr . end_time ) print ( fr . shape ) Inherent attributes: Population firing rate q Hz rate Output of the ALN model with default SC and fiber lengths Computed attributes: 0.0001 10000.0 0.0 0.883 (2, 80, 8831) # internal representation of the signal is just xarray's DataArray print ( fr . data ) # xarray is just pandas on steroids, i.e. it supports multi-dimensional arrays, not only 2D # if you'd need simple numpy array just call .values on signal's data print ( type ( fr . data . values )) print ( fr . data . values . shape ) <xarray.DataArray (output: 2, space: 80, time: 8831)> array([[[1.33261450e-02, 1.36917651e-02, 1.40695947e-02, ..., 3.48158384e-03, 3.46784876e-03, 3.46133411e-03], [6.13965587e-01, 6.25356604e-01, 6.34768740e-01, ..., 3.59993904e-01, 3.54528049e-01, 3.49018287e-01], [6.36038906e-02, 6.35557804e-02, 6.33770702e-02, ..., 4.42949449e-02, 4.37566338e-02, 4.32171260e-02], ..., [2.50859629e-03, 2.52563325e-03, 2.54037707e-03, ..., 8.00547429e-03, 7.78636724e-03, 7.61333390e-03], [5.95617787e-02, 6.07513850e-02, 6.20942706e-02, ..., 3.26872805e-02, 3.33536801e-02, 3.40569905e-02], [4.96090615e-02, 4.84730168e-02, 4.73428175e-02, ..., 1.05820581e-01, 1.05724932e-01, 1.05846529e-01]], [[4.17821712e+00, 4.21196680e+00, 4.23883558e+00, ..., 1.01836901e+01, 1.00264571e+01, 9.86191716e+00], [6.83616353e+00, 6.91560104e+00, 6.97566672e+00, ..., 8.07743197e+00, 8.08297235e+00, 8.07994833e+00], [6.57108005e+00, 6.49135703e+00, 6.43050397e+00, ..., 8.93701663e+00, 8.95484465e+00, 8.97588108e+00], ..., [8.75902323e+00, 8.81787556e+00, 8.89506320e+00, ..., 7.48694404e+00, 7.41863238e+00, 7.35970182e+00], [4.15841271e+00, 4.15037911e+00, 4.15057015e+00, ..., 6.61282248e+00, 6.60115808e+00, 6.58597805e+00], [9.52609773e+00, 9.39861579e+00, 9.28794497e+00, ..., 5.83291993e+00, 5.90070345e+00, 5.94592106e+00]]]) Coordinates: * output (output) <U9 'rates_exc' 'rates_inh' * space (space) int64 0 1 2 3 4 5 6 7 8 9 ... 70 71 72 73 74 75 76 77 78 79 * time (time) float64 0.0 0.0001 0.0002 0.0003 ... 0.8828 0.8829 0.883 <class 'numpy.ndarray'> (2, 80, 8831) Now let's see what Signal can do... Just a side note, all operations can be done inplace (everything happens inside signal class), or altered signal is returned with the same attributes as the original one # basic operations norm = fr . normalize ( std = True , inplace = False ) # so, are all temporal means close to zero? print ( np . allclose ( norm . data . mean ( dim = \"time\" ), 0. )) # aand, are all temporal std close to 1? print ( np . allclose ( norm . data . std ( dim = \"time\" ), 1.0 )) plt . plot ( fr [ \"rates_exc\" ] . data . sel ({ \"space\" : 0 }), label = \"original\" ) plt . plot ( norm [ \"rates_exc\" ] . data . sel ({ \"space\" : 0 }), label = \"normalised\" ) # you can detrend the signal, all of it, or by segments (as indices within the signal) # let's first normalise (so inplace=False), then detrend (we can inplace=True) detrended = fr . normalize ( std = True , inplace = False ) detrended . detrend ( inplace = True ) plt . plot ( detrended [ \"rates_exc\" ] . data . sel ({ \"space\" : 0 }), label = \"normalised & detrended\" ) detrended_segments = fr . detrend ( segments = np . arange ( 20000 , 1000 ), inplace = False ) plt . legend () True True <matplotlib.legend.Legend at 0x1301a4320> so, the sampling frequency is too high, let's resample print ( fr . sampling_frequency ) plt . plot ( fr . data . time , fr [ \"rates_exc\" ] . data . sel ({ \"space\" : 0 }), label = \"original\" ) fr . resample ( to_frequency = 1000. , inplace = True ) print ( fr . sampling_frequency ) plt . plot ( fr . data . time , fr [ \"rates_exc\" ] . data . sel ({ \"space\" : 0 }), label = \"resampled\" ) plt . legend () 10000.0 1000.0 <matplotlib.legend.Legend at 0x131e0e940>","title":"Run the ALN model"},{"location":"examples/example-0.2-basic_analysis/#more-complete-example","text":"Let's do a more complete example. Let's say, you run the model and want to extract phase and amplitude of the \\(\\alpha\\) band (i.e. 8-12Hz) for some phase-amplitude coupling analyses. # init again to start fresh fr = RatesSignal . from_model_output ( aln , group = \"\" , time_in_ms = True ) plt . plot ( fr . data . time , fr [ \"rates_exc\" ] . data . sel ({ \"space\" : 0 }), label = \"original\" ) # first resample fr . resample ( to_frequency = 1000. , inplace = True ) # next detrend fr . detrend ( inplace = True ) print ( fr . start_time , fr . end_time ) # next pad with 0s for 0.5 seconds in order to suppress edge effect when filtering padded = fr . pad ( how_much = 0.5 , in_seconds = True , padding_type = \"constant\" , side = \"both\" , constant_values = 0. , inplace = False ) print ( padded . start_time , padded . end_time ) # now filter - by default uses mne, if not installed, falls back to scipy basic IIR filter padded . filter ( low_freq = 8. , high_freq = 12. , inplace = True ) # now cut back the original length filtered = padded . sel ([ fr . start_time , fr . end_time ], inplace = False ) print ( filtered . start_time , filtered . end_time ) plt . plot ( filtered . data . time , filtered [ \"rates_exc\" ] . data . sel ({ \"space\" : 0 }), label = r \"filtered $\\alpha$\" ) # finally, get phase and amplitude via Hilbert transform phase = filtered . hilbert_transform ( return_as = \"phase_wrapped\" , inplace = False ) plt . plot ( phase . data . time , phase [ \"rates_exc\" ] . data . sel ({ \"space\" : 0 }), label = r \"phase $\\alpha$\" ) amplitude = filtered . hilbert_transform ( return_as = \"amplitude\" , inplace = False ) plt . plot ( amplitude . data . time , amplitude [ \"rates_exc\" ] . data . sel ({ \"space\" : 0 }), label = r \"amplitude $\\alpha$\" ) plt . legend () 0.0 0.882 -0.5 1.382 Setting up band-pass filter from 8 - 12 Hz FIR filter parameters --------------------- Designing a one-pass, zero-phase, non-causal bandpass filter: - Windowed time-domain design (firwin) method - Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation - Lower passband edge: 8.00 - Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 7.00 Hz) - Upper passband edge: 12.00 Hz - Upper transition bandwidth: 3.00 Hz (-6 dB cutoff frequency: 13.50 Hz) - Filter length: 1651 samples (1.651 sec) 0.0 0.882 <matplotlib.legend.Legend at 0x1322e6e80> # in case you forget that happened in the processing, you can easily check all steps: print ( phase . preprocessing_steps ) print ( amplitude . preprocessing_steps ) resample to 1000.0Hz -> detrend -> 0.5s constant both sides padding -> filter: low 8.0Hz - high 12.0Hz -> select x:0.882s -> Hilbert - wrapped phase resample to 1000.0Hz -> detrend -> 0.5s constant both sides padding -> filter: low 8.0Hz - high 12.0Hz -> select x:0.882s -> Hilbert - amplitude","title":"More complete example"},{"location":"examples/example-0.2-basic_analysis/#saving-loading","text":"# and you can save your signal for future generations! (saved as netCDF file) phase . save ( \"phase_from_some_experiment\" ) # and then load it phase_loaded = RatesSignal . from_file ( \"phase_from_some_experiment\" ) # compare whether it is the same print ( phase == phase_loaded ) # the attributes are saved/loaded as well print ( phase_loaded . name ) print ( phase_loaded . unit ) print ( phase_loaded . preprocessing_steps ) # delete file os . remove ( \"phase_from_some_experiment.nc\" ) True Population firing rate Hz resample to 1000.0Hz -> detrend -> 0.5s constant both sides padding -> filter: low 8.0Hz - high 12.0Hz -> select x:0.882s -> Hilbert - wrapped phase","title":"Saving / loading"},{"location":"examples/example-0.2-basic_analysis/#iterators","text":"Sometimes it is useful to apply or see something in a loop. That's why Signal supports both: iterating over space / outputs variables and applying some 1D function over temporal dimensions. # this will iterate over whole data and return one 1D temporal slice at the time, each slice is Signal class for name , ts in fr . iterate ( return_as = \"signal\" ): print ( name , type ( ts ), ts . start_time , ts . end_time ) # this will iterate over whole data and return one 1D temporal slice at the time, each slice is DataArray for name , ts in fr . iterate ( return_as = \"xr\" ): print ( name , type ( ts ), ts . shape , ts . shape ) ('rates_exc', 0) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 1) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 2) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 3) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 4) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 5) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 6) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 7) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 8) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 9) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 10) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 11) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 12) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 13) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 14) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 15) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 16) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 17) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 18) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 19) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 20) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 21) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 22) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 23) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 24) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 25) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 26) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 27) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 28) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 29) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 30) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 31) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 32) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 33) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 34) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 35) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 36) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 37) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 38) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 39) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 40) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 41) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 42) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 43) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 44) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 45) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 46) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 47) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 48) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 49) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 50) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 51) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 52) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 53) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 54) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 55) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 56) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 57) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 58) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 59) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 60) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 61) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 62) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 63) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 64) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 65) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 66) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 67) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 68) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 69) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 70) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 71) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 72) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 73) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 74) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 75) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 76) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 77) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 78) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 79) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 0) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 1) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 2) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 3) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 4) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 5) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 6) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 7) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 8) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 9) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 10) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 11) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 12) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 13) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 14) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 15) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 16) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 17) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 18) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 19) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 20) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 21) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 22) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 23) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 24) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 25) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 26) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 27) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 28) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 29) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 30) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 31) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 32) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 33) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 34) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 35) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 36) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 37) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 38) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 39) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 40) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 41) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 42) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 43) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 44) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 45) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 46) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 47) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 48) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 49) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 50) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 51) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 52) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 53) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 54) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 55) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 56) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 57) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 58) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 59) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 60) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 61) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 62) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 63) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 64) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 65) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 66) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 67) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 68) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 69) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 70) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 71) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 72) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 73) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 74) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 75) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 76) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 77) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 78) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_inh', 79) <class 'neurolib.utils.signal.RatesSignal'> 0.0 0.882 ('rates_exc', 0) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 1) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 2) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 3) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 4) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 5) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 6) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 7) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 8) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 9) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 10) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 11) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 12) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 13) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 14) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 15) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 16) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 17) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 18) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 19) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 20) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 21) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 22) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 23) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 24) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 25) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 26) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 27) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 28) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 29) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 30) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 31) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 32) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 33) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 34) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 35) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 36) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 37) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 38) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 39) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 40) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 41) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 42) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 43) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 44) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 45) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 46) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 47) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 48) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 49) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 50) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 51) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 52) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 53) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 54) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 55) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 56) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 57) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 58) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 59) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 60) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 61) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 62) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 63) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 64) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 65) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 66) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 67) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 68) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 69) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 70) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 71) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 72) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 73) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 74) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 75) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 76) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 77) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 78) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_exc', 79) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 0) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 1) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 2) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 3) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 4) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 5) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 6) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 7) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 8) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 9) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 10) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 11) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 12) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 13) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 14) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 15) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 16) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 17) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 18) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 19) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 20) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 21) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 22) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 23) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 24) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 25) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 26) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 27) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 28) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 29) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 30) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 31) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 32) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 33) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 34) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 35) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 36) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 37) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 38) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 39) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 40) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 41) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 42) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 43) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 44) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 45) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 46) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 47) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 48) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 49) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 50) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 51) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 52) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 53) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 54) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 55) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 56) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 57) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 58) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 59) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 60) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 61) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 62) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 63) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 64) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 65) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 66) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 67) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 68) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 69) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 70) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 71) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 72) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 73) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 74) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 75) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 76) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 77) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 78) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) ('rates_inh', 79) <class 'xarray.core.dataarray.DataArray'> (883,) (883,) # sliding window - let's iterate over temporal windows of 0.5seconds, with 0.1s translation and boxcar window function for window in fr . sliding_window ( length = 0.5 , step = 0.1 , window_function = \"boxcar\" , lengths_in_seconds = True ): print ( type ( window ), window . shape , window . start_time , window . end_time ) <class 'neurolib.utils.signal.RatesSignal'> (2, 80, 500) 0.0 0.499 <class 'neurolib.utils.signal.RatesSignal'> (2, 80, 500) 0.1 0.599 <class 'neurolib.utils.signal.RatesSignal'> (2, 80, 500) 0.2 0.699 <class 'neurolib.utils.signal.RatesSignal'> (2, 80, 500) 0.3 0.799 # apply 1D function - Signal supports applying 1D function per temporal slice # both are supported: function that reduces temporal dimension (e.g. mean which reduces timeseries of length N to one number), # and functions that preserve shape # reduce mean = fr . apply ( partial ( np . mean , axis =- 1 ), inplace = False ) # mean is now xr.DataArray, not Signal; but the coordinates except time are preserved print ( type ( mean ), mean . shape , mean . coords ) # preserve shape absolute_value = fr . apply ( np . abs , inplace = False ) # still Signal print ( absolute_value . shape ) WARNING:root:Shape changed after operation! Old shape: (2, 80, 883), new shape: (2, 80); Cannot cast to Signal class, returing as `xr.DataArray` <class 'xarray.core.dataarray.DataArray'> (2, 80) Coordinates: * output (output) <U9 'rates_exc' 'rates_inh' * space (space) int64 0 1 2 3 4 5 6 7 8 9 ... 70 71 72 73 74 75 76 77 78 79 (2, 80, 883)","title":"Iterators"},{"location":"examples/example-0.2-basic_analysis/#functional-connectivity","text":"Lot of modelling effort actually goes to fitting the experimental functional connectivity with the modelled one. That's why Signal class supports functional connectivity computation and with other methods (like filtering and iterating over temporal windows) we can even do timeseries of FC or band-specific FC very easily within the couple of lines. # basic FC from excitatory rates - using correlation fc_exc = fr [ \"rates_exc\" ] . functional_connectivity ( fc_function = np . corrcoef ) # results is DataArray with space coordinates print ( type ( fc_exc ), fc_exc . shape , fc_exc . coords ) plt . subplot ( 1 , 2 , 1 ) plt . title ( \"Correlation FC\" ) plt . imshow ( fc_exc . values ) # FC from covariance fc_cov_exc = fr [ \"rates_exc\" ] . functional_connectivity ( fc_function = np . cov ) plt . subplot ( 1 , 2 , 2 ) plt . title ( \"Covariance FC\" ) plt . imshow ( fc_cov_exc . values ) # so fc_function can be any function that can take (nodes x time) array and transform it to (nodes x nodes) connectivity matrix <class 'xarray.core.dataarray.DataArray'> (80, 80) Coordinates: * space (space) int64 0 1 2 3 4 5 6 7 8 9 ... 70 71 72 73 74 75 76 77 78 79 <matplotlib.image.AxesImage at 0x131f1db70> # band-specific FC BANDS = { \"delta\" : { \"low_freq\" : 2 , \"high_freq\" : 4 }, \"theta\" : { \"low_freq\" : 4 , \"high_freq\" : 8 }, \"alpha\" : { \"low_freq\" : 8 , \"high_freq\" : 12 }, \"beta\" : { \"low_freq\" : 12 , \"high_freq\" : 30 }, \"low_gamma\" : { \"low_freq\" : 30 , \"high_freq\" : 60 }, \"high_gamma\" : { \"low_freq\" : 60 , \"high_freq\" : 120 }, } padded = fr . pad ( how_much = 0.5 , in_seconds = True , padding_type = \"constant\" , side = \"both\" , constant_values = 0. , inplace = False ) plt . figure ( figsize = ( 20 , 4 )) for ii , ( band , filt_spec ) in enumerate ( BANDS . items ()): print ( f \"Processing { band } ...\" ) filtered = padded . filter ( ** filt_spec , inplace = False ) filtered . sel ([ fr . start_time , fr . end_time ], inplace = True ) plt . subplot ( 1 , len ( BANDS ), ii + 1 ) fc = filtered [ \"rates_exc\" ] . functional_connectivity ( fc_function = np . corrcoef ) print ( filtered . preprocessing_steps ) plt . imshow ( fc ) plt . title ( f \" { band } : { filt_spec [ 'low_freq' ] } - { filt_spec [ 'high_freq' ] } Hz\" ) plt . show () Processing delta... Setting up band-pass filter from 2 - 4 Hz FIR filter parameters --------------------- Designing a one-pass, zero-phase, non-causal bandpass filter: - Windowed time-domain design (firwin) method - Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation - Lower passband edge: 2.00 - Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 1.00 Hz) - Upper passband edge: 4.00 Hz - Upper transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 5.00 Hz) - Filter length: 1651 samples (1.651 sec) resample to 1000.0Hz -> detrend -> 0.5s constant both sides padding -> filter: low 2Hz - high 4Hz -> select x:0.882s Processing theta... Setting up band-pass filter from 4 - 8 Hz FIR filter parameters --------------------- Designing a one-pass, zero-phase, non-causal bandpass filter: - Windowed time-domain design (firwin) method - Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation - Lower passband edge: 4.00 - Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz) - Upper passband edge: 8.00 Hz - Upper transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 9.00 Hz) - Filter length: 1651 samples (1.651 sec) resample to 1000.0Hz -> detrend -> 0.5s constant both sides padding -> filter: low 4Hz - high 8Hz -> select x:0.882s Processing alpha... Setting up band-pass filter from 8 - 12 Hz FIR filter parameters --------------------- Designing a one-pass, zero-phase, non-causal bandpass filter: - Windowed time-domain design (firwin) method - Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation - Lower passband edge: 8.00 - Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 7.00 Hz) - Upper passband edge: 12.00 Hz - Upper transition bandwidth: 3.00 Hz (-6 dB cutoff frequency: 13.50 Hz) - Filter length: 1651 samples (1.651 sec) resample to 1000.0Hz -> detrend -> 0.5s constant both sides padding -> filter: low 8Hz - high 12Hz -> select x:0.882s Processing beta... Setting up band-pass filter from 12 - 30 Hz FIR filter parameters --------------------- Designing a one-pass, zero-phase, non-causal bandpass filter: - Windowed time-domain design (firwin) method - Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation - Lower passband edge: 12.00 - Lower transition bandwidth: 3.00 Hz (-6 dB cutoff frequency: 10.50 Hz) - Upper passband edge: 30.00 Hz - Upper transition bandwidth: 7.50 Hz (-6 dB cutoff frequency: 33.75 Hz) - Filter length: 1101 samples (1.101 sec) resample to 1000.0Hz -> detrend -> 0.5s constant both sides padding -> filter: low 12Hz - high 30Hz -> select x:0.882s Processing low_gamma... Setting up band-pass filter from 30 - 60 Hz FIR filter parameters --------------------- Designing a one-pass, zero-phase, non-causal bandpass filter: - Windowed time-domain design (firwin) method - Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation - Lower passband edge: 30.00 - Lower transition bandwidth: 7.50 Hz (-6 dB cutoff frequency: 26.25 Hz) - Upper passband edge: 60.00 Hz - Upper transition bandwidth: 15.00 Hz (-6 dB cutoff frequency: 67.50 Hz) - Filter length: 441 samples (0.441 sec) resample to 1000.0Hz -> detrend -> 0.5s constant both sides padding -> filter: low 30Hz - high 60Hz -> select x:0.882s Processing high_gamma... Setting up band-pass filter from 60 - 1.2e+02 Hz FIR filter parameters --------------------- Designing a one-pass, zero-phase, non-causal bandpass filter: - Windowed time-domain design (firwin) method - Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation - Lower passband edge: 60.00 - Lower transition bandwidth: 15.00 Hz (-6 dB cutoff frequency: 52.50 Hz) - Upper passband edge: 120.00 Hz - Upper transition bandwidth: 30.00 Hz (-6 dB cutoff frequency: 135.00 Hz) - Filter length: 221 samples (0.221 sec) resample to 1000.0Hz -> detrend -> 0.5s constant both sides padding -> filter: low 60Hz - high 120Hz -> select x:0.882s # time-varying FC for window in fr . sliding_window ( length = 0.5 , step = 0.2 , window_function = \"boxcar\" , lengths_in_seconds = True ): fc = window [ \"rates_exc\" ] . functional_connectivity ( fc_function = np . corrcoef ) plt . imshow ( fc ) plt . title ( f \"FC: { window . start_time } - { window . end_time } s\" ) plt . show ()","title":"Functional connectivity"},{"location":"examples/example-0.3-fhn-minimal/","text":"(function() { function addWidgetsRenderer() { var requireJsScript = document.createElement('script'); requireJsScript.src = 'https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js'; var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var jupyterWidgetsScript = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} jupyterWidgetsScript.src = widgetRendererSrc; document.body.appendChild(requireJsScript); document.body.appendChild(jupyterWidgetsScript); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); The Fitz-Hugh Nagumo oscillator In this notebook, the basic use of the implementation of the Fitz-Hugh Nagumo ( fhn ) model is presented. Usually, the fhn model is used to represent a single neuron (for example in Cakan et al. (2014) , \"Heterogeneous delays in neural networks\"). This is due to the difference in timescales of the two equations that define the FHN model: The first equation is often referred to as the \"fast variable\" whereas the second one is the \"slow variable\". This makes it possible to create a model with a very fast spiking mechanism but with a slow refractory period. In our case, we are using a parameterization of the fhn model that is not quite as usual. Inspired by the paper by Kostova et al. (2004) \"FitzHugh\u2013Nagumo revisited: Types of bifurcations, periodical forcing and stability regions by a Lyapunov functional.\", the implementation in neurolib produces a slowly oscillating dynamics and has the advantage to incorporate an external input term that causes a Hopf bifurcation. This means, that the model roughly approximates the behaviour of the aln model: For low input values, there is a low-activity fixed point, for intermediate inputs, there is an oscillatory region, and for high input values, the system is in a high-activity fixed point. Thus, it offers a simple way of exploring the dynamics of a neural mass model with these properties, such as the aln model. We want to start by producing a bifurcation diagram of a single node. With neurolib , this can be done with a couple of lines of code, as seen further below. # change to the root directory of the project import os if os . getcwd () . split ( \"/\" )[ - 1 ] == \"examples\" : os . chdir ( '..' ) # This will reload all imports as soon as the code changes % load_ext autoreload % autoreload 2 try : import matplotlib.pyplot as plt except ImportError : import sys ! { sys . executable } - m pip install matplotlib import matplotlib.pyplot as plt import numpy as np # Let's import the fhn model from neurolib.models.fhn import FHNModel # Some useful functions are provided here import neurolib.utils.functions as func # a nice color map plt . rcParams [ 'image.cmap' ] = 'plasma' Single node simulation fhn = FHNModel () fhn . params [ 'duration' ] = 2.0 * 1000 Let's draw a simple one-dimensional bifurcation diagram of this model to orient ourselves in the parameter space max_x = [] min_x = [] # these are the different input values that we want to scan x_inputs = np . linspace ( 0 , 2 , 50 ) for x_ext in x_inputs : # Note: this has to be a vector since it is input for all nodes # (but we have only one node in this example) fhn . params [ 'x_ext' ] = [ x_ext ] fhn . run () # we add the maximum and the minimum of the last second of the # simulation to a list max_x . append ( np . max ( fhn . x [ 0 , - int ( 1000 / fhn . params [ 'dt' ]):])) min_x . append ( np . min ( fhn . x [ 0 , - int ( 1000 / fhn . params [ 'dt' ]):])) plt . plot ( x_inputs , max_x , c = 'k' , lw = 2 ) plt . plot ( x_inputs , min_x , c = 'k' , lw = 2 ) plt . title ( \"Bifurcation diagram of the FHN oscillator\" ) plt . xlabel ( \"Input to x\" ) plt . ylabel ( \"Min / max x\" ) Text(0, 0.5, 'Min / max x') In this model, there is a Hopf bifurcation happening at two input values. We can see the oscillatory region at input values from roughly 0.75 to 1.3 . Brain network from neurolib.utils.loadData import Dataset ds = Dataset ( \"hcp\" ) fhn = FHNModel ( Cmat = ds . Cmat , Dmat = ds . Dmat ) fhn . params [ 'duration' ] = 10 * 1000 # add some noise fhn . params [ 'sigma_ou' ] = .01 # set the global coupling strenght of the brain network fhn . params [ 'K_gl' ] = 1.0 # let's put all nodes close to the limit cycle such that # noise can kick them in and out of the oscillation # all nodes get the same constant input fhn . params [ 'x_ext' ] = [ 0.72 ] * fhn . params [ 'N' ] fhn . run ( chunkwise = True , append_outputs = True ) plt . plot ( fhn . t , fhn . x [:: 5 , :] . T , alpha = 0.8 ); plt . xlabel ( \"t [ms]\" ) Text(0.5, 0, 't [ms]') fig , axs = plt . subplots ( 1 , 2 , figsize = ( 8 , 2 )) axs [ 0 ] . imshow ( func . fc ( fhn . x [:, - 10000 :])) axs [ 1 ] . plot ( fhn . t , fhn . x [:: 5 , :] . T , alpha = 0.8 ); scores = [ func . matrix_correlation ( func . fc ( fhn . x [:, - int ( 5000 / fhn . params [ 'dt' ]):]), fcemp ) for fcemp in ds . FCs ] print ( \"Correlation per subject:\" , [ f \" { s : .2 } \" for s in scores ]) print ( \"Mean FC/FC correlation: {:.2f} \" . format ( np . mean ( scores ))) Correlation per subject: ['0.41', '0.5', '0.5', '0.48', '0.49', '0.45', '0.54'] Mean FC/FC correlation: 0.48","title":"Example 0.3 fhn minimal"},{"location":"examples/example-0.3-fhn-minimal/#the-fitz-hugh-nagumo-oscillator","text":"In this notebook, the basic use of the implementation of the Fitz-Hugh Nagumo ( fhn ) model is presented. Usually, the fhn model is used to represent a single neuron (for example in Cakan et al. (2014) , \"Heterogeneous delays in neural networks\"). This is due to the difference in timescales of the two equations that define the FHN model: The first equation is often referred to as the \"fast variable\" whereas the second one is the \"slow variable\". This makes it possible to create a model with a very fast spiking mechanism but with a slow refractory period. In our case, we are using a parameterization of the fhn model that is not quite as usual. Inspired by the paper by Kostova et al. (2004) \"FitzHugh\u2013Nagumo revisited: Types of bifurcations, periodical forcing and stability regions by a Lyapunov functional.\", the implementation in neurolib produces a slowly oscillating dynamics and has the advantage to incorporate an external input term that causes a Hopf bifurcation. This means, that the model roughly approximates the behaviour of the aln model: For low input values, there is a low-activity fixed point, for intermediate inputs, there is an oscillatory region, and for high input values, the system is in a high-activity fixed point. Thus, it offers a simple way of exploring the dynamics of a neural mass model with these properties, such as the aln model. We want to start by producing a bifurcation diagram of a single node. With neurolib , this can be done with a couple of lines of code, as seen further below. # change to the root directory of the project import os if os . getcwd () . split ( \"/\" )[ - 1 ] == \"examples\" : os . chdir ( '..' ) # This will reload all imports as soon as the code changes % load_ext autoreload % autoreload 2 try : import matplotlib.pyplot as plt except ImportError : import sys ! { sys . executable } - m pip install matplotlib import matplotlib.pyplot as plt import numpy as np # Let's import the fhn model from neurolib.models.fhn import FHNModel # Some useful functions are provided here import neurolib.utils.functions as func # a nice color map plt . rcParams [ 'image.cmap' ] = 'plasma'","title":"The Fitz-Hugh Nagumo oscillator"},{"location":"examples/example-0.3-fhn-minimal/#single-node-simulation","text":"fhn = FHNModel () fhn . params [ 'duration' ] = 2.0 * 1000 Let's draw a simple one-dimensional bifurcation diagram of this model to orient ourselves in the parameter space max_x = [] min_x = [] # these are the different input values that we want to scan x_inputs = np . linspace ( 0 , 2 , 50 ) for x_ext in x_inputs : # Note: this has to be a vector since it is input for all nodes # (but we have only one node in this example) fhn . params [ 'x_ext' ] = [ x_ext ] fhn . run () # we add the maximum and the minimum of the last second of the # simulation to a list max_x . append ( np . max ( fhn . x [ 0 , - int ( 1000 / fhn . params [ 'dt' ]):])) min_x . append ( np . min ( fhn . x [ 0 , - int ( 1000 / fhn . params [ 'dt' ]):])) plt . plot ( x_inputs , max_x , c = 'k' , lw = 2 ) plt . plot ( x_inputs , min_x , c = 'k' , lw = 2 ) plt . title ( \"Bifurcation diagram of the FHN oscillator\" ) plt . xlabel ( \"Input to x\" ) plt . ylabel ( \"Min / max x\" ) Text(0, 0.5, 'Min / max x') In this model, there is a Hopf bifurcation happening at two input values. We can see the oscillatory region at input values from roughly 0.75 to 1.3 .","title":"Single node simulation"},{"location":"examples/example-0.3-fhn-minimal/#brain-network","text":"from neurolib.utils.loadData import Dataset ds = Dataset ( \"hcp\" ) fhn = FHNModel ( Cmat = ds . Cmat , Dmat = ds . Dmat ) fhn . params [ 'duration' ] = 10 * 1000 # add some noise fhn . params [ 'sigma_ou' ] = .01 # set the global coupling strenght of the brain network fhn . params [ 'K_gl' ] = 1.0 # let's put all nodes close to the limit cycle such that # noise can kick them in and out of the oscillation # all nodes get the same constant input fhn . params [ 'x_ext' ] = [ 0.72 ] * fhn . params [ 'N' ] fhn . run ( chunkwise = True , append_outputs = True ) plt . plot ( fhn . t , fhn . x [:: 5 , :] . T , alpha = 0.8 ); plt . xlabel ( \"t [ms]\" ) Text(0.5, 0, 't [ms]') fig , axs = plt . subplots ( 1 , 2 , figsize = ( 8 , 2 )) axs [ 0 ] . imshow ( func . fc ( fhn . x [:, - 10000 :])) axs [ 1 ] . plot ( fhn . t , fhn . x [:: 5 , :] . T , alpha = 0.8 ); scores = [ func . matrix_correlation ( func . fc ( fhn . x [:, - int ( 5000 / fhn . params [ 'dt' ]):]), fcemp ) for fcemp in ds . FCs ] print ( \"Correlation per subject:\" , [ f \" { s : .2 } \" for s in scores ]) print ( \"Mean FC/FC correlation: {:.2f} \" . format ( np . mean ( scores ))) Correlation per subject: ['0.41', '0.5', '0.5', '0.48', '0.49', '0.45', '0.54'] Mean FC/FC correlation: 0.48","title":"Brain network"},{"location":"examples/example-0.4-wc-minimal/","text":"(function() { function addWidgetsRenderer() { var requireJsScript = document.createElement('script'); requireJsScript.src = 'https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js'; var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var jupyterWidgetsScript = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} jupyterWidgetsScript.src = widgetRendererSrc; document.body.appendChild(requireJsScript); document.body.appendChild(jupyterWidgetsScript); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); The Wilson-Cowan model In this notebook, the basic use of the implementation of the Wilson-Cowan ( wc ) model is presented. In the wc model, the activity of a particular brain region is defined by a coupled system of excitatory (E) and inhibitory (I) neuronal populations with the mean firing rates of the E and I pools being the dynamic variables, as first described by Wilson and Cowan in 1972 ( H.R. Wilson and J.D. Cowan. Excitatory and inhibitory interactions in localized populations of model neurons . Biophys. J., 12:1\u201324 (1972)) # change to the root directory of the project import os if os . getcwd () . split ( \"/\" )[ - 1 ] == \"examples\" : os . chdir ( '..' ) % load_ext autoreload % autoreload 2 import matplotlib.pyplot as plt import numpy as np import glob from neurolib.models.wc import WCModel import neurolib.utils.loadData as ld import neurolib.utils.functions as func # a nice color map plt . rcParams [ 'image.cmap' ] = 'plasma' Bifurcation diagram wc = WCModel () wc . params [ 'duration' ] = 2.0 * 1000 Let's draw a simple one-dimensional bifurcation diagram of this model to orient ourselves in the parameter space max_exc = [] min_exc = [] # these are the different input values that we want to scan exc_inputs = np . linspace ( 0 , 3.5 , 50 ) for exc_ext in exc_inputs : # Note: this has to be a vector since it is input for all nodes # (but we have only one node in this example) wc . params [ 'exc_ext' ] = exc_ext wc . run () # we add the maximum and the minimum of the last second of the # simulation to a list max_exc . append ( np . max ( wc . exc [ 0 , - int ( 1000 / wc . params [ 'dt' ]):])) min_exc . append ( np . min ( wc . exc [ 0 , - int ( 1000 / wc . params [ 'dt' ]):])) plt . plot ( exc_inputs , max_exc , c = 'k' , lw = 2 ) plt . plot ( exc_inputs , min_exc , c = 'k' , lw = 2 ) plt . title ( \"Bifurcation diagram of the Wilson-Cowan model\" ) plt . xlabel ( \"Input to exc\" ) plt . ylabel ( \"Min / max exc\" ) Text(0,0.5,'Min / max exc') Single node simulation wc = WCModel () wc . params [ 'duration' ] = 1.0 * 1000 wc . params [ 'sigma_ou' ] = 0.01 wc . run () plt . plot ( wc . t , wc . exc . T , c = 'k' , lw = 2 ) plt . xlabel ( \"t [ms]\" ) plt . ylabel ( \"Activity\" ) Text(0,0.5,'Activity') Brain network from neurolib.utils.loadData import Dataset ds = Dataset ( \"hcp\" ) wc = WCModel ( Cmat = ds . Cmat , Dmat = ds . Dmat ) wc . params [ 'exc_ext' ] = 0.65 wc . params [ 'signalV' ] = 0 wc . params [ 'duration' ] = 20 * 1000 wc . params [ 'sigma_ou' ] = 0.14 wc . params [ 'K_gl' ] = 3.15 wc . run ( chunkwise = True ) fig , axs = plt . subplots ( 1 , 2 , figsize = ( 10 , 3 )) axs [ 0 ] . imshow ( func . fc ( wc . exc [:, - 10000 :])) axs [ 1 ] . plot ( wc . t , wc . exc [:: 5 , :] . T , alpha = 0.8 ); axs [ 1 ] . set_xlim ( 0 , 200 ) (0, 200) scores = [ func . matrix_correlation ( func . fc ( wc . exc [:, - int ( 5000 / wc . params [ 'dt' ]):]), fcemp ) for fcemp in ds . FCs ] print ( \"Correlation per subject:\" , [ f \" { s : .2 } \" for s in scores ]) print ( \"Mean FC/FC correlation: {:.2f} \" . format ( np . mean ( scores ))) Correlation per subject: ['0.13', '0.14', '0.13', '0.12', '0.11', '0.12', '0.12'] Mean FC/FC correlation: 0.13","title":"Example 0.4 wc minimal"},{"location":"examples/example-0.4-wc-minimal/#the-wilson-cowan-model","text":"In this notebook, the basic use of the implementation of the Wilson-Cowan ( wc ) model is presented. In the wc model, the activity of a particular brain region is defined by a coupled system of excitatory (E) and inhibitory (I) neuronal populations with the mean firing rates of the E and I pools being the dynamic variables, as first described by Wilson and Cowan in 1972 ( H.R. Wilson and J.D. Cowan. Excitatory and inhibitory interactions in localized populations of model neurons . Biophys. J., 12:1\u201324 (1972)) # change to the root directory of the project import os if os . getcwd () . split ( \"/\" )[ - 1 ] == \"examples\" : os . chdir ( '..' ) % load_ext autoreload % autoreload 2 import matplotlib.pyplot as plt import numpy as np import glob from neurolib.models.wc import WCModel import neurolib.utils.loadData as ld import neurolib.utils.functions as func # a nice color map plt . rcParams [ 'image.cmap' ] = 'plasma'","title":"The Wilson-Cowan model"},{"location":"examples/example-0.4-wc-minimal/#bifurcation-diagram","text":"wc = WCModel () wc . params [ 'duration' ] = 2.0 * 1000 Let's draw a simple one-dimensional bifurcation diagram of this model to orient ourselves in the parameter space max_exc = [] min_exc = [] # these are the different input values that we want to scan exc_inputs = np . linspace ( 0 , 3.5 , 50 ) for exc_ext in exc_inputs : # Note: this has to be a vector since it is input for all nodes # (but we have only one node in this example) wc . params [ 'exc_ext' ] = exc_ext wc . run () # we add the maximum and the minimum of the last second of the # simulation to a list max_exc . append ( np . max ( wc . exc [ 0 , - int ( 1000 / wc . params [ 'dt' ]):])) min_exc . append ( np . min ( wc . exc [ 0 , - int ( 1000 / wc . params [ 'dt' ]):])) plt . plot ( exc_inputs , max_exc , c = 'k' , lw = 2 ) plt . plot ( exc_inputs , min_exc , c = 'k' , lw = 2 ) plt . title ( \"Bifurcation diagram of the Wilson-Cowan model\" ) plt . xlabel ( \"Input to exc\" ) plt . ylabel ( \"Min / max exc\" ) Text(0,0.5,'Min / max exc')","title":"Bifurcation diagram"},{"location":"examples/example-0.4-wc-minimal/#single-node-simulation","text":"wc = WCModel () wc . params [ 'duration' ] = 1.0 * 1000 wc . params [ 'sigma_ou' ] = 0.01 wc . run () plt . plot ( wc . t , wc . exc . T , c = 'k' , lw = 2 ) plt . xlabel ( \"t [ms]\" ) plt . ylabel ( \"Activity\" ) Text(0,0.5,'Activity')","title":"Single node simulation"},{"location":"examples/example-0.4-wc-minimal/#brain-network","text":"from neurolib.utils.loadData import Dataset ds = Dataset ( \"hcp\" ) wc = WCModel ( Cmat = ds . Cmat , Dmat = ds . Dmat ) wc . params [ 'exc_ext' ] = 0.65 wc . params [ 'signalV' ] = 0 wc . params [ 'duration' ] = 20 * 1000 wc . params [ 'sigma_ou' ] = 0.14 wc . params [ 'K_gl' ] = 3.15 wc . run ( chunkwise = True ) fig , axs = plt . subplots ( 1 , 2 , figsize = ( 10 , 3 )) axs [ 0 ] . imshow ( func . fc ( wc . exc [:, - 10000 :])) axs [ 1 ] . plot ( wc . t , wc . exc [:: 5 , :] . T , alpha = 0.8 ); axs [ 1 ] . set_xlim ( 0 , 200 ) (0, 200) scores = [ func . matrix_correlation ( func . fc ( wc . exc [:, - int ( 5000 / wc . params [ 'dt' ]):]), fcemp ) for fcemp in ds . FCs ] print ( \"Correlation per subject:\" , [ f \" { s : .2 } \" for s in scores ]) print ( \"Mean FC/FC correlation: {:.2f} \" . format ( np . mean ( scores ))) Correlation per subject: ['0.13', '0.14', '0.13', '0.12', '0.11', '0.12', '0.12'] Mean FC/FC correlation: 0.13","title":"Brain network"},{"location":"examples/example-0.5-external-stimulus/","text":"(function() { function addWidgetsRenderer() { var requireJsScript = document.createElement('script'); requireJsScript.src = 'https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js'; var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var jupyterWidgetsScript = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} jupyterWidgetsScript.src = widgetRendererSrc; document.body.appendChild(requireJsScript); document.body.appendChild(jupyterWidgetsScript); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); Stimulation example This notebook will demonstrate how to construct stimuli using a variety of different predefined classes in neurolib . You can then apply them as an input to a whole-brain model. As an example, we will see how to add an external current to the excitatory population of the ALNModel . # change to the root directory of the project import os if os . getcwd () . split ( \"/\" )[ - 1 ] in [ \"examples\" , \"dev\" ]: os . chdir ( \"..\" ) # This will reload all imports as soon as the code changes % load_ext autoreload % autoreload 2 try : import matplotlib.pyplot as plt except ImportError : import sys ! { sys . executable } - m pip install matplotlib import matplotlib.pyplot as plt # Some useful functions are provided here import neurolib.utils.functions as func import neurolib.utils.stimulus as stim import numpy as np import scipy # Let's import the aln model from neurolib.models.aln import ALNModel Let's talk stimuli neurolib offers a range of external stimuli you can apply to your models. These range from basic noise processes like a Wiener process or an Ornstein-Uhlenbeck process, to more simple forms of inputs such as sinousoids, rectified inputs etc. All stimuli are based on the ModelInput class, and are available in the neurolib.utils.stimulus subpackage. In the following we will detail the implemented inputs and also show how to easily implement your own custom stimulus further below. All inputs are initialized as classes. Three different functions are provided for the generation of the actual stimulus as a usable input: - as_array(duration, dt) - will return numpy array. - as_cubic_splines(duration, dt) - will return a CubicHermiteSpline object, which represents a spline representation of the given input - useful for jitcdde backend in MultiModel . - to_model(model) - the easiest one - infers the duration, dt and number of nodes from the simulated model itself and returns numpy array of an appropriate shape. Each stimulus type has their own init function with attributes that apply to the specific kind of stimulus. However, all of them include the attributes n and seed . n controls how many spatial dimensions the stimulus should have, and in the case of stochastic inputs, such as a noisy Ornstein-Uhlenbeck process, this controls the number of independent realizations that are returned. For a determinitic stimulus, such as the sinusoidal input, this just returns a copy of itself. Zero input - for convenience You'll probably never use it, but you know, it's there... Maybe you can use it as a \"pause\" when concatenating two different stimuli. duration = 5000 # 5 seconds dt = 0.1 inp = stim . ZeroInput ( n = 2 ) . as_array ( duration , dt ) plt . plot ( inp . T ); WienerProcess Basic Wiener process \\(dW\\) , i.e. random numbers drawn from \\(N(0, \\sqrt{dt})\\) inp = stim . WienerProcess ( n = 2 ) . as_array ( duration , dt ) plt . plot ( inp . T , alpha = 0.8 ); Ornstein-Uhlenbeck process Ornstein-Uhlenback process, i.e. \\(\\dot{x} = (\\mu - x)/\\tau \\cdot dt + \\sigma\\cdot dW\\) inp = stim . OrnsteinUhlenbeckProcess ( mu = 1.3 , sigma = 0.04 , tau = 10.0 , n = 2 ) . as_array ( duration , dt ) plt . plot ( inp . T ); Step input Just a bias, or a DC offset, that you can use in combination with other types of stimuli. inp = stim . StepInput ( step_size = 1.43 , n = 2 ) . as_array ( duration , dt ) plt . plot ( inp . T ); # you can also set stim_start and stim_end - in ms inp = stim . StepInput ( step_size = 1.43 , start = 1200 , end = 2400 , n = 2 ) . as_array ( duration , dt ) plt . plot ( inp . T ); Sinusoidal input # frequency in Hz; dc_bias=True shifts input by its amplitude inp = stim . SinusoidalInput ( amplitude = 2.5 , frequency = 2.0 , start = 1200 , dc_bias = True ) . as_array ( duration , dt ) inp2 = stim . SinusoidalInput ( amplitude = 2.5 , frequency = 2.0 ) . as_array ( duration , dt ) plt . plot ( inp . T ) plt . plot ( inp2 . T ); Square input # frequency in Hz; dc_bias=True shifts input by its amplitude inp = stim . SquareInput ( amplitude = 2.5 , frequency = 2.0 , start = 1200 , dc_bias = True ) . as_array ( duration , dt ) inp2 = stim . SquareInput ( amplitude = 2.5 , frequency = 2.0 ) . as_array ( duration , dt ) plt . plot ( inp . T ) plt . plot ( inp2 . T ); Linear ramp When you need to go somwhhere slowly but surely # ramp_length in ms inp = stim . LinearRampInput ( inp_max = 1.7 , ramp_length = 3000 , start = 600 ) . as_array ( duration , dt ) inp2 = stim . LinearRampInput ( inp_max =- 0.7 , ramp_length = 2000 , start = 1600 ) . as_array ( duration , dt ) plt . plot ( inp . T ) plt . plot ( inp2 . T ); Exponential input When you need to get there fast. inp = stim . ExponentialInput ( inp_max = 2.5 , exp_coef = 5.0 , exp_type = \"rise\" ) . as_array ( duration , dt ) inp2 = stim . ExponentialInput ( inp_max = 2.5 , exp_coef = 35.0 , exp_type = \"rise\" ) . as_array ( duration , dt ) inp3 = stim . ExponentialInput ( inp_max = 2.5 , exp_coef = 15.0 , exp_type = \"decay\" ) . as_array ( duration , dt ) plt . plot ( inp . T ) plt . plot ( inp2 . T ) plt . plot ( inp3 . T ); RectifiedInput A mix of inputs that start with negative step, then we have exponential rise and subsequent decay to zero. Useful for detecting bistability inp = stim . RectifiedInput ( amplitude = 1.2 ) . as_array ( duration , dt ) plt . plot ( inp . T ); Operations on stimuli Sometimes you need to concatenate inputs in the temporal dimension to create a mix of different stimuli. This is easy with neurolib 's stimuli. All of them allow two operations: + for a sum of different stimuli and & to concatenate them (one after another). Below, we will show some of the weird combinations you can make. # let's create some basic inputs ou = stim . OrnsteinUhlenbeckProcess ( mu = 0.1 , sigma = 0.04 , tau = 2.0 , n = 2 ) sq = stim . SquareInput ( amplitude = 0.2 , frequency = 1.7 , n = 2 ) sin = stim . SinusoidalInput ( amplitude = 0.7 , frequency = 1.0 , n = 2 ) _ , axs = plt . subplots ( nrows = 3 , ncols = 1 , sharex = True ) for i , inp in enumerate ([ ou , sq , sin ]): axs [ i ] . plot ( inp . as_array ( duration , dt ) . T ); Sum summed = ou + sq + sin plt . plot ( summed . as_array ( duration , dt ) . T ); Concatenation # same lengths - use & conc = ou & sq & sin plt . plot ( conc . as_array ( duration , dt ) . T ); # can also do different length ratios, but for this you need to call ConcatenatedStimulus directly conc = stim . ConcatenatedStimulus ([ ou , sq , sin ], length_ratios = [ 0.5 , 2 , 5 ]) plt . plot ( conc . as_array ( duration , dt ) . T ); Mixing the operations You should be able to use as many + and & as you want. Go crazy. beast = ( ou + sq ) & ( sq + sin ) plt . plot ( beast . as_array ( duration , dt ) . T ); beast = stim . ConcatenatedStimulus ([ ou + sq , ou + sin ], [ 2 , 5 ]) plt . plot ( beast . as_array ( duration , dt ) . T ); Creating a custom stimulus Creating a custom stimulus is very easy and you can build your library of stimuili as inputs for your model. There are three necessary steps: 1. Subclass stim.Input for a basic input or stim.Stimulus to have the option to set start and end times. 2. Define an __init__() method with the necessary parameters of your stimulus and set the appropriate attributes. 3. Define a generate_input(duration, dt) method, which returns a numpy array as with a shape (space, time) and that's it. Everything else described above is taken care of. Your new input class will be also support operations like + and & . Below we implement a new stimulus class that represents currents caused by a Poission spike train convolved with an exponential kernel. class PoissonNoiseWithExpKernel ( stim . Stimulus ): \"\"\" Poisson noise with exponential kernel. By subclassing the `StimulusInput` we have an option to select `start` and `end`. \"\"\" def __init__ ( self , amp , freq , tau_syn , start = None , end = None , n = 1 , seed = None ): # save parameters as attributes self . freq = freq self . amp = amp self . tau_syn = tau_syn # pass other params to parent class super () . __init__ ( start = start , end = end , n = n , seed = seed ) def generate_input ( self , duration , dt ): # this is a helper function that creates self.times vector self . _get_times ( duration = duration , dt = dt ) # do the magic here: prepare output vector x = np . zeros (( self . n , self . times . shape [ 0 ])) # compute total number of spikes total_spikes = int ( self . freq * ( self . times [ - 1 ] - self . times [ 0 ]) / 1000.0 ) # randomly put spikes into the output vector spike_indices = np . random . choice ( x . shape [ 1 ], ( self . n , total_spikes ), replace = True ) x [ np . arange ( x . shape [ 0 ])[:, None ], spike_indices ] = 1.0 # create exponential kernel time_spike_end = - self . tau_syn * np . log ( 0.001 ) arg_spike_end = np . argmin ( np . abs ( self . times - time_spike_end )) spike_kernel = np . exp ( - self . times [: arg_spike_end ] / self . tau_syn ) # convolve over dimensions x = np . apply_along_axis ( np . convolve , axis = 1 , arr = x , v = spike_kernel , mode = \"same\" ) # self._trim_stim_input takes care of trimming the stimulus based on stim_start and stim_end return self . _trim_stim ( x * self . amp ) # test ride inp = PoissonNoiseWithExpKernel ( amp = 1.2 , freq = 20.0 , tau_syn = 50.0 , n = 1 , end = 4000 ) . as_array ( duration , dt ) inp2 = PoissonNoiseWithExpKernel ( amp = 2.2 , freq = 10.0 , tau_syn = 20.0 , n = 1 , start = 1000 ) . as_array ( duration , dt ) plt . plot ( inp . T ) plt . plot ( inp2 . T ); # sum and concat test pois = PoissonNoiseWithExpKernel ( freq = 20.0 , amp = 1.2 , tau_syn = 50.0 , n = 2 ) summed = pois + sin plt . plot ( summed . as_array ( duration , dt ) . T ); concat = pois & sin plt . plot ( concat . as_array ( duration , dt ) . T ); Using stimuli in neurolib First, we initialize a single node. model = ALNModel () model . params [ \"duration\" ] = 5 * 1000 model . params [ \"sigma_ou\" ] = 0.2 # we add some noise After creating a base for stimulus, we can simply call to_model(model) function and our stimulus is generated. stimulus = stim . SinusoidalInput ( amplitude = 1.0 , frequency = 1.0 ) . to_model ( model ) The stimulus is then set as an input current parameter to the model. The parameter that models a current that goes to the excitatory population is called ext_exc_current . For the inhibitory population, we can use ext_inh_current . We can also set a firing rate input, that will then be integrated over the synapses using the parameter model.params['ext_exc_rate'] . model . params [ \"ext_exc_current\" ] = stimulus model . run () When we plot the timeseries, we can see that the oscillatory activity locks to the stimulus. plt . figure ( figsize = ( 10 , 3 ), dpi = 150 ) plt . title ( \"1 Hz stimulus\" ) ax1 = plt . gca () ax1 . plot ( model . t , model . output . T , c = \"k\" ) ax2 = plt . gca () . twinx () ax2 . plot ( model . t , stimulus . squeeze (), lw = 2 , c = \"r\" , alpha = 0.8 ) ax1 . set_xlabel ( \"Time [ms]\" ) ax1 . set_ylabel ( \"Activity [Hz]\" ) ax2 . set_ylabel ( \"Stimulus [mV/ms]\" , color = \"r\" ) ax2 . set_ylabel ( \"Stimulus [mV/ms]\" , color = \"r\" ) ax2 . tick_params ( axis = \"y\" , labelcolor = \"r\" ) Brain network stimulation from neurolib.utils.loadData import Dataset ds = Dataset ( \"hcp\" ) model = ALNModel ( Cmat = ds . Cmat , Dmat = ds . Dmat ) # we chose a parameterization in which the brain network oscillates slowly # between up- and down-states model . params [ \"mue_ext_mean\" ] = 2.56 model . params [ \"mui_ext_mean\" ] = 3.52 model . params [ \"b\" ] = 4.67 model . params [ \"tauA\" ] = 1522.68 model . params [ \"sigma_ou\" ] = 0.40 model . params [ \"duration\" ] = 0.2 * 60 * 1000 def plot_output_and_spectrum ( model , individual = False , vertical_mark = None ): \"\"\"A simple plotting function for the timeseries and the power spectrum of the activity. \"\"\" fig , axs = plt . subplots ( 1 , 2 , figsize = ( 8 , 2 ), dpi = 150 , gridspec_kw = { \"width_ratios\" : [ 2 , 1 ]} ) axs [ 0 ] . plot ( model . t , model . output . T , lw = 1 ) axs [ 0 ] . set_xlabel ( \"Time [ms]\" ) axs [ 0 ] . set_ylabel ( \"Activity [Hz]\" ) frs , powers = func . getMeanPowerSpectrum ( model . output , dt = model . params . dt ) axs [ 1 ] . plot ( frs , powers , c = \"k\" ) if individual : for o in model . output : frs , powers = func . getPowerSpectrum ( o , dt = model . params . dt ) axs [ 1 ] . plot ( frs , powers ) axs [ 1 ] . set_xlabel ( \"Frequency [Hz]\" ) axs [ 1 ] . set_ylabel ( \"Power\" ) plt . show () Without stimulation model . run ( chunkwise = True ) plot_output_and_spectrum ( model ) Constructing a stimulus neurolib helps you to create a few basic stimuli out of the box using the function stimulus.construct_stimulus() . # construct a stimulus # we want 1-dim input - to all the nodes - 25Hz ac_stimulus = stim . SinusoidalInput ( amplitude = 0.2 , frequency = 25.0 ) . to_model ( model ) print ( ac_stimulus . shape ) # this stimulus is 1-dimensional. neurolib will threfore automatically apply it to *all nodes*. model . params [ \"ext_exc_current\" ] = ac_stimulus * 5.0 (80, 120000) model . run ( chunkwise = True ) plot_output_and_spectrum ( model ) Focal stimulation In the previous example, the stimulus was applied to all nodes simultaneously. We can also apply stimulation to a specific set of nodes. # now we create multi-d input of 25Hz ac_stimulus = stim . SinusoidalInput ( amplitude = 0.2 , frequency = 25.0 ) . to_model ( model ) print ( ac_stimulus . shape ) # We set the input to a bunch of nodes to zero. # This will have the effect that only nodes from 0 to 4 will be sitmulated! ac_stimulus [ 5 :, :] = 0 # multiply the stimulus amplitude model . params [ \"ext_exc_current\" ] = ac_stimulus * 5.0 (80, 120000) model . run ( chunkwise = True ) We can see that the spectrum has a peak at the frequency we stimulated with, but only in a subset of nodes (where we stimulated). plot_output_and_spectrum ( model , individual = True )","title":"Example 0.5 external stimulus"},{"location":"examples/example-0.5-external-stimulus/#stimulation-example","text":"This notebook will demonstrate how to construct stimuli using a variety of different predefined classes in neurolib . You can then apply them as an input to a whole-brain model. As an example, we will see how to add an external current to the excitatory population of the ALNModel . # change to the root directory of the project import os if os . getcwd () . split ( \"/\" )[ - 1 ] in [ \"examples\" , \"dev\" ]: os . chdir ( \"..\" ) # This will reload all imports as soon as the code changes % load_ext autoreload % autoreload 2 try : import matplotlib.pyplot as plt except ImportError : import sys ! { sys . executable } - m pip install matplotlib import matplotlib.pyplot as plt # Some useful functions are provided here import neurolib.utils.functions as func import neurolib.utils.stimulus as stim import numpy as np import scipy # Let's import the aln model from neurolib.models.aln import ALNModel","title":"Stimulation example"},{"location":"examples/example-0.5-external-stimulus/#lets-talk-stimuli","text":"neurolib offers a range of external stimuli you can apply to your models. These range from basic noise processes like a Wiener process or an Ornstein-Uhlenbeck process, to more simple forms of inputs such as sinousoids, rectified inputs etc. All stimuli are based on the ModelInput class, and are available in the neurolib.utils.stimulus subpackage. In the following we will detail the implemented inputs and also show how to easily implement your own custom stimulus further below. All inputs are initialized as classes. Three different functions are provided for the generation of the actual stimulus as a usable input: - as_array(duration, dt) - will return numpy array. - as_cubic_splines(duration, dt) - will return a CubicHermiteSpline object, which represents a spline representation of the given input - useful for jitcdde backend in MultiModel . - to_model(model) - the easiest one - infers the duration, dt and number of nodes from the simulated model itself and returns numpy array of an appropriate shape. Each stimulus type has their own init function with attributes that apply to the specific kind of stimulus. However, all of them include the attributes n and seed . n controls how many spatial dimensions the stimulus should have, and in the case of stochastic inputs, such as a noisy Ornstein-Uhlenbeck process, this controls the number of independent realizations that are returned. For a determinitic stimulus, such as the sinusoidal input, this just returns a copy of itself.","title":"Let's talk stimuli"},{"location":"examples/example-0.5-external-stimulus/#zero-input-for-convenience","text":"You'll probably never use it, but you know, it's there... Maybe you can use it as a \"pause\" when concatenating two different stimuli. duration = 5000 # 5 seconds dt = 0.1 inp = stim . ZeroInput ( n = 2 ) . as_array ( duration , dt ) plt . plot ( inp . T );","title":"Zero input - for convenience"},{"location":"examples/example-0.5-external-stimulus/#wienerprocess","text":"Basic Wiener process \\(dW\\) , i.e. random numbers drawn from \\(N(0, \\sqrt{dt})\\) inp = stim . WienerProcess ( n = 2 ) . as_array ( duration , dt ) plt . plot ( inp . T , alpha = 0.8 );","title":"WienerProcess"},{"location":"examples/example-0.5-external-stimulus/#ornstein-uhlenbeck-process","text":"Ornstein-Uhlenback process, i.e. \\(\\dot{x} = (\\mu - x)/\\tau \\cdot dt + \\sigma\\cdot dW\\) inp = stim . OrnsteinUhlenbeckProcess ( mu = 1.3 , sigma = 0.04 , tau = 10.0 , n = 2 ) . as_array ( duration , dt ) plt . plot ( inp . T );","title":"Ornstein-Uhlenbeck process"},{"location":"examples/example-0.5-external-stimulus/#step-input","text":"Just a bias, or a DC offset, that you can use in combination with other types of stimuli. inp = stim . StepInput ( step_size = 1.43 , n = 2 ) . as_array ( duration , dt ) plt . plot ( inp . T ); # you can also set stim_start and stim_end - in ms inp = stim . StepInput ( step_size = 1.43 , start = 1200 , end = 2400 , n = 2 ) . as_array ( duration , dt ) plt . plot ( inp . T );","title":"Step input"},{"location":"examples/example-0.5-external-stimulus/#sinusoidal-input","text":"# frequency in Hz; dc_bias=True shifts input by its amplitude inp = stim . SinusoidalInput ( amplitude = 2.5 , frequency = 2.0 , start = 1200 , dc_bias = True ) . as_array ( duration , dt ) inp2 = stim . SinusoidalInput ( amplitude = 2.5 , frequency = 2.0 ) . as_array ( duration , dt ) plt . plot ( inp . T ) plt . plot ( inp2 . T );","title":"Sinusoidal input"},{"location":"examples/example-0.5-external-stimulus/#square-input","text":"# frequency in Hz; dc_bias=True shifts input by its amplitude inp = stim . SquareInput ( amplitude = 2.5 , frequency = 2.0 , start = 1200 , dc_bias = True ) . as_array ( duration , dt ) inp2 = stim . SquareInput ( amplitude = 2.5 , frequency = 2.0 ) . as_array ( duration , dt ) plt . plot ( inp . T ) plt . plot ( inp2 . T );","title":"Square input"},{"location":"examples/example-0.5-external-stimulus/#linear-ramp","text":"When you need to go somwhhere slowly but surely # ramp_length in ms inp = stim . LinearRampInput ( inp_max = 1.7 , ramp_length = 3000 , start = 600 ) . as_array ( duration , dt ) inp2 = stim . LinearRampInput ( inp_max =- 0.7 , ramp_length = 2000 , start = 1600 ) . as_array ( duration , dt ) plt . plot ( inp . T ) plt . plot ( inp2 . T );","title":"Linear ramp"},{"location":"examples/example-0.5-external-stimulus/#exponential-input","text":"When you need to get there fast. inp = stim . ExponentialInput ( inp_max = 2.5 , exp_coef = 5.0 , exp_type = \"rise\" ) . as_array ( duration , dt ) inp2 = stim . ExponentialInput ( inp_max = 2.5 , exp_coef = 35.0 , exp_type = \"rise\" ) . as_array ( duration , dt ) inp3 = stim . ExponentialInput ( inp_max = 2.5 , exp_coef = 15.0 , exp_type = \"decay\" ) . as_array ( duration , dt ) plt . plot ( inp . T ) plt . plot ( inp2 . T ) plt . plot ( inp3 . T );","title":"Exponential input"},{"location":"examples/example-0.5-external-stimulus/#rectifiedinput","text":"A mix of inputs that start with negative step, then we have exponential rise and subsequent decay to zero. Useful for detecting bistability inp = stim . RectifiedInput ( amplitude = 1.2 ) . as_array ( duration , dt ) plt . plot ( inp . T );","title":"RectifiedInput"},{"location":"examples/example-0.5-external-stimulus/#operations-on-stimuli","text":"Sometimes you need to concatenate inputs in the temporal dimension to create a mix of different stimuli. This is easy with neurolib 's stimuli. All of them allow two operations: + for a sum of different stimuli and & to concatenate them (one after another). Below, we will show some of the weird combinations you can make. # let's create some basic inputs ou = stim . OrnsteinUhlenbeckProcess ( mu = 0.1 , sigma = 0.04 , tau = 2.0 , n = 2 ) sq = stim . SquareInput ( amplitude = 0.2 , frequency = 1.7 , n = 2 ) sin = stim . SinusoidalInput ( amplitude = 0.7 , frequency = 1.0 , n = 2 ) _ , axs = plt . subplots ( nrows = 3 , ncols = 1 , sharex = True ) for i , inp in enumerate ([ ou , sq , sin ]): axs [ i ] . plot ( inp . as_array ( duration , dt ) . T );","title":"Operations on stimuli"},{"location":"examples/example-0.5-external-stimulus/#sum","text":"summed = ou + sq + sin plt . plot ( summed . as_array ( duration , dt ) . T );","title":"Sum"},{"location":"examples/example-0.5-external-stimulus/#concatenation","text":"# same lengths - use & conc = ou & sq & sin plt . plot ( conc . as_array ( duration , dt ) . T ); # can also do different length ratios, but for this you need to call ConcatenatedStimulus directly conc = stim . ConcatenatedStimulus ([ ou , sq , sin ], length_ratios = [ 0.5 , 2 , 5 ]) plt . plot ( conc . as_array ( duration , dt ) . T );","title":"Concatenation"},{"location":"examples/example-0.5-external-stimulus/#mixing-the-operations","text":"You should be able to use as many + and & as you want. Go crazy. beast = ( ou + sq ) & ( sq + sin ) plt . plot ( beast . as_array ( duration , dt ) . T ); beast = stim . ConcatenatedStimulus ([ ou + sq , ou + sin ], [ 2 , 5 ]) plt . plot ( beast . as_array ( duration , dt ) . T );","title":"Mixing the operations"},{"location":"examples/example-0.5-external-stimulus/#creating-a-custom-stimulus","text":"Creating a custom stimulus is very easy and you can build your library of stimuili as inputs for your model. There are three necessary steps: 1. Subclass stim.Input for a basic input or stim.Stimulus to have the option to set start and end times. 2. Define an __init__() method with the necessary parameters of your stimulus and set the appropriate attributes. 3. Define a generate_input(duration, dt) method, which returns a numpy array as with a shape (space, time) and that's it. Everything else described above is taken care of. Your new input class will be also support operations like + and & . Below we implement a new stimulus class that represents currents caused by a Poission spike train convolved with an exponential kernel. class PoissonNoiseWithExpKernel ( stim . Stimulus ): \"\"\" Poisson noise with exponential kernel. By subclassing the `StimulusInput` we have an option to select `start` and `end`. \"\"\" def __init__ ( self , amp , freq , tau_syn , start = None , end = None , n = 1 , seed = None ): # save parameters as attributes self . freq = freq self . amp = amp self . tau_syn = tau_syn # pass other params to parent class super () . __init__ ( start = start , end = end , n = n , seed = seed ) def generate_input ( self , duration , dt ): # this is a helper function that creates self.times vector self . _get_times ( duration = duration , dt = dt ) # do the magic here: prepare output vector x = np . zeros (( self . n , self . times . shape [ 0 ])) # compute total number of spikes total_spikes = int ( self . freq * ( self . times [ - 1 ] - self . times [ 0 ]) / 1000.0 ) # randomly put spikes into the output vector spike_indices = np . random . choice ( x . shape [ 1 ], ( self . n , total_spikes ), replace = True ) x [ np . arange ( x . shape [ 0 ])[:, None ], spike_indices ] = 1.0 # create exponential kernel time_spike_end = - self . tau_syn * np . log ( 0.001 ) arg_spike_end = np . argmin ( np . abs ( self . times - time_spike_end )) spike_kernel = np . exp ( - self . times [: arg_spike_end ] / self . tau_syn ) # convolve over dimensions x = np . apply_along_axis ( np . convolve , axis = 1 , arr = x , v = spike_kernel , mode = \"same\" ) # self._trim_stim_input takes care of trimming the stimulus based on stim_start and stim_end return self . _trim_stim ( x * self . amp ) # test ride inp = PoissonNoiseWithExpKernel ( amp = 1.2 , freq = 20.0 , tau_syn = 50.0 , n = 1 , end = 4000 ) . as_array ( duration , dt ) inp2 = PoissonNoiseWithExpKernel ( amp = 2.2 , freq = 10.0 , tau_syn = 20.0 , n = 1 , start = 1000 ) . as_array ( duration , dt ) plt . plot ( inp . T ) plt . plot ( inp2 . T ); # sum and concat test pois = PoissonNoiseWithExpKernel ( freq = 20.0 , amp = 1.2 , tau_syn = 50.0 , n = 2 ) summed = pois + sin plt . plot ( summed . as_array ( duration , dt ) . T ); concat = pois & sin plt . plot ( concat . as_array ( duration , dt ) . T );","title":"Creating a custom stimulus"},{"location":"examples/example-0.5-external-stimulus/#using-stimuli-in-neurolib","text":"First, we initialize a single node. model = ALNModel () model . params [ \"duration\" ] = 5 * 1000 model . params [ \"sigma_ou\" ] = 0.2 # we add some noise After creating a base for stimulus, we can simply call to_model(model) function and our stimulus is generated. stimulus = stim . SinusoidalInput ( amplitude = 1.0 , frequency = 1.0 ) . to_model ( model ) The stimulus is then set as an input current parameter to the model. The parameter that models a current that goes to the excitatory population is called ext_exc_current . For the inhibitory population, we can use ext_inh_current . We can also set a firing rate input, that will then be integrated over the synapses using the parameter model.params['ext_exc_rate'] . model . params [ \"ext_exc_current\" ] = stimulus model . run () When we plot the timeseries, we can see that the oscillatory activity locks to the stimulus. plt . figure ( figsize = ( 10 , 3 ), dpi = 150 ) plt . title ( \"1 Hz stimulus\" ) ax1 = plt . gca () ax1 . plot ( model . t , model . output . T , c = \"k\" ) ax2 = plt . gca () . twinx () ax2 . plot ( model . t , stimulus . squeeze (), lw = 2 , c = \"r\" , alpha = 0.8 ) ax1 . set_xlabel ( \"Time [ms]\" ) ax1 . set_ylabel ( \"Activity [Hz]\" ) ax2 . set_ylabel ( \"Stimulus [mV/ms]\" , color = \"r\" ) ax2 . set_ylabel ( \"Stimulus [mV/ms]\" , color = \"r\" ) ax2 . tick_params ( axis = \"y\" , labelcolor = \"r\" )","title":"Using stimuli in neurolib"},{"location":"examples/example-0.5-external-stimulus/#brain-network-stimulation","text":"from neurolib.utils.loadData import Dataset ds = Dataset ( \"hcp\" ) model = ALNModel ( Cmat = ds . Cmat , Dmat = ds . Dmat ) # we chose a parameterization in which the brain network oscillates slowly # between up- and down-states model . params [ \"mue_ext_mean\" ] = 2.56 model . params [ \"mui_ext_mean\" ] = 3.52 model . params [ \"b\" ] = 4.67 model . params [ \"tauA\" ] = 1522.68 model . params [ \"sigma_ou\" ] = 0.40 model . params [ \"duration\" ] = 0.2 * 60 * 1000 def plot_output_and_spectrum ( model , individual = False , vertical_mark = None ): \"\"\"A simple plotting function for the timeseries and the power spectrum of the activity. \"\"\" fig , axs = plt . subplots ( 1 , 2 , figsize = ( 8 , 2 ), dpi = 150 , gridspec_kw = { \"width_ratios\" : [ 2 , 1 ]} ) axs [ 0 ] . plot ( model . t , model . output . T , lw = 1 ) axs [ 0 ] . set_xlabel ( \"Time [ms]\" ) axs [ 0 ] . set_ylabel ( \"Activity [Hz]\" ) frs , powers = func . getMeanPowerSpectrum ( model . output , dt = model . params . dt ) axs [ 1 ] . plot ( frs , powers , c = \"k\" ) if individual : for o in model . output : frs , powers = func . getPowerSpectrum ( o , dt = model . params . dt ) axs [ 1 ] . plot ( frs , powers ) axs [ 1 ] . set_xlabel ( \"Frequency [Hz]\" ) axs [ 1 ] . set_ylabel ( \"Power\" ) plt . show ()","title":"Brain network stimulation"},{"location":"examples/example-0.5-external-stimulus/#without-stimulation","text":"model . run ( chunkwise = True ) plot_output_and_spectrum ( model )","title":"Without stimulation"},{"location":"examples/example-0.5-external-stimulus/#constructing-a-stimulus","text":"neurolib helps you to create a few basic stimuli out of the box using the function stimulus.construct_stimulus() . # construct a stimulus # we want 1-dim input - to all the nodes - 25Hz ac_stimulus = stim . SinusoidalInput ( amplitude = 0.2 , frequency = 25.0 ) . to_model ( model ) print ( ac_stimulus . shape ) # this stimulus is 1-dimensional. neurolib will threfore automatically apply it to *all nodes*. model . params [ \"ext_exc_current\" ] = ac_stimulus * 5.0 (80, 120000) model . run ( chunkwise = True ) plot_output_and_spectrum ( model )","title":"Constructing a stimulus"},{"location":"examples/example-0.5-external-stimulus/#focal-stimulation","text":"In the previous example, the stimulus was applied to all nodes simultaneously. We can also apply stimulation to a specific set of nodes. # now we create multi-d input of 25Hz ac_stimulus = stim . SinusoidalInput ( amplitude = 0.2 , frequency = 25.0 ) . to_model ( model ) print ( ac_stimulus . shape ) # We set the input to a bunch of nodes to zero. # This will have the effect that only nodes from 0 to 4 will be sitmulated! ac_stimulus [ 5 :, :] = 0 # multiply the stimulus amplitude model . params [ \"ext_exc_current\" ] = ac_stimulus * 5.0 (80, 120000) model . run ( chunkwise = True ) We can see that the spectrum has a peak at the frequency we stimulated with, but only in a subset of nodes (where we stimulated). plot_output_and_spectrum ( model , individual = True )","title":"Focal stimulation"},{"location":"examples/example-0.6-custom-model/","text":"(function() { function addWidgetsRenderer() { var requireJsScript = document.createElement('script'); requireJsScript.src = 'https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js'; var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var jupyterWidgetsScript = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} jupyterWidgetsScript.src = widgetRendererSrc; document.body.appendChild(requireJsScript); document.body.appendChild(jupyterWidgetsScript); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); Minimal model implementation This notebook demonstrates how to implement your own model in neurolib . There are two main parts of each model: its class that inherits from the Model base class and its timeIntegration() function. # change to the root directory of the project import os if os . getcwd () . split ( \"/\" )[ - 2 ] == \"neurolib\" : os . chdir ( '..' ) % load_ext autoreload % autoreload 2 try : import matplotlib.pyplot as plt except ImportError : import sys ! { sys . executable } - m pip install matplotlib import matplotlib.pyplot as plt Model equations In this example we will implement a linear model with the following equation: \\(\\frac{d}{dt} x_i(t) = - \\frac{x_i(t)}{\\tau} + \\sum_{j=0}^{N} K G_{ij} x_j(t)\\) . Here, we simulate \\(N\\) nodes that are coupled in a network. \\(x_i\\) are the elements of an \\(N\\) -dimensional state vector, \\(\\tau\\) is the decay time constant, \\(G\\) is the adjacency matrix and \\(K\\) is the global coupling strength. Implementation We first create a class for the model called LinearModel which inherits lots of functionality from the Model base class. We define state_vars and default_output so that neurolib knows how to handle the variables of the system. Next, we define init_vars in order to use the autochunk integration scheme, so we can save a lot of RAM when we run very long simulations. class LinearModel(Model): state_vars = [\"x\"] default_output = \"x\" init_vars = [\"x_init\"] Next we define a simple parameter dictionary called params . In here, we can define all the necessary parameters of the model and change their values later. In this example, we set the timescale \\(\\tau\\) , the coupling strength \\(K\\) , the integration time step dt (in ms) and the duration to 100 ms. params = dict(tau=10, K=1e-2, dt=1e-1, duration=100) We are now ready to set up the constructor of our model! This method is supposed to set up the model and prepare it for integration. All the magic happens in the background! We pass the self.timeIntegration function and the parameter dictionary self.params to the base class using super().__init__() . def __init__(self, Cmat=np.zeros((1,1))): self.params['Cmat'] = Cmat super().__init__(self.timeIntegration, self.params) That wasn't too bad, was it? We are finally ready to define the time integration method that prepares all variables and passes it to the last function that will crunch the numbers. Here we prepare the numpy arrays that will hold the simulation results. We have to prepare them before we can execute the numba code. def timeIntegration(self, p): N = p['Cmat'].shape[0] t = np.arange(1, p['duration']/p['dt']) # holds time steps x = np.ndarray((N, len(t)+1)) # holds variable x Next, we make use of a neurolib convention to prepare the initial conditions of our model. If you remember, we defined init_vars above in order to use the autochunk feature. The autochunk feature will automatically fill this parameter with the last state of the last simulated chunk so the model integration can be continued without having to remember the entire output and state variables of the model indefinitely. In this line, we check whether x_init is set or not (which it will be, when we use chunkwise integration). If it is not set, we simply use random initial conditions using rand((N, 1)) . Remember that the convention for array dimensions is array[space, time] , meaning that we only fill in the first time step with the initial condition. # either use predefined initial conditions or random ones x[:, :1] = p.get('x_init') if p.get('x_init') is not None else rand((N, 1)) We're ready to call our accelerated integration part and return the results \ud83d\ude80! return njit_integrate(x, t, p['tau'], p['K'], N, p['Cmat'], p['dt']) Numba time integration Remember to put this function outside of the class definition, so we can use use numba acceleration to greatly increase the performance of our code. We first have to let numba know which part of the code to precompile. We do this by simply placing the decorator @numba.njit in the line above the integration function. Easy way of getting 100x faster code! \u2764\ufe0f numba ! @numba.njit def njit_integrate(x, t, tau, K, N, Cmat, dt): Next, we do some simple math. We first loop over all time steps. If you have prepared the array t as described above, you can simply loop over its length. In the next line, we calculate the coupling term from the model equation above. However, instead of looping over the sum, we use a little trick here and simply compute the dot product between the coupling matrix G and the state vector x . This results in a N -dimensional vector that carries the amount of input each node receives at each time step. Finally, we loop over all nodes so we can finally add up everything. for i in range(1, 1 + len(t)): # loop over time inp = Cmat.dot(x[:, i-1]) # input vector for n in range(N): # loop over nodes In the next line, we integrate the equation that we have shown above. This integration scheme is called Euler integration and is the most simple way of solving an ODE. The idea is easy and is best expressed as x_next = x_before + f(x) * dt where f(x) is simply the time derivative \\(\\frac{d}{dt} x_i(t)\\) shown above. x[n, i] = x[n, i-1] + (- x[n, i-1] / tau + K * inp[n]) * dt # model equations We're done! The only thing left to do is to return the data so that neurolib can take over from here on. The outputs of this simulation will be available in the model.outputs attribute. You can see an example time series below. return t, x Code import numba import numpy as np from numpy.random import random as rand from neurolib.models.model import Model class LinearModel ( Model ): state_vars = [ \"x\" ] default_output = \"x\" init_vars = [ \"x_init\" ] params = dict ( tau = 10 , K = 1e-2 , dt = 1e-1 , duration = 100 ) def __init__ ( self , Cmat = np . zeros (( 1 , 1 ))): self . params [ 'Cmat' ] = Cmat super () . __init__ ( self . timeIntegration , self . params ) def timeIntegration ( self , p ): p [ 'N' ] = p [ 'Cmat' ] . shape [ 0 ] # number of nodes t = np . arange ( 1 , p [ 'duration' ] / p [ 'dt' ] + 1 ) # holds time steps x = np . ndarray (( p [ 'N' ], len ( t ) + 1 )) # holds variable x # either use predefined initial conditions or random ones x [:, : 1 ] = p [ 'x_init' ] if 'x_init' in p else rand (( p [ 'N' ], 1 )) return njit_integrate ( x , t , p [ 'tau' ], p [ 'K' ], p [ 'N' ], p [ 'Cmat' ], p [ 'dt' ]) @numba . njit def njit_integrate ( x , t , tau , K , N , Cmat , dt ): for i in range ( 1 , 1 + len ( t )): # loop over time inp = Cmat . dot ( x [:, i - 1 ]) # input vector for n in range ( N ): # loop over nodes x [ n , i ] = x [ n , i - 1 ] + \\ ( - x [ n , i - 1 ] / tau + K * inp [ n ]) * dt # model equations return t , x Running the model We prepare a \"mock\" connectivity matrix, simply consisting of 12x12 random numbers, meaning that we will simulate 12 LinearModel 's in a network. Cmat = rand (( 12 , 12 )) # use a random connectivity matrix model = LinearModel ( Cmat ) # initialize the model That's it, we are finally ready to run the model. model . run () Plot outputs plt . plot ( model . t , model . output . T ); plt . xlabel ( \"Time [ms]\" ) plt . ylabel ( \"Activity $x$\" ) Text(0, 0.5, 'Activity $x$') BOLD and autochunk Since we've followed the model implementation guidelines, the model is also compatible with chunkwise integration and can produce a BOLD signal. Let's try it out! model . params . duration = 200000 model . run ( chunkwise = True , append_outputs = True , bold = True ) plt . plot ( model . BOLD . t_BOLD , model . BOLD . BOLD . T ); plt . xlabel ( \"Time [ms]\" ) plt . ylabel ( \"BOLD activity\" ) Text(0, 0.5, 'BOLD activity')","title":"Example 0.6 custom model"},{"location":"examples/example-0.6-custom-model/#minimal-model-implementation","text":"This notebook demonstrates how to implement your own model in neurolib . There are two main parts of each model: its class that inherits from the Model base class and its timeIntegration() function. # change to the root directory of the project import os if os . getcwd () . split ( \"/\" )[ - 2 ] == \"neurolib\" : os . chdir ( '..' ) % load_ext autoreload % autoreload 2 try : import matplotlib.pyplot as plt except ImportError : import sys ! { sys . executable } - m pip install matplotlib import matplotlib.pyplot as plt","title":"Minimal model implementation"},{"location":"examples/example-0.6-custom-model/#model-equations","text":"In this example we will implement a linear model with the following equation: \\(\\frac{d}{dt} x_i(t) = - \\frac{x_i(t)}{\\tau} + \\sum_{j=0}^{N} K G_{ij} x_j(t)\\) . Here, we simulate \\(N\\) nodes that are coupled in a network. \\(x_i\\) are the elements of an \\(N\\) -dimensional state vector, \\(\\tau\\) is the decay time constant, \\(G\\) is the adjacency matrix and \\(K\\) is the global coupling strength.","title":"Model equations"},{"location":"examples/example-0.6-custom-model/#implementation","text":"We first create a class for the model called LinearModel which inherits lots of functionality from the Model base class. We define state_vars and default_output so that neurolib knows how to handle the variables of the system. Next, we define init_vars in order to use the autochunk integration scheme, so we can save a lot of RAM when we run very long simulations. class LinearModel(Model): state_vars = [\"x\"] default_output = \"x\" init_vars = [\"x_init\"] Next we define a simple parameter dictionary called params . In here, we can define all the necessary parameters of the model and change their values later. In this example, we set the timescale \\(\\tau\\) , the coupling strength \\(K\\) , the integration time step dt (in ms) and the duration to 100 ms. params = dict(tau=10, K=1e-2, dt=1e-1, duration=100) We are now ready to set up the constructor of our model! This method is supposed to set up the model and prepare it for integration. All the magic happens in the background! We pass the self.timeIntegration function and the parameter dictionary self.params to the base class using super().__init__() . def __init__(self, Cmat=np.zeros((1,1))): self.params['Cmat'] = Cmat super().__init__(self.timeIntegration, self.params) That wasn't too bad, was it? We are finally ready to define the time integration method that prepares all variables and passes it to the last function that will crunch the numbers. Here we prepare the numpy arrays that will hold the simulation results. We have to prepare them before we can execute the numba code. def timeIntegration(self, p): N = p['Cmat'].shape[0] t = np.arange(1, p['duration']/p['dt']) # holds time steps x = np.ndarray((N, len(t)+1)) # holds variable x Next, we make use of a neurolib convention to prepare the initial conditions of our model. If you remember, we defined init_vars above in order to use the autochunk feature. The autochunk feature will automatically fill this parameter with the last state of the last simulated chunk so the model integration can be continued without having to remember the entire output and state variables of the model indefinitely. In this line, we check whether x_init is set or not (which it will be, when we use chunkwise integration). If it is not set, we simply use random initial conditions using rand((N, 1)) . Remember that the convention for array dimensions is array[space, time] , meaning that we only fill in the first time step with the initial condition. # either use predefined initial conditions or random ones x[:, :1] = p.get('x_init') if p.get('x_init') is not None else rand((N, 1)) We're ready to call our accelerated integration part and return the results \ud83d\ude80! return njit_integrate(x, t, p['tau'], p['K'], N, p['Cmat'], p['dt'])","title":"Implementation"},{"location":"examples/example-0.6-custom-model/#numba-time-integration","text":"Remember to put this function outside of the class definition, so we can use use numba acceleration to greatly increase the performance of our code. We first have to let numba know which part of the code to precompile. We do this by simply placing the decorator @numba.njit in the line above the integration function. Easy way of getting 100x faster code! \u2764\ufe0f numba ! @numba.njit def njit_integrate(x, t, tau, K, N, Cmat, dt): Next, we do some simple math. We first loop over all time steps. If you have prepared the array t as described above, you can simply loop over its length. In the next line, we calculate the coupling term from the model equation above. However, instead of looping over the sum, we use a little trick here and simply compute the dot product between the coupling matrix G and the state vector x . This results in a N -dimensional vector that carries the amount of input each node receives at each time step. Finally, we loop over all nodes so we can finally add up everything. for i in range(1, 1 + len(t)): # loop over time inp = Cmat.dot(x[:, i-1]) # input vector for n in range(N): # loop over nodes In the next line, we integrate the equation that we have shown above. This integration scheme is called Euler integration and is the most simple way of solving an ODE. The idea is easy and is best expressed as x_next = x_before + f(x) * dt where f(x) is simply the time derivative \\(\\frac{d}{dt} x_i(t)\\) shown above. x[n, i] = x[n, i-1] + (- x[n, i-1] / tau + K * inp[n]) * dt # model equations We're done! The only thing left to do is to return the data so that neurolib can take over from here on. The outputs of this simulation will be available in the model.outputs attribute. You can see an example time series below. return t, x","title":"Numba time integration"},{"location":"examples/example-0.6-custom-model/#code","text":"import numba import numpy as np from numpy.random import random as rand from neurolib.models.model import Model class LinearModel ( Model ): state_vars = [ \"x\" ] default_output = \"x\" init_vars = [ \"x_init\" ] params = dict ( tau = 10 , K = 1e-2 , dt = 1e-1 , duration = 100 ) def __init__ ( self , Cmat = np . zeros (( 1 , 1 ))): self . params [ 'Cmat' ] = Cmat super () . __init__ ( self . timeIntegration , self . params ) def timeIntegration ( self , p ): p [ 'N' ] = p [ 'Cmat' ] . shape [ 0 ] # number of nodes t = np . arange ( 1 , p [ 'duration' ] / p [ 'dt' ] + 1 ) # holds time steps x = np . ndarray (( p [ 'N' ], len ( t ) + 1 )) # holds variable x # either use predefined initial conditions or random ones x [:, : 1 ] = p [ 'x_init' ] if 'x_init' in p else rand (( p [ 'N' ], 1 )) return njit_integrate ( x , t , p [ 'tau' ], p [ 'K' ], p [ 'N' ], p [ 'Cmat' ], p [ 'dt' ]) @numba . njit def njit_integrate ( x , t , tau , K , N , Cmat , dt ): for i in range ( 1 , 1 + len ( t )): # loop over time inp = Cmat . dot ( x [:, i - 1 ]) # input vector for n in range ( N ): # loop over nodes x [ n , i ] = x [ n , i - 1 ] + \\ ( - x [ n , i - 1 ] / tau + K * inp [ n ]) * dt # model equations return t , x","title":"Code"},{"location":"examples/example-0.6-custom-model/#running-the-model","text":"We prepare a \"mock\" connectivity matrix, simply consisting of 12x12 random numbers, meaning that we will simulate 12 LinearModel 's in a network. Cmat = rand (( 12 , 12 )) # use a random connectivity matrix model = LinearModel ( Cmat ) # initialize the model That's it, we are finally ready to run the model. model . run ()","title":"Running the model"},{"location":"examples/example-0.6-custom-model/#plot-outputs","text":"plt . plot ( model . t , model . output . T ); plt . xlabel ( \"Time [ms]\" ) plt . ylabel ( \"Activity $x$\" ) Text(0, 0.5, 'Activity $x$')","title":"Plot outputs"},{"location":"examples/example-0.6-custom-model/#bold-and-autochunk","text":"Since we've followed the model implementation guidelines, the model is also compatible with chunkwise integration and can produce a BOLD signal. Let's try it out! model . params . duration = 200000 model . run ( chunkwise = True , append_outputs = True , bold = True ) plt . plot ( model . BOLD . t_BOLD , model . BOLD . BOLD . T ); plt . xlabel ( \"Time [ms]\" ) plt . ylabel ( \"BOLD activity\" ) Text(0, 0.5, 'BOLD activity')","title":"BOLD and autochunk"},{"location":"examples/example-1-aln-parameter-exploration/","text":"(function() { function addWidgetsRenderer() { var requireJsScript = document.createElement('script'); requireJsScript.src = 'https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js'; var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var jupyterWidgetsScript = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} jupyterWidgetsScript.src = widgetRendererSrc; document.body.appendChild(requireJsScript); document.body.appendChild(jupyterWidgetsScript); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); # change to the root directory of the project import os if os . getcwd () . split ( \"/\" )[ - 1 ] == \"examples\" : os . chdir ( '..' ) # This will reload all imports as soon as the code changes % load_ext autoreload % autoreload 2 try : import matplotlib.pyplot as plt except ImportError : import sys ! { sys . executable } - m pip install matplotlib import matplotlib.pyplot as plt import numpy as np from neurolib.models.aln import ALNModel from neurolib.utils.parameterSpace import ParameterSpace from neurolib.optimize.exploration import BoxSearch # a nice color map plt . rcParams [ 'image.cmap' ] = 'plasma' aln = ALNModel () parameters = ParameterSpace ({ \"mue_ext_mean\" : np . linspace ( 0 , 3 , 2 ), \"mui_ext_mean\" : np . linspace ( 0 , 3 , 2 )}) # info: chose np.linspace(0, 3, 21) or more, values here are low for testing search = BoxSearch ( aln , parameters , filename = \"example-1.hdf\" ) search . run () search . loadResults () print ( \"Number of results: {} \" . format ( len ( search . results ))) # Example analysis of the results # The .results attribute is a list and can be indexed by the run # number (which is also the index of the pandas dataframe .dfResults). # Here we compute the maximum firing rate of the node in the last second # and add the result (a float) to the pandas dataframe. for i in search . dfResults . index : search . dfResults . loc [ i , 'max_r' ] = np . max ( search . results [ i ][ 'rates_exc' ][:, - int ( 1000 / aln . params [ 'dt' ]):]) plt . imshow ( search . dfResults . pivot_table ( values = 'max_r' , index = 'mui_ext_mean' , columns = 'mue_ext_mean' ), \\ extent = [ min ( search . dfResults . mue_ext_mean ), max ( search . dfResults . mue_ext_mean ), min ( search . dfResults . mui_ext_mean ), max ( search . dfResults . mui_ext_mean )], origin = 'lower' ) plt . colorbar ( label = 'Maximum rate [Hz]' ) plt . xlabel ( \"Input to E\" ) plt . ylabel ( \"Input to I\" ) Text(0, 0.5, 'Input to I')","title":"Example 1 aln parameter exploration"},{"location":"examples/example-1.1-custom-parameter-exploration/","text":"(function() { function addWidgetsRenderer() { var requireJsScript = document.createElement('script'); requireJsScript.src = 'https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js'; var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var jupyterWidgetsScript = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} jupyterWidgetsScript.src = widgetRendererSrc; document.body.appendChild(requireJsScript); document.body.appendChild(jupyterWidgetsScript); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); A simple parameter exploration This notebook demonstrates a very simple parameter exploration of a custom function that we have defined. It is a simple function that returns the distance to a unit circle, so we expect our parameter exploration to resemble a circle. # change to the root directory of the project import os if os . getcwd () . split ( \"/\" )[ - 1 ] == \"examples\" : os . chdir ( '..' ) # This will reload all imports as soon as the code changes % load_ext autoreload % autoreload 2 try : import matplotlib.pyplot as plt except ImportError : import sys ! { sys . executable } - m pip install matplotlib import matplotlib.pyplot as plt import numpy as np from neurolib.utils.parameterSpace import ParameterSpace from neurolib.optimize.exploration import BoxSearch Define the evaluation function Here we define a very simple evaluation function. The function needs to take in traj as an argument, which is the pypet trajectory. This is how the function knows what parameters were assigned to it. Using the builtin function search.getParametersFromTraj(traj) we can then retrieve the parameters for this run. They are returned as a dictionary and can be accessed in the function. In the last step, we use search.saveToPypet(result_dict, traj) to save the results to the pypet trajectory and to an HDF. In between, the computational magic happens! def explore_me ( traj ): pars = search . getParametersFromTraj ( traj ) # let's calculate the distance to a circle computation_result = abs (( pars [ 'x' ] ** 2 + pars [ 'y' ] ** 2 ) - 1 ) result_dict = { \"distance\" : computation_result } search . saveToPypet ( result_dict , traj ) Define the parameter space and exploration Here we define which space we want to cover. For this, we use the builtin class ParameterSpace which provides a very easy interface to the exploration. To initialize the exploration, we simply pass the evaluation function and the parameter space to the BoxSearch class. parameters = ParameterSpace ({ \"x\" : np . linspace ( - 2 , 2 , 2 ), \"y\" : np . linspace ( - 2 , 2 , 2 )}) # info: chose np.linspace(-2, 2, 40) or more, values here are low for testing search = BoxSearch ( evalFunction = explore_me , parameterSpace = parameters , filename = \"example-1.1.hdf\" ) Run And off we go! search . run () Get results We can easily obtain the results from pypet. First we call search.loadResults() to make sure that the results are loaded from the hdf file to our instance. search . loadResults () print ( \"Number of results: {} \" . format ( len ( search . results ))) The runs are also ordered in a simple pandas dataframe called search.dfResults . We cycle through all results by calling search.results[i] and loading the desired result (here the distance to the circle) into the dataframe for i in search . dfResults . index : search . dfResults . loc [ i , 'distance' ] = search . results [ i ][ 'distance' ] search . dfResults .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } x y distance 0 -2.0 -2.000000 7.000000 1 -2.0 -1.897436 6.600263 2 -2.0 -1.794872 6.221565 3 -2.0 -1.692308 5.863905 4 -2.0 -1.589744 5.527285 ... ... ... ... 1595 2.0 1.589744 5.527285 1596 2.0 1.692308 5.863905 1597 2.0 1.794872 6.221565 1598 2.0 1.897436 6.600263 1599 2.0 2.000000 7.000000 1600 rows \u00d7 3 columns And of course a plot can visualize the results very easily. plt . imshow ( search . dfResults . pivot_table ( values = 'distance' , index = 'x' , columns = 'y' ), \\ extent = [ min ( search . dfResults . x ), max ( search . dfResults . x ), min ( search . dfResults . y ), max ( search . dfResults . y )], origin = 'lower' ) plt . colorbar ( label = 'Distance to the unit circle' ) <matplotlib.colorbar.Colorbar at 0x124a71588>","title":"Example 1.1 custom parameter exploration"},{"location":"examples/example-1.1-custom-parameter-exploration/#a-simple-parameter-exploration","text":"This notebook demonstrates a very simple parameter exploration of a custom function that we have defined. It is a simple function that returns the distance to a unit circle, so we expect our parameter exploration to resemble a circle. # change to the root directory of the project import os if os . getcwd () . split ( \"/\" )[ - 1 ] == \"examples\" : os . chdir ( '..' ) # This will reload all imports as soon as the code changes % load_ext autoreload % autoreload 2 try : import matplotlib.pyplot as plt except ImportError : import sys ! { sys . executable } - m pip install matplotlib import matplotlib.pyplot as plt import numpy as np from neurolib.utils.parameterSpace import ParameterSpace from neurolib.optimize.exploration import BoxSearch","title":"A simple parameter exploration"},{"location":"examples/example-1.1-custom-parameter-exploration/#define-the-evaluation-function","text":"Here we define a very simple evaluation function. The function needs to take in traj as an argument, which is the pypet trajectory. This is how the function knows what parameters were assigned to it. Using the builtin function search.getParametersFromTraj(traj) we can then retrieve the parameters for this run. They are returned as a dictionary and can be accessed in the function. In the last step, we use search.saveToPypet(result_dict, traj) to save the results to the pypet trajectory and to an HDF. In between, the computational magic happens! def explore_me ( traj ): pars = search . getParametersFromTraj ( traj ) # let's calculate the distance to a circle computation_result = abs (( pars [ 'x' ] ** 2 + pars [ 'y' ] ** 2 ) - 1 ) result_dict = { \"distance\" : computation_result } search . saveToPypet ( result_dict , traj )","title":"Define the evaluation function"},{"location":"examples/example-1.1-custom-parameter-exploration/#define-the-parameter-space-and-exploration","text":"Here we define which space we want to cover. For this, we use the builtin class ParameterSpace which provides a very easy interface to the exploration. To initialize the exploration, we simply pass the evaluation function and the parameter space to the BoxSearch class. parameters = ParameterSpace ({ \"x\" : np . linspace ( - 2 , 2 , 2 ), \"y\" : np . linspace ( - 2 , 2 , 2 )}) # info: chose np.linspace(-2, 2, 40) or more, values here are low for testing search = BoxSearch ( evalFunction = explore_me , parameterSpace = parameters , filename = \"example-1.1.hdf\" )","title":"Define the parameter space and exploration"},{"location":"examples/example-1.1-custom-parameter-exploration/#run","text":"And off we go! search . run ()","title":"Run"},{"location":"examples/example-1.1-custom-parameter-exploration/#get-results","text":"We can easily obtain the results from pypet. First we call search.loadResults() to make sure that the results are loaded from the hdf file to our instance. search . loadResults () print ( \"Number of results: {} \" . format ( len ( search . results ))) The runs are also ordered in a simple pandas dataframe called search.dfResults . We cycle through all results by calling search.results[i] and loading the desired result (here the distance to the circle) into the dataframe for i in search . dfResults . index : search . dfResults . loc [ i , 'distance' ] = search . results [ i ][ 'distance' ] search . dfResults .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } x y distance 0 -2.0 -2.000000 7.000000 1 -2.0 -1.897436 6.600263 2 -2.0 -1.794872 6.221565 3 -2.0 -1.692308 5.863905 4 -2.0 -1.589744 5.527285 ... ... ... ... 1595 2.0 1.589744 5.527285 1596 2.0 1.692308 5.863905 1597 2.0 1.794872 6.221565 1598 2.0 1.897436 6.600263 1599 2.0 2.000000 7.000000 1600 rows \u00d7 3 columns And of course a plot can visualize the results very easily. plt . imshow ( search . dfResults . pivot_table ( values = 'distance' , index = 'x' , columns = 'y' ), \\ extent = [ min ( search . dfResults . x ), max ( search . dfResults . x ), min ( search . dfResults . y ), max ( search . dfResults . y )], origin = 'lower' ) plt . colorbar ( label = 'Distance to the unit circle' ) <matplotlib.colorbar.Colorbar at 0x124a71588>","title":"Get results"},{"location":"examples/example-1.2-brain-network-exploration/","text":"(function() { function addWidgetsRenderer() { var requireJsScript = document.createElement('script'); requireJsScript.src = 'https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js'; var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var jupyterWidgetsScript = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} jupyterWidgetsScript.src = widgetRendererSrc; document.body.appendChild(requireJsScript); document.body.appendChild(jupyterWidgetsScript); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); Parameter exploration of a brain network model This notebook demonstrates how to scan the parameter space of a brain network model using neurolib . We will simulate BOLD activity and compare the results to empirical data to identify optimal parameters of the model. The steps outlined in this notebook are the following: We load a DTI and resting-state fMRI dataset ( hcp ) and set up a brain network using the FHNModel . We simulate the system for a range of different parameter configurations. We load the simulated data from disk. We postprocess the results and obtain the model fit. Finally, we plot the results in the parameter space of the exploration. #hide # change to the root directory of the project import os if os . getcwd () . split ( \"/\" )[ - 1 ] == \"examples\" : os . chdir ( '..' ) # This will reload all imports as soon as the code changes % load_ext autoreload % autoreload 2 The autoreload extension is already loaded. To reload it, use: %reload_ext autoreload #hide import logging logging . getLogger () . setLevel ( logging . INFO ) import warnings warnings . filterwarnings ( \"ignore\" ) #hide try : import matplotlib.pyplot as plt except ImportError : import sys ! { sys . executable } - m pip install matplotlib import matplotlib.pyplot as plt import numpy as np # Let's import all the necessary functions for the parameter from neurolib.models.fhn import FHNModel from neurolib.utils.parameterSpace import ParameterSpace from neurolib.optimize.exploration import BoxSearch # load some utilty functions for explorations import neurolib.utils.pypetUtils as pu import neurolib.utils.paths as paths import neurolib.optimize.exploration.explorationUtils as eu # The brain network dataset from neurolib.utils.loadData import Dataset # Some useful functions are provided here import neurolib.utils.functions as func # a nice color map plt . rcParams [ 'image.cmap' ] = 'plasma' 1. Set up a brain network We load a dataset (in this case the hcp dataset from the Human Connectome Project) and initialize a model to run on each node of the brain network (here the FHNModel which is the Fitz-Hugh Nagumo model). ds = Dataset ( \"hcp\" ) model = FHNModel ( Cmat = ds . Cmat , Dmat = ds . Dmat ) model . params . duration = 20 * 1000 #ms # testing: model.params.duration = 20 * 1000 #ms # original: model.params.duration = 5 * 60 * 1000 #ms Running the model is as simple as entering model.run(chunkwise=True) . 2. Run the exploration We define a parameter range to explore. Our first parameter is x_ext , which is the input to each node of the FHNModel in a brain network. Therefore, this parameter is a list with N entries, one per node. Our next parameter is K_gl , the global coupling strength. Finally, we have the coupling parameter, which defines how each FHNModel is coupled to its adjacent nodes via either additive coupling ( activity += input ) or diffusive ( activity += (activity - input) ). parameters = ParameterSpace ({ \"x_ext\" : [ np . ones (( model . params [ 'N' ],)) * a for a in np . linspace ( 0 , 2 , 2 )] # testing: 2, original: 41 , \"K_gl\" : np . linspace ( 0 , 2 , 2 ) # testing: 2, original: 41 , \"coupling\" : [ \"additive\" , \"diffusive\" ] }, kind = \"grid\" ) search = BoxSearch ( model = model , parameterSpace = parameters , filename = \"example-1.2.0.hdf\" ) We run the exploration, simply by calling the run() function of the BoxSearch class. We can pass parameters to this function, that will be directly passed to the FHNModel.run() function of the simulated model. This way, we can easily specify to run the simulation chunkwise , without storing all the activity in memory, and simulate bold activity as well. Note that the default behaviour of the BoxSearch class is to save the default_output of each model and if bold is simulated, then also the BOLD data. If the exploration is initialized with BoxSearch(saveAllModelOutputs=True) , the exploration would save all outputs of the model. This can obviously create a lot of data to store, so please use this option at your own discretion. search . run ( chunkwise = True , bold = True ) 3. Load results A simple helper function for getting the trajectories of an hdf file created by pypet can be found in pypetUtils.py (aka pu ). This way, you can explore which explorations are in the file and decide later which one you want to load for analysis pu . getTrajectorynamesInFile ( os . path . join ( paths . HDF_DIR , \"example-1.2.0.hdf\" )) ['results-2020-04-08-02H-01M-53S', 'results-2020-04-08-02H-50M-09S'] The default behaviour will load the latest exploration. It's name is also stored in search.trajectoryName : search . trajectoryName 'results-2020-04-08-02H-50M-09S' Now we load all results. As said above, the newest exploration will be loaded by default. You can load results from earlier explorations by adding the argument trajectoryName=results-from-earlier and also chose another hdf file by using the argument filename=/path/to/explorations.hdf . Remember that using search.loadResults() will load all results to memory. This can cause a lot of RAM, depending on how big the exploration was. search . loadResults () print ( \"Number of results: {} \" . format ( len ( search . results ))) One way of loading a result without loading everything else into RAM is to use the builtin function search.getRun() . However, you need to know which runId you're looking for! For this, you can run search.loadDfResults() to create a pandas.DataFrame search.dfResults with all parameters (which also happens when you call search.loadResults() ). search . getRun ( 6 ) . params {'x_ext': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'K_gl': 0.15000000000000002, 'coupling': 'additive'} After loading the results with search.loadResults() they are now available as a simple list using search.results . Let's look at the time series of one result. rId = 2 # test:2, original: 1327 plt . plot ( search . results [ rId ] . t , search . results [ rId ] . x . T ); plt . xlabel ( \"Time [ms]\" ) plt . ylabel ( \"Activity\" ) Text(0, 0.5, 'Activity') Using search.loadResults() also created a pandas.DataFrame with the individual run's parameters and their runId . search . dfResults . iloc [ - 4 :] .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } x_ext K_gl coupling fc max_x amp_x 3358 2.0 1.95 additive 0.304496 2.446207 1.463651e+00 3359 2.0 1.95 diffusive 0.221238 0.872110 2.275957e-14 3360 2.0 2.00 additive 0.310389 2.489208 1.503437e+00 3361 2.0 2.00 diffusive 0.226729 0.872110 2.253753e-14 If you remember from before, the external input parameter x_ext is a list of length N (one per node). Since they're all the same in this example, we reduce the parameter to only the first entry of each list. search . dfResults . x_ext = [ a [ 0 ] for a in list ( search . dfResults . x_ext )] search . dfResults . iloc [ - 4 :] .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } x_ext K_gl coupling 3358 2.0 1.95 additive 3359 2.0 1.95 diffusive 3360 2.0 2.00 additive 3361 2.0 2.00 diffusive 4. Postprocessing We can use eu.processExplorationResults() from explorationUtils.py (aka eu ) to process the results from the simluation and store results in our pandas.DataFrame of all results called search.dfResults : eu . processExplorationResults ( search , model = model , ds = ds , bold_transient = 10000 ) This finally gives us a dataframe with parameters and respective values from postprocessing the results, which we can access using search.dfResults . We can use the utility function eu.findCloseResults() to navigate in this DataFrame and find for example the runId of a run for a specific parameter configuration. eu . findCloseResults ( search . dfResults , dist = 0.2 , K_gl = 0.5 , x_ext = 1.0 ) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } x_ext K_gl coupling fc max_x amp_x 1324 0.80 0.30 additive 0.364910 1.192267 1.428502 1325 0.80 0.30 diffusive 0.302487 0.576765 0.467873 1326 0.80 0.35 additive 0.337226 1.241613 1.511995 1327 0.80 0.35 diffusive 0.187238 0.547917 0.423548 1328 0.80 0.40 additive 0.200489 1.287626 1.590182 ... ... ... ... ... ... ... 1909 1.15 0.55 diffusive 0.363809 0.772698 0.577180 1910 1.15 0.60 additive 0.348988 1.234206 1.050313 1911 1.15 0.60 diffusive 0.278103 0.768822 0.566546 1912 1.15 0.65 additive 0.371943 1.276929 1.091328 1913 1.15 0.65 diffusive 0.292993 0.762355 0.550818 128 rows \u00d7 6 columns To understand what is happening in eu.processExplorationResults() , it helps to see how we could do postprocessing on the loaded data ourselves. Let's calculate the correlation to empirical functional connectivity using the builtin funtions func.fc() and func.matrix_correlation() . mean_corr = np . mean ([ func . matrix_correlation ( func . fc ( search . results [ rId ][ 'BOLD' ]), fc ) for fc in ds . FCs ]) print ( f \"Mean correlation of run { rId } with empirical FC matrices is { mean_corr : .02 } \" ) Mean correlation of run 3324 with empirical FC matrices is 0.28 5. Plot Another usefull function is eu.plotExplorationResults() , which helps you to visualize the results from the exploration. You can specify which parameters should be the x- and the y-axis using the par1=[parameter_name, parameter_label] and par2 arguments, and you can define by which paramter plane the results should be \"sliced\". plot_key_label = \"Maximum of output\" eu . plotExplorationResults ( search . dfResults , par1 = [ 'x_ext' , '$x_ {ext} $' ], par2 = [ 'K_gl' , '$K$' ], plot_key = 'max_x' , by = [ 'coupling' ], by_label = [ 'coupling' ], plot_key_label = plot_key_label , one_figure = True ) BOLD functional connectivity We want to find parameter for which the brain network model produces realistic BOLD functional connectivity. For this, we calculated the entry fc in search.dfResults by taking the func.fc() of the model.BOLD timeseries and compared it to empirical data using func.matrix_correlation . Below, the average of this value across all subjects of the dataset is plotted. A higher value (brighter color) means a better fit to the empirical data. Observe how the best solutions tend to cluster at the edges of bifurcations, indicating that correlations in the network are generated by multiple nodes undergoing bifurcation together, such as transitioning from the constant activity (fixed point) solution to an oscillation. plot_key_label = \"FC correlation\" eu . plotExplorationResults ( search . dfResults , par1 = [ 'x_ext' , '$x_ {ext} $' ], par2 = [ 'K_gl' , '$K$' ], plot_key = 'fc' , by = [ 'coupling' ], by_label = [ 'coupling' ], plot_key_label = plot_key_label , one_figure = True )","title":"Example 1.2 brain network exploration"},{"location":"examples/example-1.2-brain-network-exploration/#parameter-exploration-of-a-brain-network-model","text":"This notebook demonstrates how to scan the parameter space of a brain network model using neurolib . We will simulate BOLD activity and compare the results to empirical data to identify optimal parameters of the model. The steps outlined in this notebook are the following: We load a DTI and resting-state fMRI dataset ( hcp ) and set up a brain network using the FHNModel . We simulate the system for a range of different parameter configurations. We load the simulated data from disk. We postprocess the results and obtain the model fit. Finally, we plot the results in the parameter space of the exploration. #hide # change to the root directory of the project import os if os . getcwd () . split ( \"/\" )[ - 1 ] == \"examples\" : os . chdir ( '..' ) # This will reload all imports as soon as the code changes % load_ext autoreload % autoreload 2 The autoreload extension is already loaded. To reload it, use: %reload_ext autoreload #hide import logging logging . getLogger () . setLevel ( logging . INFO ) import warnings warnings . filterwarnings ( \"ignore\" ) #hide try : import matplotlib.pyplot as plt except ImportError : import sys ! { sys . executable } - m pip install matplotlib import matplotlib.pyplot as plt import numpy as np # Let's import all the necessary functions for the parameter from neurolib.models.fhn import FHNModel from neurolib.utils.parameterSpace import ParameterSpace from neurolib.optimize.exploration import BoxSearch # load some utilty functions for explorations import neurolib.utils.pypetUtils as pu import neurolib.utils.paths as paths import neurolib.optimize.exploration.explorationUtils as eu # The brain network dataset from neurolib.utils.loadData import Dataset # Some useful functions are provided here import neurolib.utils.functions as func # a nice color map plt . rcParams [ 'image.cmap' ] = 'plasma'","title":"Parameter exploration of a brain network model"},{"location":"examples/example-1.2-brain-network-exploration/#1-set-up-a-brain-network","text":"We load a dataset (in this case the hcp dataset from the Human Connectome Project) and initialize a model to run on each node of the brain network (here the FHNModel which is the Fitz-Hugh Nagumo model). ds = Dataset ( \"hcp\" ) model = FHNModel ( Cmat = ds . Cmat , Dmat = ds . Dmat ) model . params . duration = 20 * 1000 #ms # testing: model.params.duration = 20 * 1000 #ms # original: model.params.duration = 5 * 60 * 1000 #ms Running the model is as simple as entering model.run(chunkwise=True) .","title":"1. Set up a brain network"},{"location":"examples/example-1.2-brain-network-exploration/#2-run-the-exploration","text":"We define a parameter range to explore. Our first parameter is x_ext , which is the input to each node of the FHNModel in a brain network. Therefore, this parameter is a list with N entries, one per node. Our next parameter is K_gl , the global coupling strength. Finally, we have the coupling parameter, which defines how each FHNModel is coupled to its adjacent nodes via either additive coupling ( activity += input ) or diffusive ( activity += (activity - input) ). parameters = ParameterSpace ({ \"x_ext\" : [ np . ones (( model . params [ 'N' ],)) * a for a in np . linspace ( 0 , 2 , 2 )] # testing: 2, original: 41 , \"K_gl\" : np . linspace ( 0 , 2 , 2 ) # testing: 2, original: 41 , \"coupling\" : [ \"additive\" , \"diffusive\" ] }, kind = \"grid\" ) search = BoxSearch ( model = model , parameterSpace = parameters , filename = \"example-1.2.0.hdf\" ) We run the exploration, simply by calling the run() function of the BoxSearch class. We can pass parameters to this function, that will be directly passed to the FHNModel.run() function of the simulated model. This way, we can easily specify to run the simulation chunkwise , without storing all the activity in memory, and simulate bold activity as well. Note that the default behaviour of the BoxSearch class is to save the default_output of each model and if bold is simulated, then also the BOLD data. If the exploration is initialized with BoxSearch(saveAllModelOutputs=True) , the exploration would save all outputs of the model. This can obviously create a lot of data to store, so please use this option at your own discretion. search . run ( chunkwise = True , bold = True )","title":"2. Run the exploration"},{"location":"examples/example-1.2-brain-network-exploration/#3-load-results","text":"A simple helper function for getting the trajectories of an hdf file created by pypet can be found in pypetUtils.py (aka pu ). This way, you can explore which explorations are in the file and decide later which one you want to load for analysis pu . getTrajectorynamesInFile ( os . path . join ( paths . HDF_DIR , \"example-1.2.0.hdf\" )) ['results-2020-04-08-02H-01M-53S', 'results-2020-04-08-02H-50M-09S'] The default behaviour will load the latest exploration. It's name is also stored in search.trajectoryName : search . trajectoryName 'results-2020-04-08-02H-50M-09S' Now we load all results. As said above, the newest exploration will be loaded by default. You can load results from earlier explorations by adding the argument trajectoryName=results-from-earlier and also chose another hdf file by using the argument filename=/path/to/explorations.hdf . Remember that using search.loadResults() will load all results to memory. This can cause a lot of RAM, depending on how big the exploration was. search . loadResults () print ( \"Number of results: {} \" . format ( len ( search . results ))) One way of loading a result without loading everything else into RAM is to use the builtin function search.getRun() . However, you need to know which runId you're looking for! For this, you can run search.loadDfResults() to create a pandas.DataFrame search.dfResults with all parameters (which also happens when you call search.loadResults() ). search . getRun ( 6 ) . params {'x_ext': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'K_gl': 0.15000000000000002, 'coupling': 'additive'} After loading the results with search.loadResults() they are now available as a simple list using search.results . Let's look at the time series of one result. rId = 2 # test:2, original: 1327 plt . plot ( search . results [ rId ] . t , search . results [ rId ] . x . T ); plt . xlabel ( \"Time [ms]\" ) plt . ylabel ( \"Activity\" ) Text(0, 0.5, 'Activity') Using search.loadResults() also created a pandas.DataFrame with the individual run's parameters and their runId . search . dfResults . iloc [ - 4 :] .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } x_ext K_gl coupling fc max_x amp_x 3358 2.0 1.95 additive 0.304496 2.446207 1.463651e+00 3359 2.0 1.95 diffusive 0.221238 0.872110 2.275957e-14 3360 2.0 2.00 additive 0.310389 2.489208 1.503437e+00 3361 2.0 2.00 diffusive 0.226729 0.872110 2.253753e-14 If you remember from before, the external input parameter x_ext is a list of length N (one per node). Since they're all the same in this example, we reduce the parameter to only the first entry of each list. search . dfResults . x_ext = [ a [ 0 ] for a in list ( search . dfResults . x_ext )] search . dfResults . iloc [ - 4 :] .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } x_ext K_gl coupling 3358 2.0 1.95 additive 3359 2.0 1.95 diffusive 3360 2.0 2.00 additive 3361 2.0 2.00 diffusive","title":"3. Load results"},{"location":"examples/example-1.2-brain-network-exploration/#4-postprocessing","text":"We can use eu.processExplorationResults() from explorationUtils.py (aka eu ) to process the results from the simluation and store results in our pandas.DataFrame of all results called search.dfResults : eu . processExplorationResults ( search , model = model , ds = ds , bold_transient = 10000 ) This finally gives us a dataframe with parameters and respective values from postprocessing the results, which we can access using search.dfResults . We can use the utility function eu.findCloseResults() to navigate in this DataFrame and find for example the runId of a run for a specific parameter configuration. eu . findCloseResults ( search . dfResults , dist = 0.2 , K_gl = 0.5 , x_ext = 1.0 ) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } x_ext K_gl coupling fc max_x amp_x 1324 0.80 0.30 additive 0.364910 1.192267 1.428502 1325 0.80 0.30 diffusive 0.302487 0.576765 0.467873 1326 0.80 0.35 additive 0.337226 1.241613 1.511995 1327 0.80 0.35 diffusive 0.187238 0.547917 0.423548 1328 0.80 0.40 additive 0.200489 1.287626 1.590182 ... ... ... ... ... ... ... 1909 1.15 0.55 diffusive 0.363809 0.772698 0.577180 1910 1.15 0.60 additive 0.348988 1.234206 1.050313 1911 1.15 0.60 diffusive 0.278103 0.768822 0.566546 1912 1.15 0.65 additive 0.371943 1.276929 1.091328 1913 1.15 0.65 diffusive 0.292993 0.762355 0.550818 128 rows \u00d7 6 columns To understand what is happening in eu.processExplorationResults() , it helps to see how we could do postprocessing on the loaded data ourselves. Let's calculate the correlation to empirical functional connectivity using the builtin funtions func.fc() and func.matrix_correlation() . mean_corr = np . mean ([ func . matrix_correlation ( func . fc ( search . results [ rId ][ 'BOLD' ]), fc ) for fc in ds . FCs ]) print ( f \"Mean correlation of run { rId } with empirical FC matrices is { mean_corr : .02 } \" ) Mean correlation of run 3324 with empirical FC matrices is 0.28","title":"4. Postprocessing"},{"location":"examples/example-1.2-brain-network-exploration/#5-plot","text":"Another usefull function is eu.plotExplorationResults() , which helps you to visualize the results from the exploration. You can specify which parameters should be the x- and the y-axis using the par1=[parameter_name, parameter_label] and par2 arguments, and you can define by which paramter plane the results should be \"sliced\". plot_key_label = \"Maximum of output\" eu . plotExplorationResults ( search . dfResults , par1 = [ 'x_ext' , '$x_ {ext} $' ], par2 = [ 'K_gl' , '$K$' ], plot_key = 'max_x' , by = [ 'coupling' ], by_label = [ 'coupling' ], plot_key_label = plot_key_label , one_figure = True )","title":"5. Plot"},{"location":"examples/example-1.2-brain-network-exploration/#bold-functional-connectivity","text":"We want to find parameter for which the brain network model produces realistic BOLD functional connectivity. For this, we calculated the entry fc in search.dfResults by taking the func.fc() of the model.BOLD timeseries and compared it to empirical data using func.matrix_correlation . Below, the average of this value across all subjects of the dataset is plotted. A higher value (brighter color) means a better fit to the empirical data. Observe how the best solutions tend to cluster at the edges of bifurcations, indicating that correlations in the network are generated by multiple nodes undergoing bifurcation together, such as transitioning from the constant activity (fixed point) solution to an oscillation. plot_key_label = \"FC correlation\" eu . plotExplorationResults ( search . dfResults , par1 = [ 'x_ext' , '$x_ {ext} $' ], par2 = [ 'K_gl' , '$K$' ], plot_key = 'fc' , by = [ 'coupling' ], by_label = [ 'coupling' ], plot_key_label = plot_key_label , one_figure = True )","title":"BOLD functional connectivity"},{"location":"examples/example-1.2.1-brain-exploration-postprocessing/","text":"(function() { function addWidgetsRenderer() { var requireJsScript = document.createElement('script'); requireJsScript.src = 'https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js'; var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var jupyterWidgetsScript = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} jupyterWidgetsScript.src = widgetRendererSrc; document.body.appendChild(requireJsScript); document.body.appendChild(jupyterWidgetsScript); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); Parameter exploration with custom run function and postprocessing This notebook demonstrates how to scan the parameter space of a brain network model using neurolib with a custom evaluation function to quickly find regions of interest. The evaluation function is designed to increase the speed for the exploration by focussing on regions where the simulated dynamics meets certain criteria. For this, the simulation is run in multiple, successive steps, that increase in duration. Iterative evaluation The evaluation of a simulation takes multiple steps: Step 1 runs for a few seconds and checks if there is any rate activity at all Step 2 runs a bit longer and checks if there is any BOLD activity Step 3 runs the full simulation Postprocessing In this scenario, we want to postprocess the simulated data as soon as the simulation is done and before writing the results to the hard disk. After the full simulation is run, the funciotnal connectivity (FC) of the BOLD signal is computed and compared to the empirical FC dataset. The Pearson correlation of the FC matrices is computed and the average is taken. We then tell pypet to save these postprocessed results along with the model output. #hide # change to the root directory of the project import os if os . getcwd () . split ( \"/\" )[ - 1 ] == \"examples\" : os . chdir ( '..' ) # This will reload all imports as soon as the code changes % load_ext autoreload % autoreload 2 #hide try : import matplotlib.pyplot as plt except ImportError : import sys ! { sys . executable } - m pip install matplotlib import matplotlib.pyplot as plt # a nice color map plt . rcParams [ 'image.cmap' ] = 'plasma' import numpy as np from neurolib.models.aln import ALNModel from neurolib.utils.parameterSpace import ParameterSpace from neurolib.optimize.exploration import BoxSearch import neurolib.utils.functions as func from neurolib.utils.loadData import Dataset ds = Dataset ( \"hcp\" ) Set up model model = ALNModel ( Cmat = ds . Cmat , Dmat = ds . Dmat ) # simulates the whole-brain model in 10s chunks by default if bold == True # Resting state fits model . params [ 'mue_ext_mean' ] = 1.57 model . params [ 'mui_ext_mean' ] = 1.6 #model.params['sigma_ou'] = 0.09 model . params [ 'b' ] = 5.0 model . params [ 'dt' ] = 0.2 model . params [ 'duration' ] = 0.2 * 1000 #ms # testing: model.params['duration'] = 0.2 * 60 * 1000 #ms # real: model.params['duration'] = 1.0 * 60 * 1000 #ms MainProcess root INFO aln: Model initialized. Define evaluation function def evaluateSimulation ( traj ): # get the model from the trajectory using `search.getModelFromTraj(traj)` model = search . getModelFromTraj ( traj ) # initiate the model with random initial contitions model . randomICs () defaultDuration = model . params [ 'duration' ] invalid_result = { \"fc\" : np . nan , \"fcd\" : np . nan } # -------- STAGEWISE EVALUATION -------- stagewise = True if stagewise : # -------- stage wise simulation -------- # Stage 1 : simulate for a few seconds to see if there is any activity # --------------------------------------- model . params [ 'duration' ] = 3 * 1000. model . run () # check if stage 1 was successful amplitude = np . max ( model . output [:, model . t > 500 ]) - np . min ( model . output [:, model . t > 500 ]) if amplitude < 0.05 : search . saveToPypet ( invalid_result , traj ) return invalid_result , {} # Stage 2: simulate BOLD for a few seconds to see if it moves # --------------------------------------- model . params [ 'duration' ] = 30 * 1000. model . run ( chunkwise = True , bold = True ) if np . max ( np . std ( model . outputs . BOLD . BOLD [:, 10 : 15 ], axis = 1 )) < 1e-5 : search . saveToPypet ( invalid_result , traj ) return invalid_result , {} # Stage 3: full and final simulation # --------------------------------------- model . params [ 'duration' ] = defaultDuration model . run ( chunkwise = True , bold = True ) # -------- POSTPROCESSING -------- # FC matrix correlation to all subject rs-fMRI BOLD_TRANSIENT = 10000 fc_score = np . mean ([ func . matrix_correlation ( func . fc ( model . BOLD . BOLD [:, model . BOLD . t_BOLD > BOLD_TRANSIENT ]), fc ) for fc in ds . FCs ]) # FCD to all subject rs-fMRI try : fcd_score = np . mean ([ func . ts_kolmogorov ( model . BOLD . BOLD [:, model . BOLD . t_BOLD > BOLD_TRANSIENT ], ds . BOLDs [ i ]) for i in range ( len ( ds . BOLDs ))]) except : fcd_score = np . nan # let's build the results dictionary result_dict = { \"fc\" : fc_score , \"fcd\" : fcd_score } # we could also save the output of the model by adding to the results_dict like this: # result_dict = {\"fc\" : fc_score, \"fcd\" : fcd_score, \"outputs\" : model.outputs} # Save the results to pypet. # Remember: This has to be dictionary! search . saveToPypet ( result_dict , traj ) Set up parameter exploration parameters = ParameterSpace ({ \"mue_ext_mean\" : np . linspace ( 0 , 3.0 , 2 ), \"mui_ext_mean\" : np . linspace ( 0.2 , 3.0 , 2 )}) # info: chose np.linspace(0, 3, 21) or more, values here are low for testing search = BoxSearch ( evalFunction = evaluateSimulation , model = model , parameterSpace = parameters , filename = \"example-1.2.1.hdf\" ) MainProcess root INFO Number of processes: 80 MainProcess pypet.storageservice.HDF5StorageService INFO I will use the hdf5 file `/mnt/raid/data/cakan/hdf/example-1.2.1.hdf`. MainProcess pypet.environment.Environment INFO Environment initialized. /home/cakan/anaconda/lib/python3.7/site-packages/pypet/parameter.py:884: FutureWarning: Conversion of the second argument of issubdtype from `str` to `str` is deprecated. In future, it will be treated as `np.str_ == np.dtype(str).type`. if np.issubdtype(dtype, np.str): MainProcess root INFO Number of parameter configurations: 4 MainProcess root INFO BoxSearch: Environment initialized. search . run () MainProcess pypet.environment.Environment INFO I am preparing the Trajectory for the experiment and initialise the store. MainProcess pypet.environment.Environment INFO Initialising the storage for the trajectory. MainProcess pypet.storageservice.HDF5StorageService INFO Initialising storage or updating meta data of Trajectory `results-2020-04-08-01H-16M-48S`. MainProcess pypet.storageservice.HDF5StorageService INFO Finished init or meta data update for `results-2020-04-08-01H-16M-48S`. MainProcess pypet.environment.Environment INFO ************************************************************ STARTING runs of trajectory `results-2020-04-08-01H-16M-48S`. ************************************************************ MainProcess pypet.storageservice.HDF5StorageService INFO Initialising storage or updating meta data of Trajectory `results-2020-04-08-01H-16M-48S`. MainProcess pypet.storageservice.HDF5StorageService INFO Finished init or meta data update for `results-2020-04-08-01H-16M-48S`. MainProcess pypet.environment.Environment INFO Starting multiprocessing with at most 80 processes running at the same time. MainProcess pypet INFO PROGRESS: Finished 0/4 runs [ ] 0.0% MainProcess pypet INFO PROGRESS: Finished 1/4 runs [===== ] 25.0%, remaining: 0:00:02 MainProcess pypet INFO PROGRESS: Finished 2/4 runs [========== ] 50.0%, remaining: 0:00:00 MainProcess pypet INFO PROGRESS: Finished 3/4 runs [=============== ] 75.0%, remaining: 0:00:09 MainProcess pypet INFO PROGRESS: Finished 4/4 runs [====================]100.0% MainProcess pypet.storageservice.HDF5StorageService INFO Initialising storage or updating meta data of Trajectory `results-2020-04-08-01H-16M-48S`. MainProcess pypet.storageservice.HDF5StorageService INFO Finished init or meta data update for `results-2020-04-08-01H-16M-48S`. MainProcess pypet.environment.Environment INFO ************************************************************ FINISHED all runs of trajectory `results-2020-04-08-01H-16M-48S`. ************************************************************ MainProcess pypet.environment.Environment INFO ************************************************************ STARTING FINAL STORING of trajectory `results-2020-04-08-01H-16M-48S` ************************************************************ MainProcess pypet.storageservice.HDF5StorageService INFO Start storing Trajectory `results-2020-04-08-01H-16M-48S`. MainProcess pypet.storageservice.HDF5StorageService INFO Storing branch `config`. /home/cakan/anaconda/lib/python3.7/site-packages/pypet/storageservice.py:4597: FutureWarning: Conversion of the second argument of issubdtype from `str` to `str` is deprecated. In future, it will be treated as `np.str_ == np.dtype(str).type`. if (np.issubdtype(val.dtype, str) or /home/cakan/anaconda/lib/python3.7/site-packages/pypet/storageservice.py:4598: FutureWarning: Conversion of the second argument of issubdtype from `bytes` to `bytes` is deprecated. In future, it will be treated as `np.bytes_ == np.dtype(bytes).type`. np.issubdtype(val.dtype, bytes)): MainProcess pypet.storageservice.HDF5StorageService INFO Storing branch `parameters`. /home/cakan/anaconda/lib/python3.7/site-packages/pypet/storageservice.py:3110: FutureWarning: Conversion of the second argument of issubdtype from `str` to `str` is deprecated. In future, it will be treated as `np.str_ == np.dtype(str).type`. np.issubdtype(data.dtype, str)): MainProcess pypet.storageservice.HDF5StorageService INFO Finished storing Trajectory `results-2020-04-08-01H-16M-48S`. MainProcess pypet.environment.Environment INFO ************************************************************ FINISHED FINAL STORING of trajectory `results-2020-04-08-01H-16M-48S`. ************************************************************ MainProcess pypet.environment.Environment INFO All runs of trajectory `results-2020-04-08-01H-16M-48S` were completed successfully. Load data search . loadResults () print ( \"Number of results: {} \" . format ( len ( search . results ))) MainProcess root INFO Loading results from /mnt/raid/data/cakan/hdf/example-1.2.1.hdf /mnt/antares_raid/home/cakan/projects/neurolib/neurolib/utils/pypetUtils.py:21: H5pyDeprecationWarning: The default file mode will change to 'r' (read-only) in h5py 3.0. To suppress this warning, pass the mode you need to h5py.File(), or set the global default h5.get_config().default_file_mode, or set the environment variable H5PY_DEFAULT_READONLY=1. Available modes are: 'r', 'r+', 'w', 'w-'/'x', 'a'. See the docs for details. hdf = h5py.File(filename) MainProcess root INFO Analyzing trajectory results-2020-04-08-01H-16M-48S MainProcess pypet.storageservice.HDF5StorageService INFO I will use the hdf5 file `/mnt/raid/data/cakan/hdf/example-1.2.1.hdf`. MainProcess pypet.storageservice.HDF5StorageService INFO Loading trajectory `results-2020-04-08-01H-16M-48S`. MainProcess pypet.storageservice.HDF5StorageService INFO Loading branch `config` in mode `2`. MainProcess pypet.storageservice.HDF5StorageService INFO Loading branch `parameters` in mode `2`. MainProcess pypet.storageservice.HDF5StorageService INFO Loading branch `results` in mode `1`. MainProcess root INFO Creating pandas dataframe ... MainProcess root INFO Creating results dictionary ... 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 4/4 [00:00<00:00, 219.06it/s] MainProcess root INFO All results loaded. Number of results: 4 for i in search . dfResults . index : search . dfResults . loc [ i , 'bold_cc' ] = np . mean ( search . results [ i ][ 'fc' ]) search . dfResults .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } mue_ext_mean mui_ext_mean bold_cc 0 0.0 0.0 0.174085 1 0.0 0.1 0.113122 2 0.0 0.2 0.488884 3 0.0 0.3 0.000000 4 0.0 0.4 0.000000 ... ... ... ... 956 3.0 2.6 -0.223068 957 3.0 2.7 -0.220481 958 3.0 2.8 -0.232276 959 3.0 2.9 -0.182681 960 3.0 3.0 -0.228365 961 rows \u00d7 3 columns Plot plt . figure ( dpi = 150 ) plt . imshow ( search . dfResults . pivot_table ( values = 'bold_cc' , index = 'mui_ext_mean' , columns = 'mue_ext_mean' ), \\ extent = [ min ( search . dfResults . mue_ext_mean ), max ( search . dfResults . mue_ext_mean ), min ( search . dfResults . mui_ext_mean ), max ( search . dfResults . mui_ext_mean )], origin = 'lower' ) plt . colorbar ( label = 'Mean correlation to empirical rs-FC' ) plt . xlabel ( \"Input to E\" ) plt . ylabel ( \"Input to I\" ) Text(0, 0.5, 'Input to I')","title":"Example 1.2.1 brain exploration postprocessing"},{"location":"examples/example-1.2.1-brain-exploration-postprocessing/#parameter-exploration-with-custom-run-function-and-postprocessing","text":"This notebook demonstrates how to scan the parameter space of a brain network model using neurolib with a custom evaluation function to quickly find regions of interest. The evaluation function is designed to increase the speed for the exploration by focussing on regions where the simulated dynamics meets certain criteria. For this, the simulation is run in multiple, successive steps, that increase in duration.","title":"Parameter exploration with custom run function and postprocessing"},{"location":"examples/example-1.2.1-brain-exploration-postprocessing/#iterative-evaluation","text":"The evaluation of a simulation takes multiple steps: Step 1 runs for a few seconds and checks if there is any rate activity at all Step 2 runs a bit longer and checks if there is any BOLD activity Step 3 runs the full simulation","title":"Iterative evaluation"},{"location":"examples/example-1.2.1-brain-exploration-postprocessing/#postprocessing","text":"In this scenario, we want to postprocess the simulated data as soon as the simulation is done and before writing the results to the hard disk. After the full simulation is run, the funciotnal connectivity (FC) of the BOLD signal is computed and compared to the empirical FC dataset. The Pearson correlation of the FC matrices is computed and the average is taken. We then tell pypet to save these postprocessed results along with the model output. #hide # change to the root directory of the project import os if os . getcwd () . split ( \"/\" )[ - 1 ] == \"examples\" : os . chdir ( '..' ) # This will reload all imports as soon as the code changes % load_ext autoreload % autoreload 2 #hide try : import matplotlib.pyplot as plt except ImportError : import sys ! { sys . executable } - m pip install matplotlib import matplotlib.pyplot as plt # a nice color map plt . rcParams [ 'image.cmap' ] = 'plasma' import numpy as np from neurolib.models.aln import ALNModel from neurolib.utils.parameterSpace import ParameterSpace from neurolib.optimize.exploration import BoxSearch import neurolib.utils.functions as func from neurolib.utils.loadData import Dataset ds = Dataset ( \"hcp\" )","title":"Postprocessing"},{"location":"examples/example-1.2.1-brain-exploration-postprocessing/#set-up-model","text":"model = ALNModel ( Cmat = ds . Cmat , Dmat = ds . Dmat ) # simulates the whole-brain model in 10s chunks by default if bold == True # Resting state fits model . params [ 'mue_ext_mean' ] = 1.57 model . params [ 'mui_ext_mean' ] = 1.6 #model.params['sigma_ou'] = 0.09 model . params [ 'b' ] = 5.0 model . params [ 'dt' ] = 0.2 model . params [ 'duration' ] = 0.2 * 1000 #ms # testing: model.params['duration'] = 0.2 * 60 * 1000 #ms # real: model.params['duration'] = 1.0 * 60 * 1000 #ms MainProcess root INFO aln: Model initialized.","title":"Set up model"},{"location":"examples/example-1.2.1-brain-exploration-postprocessing/#define-evaluation-function","text":"def evaluateSimulation ( traj ): # get the model from the trajectory using `search.getModelFromTraj(traj)` model = search . getModelFromTraj ( traj ) # initiate the model with random initial contitions model . randomICs () defaultDuration = model . params [ 'duration' ] invalid_result = { \"fc\" : np . nan , \"fcd\" : np . nan } # -------- STAGEWISE EVALUATION -------- stagewise = True if stagewise : # -------- stage wise simulation -------- # Stage 1 : simulate for a few seconds to see if there is any activity # --------------------------------------- model . params [ 'duration' ] = 3 * 1000. model . run () # check if stage 1 was successful amplitude = np . max ( model . output [:, model . t > 500 ]) - np . min ( model . output [:, model . t > 500 ]) if amplitude < 0.05 : search . saveToPypet ( invalid_result , traj ) return invalid_result , {} # Stage 2: simulate BOLD for a few seconds to see if it moves # --------------------------------------- model . params [ 'duration' ] = 30 * 1000. model . run ( chunkwise = True , bold = True ) if np . max ( np . std ( model . outputs . BOLD . BOLD [:, 10 : 15 ], axis = 1 )) < 1e-5 : search . saveToPypet ( invalid_result , traj ) return invalid_result , {} # Stage 3: full and final simulation # --------------------------------------- model . params [ 'duration' ] = defaultDuration model . run ( chunkwise = True , bold = True ) # -------- POSTPROCESSING -------- # FC matrix correlation to all subject rs-fMRI BOLD_TRANSIENT = 10000 fc_score = np . mean ([ func . matrix_correlation ( func . fc ( model . BOLD . BOLD [:, model . BOLD . t_BOLD > BOLD_TRANSIENT ]), fc ) for fc in ds . FCs ]) # FCD to all subject rs-fMRI try : fcd_score = np . mean ([ func . ts_kolmogorov ( model . BOLD . BOLD [:, model . BOLD . t_BOLD > BOLD_TRANSIENT ], ds . BOLDs [ i ]) for i in range ( len ( ds . BOLDs ))]) except : fcd_score = np . nan # let's build the results dictionary result_dict = { \"fc\" : fc_score , \"fcd\" : fcd_score } # we could also save the output of the model by adding to the results_dict like this: # result_dict = {\"fc\" : fc_score, \"fcd\" : fcd_score, \"outputs\" : model.outputs} # Save the results to pypet. # Remember: This has to be dictionary! search . saveToPypet ( result_dict , traj )","title":"Define evaluation function"},{"location":"examples/example-1.2.1-brain-exploration-postprocessing/#set-up-parameter-exploration","text":"parameters = ParameterSpace ({ \"mue_ext_mean\" : np . linspace ( 0 , 3.0 , 2 ), \"mui_ext_mean\" : np . linspace ( 0.2 , 3.0 , 2 )}) # info: chose np.linspace(0, 3, 21) or more, values here are low for testing search = BoxSearch ( evalFunction = evaluateSimulation , model = model , parameterSpace = parameters , filename = \"example-1.2.1.hdf\" ) MainProcess root INFO Number of processes: 80 MainProcess pypet.storageservice.HDF5StorageService INFO I will use the hdf5 file `/mnt/raid/data/cakan/hdf/example-1.2.1.hdf`. MainProcess pypet.environment.Environment INFO Environment initialized. /home/cakan/anaconda/lib/python3.7/site-packages/pypet/parameter.py:884: FutureWarning: Conversion of the second argument of issubdtype from `str` to `str` is deprecated. In future, it will be treated as `np.str_ == np.dtype(str).type`. if np.issubdtype(dtype, np.str): MainProcess root INFO Number of parameter configurations: 4 MainProcess root INFO BoxSearch: Environment initialized. search . run () MainProcess pypet.environment.Environment INFO I am preparing the Trajectory for the experiment and initialise the store. MainProcess pypet.environment.Environment INFO Initialising the storage for the trajectory. MainProcess pypet.storageservice.HDF5StorageService INFO Initialising storage or updating meta data of Trajectory `results-2020-04-08-01H-16M-48S`. MainProcess pypet.storageservice.HDF5StorageService INFO Finished init or meta data update for `results-2020-04-08-01H-16M-48S`. MainProcess pypet.environment.Environment INFO ************************************************************ STARTING runs of trajectory `results-2020-04-08-01H-16M-48S`. ************************************************************ MainProcess pypet.storageservice.HDF5StorageService INFO Initialising storage or updating meta data of Trajectory `results-2020-04-08-01H-16M-48S`. MainProcess pypet.storageservice.HDF5StorageService INFO Finished init or meta data update for `results-2020-04-08-01H-16M-48S`. MainProcess pypet.environment.Environment INFO Starting multiprocessing with at most 80 processes running at the same time. MainProcess pypet INFO PROGRESS: Finished 0/4 runs [ ] 0.0% MainProcess pypet INFO PROGRESS: Finished 1/4 runs [===== ] 25.0%, remaining: 0:00:02 MainProcess pypet INFO PROGRESS: Finished 2/4 runs [========== ] 50.0%, remaining: 0:00:00 MainProcess pypet INFO PROGRESS: Finished 3/4 runs [=============== ] 75.0%, remaining: 0:00:09 MainProcess pypet INFO PROGRESS: Finished 4/4 runs [====================]100.0% MainProcess pypet.storageservice.HDF5StorageService INFO Initialising storage or updating meta data of Trajectory `results-2020-04-08-01H-16M-48S`. MainProcess pypet.storageservice.HDF5StorageService INFO Finished init or meta data update for `results-2020-04-08-01H-16M-48S`. MainProcess pypet.environment.Environment INFO ************************************************************ FINISHED all runs of trajectory `results-2020-04-08-01H-16M-48S`. ************************************************************ MainProcess pypet.environment.Environment INFO ************************************************************ STARTING FINAL STORING of trajectory `results-2020-04-08-01H-16M-48S` ************************************************************ MainProcess pypet.storageservice.HDF5StorageService INFO Start storing Trajectory `results-2020-04-08-01H-16M-48S`. MainProcess pypet.storageservice.HDF5StorageService INFO Storing branch `config`. /home/cakan/anaconda/lib/python3.7/site-packages/pypet/storageservice.py:4597: FutureWarning: Conversion of the second argument of issubdtype from `str` to `str` is deprecated. In future, it will be treated as `np.str_ == np.dtype(str).type`. if (np.issubdtype(val.dtype, str) or /home/cakan/anaconda/lib/python3.7/site-packages/pypet/storageservice.py:4598: FutureWarning: Conversion of the second argument of issubdtype from `bytes` to `bytes` is deprecated. In future, it will be treated as `np.bytes_ == np.dtype(bytes).type`. np.issubdtype(val.dtype, bytes)): MainProcess pypet.storageservice.HDF5StorageService INFO Storing branch `parameters`. /home/cakan/anaconda/lib/python3.7/site-packages/pypet/storageservice.py:3110: FutureWarning: Conversion of the second argument of issubdtype from `str` to `str` is deprecated. In future, it will be treated as `np.str_ == np.dtype(str).type`. np.issubdtype(data.dtype, str)): MainProcess pypet.storageservice.HDF5StorageService INFO Finished storing Trajectory `results-2020-04-08-01H-16M-48S`. MainProcess pypet.environment.Environment INFO ************************************************************ FINISHED FINAL STORING of trajectory `results-2020-04-08-01H-16M-48S`. ************************************************************ MainProcess pypet.environment.Environment INFO All runs of trajectory `results-2020-04-08-01H-16M-48S` were completed successfully.","title":"Set up parameter exploration"},{"location":"examples/example-1.2.1-brain-exploration-postprocessing/#load-data","text":"search . loadResults () print ( \"Number of results: {} \" . format ( len ( search . results ))) MainProcess root INFO Loading results from /mnt/raid/data/cakan/hdf/example-1.2.1.hdf /mnt/antares_raid/home/cakan/projects/neurolib/neurolib/utils/pypetUtils.py:21: H5pyDeprecationWarning: The default file mode will change to 'r' (read-only) in h5py 3.0. To suppress this warning, pass the mode you need to h5py.File(), or set the global default h5.get_config().default_file_mode, or set the environment variable H5PY_DEFAULT_READONLY=1. Available modes are: 'r', 'r+', 'w', 'w-'/'x', 'a'. See the docs for details. hdf = h5py.File(filename) MainProcess root INFO Analyzing trajectory results-2020-04-08-01H-16M-48S MainProcess pypet.storageservice.HDF5StorageService INFO I will use the hdf5 file `/mnt/raid/data/cakan/hdf/example-1.2.1.hdf`. MainProcess pypet.storageservice.HDF5StorageService INFO Loading trajectory `results-2020-04-08-01H-16M-48S`. MainProcess pypet.storageservice.HDF5StorageService INFO Loading branch `config` in mode `2`. MainProcess pypet.storageservice.HDF5StorageService INFO Loading branch `parameters` in mode `2`. MainProcess pypet.storageservice.HDF5StorageService INFO Loading branch `results` in mode `1`. MainProcess root INFO Creating pandas dataframe ... MainProcess root INFO Creating results dictionary ... 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 4/4 [00:00<00:00, 219.06it/s] MainProcess root INFO All results loaded. Number of results: 4 for i in search . dfResults . index : search . dfResults . loc [ i , 'bold_cc' ] = np . mean ( search . results [ i ][ 'fc' ]) search . dfResults .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } mue_ext_mean mui_ext_mean bold_cc 0 0.0 0.0 0.174085 1 0.0 0.1 0.113122 2 0.0 0.2 0.488884 3 0.0 0.3 0.000000 4 0.0 0.4 0.000000 ... ... ... ... 956 3.0 2.6 -0.223068 957 3.0 2.7 -0.220481 958 3.0 2.8 -0.232276 959 3.0 2.9 -0.182681 960 3.0 3.0 -0.228365 961 rows \u00d7 3 columns","title":"Load data"},{"location":"examples/example-1.2.1-brain-exploration-postprocessing/#plot","text":"plt . figure ( dpi = 150 ) plt . imshow ( search . dfResults . pivot_table ( values = 'bold_cc' , index = 'mui_ext_mean' , columns = 'mue_ext_mean' ), \\ extent = [ min ( search . dfResults . mue_ext_mean ), max ( search . dfResults . mue_ext_mean ), min ( search . dfResults . mui_ext_mean ), max ( search . dfResults . mui_ext_mean )], origin = 'lower' ) plt . colorbar ( label = 'Mean correlation to empirical rs-FC' ) plt . xlabel ( \"Input to E\" ) plt . ylabel ( \"Input to I\" ) Text(0, 0.5, 'Input to I')","title":"Plot"},{"location":"examples/example-1.3-aln-bifurcation-diagram/","text":"(function() { function addWidgetsRenderer() { var requireJsScript = document.createElement('script'); requireJsScript.src = 'https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js'; var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var jupyterWidgetsScript = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} jupyterWidgetsScript.src = widgetRendererSrc; document.body.appendChild(requireJsScript); document.body.appendChild(jupyterWidgetsScript); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); Bifurcation diagram of the aln model In this notebook, we will discover how easy it is to draw bifurcation diagrams in neurolib using its powerful BoxSearch class. Bifurcation diagrams are an important tool to understand a dynamical system, may it be a single neuron model or a whole-brain network. They show how a system behaves when certain parameters of the model are changed: whether the system transitions into an oscillation for example, or whethter the system remains in a fixed point (of sustained constant activity). We will use this to draw a map of the aln model: Since the aln model consists of two populations of Adex neurons, we will change its inputs to the excitatory and to the inhibitory population independently and do so for two different values of spike-frequency adaptation strength \\(b\\) . We will measure the activity of the system and identify regions of oscillatory activity and discover bistable states, in which the system can be in two different stable states for the same set of parameters. # change into the root directory of the project import os if os . getcwd () . split ( \"/\" )[ - 1 ] == \"examples\" : os . chdir ( '..' ) import logging logger = logging . getLogger () import warnings warnings . filterwarnings ( \"ignore\" ) #logger.setLevel(logging.DEBUG) #logging.disable(logging.WARNING) #logging.disable(logging.WARN) % load_ext autoreload % autoreload 2 import numpy as np import matplotlib.pyplot as plt from neurolib.models.aln import ALNModel from neurolib.utils.parameterSpace import ParameterSpace from neurolib.optimize.exploration import BoxSearch import neurolib.utils.functions as func import neurolib.utils.stimulus as stim import neurolib.optimize.exploration.explorationUtils as eu import neurolib.utils.devutils as du from neurolib.utils.loadData import Dataset plt . style . use ( \"seaborn-white\" ) plt . rcParams [ 'image.cmap' ] = 'plasma' Create the model model = ALNModel () model . params [ 'dt' ] = 0.1 # Integration time step, ms model . params [ 'duration' ] = 20 * 1000 # Simulation time, ms model . params [ 'save_dt' ] = 10.0 # 10 ms sampling steps for saving data, should be multiple of dt model . params [ \"tauA\" ] = 600.0 # Adaptation timescale, ms Measuring bistability The aln model has a region of bistability, in which two states are stable at the same time: the low-activity down-state , and the high-activity up-state . We can find these states by constructing a stimulus, which uncovers the bistable nature of the system: Initially, we apply a negative push to the system, to make sure that it is in the down-state . We then relax this stimulus slowly and wait for the system to settle. We then apply a sharp push in order to reach the up-state and release the stimulus slowly back again. The difference of the two states after the stimulus has relaxed back to zero is a sign for bistability. # we place the system in the bistable region model . params [ 'mue_ext_mean' ] = 2.5 model . params [ 'mui_ext_mean' ] = 2.5 # construct a stimulus rect_stimulus = stim . RectifiedInput ( amplitude = 0.2 ) . to_model ( model ) model . params [ 'ext_exc_current' ] = rect_stimulus * 5.0 model . run () plt . figure ( figsize = ( 5 , 3 ), dpi = 150 ) plt . plot ( model . t , model . output . T , lw = 3 , c = 'k' , label = 'rate' ) plt . plot ( model . t , ( rect_stimulus * 100 ) . squeeze (), lw = 3 , c = 'r' , label = \"stimulus\" ) plt . text ( 3000 , 7 , 'down-state' , fontsize = 16 ) plt . text ( 15000 , 35 , 'up-state' , fontsize = 16 ) plt . legend ( fontsize = 14 ) plt . xlim ( 1 , model . t [ - 1 ]) plt . xlabel ( \"Time [ms]\" ) plt . ylabel ( \"Activity [Hz]\" ) Text(0, 0.5, 'Activity [Hz]') Define evaluation function Let's construct a rather lengthy evaluation function which does exactly that, for every parameter configuration that we want to explore. We will also measure other things like the dominant frequency and amplitude of oscillations and the maximum rate of the excitatory population. def evaluateSimulation ( traj ): # get the model from the trajectory using `search.getModelFromTraj(traj)` model = search . getModelFromTraj ( traj ) # initiate the model with random initial contitions model . randomICs () defaultDuration = model . params [ 'duration' ] # -------- stage wise simulation -------- # Stage 3: full and final simulation # --------------------------------------- model . params [ 'duration' ] = defaultDuration rect_stimulus = stim . RectifiedInput ( amplitude = 0.2 ) . to_model ( model ) model . params [ 'ext_exc_current' ] = rect_stimulus * 5.0 model . run () # up down difference state_length = 2000 last_state = ( model . t > defaultDuration - state_length ) down_window = ( defaultDuration / 2 - state_length < model . t ) & ( model . t < defaultDuration / 2 ) # time period in ms where we expect the down-state up_window = ( defaultDuration - state_length < model . t ) & ( model . t < defaultDuration ) # and up state up_state_rate = np . mean ( model . output [:, up_window ], axis = 1 ) down_state_rate = np . mean ( model . output [:, down_window ], axis = 1 ) up_down_difference = np . max ( up_state_rate - down_state_rate ) # check rates! max_amp_output = np . max ( np . max ( model . output [:, up_window ], axis = 1 ) - np . min ( model . output [:, up_window ], axis = 1 ) ) max_output = np . max ( model . output [:, up_window ]) model_frs , model_pwrs = func . getMeanPowerSpectrum ( model . output , dt = model . params . dt , maxfr = 40 , spectrum_windowsize = 10 ) max_power = np . max ( model_pwrs ) model_frs , model_pwrs = func . getMeanPowerSpectrum ( model . output [:, up_window ], dt = model . params . dt , maxfr = 40 , spectrum_windowsize = 5 ) domfr = model_frs [ np . argmax ( model_pwrs )] result = { \"end\" : 3 , \"max_output\" : max_output , \"max_amp_output\" : max_amp_output , \"max_power\" : max_power , #\"model_pwrs\" : model_pwrs, #\"output\": model.output[:, ::int(model.params['save_dt']/model.params['dt'])], \"domfr\" : domfr , \"up_down_difference\" : up_down_difference } search . saveToPypet ( result , traj ) return Let's now define the parameter space over which we want to serach. We apply a grid search over the mean external input parameters to the excitatory and the inhibitory population mue_ext_mean / mui_ext_mean and do this for two values of spike-frequency adapation strength \\(b\\) , once without and once with adaptation. Exploration parameters # low number of parameters for testing: parameters = ParameterSpace ({ \"mue_ext_mean\" : np . linspace ( 0.0 , 4 , 2 ), \"mui_ext_mean\" : np . linspace ( 0.0 , 4 , 2 ), \"b\" : [ 0.0 , 20.0 ] }, kind = \"grid\" ) # real: # parameters = ParameterSpace({\"mue_ext_mean\": np.linspace(0.0, 4, 41), # \"mui_ext_mean\": np.linspace(0.0, 4, 41), # \"b\": [0.0, 20.0] # }) search = BoxSearch ( evalFunction = evaluateSimulation , model = model , parameterSpace = parameters , filename = 'example-1.3-aln-bifurcation-diagram.hdf' ) MainProcess pypet.storageservice.HDF5StorageService INFO I will use the hdf5 file `./data/hdf/example-1.3-aln-bifurcation-diagram.hdf`. MainProcess pypet.environment.Environment INFO Environment initialized. MainProcess root INFO Number of parameter configurations: 3362 MainProcess root INFO BoxSearch: Environment initialized. Run search . run () MainProcess pypet.environment.Environment INFO I am preparing the Trajectory for the experiment and initialise the store. MainProcess pypet.environment.Environment INFO Initialising the storage for the trajectory. MainProcess pypet.storageservice.HDF5StorageService INFO Initialising storage or updating meta data of Trajectory `results-2021-06-19-01H-23M-48S`. MainProcess pypet.storageservice.HDF5StorageService INFO Finished init or meta data update for `results-2021-06-19-01H-23M-48S`. MainProcess pypet.environment.Environment INFO ************************************************************ STARTING runs of trajectory `results-2021-06-19-01H-23M-48S`. ************************************************************ MainProcess pypet.storageservice.HDF5StorageService INFO Initialising storage or updating meta data of Trajectory `results-2021-06-19-01H-23M-48S`. MainProcess pypet.storageservice.HDF5StorageService INFO Finished init or meta data update for `results-2021-06-19-01H-23M-48S`. MainProcess pypet.environment.Environment INFO Starting multiprocessing with at most 8 processes running at the same time. MainProcess pypet INFO PROGRESS: Finished 0/3362 runs [ ] 0.0% MainProcess pypet INFO PROGRESS: Finished 169/3362 runs [= ] 5.0%, remaining: 0:01:27 MainProcess pypet INFO PROGRESS: Finished 337/3362 runs [== ] 10.0%, remaining: 0:01:24 MainProcess pypet INFO PROGRESS: Finished 505/3362 runs [=== ] 15.0%, remaining: 0:01:27 MainProcess pypet INFO PROGRESS: Finished 673/3362 runs [==== ] 20.0%, remaining: 0:01:26 MainProcess pypet INFO PROGRESS: Finished 841/3362 runs [===== ] 25.0%, remaining: 0:01:26 MainProcess pypet INFO PROGRESS: Finished 1009/3362 runs [====== ] 30.0%, remaining: 0:01:24 MainProcess pypet INFO PROGRESS: Finished 1177/3362 runs [======= ] 35.0%, remaining: 0:01:19 MainProcess pypet INFO PROGRESS: Finished 1345/3362 runs [======== ] 40.0%, remaining: 0:01:15 MainProcess pypet INFO PROGRESS: Finished 1513/3362 runs [========= ] 45.0%, remaining: 0:01:10 MainProcess pypet INFO PROGRESS: Finished 1681/3362 runs [========== ] 50.0%, remaining: 0:01:05 MainProcess pypet INFO PROGRESS: Finished 1850/3362 runs [=========== ] 55.0%, remaining: 0:00:59 MainProcess pypet INFO PROGRESS: Finished 2018/3362 runs [============ ] 60.0%, remaining: 0:00:55 MainProcess pypet INFO PROGRESS: Finished 2186/3362 runs [============= ] 65.0%, remaining: 0:00:49 MainProcess pypet INFO PROGRESS: Finished 2354/3362 runs [============== ] 70.0%, remaining: 0:00:42 MainProcess pypet INFO PROGRESS: Finished 2522/3362 runs [=============== ] 75.0%, remaining: 0:00:36 MainProcess pypet INFO PROGRESS: Finished 2690/3362 runs [================ ] 80.0%, remaining: 0:00:29 MainProcess pypet INFO PROGRESS: Finished 2858/3362 runs [================= ] 85.0%, remaining: 0:00:22 MainProcess pypet INFO PROGRESS: Finished 3026/3362 runs [================== ] 90.0%, remaining: 0:00:15 MainProcess pypet INFO PROGRESS: Finished 3194/3362 runs [=================== ] 95.0%, remaining: 0:00:07 MainProcess pypet INFO PROGRESS: Finished 3362/3362 runs [====================]100.0% MainProcess pypet.storageservice.HDF5StorageService INFO Initialising storage or updating meta data of Trajectory `results-2021-06-19-01H-23M-48S`. MainProcess pypet.storageservice.HDF5StorageService INFO Finished init or meta data update for `results-2021-06-19-01H-23M-48S`. MainProcess pypet.environment.Environment INFO ************************************************************ FINISHED all runs of trajectory `results-2021-06-19-01H-23M-48S`. ************************************************************ MainProcess pypet.environment.Environment INFO ************************************************************ STARTING FINAL STORING of trajectory `results-2021-06-19-01H-23M-48S` ************************************************************ MainProcess pypet.storageservice.HDF5StorageService INFO Start storing Trajectory `results-2021-06-19-01H-23M-48S`. MainProcess pypet.storageservice.HDF5StorageService INFO Storing branch `config`. MainProcess pypet.storageservice.HDF5StorageService INFO Storing branch `parameters`. MainProcess pypet.storageservice.HDF5StorageService INFO Finished storing Trajectory `results-2021-06-19-01H-23M-48S`. MainProcess pypet.environment.Environment INFO ************************************************************ FINISHED FINAL STORING of trajectory `results-2021-06-19-01H-23M-48S`. ************************************************************ MainProcess pypet.environment.Environment INFO All runs of trajectory `results-2021-06-19-01H-23M-48S` were completed successfully. Analysis search . loadResults ( all = False ) MainProcess root INFO Loading results from ./data/hdf/example-1.3-aln-bifurcation-diagram.hdf MainProcess root INFO Analyzing trajectory results-2021-06-19-01H-23M-48S MainProcess pypet.storageservice.HDF5StorageService INFO I will use the hdf5 file `./data/hdf/example-1.3-aln-bifurcation-diagram.hdf`. MainProcess pypet.storageservice.HDF5StorageService INFO Loading trajectory `results-2021-06-19-01H-23M-48S`. MainProcess pypet.storageservice.HDF5StorageService INFO Loading branch `config` in mode `2`. MainProcess pypet.storageservice.HDF5StorageService INFO Loading branch `parameters` in mode `2`. MainProcess pypet.storageservice.HDF5StorageService INFO Loading branch `results` in mode `1`. MainProcess root INFO Creating `dfResults` dataframe ... MainProcess root INFO Aggregating results to `dfResults` ... 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 3362/3362 [00:22<00:00, 152.47it/s] MainProcess root INFO All results loaded. The results dataframe search . dfResults .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } mue_ext_mean mui_ext_mean b up_down_difference max_power max_output max_amp_output end domfr 0 0.0 0.0 0.0 0.000019 17.665778 0.038741 3.747003e-16 3.0 0.500025 1 0.0 0.0 20.0 0.000009 5.151548 0.037037 2.042323e-05 3.0 0.500025 2 0.0 0.1 0.0 0.000010 15.441657 0.024629 1.110223e-16 3.0 0.500025 3 0.0 0.1 20.0 0.000006 4.140089 0.024062 8.806806e-06 3.0 0.500025 4 0.0 0.2 0.0 0.000006 12.466037 0.012277 7.112366e-17 3.0 0.500025 ... ... ... ... ... ... ... ... ... ... 3357 4.0 3.8 20.0 0.000038 14.426393 29.965853 1.263433e-06 3.0 0.000000 3358 4.0 3.9 0.0 0.000674 58.447442 93.451476 2.842171e-14 3.0 0.000000 3359 4.0 3.9 20.0 0.000038 14.482713 29.928097 1.243205e-06 3.0 0.000000 3360 4.0 4.0 0.0 0.000674 58.494615 93.380582 1.421085e-14 3.0 0.000000 3361 4.0 4.0 20.0 0.000038 14.534853 29.891972 1.224562e-06 3.0 0.000000 3362 rows \u00d7 9 columns Plotting 2D bifurcation diagrams Let's draw the bifurcation diagrams. We will use a white contour for oscillatory areas (measured by max_amp_output ) and a green dashed lined for the bistable region (measured by up_down_difference ). We can use the function explorationUtils.plotExplorationResults() for this. plot_key_label = \"Max. $r_E$\" eu . plotExplorationResults ( search . dfResults , par1 = [ 'mue_ext_mean' , '$\\mu_e$' ], par2 = [ 'mui_ext_mean' , '$\\mu_i$' ], by = [ 'b' ], plot_key = 'max_output' , plot_clim = [ 0.0 , 80.0 ], nan_to_zero = False , plot_key_label = plot_key_label , one_figure = False , contour = [ \"max_amp_output\" , \"up_down_difference\" ], contour_color = [[ 'white' ], [ 'springgreen' ]], contour_levels = [[ 10 ], [ 10 ]], contour_alpha = [ 1.0 , 1.0 ], contour_kwargs = { 0 : { \"linewidths\" : ( 5 ,)}, 1 : { \"linestyles\" : \"--\" , \"linewidths\" : ( 5 ,)}}, #alpha_mask=\"relative_amplitude_BOLD\", mask_threshold = 0.1 , mask_alpha = 0.2 )","title":"Example 1.3 aln bifurcation diagram"},{"location":"examples/example-1.3-aln-bifurcation-diagram/#bifurcation-diagram-of-the-aln-model","text":"In this notebook, we will discover how easy it is to draw bifurcation diagrams in neurolib using its powerful BoxSearch class. Bifurcation diagrams are an important tool to understand a dynamical system, may it be a single neuron model or a whole-brain network. They show how a system behaves when certain parameters of the model are changed: whether the system transitions into an oscillation for example, or whethter the system remains in a fixed point (of sustained constant activity). We will use this to draw a map of the aln model: Since the aln model consists of two populations of Adex neurons, we will change its inputs to the excitatory and to the inhibitory population independently and do so for two different values of spike-frequency adaptation strength \\(b\\) . We will measure the activity of the system and identify regions of oscillatory activity and discover bistable states, in which the system can be in two different stable states for the same set of parameters. # change into the root directory of the project import os if os . getcwd () . split ( \"/\" )[ - 1 ] == \"examples\" : os . chdir ( '..' ) import logging logger = logging . getLogger () import warnings warnings . filterwarnings ( \"ignore\" ) #logger.setLevel(logging.DEBUG) #logging.disable(logging.WARNING) #logging.disable(logging.WARN) % load_ext autoreload % autoreload 2 import numpy as np import matplotlib.pyplot as plt from neurolib.models.aln import ALNModel from neurolib.utils.parameterSpace import ParameterSpace from neurolib.optimize.exploration import BoxSearch import neurolib.utils.functions as func import neurolib.utils.stimulus as stim import neurolib.optimize.exploration.explorationUtils as eu import neurolib.utils.devutils as du from neurolib.utils.loadData import Dataset plt . style . use ( \"seaborn-white\" ) plt . rcParams [ 'image.cmap' ] = 'plasma'","title":"Bifurcation diagram of the aln model"},{"location":"examples/example-1.3-aln-bifurcation-diagram/#create-the-model","text":"model = ALNModel () model . params [ 'dt' ] = 0.1 # Integration time step, ms model . params [ 'duration' ] = 20 * 1000 # Simulation time, ms model . params [ 'save_dt' ] = 10.0 # 10 ms sampling steps for saving data, should be multiple of dt model . params [ \"tauA\" ] = 600.0 # Adaptation timescale, ms","title":"Create the model"},{"location":"examples/example-1.3-aln-bifurcation-diagram/#measuring-bistability","text":"The aln model has a region of bistability, in which two states are stable at the same time: the low-activity down-state , and the high-activity up-state . We can find these states by constructing a stimulus, which uncovers the bistable nature of the system: Initially, we apply a negative push to the system, to make sure that it is in the down-state . We then relax this stimulus slowly and wait for the system to settle. We then apply a sharp push in order to reach the up-state and release the stimulus slowly back again. The difference of the two states after the stimulus has relaxed back to zero is a sign for bistability. # we place the system in the bistable region model . params [ 'mue_ext_mean' ] = 2.5 model . params [ 'mui_ext_mean' ] = 2.5 # construct a stimulus rect_stimulus = stim . RectifiedInput ( amplitude = 0.2 ) . to_model ( model ) model . params [ 'ext_exc_current' ] = rect_stimulus * 5.0 model . run () plt . figure ( figsize = ( 5 , 3 ), dpi = 150 ) plt . plot ( model . t , model . output . T , lw = 3 , c = 'k' , label = 'rate' ) plt . plot ( model . t , ( rect_stimulus * 100 ) . squeeze (), lw = 3 , c = 'r' , label = \"stimulus\" ) plt . text ( 3000 , 7 , 'down-state' , fontsize = 16 ) plt . text ( 15000 , 35 , 'up-state' , fontsize = 16 ) plt . legend ( fontsize = 14 ) plt . xlim ( 1 , model . t [ - 1 ]) plt . xlabel ( \"Time [ms]\" ) plt . ylabel ( \"Activity [Hz]\" ) Text(0, 0.5, 'Activity [Hz]')","title":"Measuring bistability"},{"location":"examples/example-1.3-aln-bifurcation-diagram/#define-evaluation-function","text":"Let's construct a rather lengthy evaluation function which does exactly that, for every parameter configuration that we want to explore. We will also measure other things like the dominant frequency and amplitude of oscillations and the maximum rate of the excitatory population. def evaluateSimulation ( traj ): # get the model from the trajectory using `search.getModelFromTraj(traj)` model = search . getModelFromTraj ( traj ) # initiate the model with random initial contitions model . randomICs () defaultDuration = model . params [ 'duration' ] # -------- stage wise simulation -------- # Stage 3: full and final simulation # --------------------------------------- model . params [ 'duration' ] = defaultDuration rect_stimulus = stim . RectifiedInput ( amplitude = 0.2 ) . to_model ( model ) model . params [ 'ext_exc_current' ] = rect_stimulus * 5.0 model . run () # up down difference state_length = 2000 last_state = ( model . t > defaultDuration - state_length ) down_window = ( defaultDuration / 2 - state_length < model . t ) & ( model . t < defaultDuration / 2 ) # time period in ms where we expect the down-state up_window = ( defaultDuration - state_length < model . t ) & ( model . t < defaultDuration ) # and up state up_state_rate = np . mean ( model . output [:, up_window ], axis = 1 ) down_state_rate = np . mean ( model . output [:, down_window ], axis = 1 ) up_down_difference = np . max ( up_state_rate - down_state_rate ) # check rates! max_amp_output = np . max ( np . max ( model . output [:, up_window ], axis = 1 ) - np . min ( model . output [:, up_window ], axis = 1 ) ) max_output = np . max ( model . output [:, up_window ]) model_frs , model_pwrs = func . getMeanPowerSpectrum ( model . output , dt = model . params . dt , maxfr = 40 , spectrum_windowsize = 10 ) max_power = np . max ( model_pwrs ) model_frs , model_pwrs = func . getMeanPowerSpectrum ( model . output [:, up_window ], dt = model . params . dt , maxfr = 40 , spectrum_windowsize = 5 ) domfr = model_frs [ np . argmax ( model_pwrs )] result = { \"end\" : 3 , \"max_output\" : max_output , \"max_amp_output\" : max_amp_output , \"max_power\" : max_power , #\"model_pwrs\" : model_pwrs, #\"output\": model.output[:, ::int(model.params['save_dt']/model.params['dt'])], \"domfr\" : domfr , \"up_down_difference\" : up_down_difference } search . saveToPypet ( result , traj ) return Let's now define the parameter space over which we want to serach. We apply a grid search over the mean external input parameters to the excitatory and the inhibitory population mue_ext_mean / mui_ext_mean and do this for two values of spike-frequency adapation strength \\(b\\) , once without and once with adaptation.","title":"Define evaluation function"},{"location":"examples/example-1.3-aln-bifurcation-diagram/#exploration-parameters","text":"# low number of parameters for testing: parameters = ParameterSpace ({ \"mue_ext_mean\" : np . linspace ( 0.0 , 4 , 2 ), \"mui_ext_mean\" : np . linspace ( 0.0 , 4 , 2 ), \"b\" : [ 0.0 , 20.0 ] }, kind = \"grid\" ) # real: # parameters = ParameterSpace({\"mue_ext_mean\": np.linspace(0.0, 4, 41), # \"mui_ext_mean\": np.linspace(0.0, 4, 41), # \"b\": [0.0, 20.0] # }) search = BoxSearch ( evalFunction = evaluateSimulation , model = model , parameterSpace = parameters , filename = 'example-1.3-aln-bifurcation-diagram.hdf' ) MainProcess pypet.storageservice.HDF5StorageService INFO I will use the hdf5 file `./data/hdf/example-1.3-aln-bifurcation-diagram.hdf`. MainProcess pypet.environment.Environment INFO Environment initialized. MainProcess root INFO Number of parameter configurations: 3362 MainProcess root INFO BoxSearch: Environment initialized.","title":"Exploration parameters"},{"location":"examples/example-1.3-aln-bifurcation-diagram/#run","text":"search . run () MainProcess pypet.environment.Environment INFO I am preparing the Trajectory for the experiment and initialise the store. MainProcess pypet.environment.Environment INFO Initialising the storage for the trajectory. MainProcess pypet.storageservice.HDF5StorageService INFO Initialising storage or updating meta data of Trajectory `results-2021-06-19-01H-23M-48S`. MainProcess pypet.storageservice.HDF5StorageService INFO Finished init or meta data update for `results-2021-06-19-01H-23M-48S`. MainProcess pypet.environment.Environment INFO ************************************************************ STARTING runs of trajectory `results-2021-06-19-01H-23M-48S`. ************************************************************ MainProcess pypet.storageservice.HDF5StorageService INFO Initialising storage or updating meta data of Trajectory `results-2021-06-19-01H-23M-48S`. MainProcess pypet.storageservice.HDF5StorageService INFO Finished init or meta data update for `results-2021-06-19-01H-23M-48S`. MainProcess pypet.environment.Environment INFO Starting multiprocessing with at most 8 processes running at the same time. MainProcess pypet INFO PROGRESS: Finished 0/3362 runs [ ] 0.0% MainProcess pypet INFO PROGRESS: Finished 169/3362 runs [= ] 5.0%, remaining: 0:01:27 MainProcess pypet INFO PROGRESS: Finished 337/3362 runs [== ] 10.0%, remaining: 0:01:24 MainProcess pypet INFO PROGRESS: Finished 505/3362 runs [=== ] 15.0%, remaining: 0:01:27 MainProcess pypet INFO PROGRESS: Finished 673/3362 runs [==== ] 20.0%, remaining: 0:01:26 MainProcess pypet INFO PROGRESS: Finished 841/3362 runs [===== ] 25.0%, remaining: 0:01:26 MainProcess pypet INFO PROGRESS: Finished 1009/3362 runs [====== ] 30.0%, remaining: 0:01:24 MainProcess pypet INFO PROGRESS: Finished 1177/3362 runs [======= ] 35.0%, remaining: 0:01:19 MainProcess pypet INFO PROGRESS: Finished 1345/3362 runs [======== ] 40.0%, remaining: 0:01:15 MainProcess pypet INFO PROGRESS: Finished 1513/3362 runs [========= ] 45.0%, remaining: 0:01:10 MainProcess pypet INFO PROGRESS: Finished 1681/3362 runs [========== ] 50.0%, remaining: 0:01:05 MainProcess pypet INFO PROGRESS: Finished 1850/3362 runs [=========== ] 55.0%, remaining: 0:00:59 MainProcess pypet INFO PROGRESS: Finished 2018/3362 runs [============ ] 60.0%, remaining: 0:00:55 MainProcess pypet INFO PROGRESS: Finished 2186/3362 runs [============= ] 65.0%, remaining: 0:00:49 MainProcess pypet INFO PROGRESS: Finished 2354/3362 runs [============== ] 70.0%, remaining: 0:00:42 MainProcess pypet INFO PROGRESS: Finished 2522/3362 runs [=============== ] 75.0%, remaining: 0:00:36 MainProcess pypet INFO PROGRESS: Finished 2690/3362 runs [================ ] 80.0%, remaining: 0:00:29 MainProcess pypet INFO PROGRESS: Finished 2858/3362 runs [================= ] 85.0%, remaining: 0:00:22 MainProcess pypet INFO PROGRESS: Finished 3026/3362 runs [================== ] 90.0%, remaining: 0:00:15 MainProcess pypet INFO PROGRESS: Finished 3194/3362 runs [=================== ] 95.0%, remaining: 0:00:07 MainProcess pypet INFO PROGRESS: Finished 3362/3362 runs [====================]100.0% MainProcess pypet.storageservice.HDF5StorageService INFO Initialising storage or updating meta data of Trajectory `results-2021-06-19-01H-23M-48S`. MainProcess pypet.storageservice.HDF5StorageService INFO Finished init or meta data update for `results-2021-06-19-01H-23M-48S`. MainProcess pypet.environment.Environment INFO ************************************************************ FINISHED all runs of trajectory `results-2021-06-19-01H-23M-48S`. ************************************************************ MainProcess pypet.environment.Environment INFO ************************************************************ STARTING FINAL STORING of trajectory `results-2021-06-19-01H-23M-48S` ************************************************************ MainProcess pypet.storageservice.HDF5StorageService INFO Start storing Trajectory `results-2021-06-19-01H-23M-48S`. MainProcess pypet.storageservice.HDF5StorageService INFO Storing branch `config`. MainProcess pypet.storageservice.HDF5StorageService INFO Storing branch `parameters`. MainProcess pypet.storageservice.HDF5StorageService INFO Finished storing Trajectory `results-2021-06-19-01H-23M-48S`. MainProcess pypet.environment.Environment INFO ************************************************************ FINISHED FINAL STORING of trajectory `results-2021-06-19-01H-23M-48S`. ************************************************************ MainProcess pypet.environment.Environment INFO All runs of trajectory `results-2021-06-19-01H-23M-48S` were completed successfully.","title":"Run"},{"location":"examples/example-1.3-aln-bifurcation-diagram/#analysis","text":"search . loadResults ( all = False ) MainProcess root INFO Loading results from ./data/hdf/example-1.3-aln-bifurcation-diagram.hdf MainProcess root INFO Analyzing trajectory results-2021-06-19-01H-23M-48S MainProcess pypet.storageservice.HDF5StorageService INFO I will use the hdf5 file `./data/hdf/example-1.3-aln-bifurcation-diagram.hdf`. MainProcess pypet.storageservice.HDF5StorageService INFO Loading trajectory `results-2021-06-19-01H-23M-48S`. MainProcess pypet.storageservice.HDF5StorageService INFO Loading branch `config` in mode `2`. MainProcess pypet.storageservice.HDF5StorageService INFO Loading branch `parameters` in mode `2`. MainProcess pypet.storageservice.HDF5StorageService INFO Loading branch `results` in mode `1`. MainProcess root INFO Creating `dfResults` dataframe ... MainProcess root INFO Aggregating results to `dfResults` ... 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 3362/3362 [00:22<00:00, 152.47it/s] MainProcess root INFO All results loaded.","title":"Analysis"},{"location":"examples/example-1.3-aln-bifurcation-diagram/#the-results-dataframe","text":"search . dfResults .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } mue_ext_mean mui_ext_mean b up_down_difference max_power max_output max_amp_output end domfr 0 0.0 0.0 0.0 0.000019 17.665778 0.038741 3.747003e-16 3.0 0.500025 1 0.0 0.0 20.0 0.000009 5.151548 0.037037 2.042323e-05 3.0 0.500025 2 0.0 0.1 0.0 0.000010 15.441657 0.024629 1.110223e-16 3.0 0.500025 3 0.0 0.1 20.0 0.000006 4.140089 0.024062 8.806806e-06 3.0 0.500025 4 0.0 0.2 0.0 0.000006 12.466037 0.012277 7.112366e-17 3.0 0.500025 ... ... ... ... ... ... ... ... ... ... 3357 4.0 3.8 20.0 0.000038 14.426393 29.965853 1.263433e-06 3.0 0.000000 3358 4.0 3.9 0.0 0.000674 58.447442 93.451476 2.842171e-14 3.0 0.000000 3359 4.0 3.9 20.0 0.000038 14.482713 29.928097 1.243205e-06 3.0 0.000000 3360 4.0 4.0 0.0 0.000674 58.494615 93.380582 1.421085e-14 3.0 0.000000 3361 4.0 4.0 20.0 0.000038 14.534853 29.891972 1.224562e-06 3.0 0.000000 3362 rows \u00d7 9 columns","title":"The results dataframe"},{"location":"examples/example-1.3-aln-bifurcation-diagram/#plotting-2d-bifurcation-diagrams","text":"Let's draw the bifurcation diagrams. We will use a white contour for oscillatory areas (measured by max_amp_output ) and a green dashed lined for the bistable region (measured by up_down_difference ). We can use the function explorationUtils.plotExplorationResults() for this. plot_key_label = \"Max. $r_E$\" eu . plotExplorationResults ( search . dfResults , par1 = [ 'mue_ext_mean' , '$\\mu_e$' ], par2 = [ 'mui_ext_mean' , '$\\mu_i$' ], by = [ 'b' ], plot_key = 'max_output' , plot_clim = [ 0.0 , 80.0 ], nan_to_zero = False , plot_key_label = plot_key_label , one_figure = False , contour = [ \"max_amp_output\" , \"up_down_difference\" ], contour_color = [[ 'white' ], [ 'springgreen' ]], contour_levels = [[ 10 ], [ 10 ]], contour_alpha = [ 1.0 , 1.0 ], contour_kwargs = { 0 : { \"linewidths\" : ( 5 ,)}, 1 : { \"linestyles\" : \"--\" , \"linewidths\" : ( 5 ,)}}, #alpha_mask=\"relative_amplitude_BOLD\", mask_threshold = 0.1 , mask_alpha = 0.2 )","title":"Plotting 2D bifurcation diagrams"},{"location":"examples/example-2-evolutionary-optimization-minimal/","text":"(function() { function addWidgetsRenderer() { var requireJsScript = document.createElement('script'); requireJsScript.src = 'https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js'; var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var jupyterWidgetsScript = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} jupyterWidgetsScript.src = widgetRendererSrc; document.body.appendChild(requireJsScript); document.body.appendChild(jupyterWidgetsScript); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); Simple example of the evolutionary optimization framework This notebook provides a simple example for the use of the evolutionary optimization framework builtin to the library. Under the hood, the implementation of the evolutionary algorithm is powered by deap and pypet cares about the parallelization and storage of the simulation data for us. Here we demonstrate how to fit parameters of a the evaluation function optimize_me which simply computes the distance of the parameters to the unit circle and returns this as the fitness_tuple that DEAP expects. # change to the root directory of the project import os if os . getcwd () . split ( \"/\" )[ - 1 ] == \"examples\" : os . chdir ( '..' ) # This will reload all imports as soon as the code changes % load_ext autoreload % autoreload 2 try : import matplotlib.pyplot as plt except ImportError : import sys ! { sys . executable } - m pip install matplotlib seaborn import matplotlib.pyplot as plt import numpy as np import logging from neurolib.utils.parameterSpace import ParameterSpace from neurolib.optimize.evolution import Evolution import neurolib.optimize.evolution.evolutionaryUtils as eu import neurolib.utils.functions as func def optimize_me ( traj ): ind = evolution . getIndividualFromTraj ( traj ) logging . info ( \"Hello, I am {} \" . format ( ind . id )) logging . info ( \"You can also call me {} , or simply ( {:.2} , {:.2} ).\" . format ( ind . params , ind . x , ind . y )) # let's make a circle computation_result = abs (( ind . x ** 2 + ind . y ** 2 ) - 1 ) # DEAP wants a tuple as fitness, ALWAYS! fitness_tuple = ( computation_result ,) # we also require a dictionary with at least a single result for storing the results in the hdf result_dict = {} return fitness_tuple , result_dict pars = ParameterSpace ([ 'x' , 'y' ], [[ - 5.0 , 5.0 ], [ - 5.0 , 5.0 ]]) evolution = Evolution ( optimize_me , pars , weightList = [ - 1.0 ], POP_INIT_SIZE = 10 , POP_SIZE = 6 , NGEN = 4 , filename = \"example-2.0.hdf\" ) # info: chose POP_INIT_SIZE=100, POP_SIZE = 50, NGEN=10 for real exploration, # values here are low for testing: POP_INIT_SIZE=10, POP_SIZE = 6, NGEN=4 evolution . run ( verbose = True ) evolution . loadResults () evolution . info ( plot = True ) gens , all_scores = evolution . getScoresDuringEvolution ( reverse = True ) import matplotlib.pyplot as plt plt . figure ( figsize = ( 8 , 4 ), dpi = 200 ) plt . plot ( gens , np . nanmean ( all_scores , axis = 1 )) plt . fill_between ( gens , np . nanmin ( all_scores , axis = 1 ), np . nanmax ( all_scores , axis = 1 ), alpha = 0.3 ) plt . xlabel ( \"Generation #\" ) plt . ylabel ( \"Score\" )","title":"Example 2 evolutionary optimization minimal"},{"location":"examples/example-2-evolutionary-optimization-minimal/#simple-example-of-the-evolutionary-optimization-framework","text":"This notebook provides a simple example for the use of the evolutionary optimization framework builtin to the library. Under the hood, the implementation of the evolutionary algorithm is powered by deap and pypet cares about the parallelization and storage of the simulation data for us. Here we demonstrate how to fit parameters of a the evaluation function optimize_me which simply computes the distance of the parameters to the unit circle and returns this as the fitness_tuple that DEAP expects. # change to the root directory of the project import os if os . getcwd () . split ( \"/\" )[ - 1 ] == \"examples\" : os . chdir ( '..' ) # This will reload all imports as soon as the code changes % load_ext autoreload % autoreload 2 try : import matplotlib.pyplot as plt except ImportError : import sys ! { sys . executable } - m pip install matplotlib seaborn import matplotlib.pyplot as plt import numpy as np import logging from neurolib.utils.parameterSpace import ParameterSpace from neurolib.optimize.evolution import Evolution import neurolib.optimize.evolution.evolutionaryUtils as eu import neurolib.utils.functions as func def optimize_me ( traj ): ind = evolution . getIndividualFromTraj ( traj ) logging . info ( \"Hello, I am {} \" . format ( ind . id )) logging . info ( \"You can also call me {} , or simply ( {:.2} , {:.2} ).\" . format ( ind . params , ind . x , ind . y )) # let's make a circle computation_result = abs (( ind . x ** 2 + ind . y ** 2 ) - 1 ) # DEAP wants a tuple as fitness, ALWAYS! fitness_tuple = ( computation_result ,) # we also require a dictionary with at least a single result for storing the results in the hdf result_dict = {} return fitness_tuple , result_dict pars = ParameterSpace ([ 'x' , 'y' ], [[ - 5.0 , 5.0 ], [ - 5.0 , 5.0 ]]) evolution = Evolution ( optimize_me , pars , weightList = [ - 1.0 ], POP_INIT_SIZE = 10 , POP_SIZE = 6 , NGEN = 4 , filename = \"example-2.0.hdf\" ) # info: chose POP_INIT_SIZE=100, POP_SIZE = 50, NGEN=10 for real exploration, # values here are low for testing: POP_INIT_SIZE=10, POP_SIZE = 6, NGEN=4 evolution . run ( verbose = True ) evolution . loadResults () evolution . info ( plot = True ) gens , all_scores = evolution . getScoresDuringEvolution ( reverse = True ) import matplotlib.pyplot as plt plt . figure ( figsize = ( 8 , 4 ), dpi = 200 ) plt . plot ( gens , np . nanmean ( all_scores , axis = 1 )) plt . fill_between ( gens , np . nanmin ( all_scores , axis = 1 ), np . nanmax ( all_scores , axis = 1 ), alpha = 0.3 ) plt . xlabel ( \"Generation #\" ) plt . ylabel ( \"Score\" )","title":"Simple example of the evolutionary optimization framework"},{"location":"examples/example-2.0.1-save-and-load-evolution/","text":"(function() { function addWidgetsRenderer() { var requireJsScript = document.createElement('script'); requireJsScript.src = 'https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js'; var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var jupyterWidgetsScript = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} jupyterWidgetsScript.src = widgetRendererSrc; document.body.appendChild(requireJsScript); document.body.appendChild(jupyterWidgetsScript); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); Saving and loading Evolution In this example, we will demonstrate how to save an evolutionary optimization on one machine or instance and load the results in another machine. This is useful, when the optimization is carried out on another computer as the analysis of the results are done. # change to the root directory of the project import os if os . getcwd () . split ( \"/\" )[ - 2 ] == \"neurolib\" : os . chdir ( '..' ) # This will reload all imports as soon as the code changes % load_ext autoreload % autoreload 2 # prepare logging import logging logger = logging . getLogger () logger . setLevel ( logging . INFO ) % load_ext autoreload % autoreload 2 We import the modules that we need for evolution from neurolib.utils.parameterSpace import ParameterSpace from neurolib.optimize.evolution import Evolution import numpy as np We will simply run the basic optimization on a circle from Example 2. def optimize_me ( traj ): ind = evolution . getIndividualFromTraj ( traj ) result = tuple ([ abs (( ind . x ** 2 + ind . y ** 2 ) - 1 )]) return result , { \"random_output\" : np . random . randint ( 100 )} pars = ParameterSpace ([ 'x' , 'y' ], [[ - 5.0 , 5.0 ], [ - 5.0 , 5.0 ]]) evolution = Evolution ( optimize_me , pars , weightList = [ - 1.0 ], POP_INIT_SIZE = 10 , POP_SIZE = 6 , NGEN = 4 , filename = \"example-2.0.1.hdf\" ) evolution . run ( verbose = True ) Save evolution Now that the optimization is done, we can serialize and save the evolution using the dill module. EVOLUTION_DILL = \"saved_evolution.dill\" evolution . saveEvolution ( EVOLUTION_DILL ) MainProcess root INFO Saving evolution to saved_evolution.dill Load evolution Here, we pretend as if we're on a completely new machine. We need to instantiate the Evolution class in order to fill it with the data from the previous optimization. For this, we create a \"mock\" evolution with some fake parameters and then load the dill file to fill out the mock values with the real ones. # initialize mock evolution for loading previously generated data pars = ParameterSpace ([ 'mock' ], [[ 0 , 1 ]]) evaluateSimulation = lambda x : x evolution_new = Evolution ( evaluateSimulation , pars ) evolution_new = evolution_new . loadEvolution ( EVOLUTION_DILL ) MainProcess root INFO weightList not set, assuming single fitness value to be maximized. MainProcess root INFO Trajectory Name: results-2021-02-15-12H-13M-39S MainProcess root INFO Storing data to: ./data/hdf/evolution.hdf MainProcess root INFO Trajectory Name: results-2021-02-15-12H-13M-39S MainProcess root INFO Number of cores: 8 MainProcess pypet.storageservice.HDF5StorageService INFO I will use the hdf5 file `./data/hdf/evolution.hdf`. MainProcess pypet.environment.Environment INFO Environment initialized. MainProcess root INFO Evolution: Using algorithm: adaptive /Users/caglar/anaconda/lib/python3.7/site-packages/deap/creator.py:141: RuntimeWarning: A class named 'FitnessMulti' has already been created and it will be overwritten. Consider deleting previous creation of that class or rename it. RuntimeWarning) /Users/caglar/anaconda/lib/python3.7/site-packages/deap/creator.py:141: RuntimeWarning: A class named 'Individual' has already been created and it will be overwritten. Consider deleting previous creation of that class or rename it. RuntimeWarning) MainProcess root INFO Evolution: Individual generation: <function randomParametersAdaptive at 0x7fd122dfa950> MainProcess root INFO Evolution: Mating operator: <function cxBlend at 0x7fd122dcdb70> MainProcess root INFO Evolution: Mutation operator: <function gaussianAdaptiveMutation_nStepSizes at 0x7fd122dfad90> MainProcess root INFO Evolution: Parent selection: <function selRank at 0x7fd122dfaae8> MainProcess root INFO Evolution: Selection operator: <function selBest_multiObj at 0x7fd122dfab70> Now, we should be able to do everything we want with the new evolution object. dfEvolution = evolution_new . dfEvolution () dfEvolution .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } x y score id gen f0 0 1.767126 0.547244 -2.422212 1 0 2.422212 1 1.908967 -0.899728 -3.453668 7 0 3.453668 2 2.047736 1.437642 -5.260036 9 0 5.260036 3 -1.521826 2.259241 -6.420126 8 0 6.420126 4 -0.898959 2.578525 -6.456920 0 0 6.456920 5 2.622927 -1.558091 -8.307394 3 0 8.307394 6 0.517562 1.942211 -3.040056 10 1 3.040056 7 -1.820438 2.712097 -9.669464 11 1 9.669464 8 0.777049 1.272183 -1.222253 12 1 1.222253 9 3.143349 0.980240 -9.841516 13 1 9.841516 10 2.267286 -0.238797 -4.197609 14 1 4.197609 11 2.098299 3.682854 -16.966271 15 1 16.966271 12 -1.746393 0.288008 -2.132837 16 2 2.132837 13 0.759040 0.168302 -0.395532 17 2 0.395532 14 -1.477419 2.202671 -6.034527 18 2 6.034527 15 0.384431 3.804135 -13.619231 19 2 13.619231 16 1.236164 -2.969863 -9.348190 20 2 9.348190 17 1.478068 0.033220 -1.185788 21 2 1.185788 18 2.544810 3.003174 -14.495107 22 3 14.495107 19 0.606182 -0.408578 -0.465607 23 3 0.465607 20 0.741795 0.783160 -0.163599 24 3 0.163599 21 1.678066 2.696300 -9.085941 25 3 9.085941 22 1.190213 -3.732895 -14.351114 26 3 14.351114 23 -2.492132 -1.219275 -6.697355 27 3 6.697355 We can also be able to load the hdf file in which all simulated was stored (\"random_output\" in the evaluation function above). evolution_new . loadResults () MainProcess root INFO Loading results from ./data/hdf/example-2.0.1.hdf MainProcess root INFO Analyzing trajectory results-2021-02-15-12H-13M-24S MainProcess pypet.storageservice.HDF5StorageService INFO I will use the hdf5 file `./data/hdf/example-2.0.1.hdf`. MainProcess pypet.storageservice.HDF5StorageService INFO Loading trajectory `results-2021-02-15-12H-13M-24S`. MainProcess pypet.storageservice.HDF5StorageService INFO Loading branch `config` in mode `2`. MainProcess pypet.storageservice.HDF5StorageService INFO Loading branch `derived_parameters` in mode `1`. MainProcess pypet.storageservice.HDF5StorageService INFO Loading branch `parameters` in mode `2`. MainProcess pypet.storageservice.HDF5StorageService INFO Loading branch `results` in mode `1`. We can load the output from the hdf file by passing the argument outputs=True to the dfEvolution() method: evolution_new . dfEvolution ( outputs = True ) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } x y score id gen random_output f0 0 1.767126 0.547244 -2.422212 1 0 1.0 2.422212 1 1.908967 -0.899728 -3.453668 7 0 1.0 3.453668 2 2.047736 1.437642 -5.260036 9 0 1.0 5.260036 3 -1.521826 2.259241 -6.420126 8 0 1.0 6.420126 4 -0.898959 2.578525 -6.456920 0 0 1.0 6.456920 5 2.622927 -1.558091 -8.307394 3 0 1.0 8.307394 6 0.517562 1.942211 -3.040056 10 1 51.0 3.040056 7 -1.820438 2.712097 -9.669464 11 1 51.0 9.669464 8 0.777049 1.272183 -1.222253 12 1 51.0 1.222253 9 3.143349 0.980240 -9.841516 13 1 51.0 9.841516 10 2.267286 -0.238797 -4.197609 14 1 51.0 4.197609 11 2.098299 3.682854 -16.966271 15 1 51.0 16.966271 12 -1.746393 0.288008 -2.132837 16 2 36.0 2.132837 13 0.759040 0.168302 -0.395532 17 2 36.0 0.395532 14 -1.477419 2.202671 -6.034527 18 2 36.0 6.034527 15 0.384431 3.804135 -13.619231 19 2 36.0 13.619231 16 1.236164 -2.969863 -9.348190 20 2 36.0 9.348190 17 1.478068 0.033220 -1.185788 21 2 36.0 1.185788 18 2.544810 3.003174 -14.495107 22 3 23.0 14.495107 19 0.606182 -0.408578 -0.465607 23 3 23.0 0.465607 20 0.741795 0.783160 -0.163599 24 3 23.0 0.163599 21 1.678066 2.696300 -9.085941 25 3 23.0 9.085941 22 1.190213 -3.732895 -14.351114 26 3 23.0 14.351114 23 -2.492132 -1.219275 -6.697355 27 3 23.0 6.697355 evolution . info () > Simulation parameters HDF file storage: ./data/hdf/example-2.0.1.hdf Trajectory Name: results-2021-02-15-12H-13M-24S Duration of evaluating initial population 0:00:01.093011 Duration of evolution 0:00:08.117928 Eval function: <function optimize_me at 0x7fd124ee4840> Parameter space: {'x': [-5.0, 5.0], 'y': [-5.0, 5.0]} > Evolution parameters Number of generations: 4 Initial population size: 10 Population size: 6 > Evolutionary operators Mating operator: <function cxBlend at 0x7fd122dcdb70> Mating paramter: {'alpha': 0.5} Selection operator: <function selBest_multiObj at 0x7fd122dfab70> Selection paramter: {} Parent selection operator: <function selRank at 0x7fd122dfaae8> Comments: no comments --- Info summary --- Valid: 6 Mean score (weighted fitness): -0.93 Parameter distribution (Generation 3): x: mean: 0.4360, std: 1.0159 y: mean: 0.3560, std: 0.5401 -------------------- Best 5 individuals: Printing 5 individuals Individual 0 Fitness values: 0.16 Score: -0.16 Weighted fitness: -0.16 Stats mean 0.16 std 0.00 min 0.16 max 0.16 model.params[\"x\"] = 0.74 model.params[\"y\"] = 0.78 Individual 1 Fitness values: 0.4 Score: -0.4 Weighted fitness: -0.4 Stats mean 0.40 std 0.00 min 0.40 max 0.40 model.params[\"x\"] = 0.76 model.params[\"y\"] = 0.17 Individual 2 Fitness values: 0.47 Score: -0.47 Weighted fitness: -0.47 Stats mean 0.47 std 0.00 min 0.47 max 0.47 model.params[\"x\"] = 0.61 model.params[\"y\"] = -0.41 Individual 3 Fitness values: 1.19 Score: -1.19 Weighted fitness: -1.19 Stats mean 1.19 std 0.00 min 1.19 max 1.19 model.params[\"x\"] = 1.48 model.params[\"y\"] = 0.03 Individual 4 Fitness values: 1.22 Score: -1.22 Weighted fitness: -1.22 Stats mean 1.22 std 0.00 min 1.22 max 1.22 model.params[\"x\"] = 0.78 model.params[\"y\"] = 1.27 -------------------- /Users/caglar/anaconda/lib/python3.7/site-packages/neurolib/optimize/evolution/evolutionaryUtils.py:212: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect. plt.tight_layout() MainProcess root INFO Saving plot to ./data/figures/results-2021-02-15-12H-13M-24S_hist_3.png There are 6 valid individuals Mean score across population: -0.93 <Figure size 432x288 with 0 Axes>","title":"Example 2.0.1 save and load evolution"},{"location":"examples/example-2.0.1-save-and-load-evolution/#saving-and-loading-evolution","text":"In this example, we will demonstrate how to save an evolutionary optimization on one machine or instance and load the results in another machine. This is useful, when the optimization is carried out on another computer as the analysis of the results are done. # change to the root directory of the project import os if os . getcwd () . split ( \"/\" )[ - 2 ] == \"neurolib\" : os . chdir ( '..' ) # This will reload all imports as soon as the code changes % load_ext autoreload % autoreload 2 # prepare logging import logging logger = logging . getLogger () logger . setLevel ( logging . INFO ) % load_ext autoreload % autoreload 2 We import the modules that we need for evolution from neurolib.utils.parameterSpace import ParameterSpace from neurolib.optimize.evolution import Evolution import numpy as np We will simply run the basic optimization on a circle from Example 2. def optimize_me ( traj ): ind = evolution . getIndividualFromTraj ( traj ) result = tuple ([ abs (( ind . x ** 2 + ind . y ** 2 ) - 1 )]) return result , { \"random_output\" : np . random . randint ( 100 )} pars = ParameterSpace ([ 'x' , 'y' ], [[ - 5.0 , 5.0 ], [ - 5.0 , 5.0 ]]) evolution = Evolution ( optimize_me , pars , weightList = [ - 1.0 ], POP_INIT_SIZE = 10 , POP_SIZE = 6 , NGEN = 4 , filename = \"example-2.0.1.hdf\" ) evolution . run ( verbose = True )","title":"Saving and loading Evolution"},{"location":"examples/example-2.0.1-save-and-load-evolution/#save-evolution","text":"Now that the optimization is done, we can serialize and save the evolution using the dill module. EVOLUTION_DILL = \"saved_evolution.dill\" evolution . saveEvolution ( EVOLUTION_DILL ) MainProcess root INFO Saving evolution to saved_evolution.dill","title":"Save evolution"},{"location":"examples/example-2.0.1-save-and-load-evolution/#load-evolution","text":"Here, we pretend as if we're on a completely new machine. We need to instantiate the Evolution class in order to fill it with the data from the previous optimization. For this, we create a \"mock\" evolution with some fake parameters and then load the dill file to fill out the mock values with the real ones. # initialize mock evolution for loading previously generated data pars = ParameterSpace ([ 'mock' ], [[ 0 , 1 ]]) evaluateSimulation = lambda x : x evolution_new = Evolution ( evaluateSimulation , pars ) evolution_new = evolution_new . loadEvolution ( EVOLUTION_DILL ) MainProcess root INFO weightList not set, assuming single fitness value to be maximized. MainProcess root INFO Trajectory Name: results-2021-02-15-12H-13M-39S MainProcess root INFO Storing data to: ./data/hdf/evolution.hdf MainProcess root INFO Trajectory Name: results-2021-02-15-12H-13M-39S MainProcess root INFO Number of cores: 8 MainProcess pypet.storageservice.HDF5StorageService INFO I will use the hdf5 file `./data/hdf/evolution.hdf`. MainProcess pypet.environment.Environment INFO Environment initialized. MainProcess root INFO Evolution: Using algorithm: adaptive /Users/caglar/anaconda/lib/python3.7/site-packages/deap/creator.py:141: RuntimeWarning: A class named 'FitnessMulti' has already been created and it will be overwritten. Consider deleting previous creation of that class or rename it. RuntimeWarning) /Users/caglar/anaconda/lib/python3.7/site-packages/deap/creator.py:141: RuntimeWarning: A class named 'Individual' has already been created and it will be overwritten. Consider deleting previous creation of that class or rename it. RuntimeWarning) MainProcess root INFO Evolution: Individual generation: <function randomParametersAdaptive at 0x7fd122dfa950> MainProcess root INFO Evolution: Mating operator: <function cxBlend at 0x7fd122dcdb70> MainProcess root INFO Evolution: Mutation operator: <function gaussianAdaptiveMutation_nStepSizes at 0x7fd122dfad90> MainProcess root INFO Evolution: Parent selection: <function selRank at 0x7fd122dfaae8> MainProcess root INFO Evolution: Selection operator: <function selBest_multiObj at 0x7fd122dfab70> Now, we should be able to do everything we want with the new evolution object. dfEvolution = evolution_new . dfEvolution () dfEvolution .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } x y score id gen f0 0 1.767126 0.547244 -2.422212 1 0 2.422212 1 1.908967 -0.899728 -3.453668 7 0 3.453668 2 2.047736 1.437642 -5.260036 9 0 5.260036 3 -1.521826 2.259241 -6.420126 8 0 6.420126 4 -0.898959 2.578525 -6.456920 0 0 6.456920 5 2.622927 -1.558091 -8.307394 3 0 8.307394 6 0.517562 1.942211 -3.040056 10 1 3.040056 7 -1.820438 2.712097 -9.669464 11 1 9.669464 8 0.777049 1.272183 -1.222253 12 1 1.222253 9 3.143349 0.980240 -9.841516 13 1 9.841516 10 2.267286 -0.238797 -4.197609 14 1 4.197609 11 2.098299 3.682854 -16.966271 15 1 16.966271 12 -1.746393 0.288008 -2.132837 16 2 2.132837 13 0.759040 0.168302 -0.395532 17 2 0.395532 14 -1.477419 2.202671 -6.034527 18 2 6.034527 15 0.384431 3.804135 -13.619231 19 2 13.619231 16 1.236164 -2.969863 -9.348190 20 2 9.348190 17 1.478068 0.033220 -1.185788 21 2 1.185788 18 2.544810 3.003174 -14.495107 22 3 14.495107 19 0.606182 -0.408578 -0.465607 23 3 0.465607 20 0.741795 0.783160 -0.163599 24 3 0.163599 21 1.678066 2.696300 -9.085941 25 3 9.085941 22 1.190213 -3.732895 -14.351114 26 3 14.351114 23 -2.492132 -1.219275 -6.697355 27 3 6.697355 We can also be able to load the hdf file in which all simulated was stored (\"random_output\" in the evaluation function above). evolution_new . loadResults () MainProcess root INFO Loading results from ./data/hdf/example-2.0.1.hdf MainProcess root INFO Analyzing trajectory results-2021-02-15-12H-13M-24S MainProcess pypet.storageservice.HDF5StorageService INFO I will use the hdf5 file `./data/hdf/example-2.0.1.hdf`. MainProcess pypet.storageservice.HDF5StorageService INFO Loading trajectory `results-2021-02-15-12H-13M-24S`. MainProcess pypet.storageservice.HDF5StorageService INFO Loading branch `config` in mode `2`. MainProcess pypet.storageservice.HDF5StorageService INFO Loading branch `derived_parameters` in mode `1`. MainProcess pypet.storageservice.HDF5StorageService INFO Loading branch `parameters` in mode `2`. MainProcess pypet.storageservice.HDF5StorageService INFO Loading branch `results` in mode `1`. We can load the output from the hdf file by passing the argument outputs=True to the dfEvolution() method: evolution_new . dfEvolution ( outputs = True ) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } x y score id gen random_output f0 0 1.767126 0.547244 -2.422212 1 0 1.0 2.422212 1 1.908967 -0.899728 -3.453668 7 0 1.0 3.453668 2 2.047736 1.437642 -5.260036 9 0 1.0 5.260036 3 -1.521826 2.259241 -6.420126 8 0 1.0 6.420126 4 -0.898959 2.578525 -6.456920 0 0 1.0 6.456920 5 2.622927 -1.558091 -8.307394 3 0 1.0 8.307394 6 0.517562 1.942211 -3.040056 10 1 51.0 3.040056 7 -1.820438 2.712097 -9.669464 11 1 51.0 9.669464 8 0.777049 1.272183 -1.222253 12 1 51.0 1.222253 9 3.143349 0.980240 -9.841516 13 1 51.0 9.841516 10 2.267286 -0.238797 -4.197609 14 1 51.0 4.197609 11 2.098299 3.682854 -16.966271 15 1 51.0 16.966271 12 -1.746393 0.288008 -2.132837 16 2 36.0 2.132837 13 0.759040 0.168302 -0.395532 17 2 36.0 0.395532 14 -1.477419 2.202671 -6.034527 18 2 36.0 6.034527 15 0.384431 3.804135 -13.619231 19 2 36.0 13.619231 16 1.236164 -2.969863 -9.348190 20 2 36.0 9.348190 17 1.478068 0.033220 -1.185788 21 2 36.0 1.185788 18 2.544810 3.003174 -14.495107 22 3 23.0 14.495107 19 0.606182 -0.408578 -0.465607 23 3 23.0 0.465607 20 0.741795 0.783160 -0.163599 24 3 23.0 0.163599 21 1.678066 2.696300 -9.085941 25 3 23.0 9.085941 22 1.190213 -3.732895 -14.351114 26 3 23.0 14.351114 23 -2.492132 -1.219275 -6.697355 27 3 23.0 6.697355 evolution . info () > Simulation parameters HDF file storage: ./data/hdf/example-2.0.1.hdf Trajectory Name: results-2021-02-15-12H-13M-24S Duration of evaluating initial population 0:00:01.093011 Duration of evolution 0:00:08.117928 Eval function: <function optimize_me at 0x7fd124ee4840> Parameter space: {'x': [-5.0, 5.0], 'y': [-5.0, 5.0]} > Evolution parameters Number of generations: 4 Initial population size: 10 Population size: 6 > Evolutionary operators Mating operator: <function cxBlend at 0x7fd122dcdb70> Mating paramter: {'alpha': 0.5} Selection operator: <function selBest_multiObj at 0x7fd122dfab70> Selection paramter: {} Parent selection operator: <function selRank at 0x7fd122dfaae8> Comments: no comments --- Info summary --- Valid: 6 Mean score (weighted fitness): -0.93 Parameter distribution (Generation 3): x: mean: 0.4360, std: 1.0159 y: mean: 0.3560, std: 0.5401 -------------------- Best 5 individuals: Printing 5 individuals Individual 0 Fitness values: 0.16 Score: -0.16 Weighted fitness: -0.16 Stats mean 0.16 std 0.00 min 0.16 max 0.16 model.params[\"x\"] = 0.74 model.params[\"y\"] = 0.78 Individual 1 Fitness values: 0.4 Score: -0.4 Weighted fitness: -0.4 Stats mean 0.40 std 0.00 min 0.40 max 0.40 model.params[\"x\"] = 0.76 model.params[\"y\"] = 0.17 Individual 2 Fitness values: 0.47 Score: -0.47 Weighted fitness: -0.47 Stats mean 0.47 std 0.00 min 0.47 max 0.47 model.params[\"x\"] = 0.61 model.params[\"y\"] = -0.41 Individual 3 Fitness values: 1.19 Score: -1.19 Weighted fitness: -1.19 Stats mean 1.19 std 0.00 min 1.19 max 1.19 model.params[\"x\"] = 1.48 model.params[\"y\"] = 0.03 Individual 4 Fitness values: 1.22 Score: -1.22 Weighted fitness: -1.22 Stats mean 1.22 std 0.00 min 1.22 max 1.22 model.params[\"x\"] = 0.78 model.params[\"y\"] = 1.27 -------------------- /Users/caglar/anaconda/lib/python3.7/site-packages/neurolib/optimize/evolution/evolutionaryUtils.py:212: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect. plt.tight_layout() MainProcess root INFO Saving plot to ./data/figures/results-2021-02-15-12H-13M-24S_hist_3.png There are 6 valid individuals Mean score across population: -0.93 <Figure size 432x288 with 0 Axes>","title":"Load evolution"},{"location":"examples/example-2.1-evolutionary-optimization-aln/","text":"(function() { function addWidgetsRenderer() { var requireJsScript = document.createElement('script'); requireJsScript.src = 'https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js'; var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var jupyterWidgetsScript = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} jupyterWidgetsScript.src = widgetRendererSrc; document.body.appendChild(requireJsScript); document.body.appendChild(jupyterWidgetsScript); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); Evolutionary parameter search with a single neural mass model This notebook provides a simple example for the use of the evolutionary optimization framework built-in to the library. Under the hood, the implementation of the evolutionary algorithm is powered by deap and pypet cares about the parallelization and storage of the simulation data for us. We want to optimize for a simple target, namely finding a parameter configuration that produces activity with a peak power frequency spectrum at 25 Hz. In this notebook, we will also plot the evolutionary genealogy tree, to visualize how the population evolves over generations. # change to the root directory of the project import os if os . getcwd () . split ( \"/\" )[ - 1 ] == \"examples\" : os . chdir ( '..' ) # This will reload all imports as soon as the code changes % load_ext autoreload % autoreload 2 try : import matplotlib.pyplot as plt except ImportError : import sys ! { sys . executable } - m pip install matplotlib seaborn import matplotlib.pyplot as plt import numpy as np import logging from neurolib.models.aln import ALNModel from neurolib.utils.parameterSpace import ParameterSpace from neurolib.optimize.evolution import Evolution import neurolib.utils.functions as func import neurolib.optimize.evolution.deapUtils as deapUtils # a nice color map plt . rcParams [ 'image.cmap' ] = 'plasma' Model definition aln = ALNModel () # Here we define our evaluation function. This function will # be called reapedly and perform a single simulation. The object # that is passed to the function, `traj`, is a pypet trajectory # and serves as a \"bridge\" to load the parameter set of this # particular trajectory and execute a run. # Then the power spectrum of the run is computed and its maximum # is fitted to the target of 25 Hz peak frequency. def evaluateSimulation ( traj ): # The trajectory id is provided as an attribute rid = traj . id logging . info ( \"Running run id {} \" . format ( rid )) # this function provides the a model with the partuclar # parameter set for this given run model = evolution . getModelFromTraj ( traj ) # parameters can also be modified after loading model . params [ 'dt' ] = 0.1 model . params [ 'duration' ] = 2 * 1000. # and the simulation is run model . run () # compute power spectrum frs , powers = func . getPowerSpectrum ( model . rates_exc [:, - int ( 1000 / model . params [ 'dt' ]):], dt = model . params [ 'dt' ]) # find the peak frequency domfr = frs [ np . argmax ( powers )] # fitness evaluation: let's try to find a 25 Hz oscillation fitness = abs ( domfr - 25 ) # deap needs a fitness *tuple*! fitness_tuple = () # more fitness values could be added fitness_tuple += ( fitness , ) # we need to return the fitness tuple and the outputs of the model return fitness_tuple , model . outputs Initialize and run evolution The evolutionary algorithm tries to find the optimal parameter set that will maximize (or minimize) a certain fitness function. This achieved by seeding an initial population of size POP_INIT_SIZE that is randomly initiated in the parameter space parameterSpace . INIT: After simulating the initial population using evalFunction , only a subset of the individuals is kept, defined by POP_SIZE . START: Members of the remaining population are chosen based on their fitness (using rank selection) to mate and produce offspring . These offspring have parameters that are drawn from a normal distribution defined by the mean of the parameters between the two parents. Then the offspring population is evaluated and the process loops back to START: This process is repeated for NGEN generations. # Here we define the parameters and the range in which we want # to perform the evolutionary optimization. # Create a `ParameterSpace` pars = ParameterSpace ([ 'mue_ext_mean' , 'mui_ext_mean' ], [[ 0.0 , 4.0 ], [ 0.0 , 4.0 ]]) # Iitialize evolution with # :evaluateSimulation: The function that returns a fitness, # :pars: The parameter space and its boundaries to optimize # :model: The model that should be passed to the evaluation function # :weightList: A list of optimization weights for the `fitness_tuple`, # positive values will lead to a maximization, negative # values to a minimzation. The length of this list must # be the same as the length of the `fitness_tuple`. # # :POP_INIT_SIZE: The size of the initial population that will be # randomly sampled in the parameter space `pars`. # Should be higher than POP_SIZE. 50-200 might be a good # range to start experimenting with. # :POP_SIZE: Size of the population that should evolve. Must be an # even number. 20-100 might be a good range to start with. # :NGEN: Number of generations to simulate the evolution for. A good # range to start with might be 20-100. weightList = [ - 1.0 ] evolution = Evolution ( evalFunction = evaluateSimulation , parameterSpace = pars , model = aln , weightList = [ - 1.0 ], POP_INIT_SIZE = 4 , POP_SIZE = 4 , NGEN = 2 , filename = \"example-2.1.hdf\" ) # info: chose POP_INIT_SIZE=50, POP_SIZE = 20, NGEN=20 for real exploration, # values are lower here for testing # Enabling `verbose = True` will print statistics and generate plots # of the current population for each generation. evolution . run ( verbose = False ) Analysis Population # the current population is always accesible via pop = evolution . pop # we can also use the functions registered to deap # to select the best of the population: best_10 = evolution . toolbox . selBest ( pop , k = 10 ) # Remember, we performed a minimization so a fitness # of 0 is optimal print ( \"Best individual\" , best_10 [ 0 ], \"fitness\" , best_10 [ 0 ] . fitness ) Best individual [1.182184510022096, 0.29660620374273683, 0.4936712969767474, 0.07875430013351538] fitness (0.0,) We can look at the current population by calling evolution.dfPop() which returns a pandas dataframe with the parameters of each individual, its id, generation of birth, its outputs, and the fitness (called \"f0\" here). evolution . dfPop ( outputs = True ) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } mue_ext_mean mui_ext_mean score id gen t rates_exc rates_inh IA f0 0 1.182185 0.296606 0.0 294 13 [0.1, 0.2, 0.30000000000000004, 0.4, 0.5, 0.60... [[4.3201372225314945, 3.9353836030865286, 3.58... [[10.920182546008649, 11.229353479381396, 11.5... [[111.41612911461853, 111.36042105006122, 111.... 0.0 1 1.114270 0.240422 0.0 368 16 [0.1, 0.2, 0.30000000000000004, 0.4, 0.5, 0.60... [[4.3201372225314945, 3.9353836030865286, 3.58... [[10.920182546008649, 11.229353479381396, 11.5... [[111.41612911461853, 111.36042105006122, 111.... 0.0 2 0.910558 0.075463 0.0 403 18 [0.1, 0.2, 0.30000000000000004, 0.4, 0.5, 0.60... [[4.3201372225314945, 3.9353836030865286, 3.58... [[10.920182546008649, 11.229353479381396, 11.5... [[111.41612911461853, 111.36042105006122, 111.... 0.0 3 1.188440 0.356385 -1.0 171 7 [0.1, 0.2, 0.30000000000000004, 0.4, 0.5, 0.60... [[4.3201372225314945, 3.9353836030865286, 3.58... [[10.920182546008649, 11.229353479381396, 11.5... [[111.41612911461853, 111.36042105006122, 111.... 1.0 4 1.007371 0.113623 -1.0 177 7 [0.1, 0.2, 0.30000000000000004, 0.4, 0.5, 0.60... [[4.3201372225314945, 3.9353836030865286, 3.58... [[10.920182546008649, 11.229353479381396, 11.5... [[111.41612911461853, 111.36042105006122, 111.... 1.0 5 1.031484 0.120989 -1.0 192 8 [0.1, 0.2, 0.30000000000000004, 0.4, 0.5, 0.60... [[4.3201372225314945, 3.9353836030865286, 3.58... [[10.920182546008649, 11.229353479381396, 11.5... [[111.41612911461853, 111.36042105006122, 111.... 1.0 6 0.900787 0.038763 -1.0 193 8 [0.1, 0.2, 0.30000000000000004, 0.4, 0.5, 0.60... [[4.3201372225314945, 3.9353836030865286, 3.58... [[10.920182546008649, 11.229353479381396, 11.5... [[111.41612911461853, 111.36042105006122, 111.... 1.0 7 1.217021 0.213936 -1.0 245 10 [0.1, 0.2, 0.30000000000000004, 0.4, 0.5, 0.60... [[4.3201372225314945, 3.9353836030865286, 3.58... [[10.920182546008649, 11.229353479381396, 11.5... [[111.41612911461853, 111.36042105006122, 111.... 1.0 8 1.241895 0.365758 -1.0 248 10 [0.1, 0.2, 0.30000000000000004, 0.4, 0.5, 0.60... [[4.3201372225314945, 3.9353836030865286, 3.58... [[10.920182546008649, 11.229353479381396, 11.5... [[111.41612911461853, 111.36042105006122, 111.... 1.0 9 1.062928 0.265389 -1.0 267 11 [0.1, 0.2, 0.30000000000000004, 0.4, 0.5, 0.60... [[4.3201372225314945, 3.9353836030865286, 3.58... [[10.920182546008649, 11.229353479381396, 11.5... [[111.41612911461853, 111.36042105006122, 111.... 1.0 10 1.007366 0.110587 -1.0 286 12 [0.1, 0.2, 0.30000000000000004, 0.4, 0.5, 0.60... [[4.3201372225314945, 3.9353836030865286, 3.58... [[10.920182546008649, 11.229353479381396, 11.5... [[111.41612911461853, 111.36042105006122, 111.... 1.0 11 0.904612 0.123308 -1.0 320 14 [0.1, 0.2, 0.30000000000000004, 0.4, 0.5, 0.60... [[4.3201372225314945, 3.9353836030865286, 3.58... [[10.920182546008649, 11.229353479381396, 11.5... [[111.41612911461853, 111.36042105006122, 111.... 1.0 12 1.119281 0.188307 -1.0 330 15 [0.1, 0.2, 0.30000000000000004, 0.4, 0.5, 0.60... [[4.3201372225314945, 3.9353836030865286, 3.58... [[10.920182546008649, 11.229353479381396, 11.5... [[111.41612911461853, 111.36042105006122, 111.... 1.0 13 1.158463 0.227194 -1.0 342 15 [0.1, 0.2, 0.30000000000000004, 0.4, 0.5, 0.60... [[4.3201372225314945, 3.9353836030865286, 3.58... [[10.920182546008649, 11.229353479381396, 11.5... [[111.41612911461853, 111.36042105006122, 111.... 1.0 14 1.053327 0.281852 -1.0 344 15 [0.1, 0.2, 0.30000000000000004, 0.4, 0.5, 0.60... [[4.3201372225314945, 3.9353836030865286, 3.58... [[10.920182546008649, 11.229353479381396, 11.5... [[111.41612911461853, 111.36042105006122, 111.... 1.0 15 1.124747 0.318747 -1.0 360 16 [0.1, 0.2, 0.30000000000000004, 0.4, 0.5, 0.60... [[4.3201372225314945, 3.9353836030865286, 3.58... [[10.920182546008649, 11.229353479381396, 11.5... [[111.41612911461853, 111.36042105006122, 111.... 1.0 16 1.266317 0.360644 -1.0 364 16 [0.1, 0.2, 0.30000000000000004, 0.4, 0.5, 0.60... [[4.3201372225314945, 3.9353836030865286, 3.58... [[10.920182546008649, 11.229353479381396, 11.5... [[111.41612911461853, 111.36042105006122, 111.... 1.0 17 1.329988 0.388133 -1.0 365 16 [0.1, 0.2, 0.30000000000000004, 0.4, 0.5, 0.60... [[4.3201372225314945, 3.9353836030865286, 3.58... [[10.920182546008649, 11.229353479381396, 11.5... [[111.41612911461853, 111.36042105006122, 111.... 1.0 18 0.986030 0.189384 -1.0 390 18 [0.1, 0.2, 0.30000000000000004, 0.4, 0.5, 0.60... [[4.3201372225314945, 3.9353836030865286, 3.58... [[10.920182546008649, 11.229353479381396, 11.5... [[111.41612911461853, 111.36042105006122, 111.... 1.0 19 0.896915 0.125212 -1.0 399 18 [0.1, 0.2, 0.30000000000000004, 0.4, 0.5, 0.60... [[4.3201372225314945, 3.9353836030865286, 3.58... [[10.920182546008649, 11.229353479381396, 11.5... [[111.41612911461853, 111.36042105006122, 111.... 1.0 You can also view all individuals that were created during the entire evolution, by calling evolution.dfEvolution(): evolution . dfEvolution () .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } mue_ext_mean mui_ext_mean score id gen f0 0 1.400310 1.209331 -4.0 39 0 4.0 1 1.173593 0.662050 -5.0 31 0 5.0 2 1.134601 0.809371 -6.0 22 0 6.0 3 0.992049 0.694590 -6.0 29 0 6.0 4 1.470708 1.073607 -7.0 47 0 7.0 ... ... ... ... ... ... ... 395 1.881591 0.299691 -24.0 425 19 24.0 396 0.681422 0.489003 -8.0 426 19 8.0 397 1.430791 0.268028 -24.0 427 19 24.0 398 1.275903 0.534227 -3.0 428 19 3.0 399 0.870652 0.326687 -5.0 429 19 5.0 400 rows \u00d7 6 columns # a sinple overview of the current population (in this case the # last one) is given via the `info()` method. This provides a # a histogram of the score (= mean fitness) and scatterplots # and density estimates across orthogonal parameter space cross # sections. evolution . info ( plot = True ) > Simulation parameters HDF file storage: ./data/hdf/example-2.1.hdf Trajectory Name: results-2020-07-02-14H-20M-45S Duration of evaluating initial population 0:00:29.656935 Duration of evolution 0:03:50.565418 Model: <class 'neurolib.models.aln.model.ALNModel'> Model name: aln Eval function: <function evaluateSimulation at 0x10ba8cae8> Parameter space: {'mue_ext_mean': [0.0, 4.0], 'mui_ext_mean': [0.0, 4.0]} > Evolution parameters Number of generations: 20 Initial population size: 50 Population size: 20 > Evolutionary operators Mating operator: <function cxBlend at 0x11dcaf510> Mating paramter: {'alpha': 0.5} Selection operator: <function selBest_multiObj at 0x11f4d9d08> Selection paramter: {} Parent selection operator: <function selRank at 0x11f4d9c80> Comments: no comments --- Info summary --- Valid: 20 Mean score (weighted fitness): -0.85 Parameter distribution (Generation 19): mue_ext_mean: mean: 1.0852, std: 0.1270 mui_ext_mean: mean: 0.2200, std: 0.1042 -------------------- Best 5 individuals: Printing 5 individuals Individual 0 Fitness values: 0.0 Score: 0.0 Weighted fitness: -0.0 Stats mean 0.00 std 0.00 min 0.00 max 0.00 model.params[\"mue_ext_mean\"] = 1.18 model.params[\"mui_ext_mean\"] = 0.30 Individual 1 Fitness values: 0.0 Score: 0.0 Weighted fitness: -0.0 Stats mean 0.00 std 0.00 min 0.00 max 0.00 model.params[\"mue_ext_mean\"] = 1.11 model.params[\"mui_ext_mean\"] = 0.24 Individual 2 Fitness values: 0.0 Score: 0.0 Weighted fitness: -0.0 Stats mean 0.00 std 0.00 min 0.00 max 0.00 model.params[\"mue_ext_mean\"] = 0.91 model.params[\"mui_ext_mean\"] = 0.08 Individual 3 Fitness values: 1.0 Score: -1.0 Weighted fitness: -1.0 Stats mean 1.00 std 0.00 min 1.00 max 1.00 model.params[\"mue_ext_mean\"] = 1.19 model.params[\"mui_ext_mean\"] = 0.36 Individual 4 Fitness values: 1.0 Score: -1.0 Weighted fitness: -1.0 Stats mean 1.00 std 0.00 min 1.00 max 1.00 model.params[\"mue_ext_mean\"] = 1.01 model.params[\"mui_ext_mean\"] = 0.11 -------------------- MainProcess root INFO Saving plot to ./data/figures/results-2020-07-02-14H-20M-45S_hist_19.png There are 20 valid individuals Mean score across population: -0.85 <Figure size 432x288 with 0 Axes> Plotting genealogy tree neurolib keeps track of all individuals during the evolution. You can see all individuals from each generation by calling evolution.history . The object evolution.tree provides a network description of the genealogy of the evolution: each individual (indexed by its unique .id ) is connected to its parents. We can use this object in combination with the network library networkx to plot the tree: # we put this into a try except block since we don't do testing on networkx try : import matplotlib.pyplot as plt import networkx as nx from networkx.drawing.nx_pydot import graphviz_layout G = nx . DiGraph ( evolution . tree ) G = G . reverse () # Make the graph top-down pos = graphviz_layout ( G , prog = 'dot' ) plt . figure ( figsize = ( 8 , 8 )) nx . draw ( G , pos , node_size = 50 , alpha = 0.5 , node_color = list ( evolution . id_score . values ()), with_labels = False ) plt . show () except : print ( \"It looks like networkx or pydot are not installed\" ) /Users/caglar/anaconda/lib/python3.7/site-packages/networkx/drawing/nx_pylab.py:579: MatplotlibDeprecationWarning: The iterable function was deprecated in Matplotlib 3.1 and will be removed in 3.3. Use np.iterable instead. if not cb.iterable(width): /Users/caglar/anaconda/lib/python3.7/site-packages/networkx/drawing/nx_pylab.py:676: MatplotlibDeprecationWarning: The iterable function was deprecated in Matplotlib 3.1 and will be removed in 3.3. Use np.iterable instead. if cb.iterable(node_size): # many node sizes","title":"Example 2.1 evolutionary optimization aln"},{"location":"examples/example-2.1-evolutionary-optimization-aln/#evolutionary-parameter-search-with-a-single-neural-mass-model","text":"This notebook provides a simple example for the use of the evolutionary optimization framework built-in to the library. Under the hood, the implementation of the evolutionary algorithm is powered by deap and pypet cares about the parallelization and storage of the simulation data for us. We want to optimize for a simple target, namely finding a parameter configuration that produces activity with a peak power frequency spectrum at 25 Hz. In this notebook, we will also plot the evolutionary genealogy tree, to visualize how the population evolves over generations. # change to the root directory of the project import os if os . getcwd () . split ( \"/\" )[ - 1 ] == \"examples\" : os . chdir ( '..' ) # This will reload all imports as soon as the code changes % load_ext autoreload % autoreload 2 try : import matplotlib.pyplot as plt except ImportError : import sys ! { sys . executable } - m pip install matplotlib seaborn import matplotlib.pyplot as plt import numpy as np import logging from neurolib.models.aln import ALNModel from neurolib.utils.parameterSpace import ParameterSpace from neurolib.optimize.evolution import Evolution import neurolib.utils.functions as func import neurolib.optimize.evolution.deapUtils as deapUtils # a nice color map plt . rcParams [ 'image.cmap' ] = 'plasma'","title":"Evolutionary parameter search with a single neural mass model"},{"location":"examples/example-2.1-evolutionary-optimization-aln/#model-definition","text":"aln = ALNModel () # Here we define our evaluation function. This function will # be called reapedly and perform a single simulation. The object # that is passed to the function, `traj`, is a pypet trajectory # and serves as a \"bridge\" to load the parameter set of this # particular trajectory and execute a run. # Then the power spectrum of the run is computed and its maximum # is fitted to the target of 25 Hz peak frequency. def evaluateSimulation ( traj ): # The trajectory id is provided as an attribute rid = traj . id logging . info ( \"Running run id {} \" . format ( rid )) # this function provides the a model with the partuclar # parameter set for this given run model = evolution . getModelFromTraj ( traj ) # parameters can also be modified after loading model . params [ 'dt' ] = 0.1 model . params [ 'duration' ] = 2 * 1000. # and the simulation is run model . run () # compute power spectrum frs , powers = func . getPowerSpectrum ( model . rates_exc [:, - int ( 1000 / model . params [ 'dt' ]):], dt = model . params [ 'dt' ]) # find the peak frequency domfr = frs [ np . argmax ( powers )] # fitness evaluation: let's try to find a 25 Hz oscillation fitness = abs ( domfr - 25 ) # deap needs a fitness *tuple*! fitness_tuple = () # more fitness values could be added fitness_tuple += ( fitness , ) # we need to return the fitness tuple and the outputs of the model return fitness_tuple , model . outputs","title":"Model definition"},{"location":"examples/example-2.1-evolutionary-optimization-aln/#initialize-and-run-evolution","text":"The evolutionary algorithm tries to find the optimal parameter set that will maximize (or minimize) a certain fitness function. This achieved by seeding an initial population of size POP_INIT_SIZE that is randomly initiated in the parameter space parameterSpace . INIT: After simulating the initial population using evalFunction , only a subset of the individuals is kept, defined by POP_SIZE . START: Members of the remaining population are chosen based on their fitness (using rank selection) to mate and produce offspring . These offspring have parameters that are drawn from a normal distribution defined by the mean of the parameters between the two parents. Then the offspring population is evaluated and the process loops back to START: This process is repeated for NGEN generations. # Here we define the parameters and the range in which we want # to perform the evolutionary optimization. # Create a `ParameterSpace` pars = ParameterSpace ([ 'mue_ext_mean' , 'mui_ext_mean' ], [[ 0.0 , 4.0 ], [ 0.0 , 4.0 ]]) # Iitialize evolution with # :evaluateSimulation: The function that returns a fitness, # :pars: The parameter space and its boundaries to optimize # :model: The model that should be passed to the evaluation function # :weightList: A list of optimization weights for the `fitness_tuple`, # positive values will lead to a maximization, negative # values to a minimzation. The length of this list must # be the same as the length of the `fitness_tuple`. # # :POP_INIT_SIZE: The size of the initial population that will be # randomly sampled in the parameter space `pars`. # Should be higher than POP_SIZE. 50-200 might be a good # range to start experimenting with. # :POP_SIZE: Size of the population that should evolve. Must be an # even number. 20-100 might be a good range to start with. # :NGEN: Number of generations to simulate the evolution for. A good # range to start with might be 20-100. weightList = [ - 1.0 ] evolution = Evolution ( evalFunction = evaluateSimulation , parameterSpace = pars , model = aln , weightList = [ - 1.0 ], POP_INIT_SIZE = 4 , POP_SIZE = 4 , NGEN = 2 , filename = \"example-2.1.hdf\" ) # info: chose POP_INIT_SIZE=50, POP_SIZE = 20, NGEN=20 for real exploration, # values are lower here for testing # Enabling `verbose = True` will print statistics and generate plots # of the current population for each generation. evolution . run ( verbose = False )","title":"Initialize and run evolution"},{"location":"examples/example-2.1-evolutionary-optimization-aln/#analysis","text":"","title":"Analysis"},{"location":"examples/example-2.1-evolutionary-optimization-aln/#population","text":"# the current population is always accesible via pop = evolution . pop # we can also use the functions registered to deap # to select the best of the population: best_10 = evolution . toolbox . selBest ( pop , k = 10 ) # Remember, we performed a minimization so a fitness # of 0 is optimal print ( \"Best individual\" , best_10 [ 0 ], \"fitness\" , best_10 [ 0 ] . fitness ) Best individual [1.182184510022096, 0.29660620374273683, 0.4936712969767474, 0.07875430013351538] fitness (0.0,) We can look at the current population by calling evolution.dfPop() which returns a pandas dataframe with the parameters of each individual, its id, generation of birth, its outputs, and the fitness (called \"f0\" here). evolution . dfPop ( outputs = True ) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } mue_ext_mean mui_ext_mean score id gen t rates_exc rates_inh IA f0 0 1.182185 0.296606 0.0 294 13 [0.1, 0.2, 0.30000000000000004, 0.4, 0.5, 0.60... [[4.3201372225314945, 3.9353836030865286, 3.58... [[10.920182546008649, 11.229353479381396, 11.5... [[111.41612911461853, 111.36042105006122, 111.... 0.0 1 1.114270 0.240422 0.0 368 16 [0.1, 0.2, 0.30000000000000004, 0.4, 0.5, 0.60... [[4.3201372225314945, 3.9353836030865286, 3.58... [[10.920182546008649, 11.229353479381396, 11.5... [[111.41612911461853, 111.36042105006122, 111.... 0.0 2 0.910558 0.075463 0.0 403 18 [0.1, 0.2, 0.30000000000000004, 0.4, 0.5, 0.60... [[4.3201372225314945, 3.9353836030865286, 3.58... [[10.920182546008649, 11.229353479381396, 11.5... [[111.41612911461853, 111.36042105006122, 111.... 0.0 3 1.188440 0.356385 -1.0 171 7 [0.1, 0.2, 0.30000000000000004, 0.4, 0.5, 0.60... [[4.3201372225314945, 3.9353836030865286, 3.58... [[10.920182546008649, 11.229353479381396, 11.5... [[111.41612911461853, 111.36042105006122, 111.... 1.0 4 1.007371 0.113623 -1.0 177 7 [0.1, 0.2, 0.30000000000000004, 0.4, 0.5, 0.60... [[4.3201372225314945, 3.9353836030865286, 3.58... [[10.920182546008649, 11.229353479381396, 11.5... [[111.41612911461853, 111.36042105006122, 111.... 1.0 5 1.031484 0.120989 -1.0 192 8 [0.1, 0.2, 0.30000000000000004, 0.4, 0.5, 0.60... [[4.3201372225314945, 3.9353836030865286, 3.58... [[10.920182546008649, 11.229353479381396, 11.5... [[111.41612911461853, 111.36042105006122, 111.... 1.0 6 0.900787 0.038763 -1.0 193 8 [0.1, 0.2, 0.30000000000000004, 0.4, 0.5, 0.60... [[4.3201372225314945, 3.9353836030865286, 3.58... [[10.920182546008649, 11.229353479381396, 11.5... [[111.41612911461853, 111.36042105006122, 111.... 1.0 7 1.217021 0.213936 -1.0 245 10 [0.1, 0.2, 0.30000000000000004, 0.4, 0.5, 0.60... [[4.3201372225314945, 3.9353836030865286, 3.58... [[10.920182546008649, 11.229353479381396, 11.5... [[111.41612911461853, 111.36042105006122, 111.... 1.0 8 1.241895 0.365758 -1.0 248 10 [0.1, 0.2, 0.30000000000000004, 0.4, 0.5, 0.60... [[4.3201372225314945, 3.9353836030865286, 3.58... [[10.920182546008649, 11.229353479381396, 11.5... [[111.41612911461853, 111.36042105006122, 111.... 1.0 9 1.062928 0.265389 -1.0 267 11 [0.1, 0.2, 0.30000000000000004, 0.4, 0.5, 0.60... [[4.3201372225314945, 3.9353836030865286, 3.58... [[10.920182546008649, 11.229353479381396, 11.5... [[111.41612911461853, 111.36042105006122, 111.... 1.0 10 1.007366 0.110587 -1.0 286 12 [0.1, 0.2, 0.30000000000000004, 0.4, 0.5, 0.60... [[4.3201372225314945, 3.9353836030865286, 3.58... [[10.920182546008649, 11.229353479381396, 11.5... [[111.41612911461853, 111.36042105006122, 111.... 1.0 11 0.904612 0.123308 -1.0 320 14 [0.1, 0.2, 0.30000000000000004, 0.4, 0.5, 0.60... [[4.3201372225314945, 3.9353836030865286, 3.58... [[10.920182546008649, 11.229353479381396, 11.5... [[111.41612911461853, 111.36042105006122, 111.... 1.0 12 1.119281 0.188307 -1.0 330 15 [0.1, 0.2, 0.30000000000000004, 0.4, 0.5, 0.60... [[4.3201372225314945, 3.9353836030865286, 3.58... [[10.920182546008649, 11.229353479381396, 11.5... [[111.41612911461853, 111.36042105006122, 111.... 1.0 13 1.158463 0.227194 -1.0 342 15 [0.1, 0.2, 0.30000000000000004, 0.4, 0.5, 0.60... [[4.3201372225314945, 3.9353836030865286, 3.58... [[10.920182546008649, 11.229353479381396, 11.5... [[111.41612911461853, 111.36042105006122, 111.... 1.0 14 1.053327 0.281852 -1.0 344 15 [0.1, 0.2, 0.30000000000000004, 0.4, 0.5, 0.60... [[4.3201372225314945, 3.9353836030865286, 3.58... [[10.920182546008649, 11.229353479381396, 11.5... [[111.41612911461853, 111.36042105006122, 111.... 1.0 15 1.124747 0.318747 -1.0 360 16 [0.1, 0.2, 0.30000000000000004, 0.4, 0.5, 0.60... [[4.3201372225314945, 3.9353836030865286, 3.58... [[10.920182546008649, 11.229353479381396, 11.5... [[111.41612911461853, 111.36042105006122, 111.... 1.0 16 1.266317 0.360644 -1.0 364 16 [0.1, 0.2, 0.30000000000000004, 0.4, 0.5, 0.60... [[4.3201372225314945, 3.9353836030865286, 3.58... [[10.920182546008649, 11.229353479381396, 11.5... [[111.41612911461853, 111.36042105006122, 111.... 1.0 17 1.329988 0.388133 -1.0 365 16 [0.1, 0.2, 0.30000000000000004, 0.4, 0.5, 0.60... [[4.3201372225314945, 3.9353836030865286, 3.58... [[10.920182546008649, 11.229353479381396, 11.5... [[111.41612911461853, 111.36042105006122, 111.... 1.0 18 0.986030 0.189384 -1.0 390 18 [0.1, 0.2, 0.30000000000000004, 0.4, 0.5, 0.60... [[4.3201372225314945, 3.9353836030865286, 3.58... [[10.920182546008649, 11.229353479381396, 11.5... [[111.41612911461853, 111.36042105006122, 111.... 1.0 19 0.896915 0.125212 -1.0 399 18 [0.1, 0.2, 0.30000000000000004, 0.4, 0.5, 0.60... [[4.3201372225314945, 3.9353836030865286, 3.58... [[10.920182546008649, 11.229353479381396, 11.5... [[111.41612911461853, 111.36042105006122, 111.... 1.0 You can also view all individuals that were created during the entire evolution, by calling evolution.dfEvolution(): evolution . dfEvolution () .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } mue_ext_mean mui_ext_mean score id gen f0 0 1.400310 1.209331 -4.0 39 0 4.0 1 1.173593 0.662050 -5.0 31 0 5.0 2 1.134601 0.809371 -6.0 22 0 6.0 3 0.992049 0.694590 -6.0 29 0 6.0 4 1.470708 1.073607 -7.0 47 0 7.0 ... ... ... ... ... ... ... 395 1.881591 0.299691 -24.0 425 19 24.0 396 0.681422 0.489003 -8.0 426 19 8.0 397 1.430791 0.268028 -24.0 427 19 24.0 398 1.275903 0.534227 -3.0 428 19 3.0 399 0.870652 0.326687 -5.0 429 19 5.0 400 rows \u00d7 6 columns # a sinple overview of the current population (in this case the # last one) is given via the `info()` method. This provides a # a histogram of the score (= mean fitness) and scatterplots # and density estimates across orthogonal parameter space cross # sections. evolution . info ( plot = True ) > Simulation parameters HDF file storage: ./data/hdf/example-2.1.hdf Trajectory Name: results-2020-07-02-14H-20M-45S Duration of evaluating initial population 0:00:29.656935 Duration of evolution 0:03:50.565418 Model: <class 'neurolib.models.aln.model.ALNModel'> Model name: aln Eval function: <function evaluateSimulation at 0x10ba8cae8> Parameter space: {'mue_ext_mean': [0.0, 4.0], 'mui_ext_mean': [0.0, 4.0]} > Evolution parameters Number of generations: 20 Initial population size: 50 Population size: 20 > Evolutionary operators Mating operator: <function cxBlend at 0x11dcaf510> Mating paramter: {'alpha': 0.5} Selection operator: <function selBest_multiObj at 0x11f4d9d08> Selection paramter: {} Parent selection operator: <function selRank at 0x11f4d9c80> Comments: no comments --- Info summary --- Valid: 20 Mean score (weighted fitness): -0.85 Parameter distribution (Generation 19): mue_ext_mean: mean: 1.0852, std: 0.1270 mui_ext_mean: mean: 0.2200, std: 0.1042 -------------------- Best 5 individuals: Printing 5 individuals Individual 0 Fitness values: 0.0 Score: 0.0 Weighted fitness: -0.0 Stats mean 0.00 std 0.00 min 0.00 max 0.00 model.params[\"mue_ext_mean\"] = 1.18 model.params[\"mui_ext_mean\"] = 0.30 Individual 1 Fitness values: 0.0 Score: 0.0 Weighted fitness: -0.0 Stats mean 0.00 std 0.00 min 0.00 max 0.00 model.params[\"mue_ext_mean\"] = 1.11 model.params[\"mui_ext_mean\"] = 0.24 Individual 2 Fitness values: 0.0 Score: 0.0 Weighted fitness: -0.0 Stats mean 0.00 std 0.00 min 0.00 max 0.00 model.params[\"mue_ext_mean\"] = 0.91 model.params[\"mui_ext_mean\"] = 0.08 Individual 3 Fitness values: 1.0 Score: -1.0 Weighted fitness: -1.0 Stats mean 1.00 std 0.00 min 1.00 max 1.00 model.params[\"mue_ext_mean\"] = 1.19 model.params[\"mui_ext_mean\"] = 0.36 Individual 4 Fitness values: 1.0 Score: -1.0 Weighted fitness: -1.0 Stats mean 1.00 std 0.00 min 1.00 max 1.00 model.params[\"mue_ext_mean\"] = 1.01 model.params[\"mui_ext_mean\"] = 0.11 -------------------- MainProcess root INFO Saving plot to ./data/figures/results-2020-07-02-14H-20M-45S_hist_19.png There are 20 valid individuals Mean score across population: -0.85 <Figure size 432x288 with 0 Axes>","title":"Population"},{"location":"examples/example-2.1-evolutionary-optimization-aln/#plotting-genealogy-tree","text":"neurolib keeps track of all individuals during the evolution. You can see all individuals from each generation by calling evolution.history . The object evolution.tree provides a network description of the genealogy of the evolution: each individual (indexed by its unique .id ) is connected to its parents. We can use this object in combination with the network library networkx to plot the tree: # we put this into a try except block since we don't do testing on networkx try : import matplotlib.pyplot as plt import networkx as nx from networkx.drawing.nx_pydot import graphviz_layout G = nx . DiGraph ( evolution . tree ) G = G . reverse () # Make the graph top-down pos = graphviz_layout ( G , prog = 'dot' ) plt . figure ( figsize = ( 8 , 8 )) nx . draw ( G , pos , node_size = 50 , alpha = 0.5 , node_color = list ( evolution . id_score . values ()), with_labels = False ) plt . show () except : print ( \"It looks like networkx or pydot are not installed\" ) /Users/caglar/anaconda/lib/python3.7/site-packages/networkx/drawing/nx_pylab.py:579: MatplotlibDeprecationWarning: The iterable function was deprecated in Matplotlib 3.1 and will be removed in 3.3. Use np.iterable instead. if not cb.iterable(width): /Users/caglar/anaconda/lib/python3.7/site-packages/networkx/drawing/nx_pylab.py:676: MatplotlibDeprecationWarning: The iterable function was deprecated in Matplotlib 3.1 and will be removed in 3.3. Use np.iterable instead. if cb.iterable(node_size): # many node sizes","title":"Plotting genealogy tree"},{"location":"examples/example-2.2-evolution-brain-network-aln-resting-state-fit/","text":"(function() { function addWidgetsRenderer() { var requireJsScript = document.createElement('script'); requireJsScript.src = 'https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js'; var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var jupyterWidgetsScript = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} jupyterWidgetsScript.src = widgetRendererSrc; document.body.appendChild(requireJsScript); document.body.appendChild(jupyterWidgetsScript); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); Evolutionary optimization of a whole-brain model This notebook provides an example for the use of the evolutionary optimization framework built-in to the library. Under the hood, the implementation of the evolutionary algorithm is powered by deap and pypet cares about the parallelization and storage of the simulation data for us. We want to optimize a whole-brain network that should produce simulated BOLD activity (fMRI data) that is similar to the empirical dataset. We measure the fitness of each simulation by computing the func.matrix_correlation of the functional connectivity func.fc(model.BOLD.BOLD) to the empirical data ds.FCs . The ones that are closest to the empirical data get a higher fitness and have a higher chance of reproducing and survival. # change to the root directory of the project import os if os . getcwd () . split ( \"/\" )[ - 1 ] == \"examples\" : os . chdir ( '..' ) # This will reload all imports as soon as the code changes % load_ext autoreload % autoreload 2 try : import matplotlib.pyplot as plt except ImportError : import sys ! { sys . executable } - m pip install matplotlib seaborn import matplotlib.pyplot as plt import numpy as np import logging from neurolib.models.aln import ALNModel from neurolib.utils.parameterSpace import ParameterSpace from neurolib.optimize.evolution import Evolution import neurolib.utils.functions as func from neurolib.utils.loadData import Dataset ds = Dataset ( \"hcp\" ) # a nice color map plt . rcParams [ 'image.cmap' ] = 'plasma' We create a brain network model using the empirical dataset ds : model = ALNModel ( Cmat = ds . Cmat , Dmat = ds . Dmat ) # simulates the whole-brain model in 10s chunks by default if bold == True # Resting state fits model . params [ 'mue_ext_mean' ] = 1.57 model . params [ 'mui_ext_mean' ] = 1.6 model . params [ 'sigma_ou' ] = 0.09 model . params [ 'b' ] = 5.0 model . params [ 'signalV' ] = 2 model . params [ 'dt' ] = 0.2 model . params [ 'duration' ] = 0.2 * 60 * 1000 #ms # testing: aln.params['duration'] = 0.2 * 60 * 1000 #ms # real: aln.params['duration'] = 1.0 * 60 * 1000 #ms Our evaluation function will do the following: first it will simulate the model for a short time to see whether there is any sufficient activity. This speeds up the evolution considerably, since large regions of the state space show almost no neuronal activity. Only then do we simulate the model for the full duration and compute the fitness using the empirical dataset. def evaluateSimulation ( traj ): rid = traj . id model = evolution . getModelFromTraj ( traj ) defaultDuration = model . params [ 'duration' ] invalid_result = ( np . nan ,) * len ( ds . BOLDs ) # -------- stage wise simulation -------- # Stage 1 : simulate for a few seconds to see if there is any activity # --------------------------------------- model . params [ 'duration' ] = 3 * 1000. model . run () # check if stage 1 was successful if np . max ( model . output [:, model . t > 500 ]) > 160 or np . max ( model . output [:, model . t > 500 ]) < 10 : return invalid_result , {} # Stage 2: full and final simulation # --------------------------------------- model . params [ 'duration' ] = defaultDuration model . run ( chunkwise = True , bold = True ) # -------- fitness evaluation here -------- scores = [] for i , fc in enumerate ( ds . FCs ): #range(len(ds.FCs)): fc_score = func . matrix_correlation ( func . fc ( model . BOLD . BOLD [:, 5 :]), fc ) scores . append ( fc_score ) meanFitness = np . mean ( scores ) fitness_tuple = ( meanFitness ,) #print(f\"fitness {meanFitness}\") #print(f\"scores {scores}\") fitness_tuple = tuple ( scores ) return fitness_tuple , {} We specify the parameter space that we want to search. pars = ParameterSpace ([ 'mue_ext_mean' , 'mui_ext_mean' , 'b' , 'sigma_ou' , 'Ke_gl' , 'signalV' ], [[ 0.0 , 3.0 ], [ 0.0 , 3.0 ], [ 0.0 , 100.0 ], [ 0.0 , 0.3 ], [ 0.0 , 500.0 ], [ 0.0 , 400.0 ]]) Note that we chose algorithm='nsga2' when we create the Evolution . This will use the multi-objective optimization algorithm by Deb et al. 2002. Although we have only one objective here (namely the FC fit), we could in principle add more objectives, like the FCD matrix fit or other objectives. For this, we would have to add these values to the fitness in the evaluation function above and add more weights in the definition of the Evolution . We can use positive weights for that objective to be maximized and negative ones for minimization. Please refer to the DEAP documentation for more information. evolution = Evolution ( evaluateSimulation , pars , algorithm = 'nsga2' , weightList = [ 1.0 ] * len ( ds . BOLDs ), model = model , POP_INIT_SIZE = 4 , POP_SIZE = 4 , NGEN = 2 , filename = \"example-2.2.hdf\" ) #testing: evolution = Evolution(evaluateSimulation, pars, algorithm = 'nsga2', weightList = [1.0] * len(ds.BOLDs), model = model, POP_INIT_SIZE=4, POP_SIZE = 4, NGEN=2) # real: evolution = Evolution(evaluateSimulation, pars, algorithm = 'nsga2', weightList = [1.0] * len(ds.BOLDs), model = model, POP_INIT_SIZE=1600, POP_SIZE = 160, NGEN=100) That's it, we can run the evolution now. evolution . run ( verbose = False ) We could now save the full evolution object for later analysis using evolution.saveEvolution() . Analysis The info() method gives us a useful overview of the evolution, like a summary of the evolution parameters, the statistics of the population and also scatterplots of the individuals in our search space. evolution . info () --- Info summary --- Valid: 160 Mean score (weighted fitness): 0.53 Parameters dictribution (Generation 99): mue_ext_mean: mean: 0.147, std: 0.02449 mui_ext_mean: mean: 0.1343, std: 0.05387 b: mean: 93.05, std: 5.84 sigma_ou: mean: 0.05296, std: 0.01099 Ke_gl: mean: 233.1, std: 20.57 signalV: mean: 344.3, std: 68.9 -------------------- Best 5 individuals: Printing 5 individuals Individual 0 pars mue_ext_mean 0.1557, mui_ext_mean 0.08049, b 96.18, sigma_ou 0.05687, Ke_gl 222.8, signalV 354.9 Fitness values: 0.5426 0.4137 0.6459 0.5287 0.552 0.7209 0.5181 0.4997 0.42 0.4226 0.4279 0.5029 0.652 0.5667 0.5394 0.5894 0.472 0.6361 0.5217 0.5899 0.6456 0.5204 0.637 0.7114 Individual 1 pars mue_ext_mean 0.172, mui_ext_mean 0.1519, b 83.8, sigma_ou 0.06809, Ke_gl 219.2, signalV 308.3 Fitness values: 0.5798 0.4495 0.6525 0.4953 0.5876 0.7077 0.5263 0.5381 0.4222 0.4486 0.4347 0.5051 0.6232 0.5411 0.5383 0.5532 0.4716 0.6162 0.5442 0.5476 0.6644 0.5176 0.5826 0.6867 Individual 2 pars mue_ext_mean 0.09511, mui_ext_mean 0.1325, b 84.53, sigma_ou 0.04644, Ke_gl 206.9, signalV 382.1 Fitness values: 0.5212 0.4309 0.6206 0.5142 0.551 0.6844 0.5321 0.4911 0.4151 0.4368 0.4358 0.4803 0.6534 0.535 0.5388 0.5712 0.4784 0.659 0.5016 0.5962 0.6281 0.5063 0.6328 0.7097 Individual 3 pars mue_ext_mean 0.1333, mui_ext_mean 0.1794, b 92.41, sigma_ou 0.04781, Ke_gl 247.8, signalV 374.4 Fitness values: 0.5359 0.4445 0.622 0.4913 0.5438 0.717 0.5579 0.4572 0.3963 0.4511 0.4247 0.4688 0.6558 0.5271 0.5403 0.5763 0.4736 0.6079 0.4863 0.6064 0.6628 0.5144 0.6055 0.6958 Individual 4 pars mue_ext_mean 0.2655, mui_ext_mean 0.2683, b 88.81, sigma_ou 0.04314, Ke_gl 231.0, signalV 371.8 Fitness values: 0.5668 0.4402 0.6421 0.5091 0.5613 0.6858 0.4896 0.516 0.4525 0.437 0.4513 0.5346 0.5927 0.5819 0.5021 0.5367 0.4718 0.6038 0.563 0.5354 0.5889 0.5078 0.5844 0.7061 -------------------- There are 160 valid individuals Mean score across population: 0.53 <Figure size 432x288 with 0 Axes> # This will load results from disk in case the session is # started newly and the trajectory is not in memory traj = evolution . loadResults () gens , all_scores = evolution . getScoresDuringEvolution ( reverse = True ) plt . figure ( figsize = ( 8 , 4 ), dpi = 200 ) plt . plot ( gens , np . nanmean ( all_scores , axis = 1 )) plt . fill_between ( gens , np . nanmin ( all_scores , axis = 1 ), np . nanmax ( all_scores , axis = 1 ), alpha = 0.3 ) plt . xlabel ( \"Generation #\" ) plt . ylabel ( \"Score\" ) Text(0, 0.5, 'Score')","title":"Example 2.2 evolution brain network aln resting state fit"},{"location":"examples/example-2.2-evolution-brain-network-aln-resting-state-fit/#evolutionary-optimization-of-a-whole-brain-model","text":"This notebook provides an example for the use of the evolutionary optimization framework built-in to the library. Under the hood, the implementation of the evolutionary algorithm is powered by deap and pypet cares about the parallelization and storage of the simulation data for us. We want to optimize a whole-brain network that should produce simulated BOLD activity (fMRI data) that is similar to the empirical dataset. We measure the fitness of each simulation by computing the func.matrix_correlation of the functional connectivity func.fc(model.BOLD.BOLD) to the empirical data ds.FCs . The ones that are closest to the empirical data get a higher fitness and have a higher chance of reproducing and survival. # change to the root directory of the project import os if os . getcwd () . split ( \"/\" )[ - 1 ] == \"examples\" : os . chdir ( '..' ) # This will reload all imports as soon as the code changes % load_ext autoreload % autoreload 2 try : import matplotlib.pyplot as plt except ImportError : import sys ! { sys . executable } - m pip install matplotlib seaborn import matplotlib.pyplot as plt import numpy as np import logging from neurolib.models.aln import ALNModel from neurolib.utils.parameterSpace import ParameterSpace from neurolib.optimize.evolution import Evolution import neurolib.utils.functions as func from neurolib.utils.loadData import Dataset ds = Dataset ( \"hcp\" ) # a nice color map plt . rcParams [ 'image.cmap' ] = 'plasma' We create a brain network model using the empirical dataset ds : model = ALNModel ( Cmat = ds . Cmat , Dmat = ds . Dmat ) # simulates the whole-brain model in 10s chunks by default if bold == True # Resting state fits model . params [ 'mue_ext_mean' ] = 1.57 model . params [ 'mui_ext_mean' ] = 1.6 model . params [ 'sigma_ou' ] = 0.09 model . params [ 'b' ] = 5.0 model . params [ 'signalV' ] = 2 model . params [ 'dt' ] = 0.2 model . params [ 'duration' ] = 0.2 * 60 * 1000 #ms # testing: aln.params['duration'] = 0.2 * 60 * 1000 #ms # real: aln.params['duration'] = 1.0 * 60 * 1000 #ms Our evaluation function will do the following: first it will simulate the model for a short time to see whether there is any sufficient activity. This speeds up the evolution considerably, since large regions of the state space show almost no neuronal activity. Only then do we simulate the model for the full duration and compute the fitness using the empirical dataset. def evaluateSimulation ( traj ): rid = traj . id model = evolution . getModelFromTraj ( traj ) defaultDuration = model . params [ 'duration' ] invalid_result = ( np . nan ,) * len ( ds . BOLDs ) # -------- stage wise simulation -------- # Stage 1 : simulate for a few seconds to see if there is any activity # --------------------------------------- model . params [ 'duration' ] = 3 * 1000. model . run () # check if stage 1 was successful if np . max ( model . output [:, model . t > 500 ]) > 160 or np . max ( model . output [:, model . t > 500 ]) < 10 : return invalid_result , {} # Stage 2: full and final simulation # --------------------------------------- model . params [ 'duration' ] = defaultDuration model . run ( chunkwise = True , bold = True ) # -------- fitness evaluation here -------- scores = [] for i , fc in enumerate ( ds . FCs ): #range(len(ds.FCs)): fc_score = func . matrix_correlation ( func . fc ( model . BOLD . BOLD [:, 5 :]), fc ) scores . append ( fc_score ) meanFitness = np . mean ( scores ) fitness_tuple = ( meanFitness ,) #print(f\"fitness {meanFitness}\") #print(f\"scores {scores}\") fitness_tuple = tuple ( scores ) return fitness_tuple , {} We specify the parameter space that we want to search. pars = ParameterSpace ([ 'mue_ext_mean' , 'mui_ext_mean' , 'b' , 'sigma_ou' , 'Ke_gl' , 'signalV' ], [[ 0.0 , 3.0 ], [ 0.0 , 3.0 ], [ 0.0 , 100.0 ], [ 0.0 , 0.3 ], [ 0.0 , 500.0 ], [ 0.0 , 400.0 ]]) Note that we chose algorithm='nsga2' when we create the Evolution . This will use the multi-objective optimization algorithm by Deb et al. 2002. Although we have only one objective here (namely the FC fit), we could in principle add more objectives, like the FCD matrix fit or other objectives. For this, we would have to add these values to the fitness in the evaluation function above and add more weights in the definition of the Evolution . We can use positive weights for that objective to be maximized and negative ones for minimization. Please refer to the DEAP documentation for more information. evolution = Evolution ( evaluateSimulation , pars , algorithm = 'nsga2' , weightList = [ 1.0 ] * len ( ds . BOLDs ), model = model , POP_INIT_SIZE = 4 , POP_SIZE = 4 , NGEN = 2 , filename = \"example-2.2.hdf\" ) #testing: evolution = Evolution(evaluateSimulation, pars, algorithm = 'nsga2', weightList = [1.0] * len(ds.BOLDs), model = model, POP_INIT_SIZE=4, POP_SIZE = 4, NGEN=2) # real: evolution = Evolution(evaluateSimulation, pars, algorithm = 'nsga2', weightList = [1.0] * len(ds.BOLDs), model = model, POP_INIT_SIZE=1600, POP_SIZE = 160, NGEN=100) That's it, we can run the evolution now. evolution . run ( verbose = False ) We could now save the full evolution object for later analysis using evolution.saveEvolution() .","title":"Evolutionary optimization of a whole-brain model"},{"location":"examples/example-2.2-evolution-brain-network-aln-resting-state-fit/#analysis","text":"The info() method gives us a useful overview of the evolution, like a summary of the evolution parameters, the statistics of the population and also scatterplots of the individuals in our search space. evolution . info () --- Info summary --- Valid: 160 Mean score (weighted fitness): 0.53 Parameters dictribution (Generation 99): mue_ext_mean: mean: 0.147, std: 0.02449 mui_ext_mean: mean: 0.1343, std: 0.05387 b: mean: 93.05, std: 5.84 sigma_ou: mean: 0.05296, std: 0.01099 Ke_gl: mean: 233.1, std: 20.57 signalV: mean: 344.3, std: 68.9 -------------------- Best 5 individuals: Printing 5 individuals Individual 0 pars mue_ext_mean 0.1557, mui_ext_mean 0.08049, b 96.18, sigma_ou 0.05687, Ke_gl 222.8, signalV 354.9 Fitness values: 0.5426 0.4137 0.6459 0.5287 0.552 0.7209 0.5181 0.4997 0.42 0.4226 0.4279 0.5029 0.652 0.5667 0.5394 0.5894 0.472 0.6361 0.5217 0.5899 0.6456 0.5204 0.637 0.7114 Individual 1 pars mue_ext_mean 0.172, mui_ext_mean 0.1519, b 83.8, sigma_ou 0.06809, Ke_gl 219.2, signalV 308.3 Fitness values: 0.5798 0.4495 0.6525 0.4953 0.5876 0.7077 0.5263 0.5381 0.4222 0.4486 0.4347 0.5051 0.6232 0.5411 0.5383 0.5532 0.4716 0.6162 0.5442 0.5476 0.6644 0.5176 0.5826 0.6867 Individual 2 pars mue_ext_mean 0.09511, mui_ext_mean 0.1325, b 84.53, sigma_ou 0.04644, Ke_gl 206.9, signalV 382.1 Fitness values: 0.5212 0.4309 0.6206 0.5142 0.551 0.6844 0.5321 0.4911 0.4151 0.4368 0.4358 0.4803 0.6534 0.535 0.5388 0.5712 0.4784 0.659 0.5016 0.5962 0.6281 0.5063 0.6328 0.7097 Individual 3 pars mue_ext_mean 0.1333, mui_ext_mean 0.1794, b 92.41, sigma_ou 0.04781, Ke_gl 247.8, signalV 374.4 Fitness values: 0.5359 0.4445 0.622 0.4913 0.5438 0.717 0.5579 0.4572 0.3963 0.4511 0.4247 0.4688 0.6558 0.5271 0.5403 0.5763 0.4736 0.6079 0.4863 0.6064 0.6628 0.5144 0.6055 0.6958 Individual 4 pars mue_ext_mean 0.2655, mui_ext_mean 0.2683, b 88.81, sigma_ou 0.04314, Ke_gl 231.0, signalV 371.8 Fitness values: 0.5668 0.4402 0.6421 0.5091 0.5613 0.6858 0.4896 0.516 0.4525 0.437 0.4513 0.5346 0.5927 0.5819 0.5021 0.5367 0.4718 0.6038 0.563 0.5354 0.5889 0.5078 0.5844 0.7061 -------------------- There are 160 valid individuals Mean score across population: 0.53 <Figure size 432x288 with 0 Axes> # This will load results from disk in case the session is # started newly and the trajectory is not in memory traj = evolution . loadResults () gens , all_scores = evolution . getScoresDuringEvolution ( reverse = True ) plt . figure ( figsize = ( 8 , 4 ), dpi = 200 ) plt . plot ( gens , np . nanmean ( all_scores , axis = 1 )) plt . fill_between ( gens , np . nanmin ( all_scores , axis = 1 ), np . nanmax ( all_scores , axis = 1 ), alpha = 0.3 ) plt . xlabel ( \"Generation #\" ) plt . ylabel ( \"Score\" ) Text(0, 0.5, 'Score')","title":"Analysis"},{"location":"examples/example-3-meg-functional-connectivity/","text":"(function() { function addWidgetsRenderer() { var requireJsScript = document.createElement('script'); requireJsScript.src = 'https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js'; var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var jupyterWidgetsScript = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} jupyterWidgetsScript.src = widgetRendererSrc; document.body.appendChild(requireJsScript); document.body.appendChild(jupyterWidgetsScript); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); Modeling resting-state MEG-Data In this example we will learn how to use neurolib to simulate resting state functional connectivity of MEG recordings. In the first part of the notebook, we will compute the frequency specific functional connectivity matrix of an examplary resting state MEG recording from the YouR-Study Uhlhaas, P.J., Gajwani, R., Gross, J. et al. The Youth Mental Health Risk and Resilience Study (YouR-Study). BMC Psychiatry 17, 43 (2017) . To this end we will: Band-Pass filter the signal Apply the hilbert -transformation to extract the signal envelope Orthogonalize the signal envelopes of two examplary regions Low-Pass filter the signal envelopes and compute the pairwise envelope correlations which yields the functional connectivity matrix. We follow the approach presented in Hipp, J., Hawellek, D., Corbetta, M. et al. , Large-scale cortical correlation structure of spontaneous oscillatory activity. Nat Neurosci 15, 884\u2013890 (2012) In the second part of this notebook, we will use a whole-brain model to simulate brain activity and compute functional connectivity matrix of the simulated signal envelope, as was done for the empirical MEG data. The parameters of this model have been previously optimized with neurolib 's evolutionary algorithms (not shown here). Finally, we will compute the fit (Pearson correlation) of the simulated functional connectivity to the empirical MEG data, which was used as a fitting objective in a previous optimization procedure. # change to the root directory of the project import os if os . getcwd () . split ( \"/\" )[ - 1 ] == \"examples\" : os . chdir ( '..' ) # This will reload all imports as soon as the code changes % load_ext autoreload % autoreload 2 import os import numpy as np import xarray as xr import matplotlib.pyplot as plt import seaborn as sns import ipywidgets as widgets from IPython.utils import io import warnings warnings . simplefilter ( action = 'ignore' , category = FutureWarning ) import time import pandas as pd /Users/caglar/anaconda/lib/python3.7/site-packages/pandas/compat/_optional.py:138: UserWarning: Pandas requires version '2.7.0' or newer of 'numexpr' (version '2.6.9' currently installed). warnings.warn(msg, UserWarning) Empirical Functional Connectivity Load MEG-Data First off, let's load the MEG data using the Signal class from neurolib . Our example data has already been preprocessed and projected into source space using the AAL2 atlas. from neurolib.utils.signal import Signal signal = Signal . from_file ( os . path . join ( 'examples' , 'data' , 'rs-meg.nc' )) region_labels = signal . data . regions . values nr_regions = len ( region_labels ) display ( signal . data ) /* CSS stylesheet for displaying xarray objects in jupyterlab. * */ :root { --xr-font-color0: var(--jp-content-font-color0, rgba(0, 0, 0, 1)); --xr-font-color2: var(--jp-content-font-color2, rgba(0, 0, 0, 0.54)); --xr-font-color3: var(--jp-content-font-color3, rgba(0, 0, 0, 0.38)); --xr-border-color: var(--jp-border-color2, #e0e0e0); --xr-disabled-color: var(--jp-layout-color3, #bdbdbd); --xr-background-color: var(--jp-layout-color0, white); --xr-background-color-row-even: var(--jp-layout-color1, white); --xr-background-color-row-odd: var(--jp-layout-color2, #eeeeee); } html[theme=dark], body.vscode-dark { --xr-font-color0: rgba(255, 255, 255, 1); --xr-font-color2: rgba(255, 255, 255, 0.54); --xr-font-color3: rgba(255, 255, 255, 0.38); --xr-border-color: #1F1F1F; --xr-disabled-color: #515151; --xr-background-color: #111111; --xr-background-color-row-even: #111111; --xr-background-color-row-odd: #313131; } .xr-wrap { display: block; min-width: 300px; max-width: 700px; } .xr-text-repr-fallback { /* fallback to plain text repr when CSS is not injected (untrusted notebook) */ display: none; } .xr-header { padding-top: 6px; padding-bottom: 6px; margin-bottom: 4px; border-bottom: solid 1px var(--xr-border-color); } .xr-header > div, .xr-header > ul { display: inline; margin-top: 0; margin-bottom: 0; } .xr-obj-type, .xr-array-name { margin-left: 2px; margin-right: 10px; } .xr-obj-type { color: var(--xr-font-color2); } .xr-sections { padding-left: 0 !important; display: grid; grid-template-columns: 150px auto auto 1fr 20px 20px; } .xr-section-item { display: contents; } .xr-section-item input { display: none; } .xr-section-item input + label { color: var(--xr-disabled-color); } .xr-section-item input:enabled + label { cursor: pointer; color: var(--xr-font-color2); } .xr-section-item input:enabled + label:hover { color: var(--xr-font-color0); } .xr-section-summary { grid-column: 1; color: var(--xr-font-color2); font-weight: 500; } .xr-section-summary > span { display: inline-block; padding-left: 0.5em; } .xr-section-summary-in:disabled + label { color: var(--xr-font-color2); } .xr-section-summary-in + label:before { display: inline-block; content: '\u25ba'; font-size: 11px; width: 15px; text-align: center; } .xr-section-summary-in:disabled + label:before { color: var(--xr-disabled-color); } .xr-section-summary-in:checked + label:before { content: '\u25bc'; } .xr-section-summary-in:checked + label > span { display: none; } .xr-section-summary, .xr-section-inline-details { padding-top: 4px; padding-bottom: 4px; } .xr-section-inline-details { grid-column: 2 / -1; } .xr-section-details { display: none; grid-column: 1 / -1; margin-bottom: 5px; } .xr-section-summary-in:checked ~ .xr-section-details { display: contents; } .xr-array-wrap { grid-column: 1 / -1; display: grid; grid-template-columns: 20px auto; } .xr-array-wrap > label { grid-column: 1; vertical-align: top; } .xr-preview { color: var(--xr-font-color3); } .xr-array-preview, .xr-array-data { padding: 0 5px !important; grid-column: 2; } .xr-array-data, .xr-array-in:checked ~ .xr-array-preview { display: none; } .xr-array-in:checked ~ .xr-array-data, .xr-array-preview { display: inline-block; } .xr-dim-list { display: inline-block !important; list-style: none; padding: 0 !important; margin: 0; } .xr-dim-list li { display: inline-block; padding: 0; margin: 0; } .xr-dim-list:before { content: '('; } .xr-dim-list:after { content: ')'; } .xr-dim-list li:not(:last-child):after { content: ','; padding-right: 5px; } .xr-has-index { font-weight: bold; } .xr-var-list, .xr-var-item { display: contents; } .xr-var-item > div, .xr-var-item label, .xr-var-item > .xr-var-name span { background-color: var(--xr-background-color-row-even); margin-bottom: 0; } .xr-var-item > .xr-var-name:hover span { padding-right: 5px; } .xr-var-list > li:nth-child(odd) > div, .xr-var-list > li:nth-child(odd) > label, .xr-var-list > li:nth-child(odd) > .xr-var-name span { background-color: var(--xr-background-color-row-odd); } .xr-var-name { grid-column: 1; } .xr-var-dims { grid-column: 2; } .xr-var-dtype { grid-column: 3; text-align: right; color: var(--xr-font-color2); } .xr-var-preview { grid-column: 4; } .xr-var-name, .xr-var-dims, .xr-var-dtype, .xr-preview, .xr-attrs dt { white-space: nowrap; overflow: hidden; text-overflow: ellipsis; padding-right: 10px; } .xr-var-name:hover, .xr-var-dims:hover, .xr-var-dtype:hover, .xr-attrs dt:hover { overflow: visible; width: auto; z-index: 1; } .xr-var-attrs, .xr-var-data { display: none; background-color: var(--xr-background-color) !important; padding-bottom: 5px !important; } .xr-var-attrs-in:checked ~ .xr-var-attrs, .xr-var-data-in:checked ~ .xr-var-data { display: block; } .xr-var-data > table { float: right; } .xr-var-name span, .xr-var-data, .xr-attrs { padding-left: 25px !important; } .xr-attrs, .xr-var-attrs, .xr-var-data { grid-column: 1 / -1; } dl.xr-attrs { padding: 0; margin: 0; display: grid; grid-template-columns: 125px auto; } .xr-attrs dt, .xr-attrs dd { padding: 0; margin: 0; float: left; padding-right: 10px; width: auto; } .xr-attrs dt { font-weight: normal; grid-column: 1; } .xr-attrs dt:hover span { display: inline-block; background: var(--xr-background-color); padding-right: 10px; } .xr-attrs dd { grid-column: 2; white-space: pre-wrap; word-break: break-all; } .xr-icon-database, .xr-icon-file-text2 { display: inline-block; vertical-align: middle; width: 1em; height: 1.5em !important; stroke-width: 0; stroke: currentColor; fill: currentColor; } <xarray.DataArray (regions: 94, time: 6000)> array([[-0.17628077, -0.33449804, -0.27283166, ..., 0.20004052, 0.19379806, 0.0271034 ], [ 0.00513031, 0.0319704 , 0.18478207, ..., 0.22112991, 0.30244658, 0.21108818], [ 0.01999333, -0.1601617 , -0.21931987, ..., 0.01844522, -0.03713842, 0.08175757], ..., [-0.2381615 , -0.34838511, -0.50638238, ..., -0.08763395, -0.05396606, -0.06218967], [-0.09900261, -0.1525903 , -0.16444704, ..., 0.04080438, 0.01664182, 0.15847579], [ 0.13203698, 0.17482835, 0.21212731, ..., -0.19971229, -0.01869223, -0.16379495]]) Coordinates: * time (time) float64 0.0 0.01 0.02 0.03 0.04 ... 59.96 59.97 59.98 59.99 * regions (regions) object 'PreCG.L' 'PreCG.R' 'SFG.L' ... 'ITG.L' 'ITG.R' Attributes: name: rest meg label: signal_type: unit: T description: MEG recording in AAL2 space process_steps_0: resample to 100.0Hz xarray.DataArray regions : 94 time : 6000 -0.1763 -0.3345 -0.2728 -0.1313 ... -0.2128 -0.1997 -0.01869 -0.1638 array([[-0.17628077, -0.33449804, -0.27283166, ..., 0.20004052, 0.19379806, 0.0271034 ], [ 0.00513031, 0.0319704 , 0.18478207, ..., 0.22112991, 0.30244658, 0.21108818], [ 0.01999333, -0.1601617 , -0.21931987, ..., 0.01844522, -0.03713842, 0.08175757], ..., [-0.2381615 , -0.34838511, -0.50638238, ..., -0.08763395, -0.05396606, -0.06218967], [-0.09900261, -0.1525903 , -0.16444704, ..., 0.04080438, 0.01664182, 0.15847579], [ 0.13203698, 0.17482835, 0.21212731, ..., -0.19971229, -0.01869223, -0.16379495]]) Coordinates: (2) time (time) float64 0.0 0.01 0.02 ... 59.97 59.98 59.99 array([0.000e+00, 1.000e-02, 2.000e-02, ..., 5.997e+01, 5.998e+01, 5.999e+01]) regions (regions) object 'PreCG.L' 'PreCG.R' ... 'ITG.R' array(['PreCG.L', 'PreCG.R', 'SFG.L', 'SFG.R', 'MFG.L', 'MFG.R', 'IFGoperc.L', 'IFGoperc.R', 'IFGtriang.L', 'IFGtriang.R', 'IFGorb.L', 'IFGorb.R', 'ROL.L', 'ROL.R', 'SMA.L', 'SMA.R', 'OLF.L', 'OLF.R', 'SFGmed.L', 'SFGmed.R', 'PFCventmed.L', 'PFCventmed.R', 'REC.L', 'REC.R', 'OFCmed.L', 'OFCmed.R', 'OFCant.L', 'OFCant.R', 'OFCpos.L', 'OFCpos.R', 'OFClat.L', 'OFClat.R', 'INS.L', 'INS.R', 'ACC.L', 'ACC.R', 'MCC.L', 'MCC.R', 'PCC.L', 'PCC.R', 'HIP.L', 'HIP.R', 'PHG.L', 'PHG.R', 'AMYG.L', 'AMYG.R', 'CAL.L', 'CAL.R', 'CUN.L', 'CUN.R', 'LING.L', 'LING.R', 'SOG.L', 'SOG.R', 'MOG.L', 'MOG.R', 'IOG.L', 'IOG.R', 'FFG.L', 'FFG.R', 'PoCG.L', 'PoCG.R', 'SPG.L', 'SPG.R', 'IPG.L', 'IPG.R', 'SMG.L', 'SMG.R', 'ANG.L', 'ANG.R', 'PCUN.L', 'PCUN.R', 'PCL.L', 'PCL.R', 'CAU.L', 'CAU.R', 'PUT.L', 'PUT.R', 'PAL.L', 'PAL.R', 'THA.L', 'THA.R', 'HES.L', 'HES.R', 'STG.L', 'STG.R', 'TPOsup.L', 'TPOsup.R', 'MTG.L', 'MTG.R', 'TPOmid.L', 'TPOmid.R', 'ITG.L', 'ITG.R'], dtype=object) Attributes: (6) name : rest meg label : signal_type : unit : T description : MEG recording in AAL2 space process_steps_0 : resample to 100.0Hz Band-Pass filter and Hilbert transform We will now filter the signal into the desidered frequency band and apply the hilbert transform on the band-passed filtered signal. This will provide us with the analytic representation of the signal, which we can then use to extract the signal's envelope and its phase. In the following, we plot each processing step for an example target region that you can chose using the widgets below (default: left Precentral Gyrus) . Furthermore, we can also choose the frequency range that we'd like to filter the signal in (default: alpha (8-12Hz)) . print ( 'Select a region from the AAL2 atlas and a frequency range' ) # Select a Region target = widgets . Select ( options = region_labels , value = 'PreCG.L' , description = 'Regions' , tooltips = [ 'Description of slow' , 'Description of regular' , 'Description of fast' ], layout = widgets . Layout ( width = '50%' , height = '150px' )) display ( target ) # Select Frequency Range freq = widgets . IntRangeSlider ( min = 1 , max = 46 , description = 'Frequency (Hz)' , value = [ 8 , 12 ], layout = widgets . Layout ( width = '80%' ), style = { 'description_width' : 'initial' }) display ( freq ) Select a region from the AAL2 atlas and a frequency range Select(description='Regions', layout=Layout(height='150px', width='50%'), options=('PreCG.L', 'PreCG.R', 'SFG.\u2026 IntRangeSlider(value=(8, 12), description='Frequency (Hz)', layout=Layout(width='80%'), max=46, min=1, style=S\u2026 # Define how many timepoints you'd like to plot plot_timepoints = 1000 # Plot unfiltered Signal fig , ax = plt . subplots ( 2 , 1 , figsize = ( 12 , 8 ), sharex = True ) sns . lineplot ( x = signal . data . time [: plot_timepoints ] . values , y = signal . data . sel ( regions = target . value )[: plot_timepoints ] . values , ax = ax [ 0 ], color = 'k' , alpha = 0.6 ) ax [ 0 ] . set_title ( f 'Unfiltered Signal ( { target . value } )' ); # Band Pass Filter the Signal signal . filter ( freq . value [ 0 ], freq . value [ 1 ], inplace = True ); # Apply hilbert-transform to extract the signal envelope complex_signal = signal . hilbert_transform ( 'complex' , inplace = False ) signal_env = np . abs ( complex_signal . data ) # Plot filtered Signal and Signal Envelope sns . lineplot ( x = signal . data . time [: plot_timepoints ] . values , y = signal . data . sel ( regions = target . value )[: plot_timepoints ] . values , ax = ax [ 1 ], label = 'Bandpass-Filtered Signal' ) sns . lineplot ( x = signal_env . time [: plot_timepoints ] . values , y = signal_env . sel ( regions = target . value )[: plot_timepoints ] . values , ax = ax [ 1 ], label = 'Signal Envelope' ) ax [ 1 ] . set_title ( f 'Filtered Signal ( { target . value } )' ); ax [ 1 ] . legend ( bbox_to_anchor = ( 1.2 , 1 ), borderaxespad = 0 ) sns . despine ( trim = True ) Setting up band-pass filter from 8 - 12 Hz FIR filter parameters --------------------- Designing a one-pass, zero-phase, non-causal bandpass filter: - Windowed time-domain design (firwin) method - Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation - Lower passband edge: 8.00 - Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 7.00 Hz) - Upper passband edge: 12.00 Hz - Upper transition bandwidth: 3.00 Hz (-6 dB cutoff frequency: 13.50 Hz) - Filter length: 165 samples (1.650 sec) Orthogonalized signal envelope Now we are going to address the main methodological issue of MEG when it comes to the analysis of the cortical functional connectivity structure, i.e. its low spatial resolution. The electric field generated by any given neural source spreads widely over the cortex so that the signal captured at the MEG sensors is a complex mixture of signals from multiple underlying neural sources. To account for the effect of electric field spread on our MEG connectivity measures, we adapted the orthogonalization approach by Hipp, J., Hawellek, D., Corbetta, M. et al. Large-scale cortical correlation structure of spontaneous oscillatory activity. Nat Neurosci 15, 884\u2013890 (2012) link . The basic idea here is that a signal generated by one neural source and measured at two separate sensors must have exactly the same phase at both sensors. In contrast, signals from different neural sources have different phases. And thus it is possible to eliminate the effect of a reference signal on the target signal by removing the signal component that has the same phase as a reference region. Formally, this can be expressed as: \\(Y_{\\perp X}(t,f) = imag\\big(\\ Y(t,f)\\ \\frac{X(t,f)^\\star}{|X(t,f)|}\\ \\big)\\ \\label{eq:orth}\\) . Here, \\(Y\\) represents the analytic signal from our target regions that is being orthogonalized with respect to the signal from region \\(X\\) . Using the widgets below, you can choose the reference region \\(X\\) (default: right Precentral Gyrus) print ( 'Select a reference region for the orthogonalization' ) # Select a Region referenz = widgets . Select ( options = region_labels , value = 'PreCG.R' , description = 'Regions' , tooltips = [ 'Description of slow' , 'Description of regular' , 'Description of fast' ], layout = widgets . Layout ( width = '50%' , height = '150px' )) display ( referenz ) Select a reference region for the orthogonalization Select(description='Regions', index=1, layout=Layout(height='150px', width='50%'), options=('PreCG.L', 'PreCG.\u2026 # Perform Orthogonalization signal_conj = complex_signal . data . conj () conj_div_env = signal_conj / signal_env orth_signal = ( complex_signal . data . sel ( regions = target . value ) * conj_div_env . sel ( regions = referenz . value )) . imag orth_env = np . abs ( orth_signal ) # Plot fig , ax = plt . subplots ( 2 , 1 , figsize = ( 12 , 8 ), sharex = True ) sns . lineplot ( x = signal . data . time [: plot_timepoints ] . values , y = signal . data . sel ( regions = referenz . value )[: plot_timepoints ] . values , ax = ax [ 0 ]) sns . lineplot ( x = signal_env . time [: plot_timepoints ] . values , y = signal_env . sel ( regions = referenz . value )[: plot_timepoints ] . values , ax = ax [ 0 ]) ax [ 0 ] . set_title ( f 'Referenz Region X ( { referenz . value } )' ); sns . lineplot ( x = signal . data . time [: plot_timepoints ] . values , y = signal . data . sel ( regions = target . value )[: plot_timepoints ] . values , ax = ax [ 1 ], label = 'Bandpass-Filtered Signal' ) sns . lineplot ( x = signal_env . time [: plot_timepoints ] . values , y = signal_env . sel ( regions = target . value )[: plot_timepoints ] . values , ax = ax [ 1 ], label = 'Signal Envelope' ) sns . lineplot ( x = orth_env . time [: plot_timepoints ] . values , y = orth_env [: plot_timepoints ] . values , ax = ax [ 1 ], label = 'Orthogonalized Envelope' ) ax [ 1 ] . legend ( bbox_to_anchor = ( 1.2 , 1 ), borderaxespad = 0 ) ax [ 1 ] . set_title ( f 'Target Region Y ( { target . value } )' ); sns . despine ( trim = True ) Low-Pass filtering of the envelopes As a last step, before calculating the envelope correlations, we need to low-pass filter the signal envelopes since the connectivity measures of (ultra)-low frequency components of the MEG-signal correspond best to the functional connectivity as measured using fMRI. Below, you can choose the low-pass frequency (default: 0.2 Hz) . low_pass = widgets . FloatSlider ( value = 0.2 , min = 0 , max = 2.0 , step = 0.1 , description = 'Low-Pass Frequency (Hz)' , disabled = False , readout = True , readout_format = '.1f' , layout = widgets . Layout ( width = '80%' ), style = { 'description_width' : 'initial' }) display ( low_pass ) FloatSlider(value=0.2, description='Low-Pass Frequency (Hz)', layout=Layout(width='80%'), max=2.0, readout_for\u2026 with io . capture_output () as captured : low_orth_env = Signal ( orth_env ) . filter ( low_freq = None , high_freq = low_pass . value , inplace = False ) low_signal_env = Signal ( signal_env . sel ( regions = referenz . value )) . filter ( low_freq = None , high_freq = low_pass . value , inplace = False ) # Plot fig , ax = plt . subplots ( 1 , 2 , figsize = ( 15 , 4 ), sharey = True ) sns . lineplot ( x = signal_env . time [: plot_timepoints ] . values , y = signal_env . sel ( regions = referenz . value )[: plot_timepoints ] . values , ax = ax [ 0 ]) sns . lineplot ( x = low_signal_env . data . time [: plot_timepoints ] . values , y = low_signal_env . data [: plot_timepoints ] . values , ax = ax [ 0 ]) ax [ 0 ] . set_title ( f 'Referenz Region X ( { referenz . value } )' ); sns . lineplot ( x = orth_env . time [: plot_timepoints ] . values , y = orth_env [: plot_timepoints ] . values , ax = ax [ 1 ], label = 'Orthogonalized Envelope' ) sns . lineplot ( x = low_orth_env . data . time [: plot_timepoints ] . values , y = low_orth_env . data [: plot_timepoints ] . values , ax = ax [ 1 ], label = 'Low-Passed Orthogonalized Envelope' ) ax [ 1 ] . legend ( bbox_to_anchor = ( 1 , - 0.18 ), borderaxespad = 0 ) ax [ 1 ] . set_title ( f 'Target Region Y ( { target . value } )' ); sns . despine ( trim = True ) print ( f 'Orthogonalized envelope correlation between { referenz . value } and { target . value } : ' , np . round ( np . corrcoef ( low_orth_env . data , low_signal_env . data )[ 0 , 1 ], 2 )) Orthogonalized envelope correlation between PreCG.R and PreCG.L: 0.13 Computing the functional connectivity matrix We will now define a function that iterates over each pair of brain regions and performs the previously presented processing steps, i.e. that extracts the envelopes, performs the orthogonalization, applies the low-pass filter, and returns the functional connectivity matrix that contains the pairwise envelope correlations. This step may take a minute. def orth_fc ( signal , low_pass ): nr_regions = signal . data . shape [ 0 ] progress = widgets . IntProgress ( min = 0 , max = nr_regions , description = ( 'Calculating FC Matrix' ), layout = widgets . Layout ( width = '80%' ), style = { 'description_width' : 'initial' }) display ( progress ) complex_signal = signal . hilbert_transform ( 'complex' , inplace = False ) signal_env = signal . hilbert_transform ( 'amplitude' , inplace = False ); conj_div_env = complex_signal . data . conj () / signal_env . data # Low-pass filter Signal envelope with io . capture_output () as captured : signal_env . filter ( low_freq = None , high_freq = low_pass ) corr = [] for complex_region in complex_signal . data : orth_signal = ( complex_region * conj_div_env ) . imag orth_env = np . abs ( orth_signal ) . T orth_env = Signal ( orth_env ) with io . capture_output () as captured : orth_env . filter ( low_freq = None , high_freq = low_pass ) corr_mat = np . corrcoef ( orth_env . data , signal_env . data ) corr . append ( np . diag ( corr_mat , k = nr_regions )) progress . value += 1 fc = np . array ( corr ) # Since the orthogonalization process is not symmetric we take the mean of both directions. fc = ( fc . T + fc ) / 2. np . fill_diagonal ( fc , 0 ) return fc # Execute Function fc = orth_fc ( signal , low_pass . value ) IntProgress(value=0, description='Calculating FC Matrix', layout=Layout(width='80%'), max=94, style=ProgressSt\u2026 Let's now plot the functional connectivity matrix. We label only every second row/column since right and left regions alternate in the AAL2 atlas. fig , ax = plt . subplots ( figsize = ( 10 , 8 )) sns . heatmap ( fc , square = True , ax = ax , cmap = 'YlGnBu' , linewidth = 0.005 , cbar_kws = { \"shrink\" : .8 }) ticks = [ tick [: - 2 ] for tick in region_labels [:: 2 ]] ax . set_xticks ( np . arange ( 0 , 94 , 2 )); ax . set_yticks ( np . arange ( 0 , 94 , 2 )) ax . set_xticklabels ( ticks , rotation = 90 , fontsize = 8 ); ax . set_yticklabels ( ticks , rotation = 0 , fontsize = 8 ); Exclude subcortical regions For the following whole-brain simulation we are only interested in the cortical regions. So we'll now exclude all subcortical regions: * Hippocampus: 41 - 44 * Amygdala: 45-46 * Basal Ganglia: 75-80 * Thalamus: 81-82 Attention: AAL indices start with 1 exclude = list ( range ( 40 , 46 )) + list ( range ( 74 , 82 )) tmp = np . delete ( fc , exclude , axis = 0 ) emp_fc = np . delete ( tmp , exclude , axis = 1 ) # Exclude regions from the list of region labels emp_labels = np . delete ( region_labels , exclude ) Whole-brain model In this part of the notebook, we will use neurolib to simulate the functional connectivity. We will therefore: Load structural connectivity matrices from the Human Connectome Project and initiate the whole-brain model using the Wilson-Cowan model to simulate each brain region Set the global coupling strength , exc. background input , and the noise strength parameters of the model Run the simulation Compute the functional connectivity using the signal envelopes Please refer to the wc-minimal example for an introduction to the Wilson-Cowan model. Initiate whole-brain model # Let's import the neurolib from neurolib.models.wc import WCModel from neurolib.utils.loadData import Dataset # First we load the structural data set from the Human Connectome Project ds = Dataset ( \"hcp\" ) # We initiate the Wilson-Cowan model wc = WCModel ( Cmat = ds . Cmat , Dmat = ds . Dmat , seed = 0 ) Parameter settings You may now choose parameters settings for the global coupling , the excitatory background input , and the noise strength , which will be used when we run the model. The final fit between simulated and empirical connectivity matrices will depend on the parameters choosen here. global_coupling = widgets . FloatSlider ( value = 6.55 , min = 0. , max = 20.0 , step = 0.01 , description = 'Global Coupling' , disabled = False , readout = True , readout_format = '.2f' , layout = widgets . Layout ( width = '80%' ), style = { 'description_width' : 'initial' }) exc_drive = widgets . FloatSlider ( value = 1.58 , min = 0.0 , max = 4.0 , step = 0.01 , description = 'Exc. Background Drive' , disabled = False , readout = True , readout_format = '.2f' , layout = widgets . Layout ( width = '80%' ), style = { 'description_width' : 'initial' }) inh_drive = widgets . FloatSlider ( value = 2.83 , min = 0.0 , max = 4.0 , step = 0.01 , description = 'Inh. Background Drive' , disabled = False , readout = True , readout_format = '.2f' , layout = widgets . Layout ( width = '80%' ), style = { 'description_width' : 'initial' }) noise_level = widgets . FloatSlider ( value = 0.02 , min = 0.001 , max = 0.05 , step = 0.001 , description = 'Noise Level' , disabled = False , readout = True , readout_format = '.3f' , layout = widgets . Layout ( width = '80%' ), style = { 'description_width' : 'initial' }) display ( global_coupling ) display ( exc_drive ) display ( inh_drive ) display ( noise_level ) FloatSlider(value=6.55, description='Global Coupling', layout=Layout(width='80%'), max=20.0, step=0.01, style=\u2026 FloatSlider(value=1.58, description='Exc. Background Drive', layout=Layout(width='80%'), max=4.0, step=0.01, s\u2026 FloatSlider(value=2.83, description='Inh. Background Drive', layout=Layout(width='80%'), max=4.0, step=0.01, s\u2026 FloatSlider(value=0.02, description='Noise Level', layout=Layout(width='80%'), max=0.05, min=0.001, readout_fo\u2026 Run the simulation Let's now run the whole-brain model using the defined parameter settings. This may take some time since we're simulating a complete minute here. # Let's set the previously defined parameters # note: the duraiton here is short for testing: wc . params [ 'duration' ] = 10 * 1000 # use longer simulation for real run: #wc.params['duration'] = 1*60*1000 wc . params [ 'K_gl' ] = global_coupling . value wc . params [ 'exc_ext' ] = exc_drive . value wc . params [ 'inh_ext' ] = inh_drive . value wc . params [ 'sigma_ou' ] = noise_level . value # Run the model wc . run () Simulated functional connectivity We'll now compute the functional connectivity matrix containing the pairwise envelope correlations between all cortical regions of the AAL2 atlas. We'll thus follow the processing steps as before, i.e. band-pass filter the signal, extract the signal envelopes using the hilbert transformation, low-pass filter the envelopes and compute the pairwise pearson correlations. Note that we don't apply the orthogonalization scheme here, since this was only done to account to the electric field spread in the empirical data. # Create xr DataArray from the simulated excitatory timeseries (keeping the region labels) sim_signal = xr . DataArray ( wc . exc [:, int ( 1000 / wc . params . dt ):], dims = ( \"regions\" , \"time\" ), coords = { \"regions\" : emp_labels , \"time\" : wc . t [ int ( 1000 / wc . params . dt ):] / 1000 }, attrs = { 'atlas' : 'AAL2' }) # Initialize Figure fig , ax = plt . subplots ( figsize = ( 12 , 4 )) # Filter signal sim_signal = Signal ( sim_signal ) sim_signal . resample ( to_frequency = 100 ) with io . capture_output () as captured : sim_signal . filter ( freq . value [ 0 ], freq . value [ 1 ], inplace = True ); sns . lineplot ( x = sim_signal . data . time [: plot_timepoints ] . values , y = sim_signal . data . sel ( regions = target . value )[: plot_timepoints ] . values , ax = ax , label = 'Filtered Signal' ) # Extract signal envelope sim_signal . hilbert_transform ( 'amplitude' , inplace = True ) sns . lineplot ( x = sim_signal . data . time [: plot_timepoints ] . values , y = sim_signal . data . sel ( regions = target . value )[: plot_timepoints ] . values , ax = ax , label = 'Signal Envelope' ) # Low-Pass Filter with io . capture_output () as captured : sim_signal . filter ( low_freq = None , high_freq = low_pass . value , inplace = True ) sns . lineplot ( x = sim_signal . data . time [: plot_timepoints ] . values , y = sim_signal . data . sel ( regions = target . value )[: plot_timepoints ] . values , ax = ax , label = 'Low-Pass Signal Envelope' ) ax . legend ( bbox_to_anchor = ( 1.2 , 1 ), borderaxespad = 0 ) ax . set_title ( f 'Simulated Signal of Target Region Y ( { target . value } )' ); sns . despine ( trim = True ) To compute the simulated functional connectivity matrix we use the fc functions from neurolib. import neurolib.utils.functions as func # Compute the functional connectivity matrix sim_fc = func . fc ( sim_signal . data ) # Set diagonal to zero np . fill_diagonal ( sim_fc , 0 ) # Plot Empirical and simulated connectivity matrix fig , ax = plt . subplots ( 1 , 2 , figsize = ( 16 , 10 )) sns . heatmap ( emp_fc , square = True , ax = ax [ 0 ], cmap = 'YlGnBu' , linewidth = 0.005 , cbar_kws = { \"shrink\" : .5 }) ax [ 0 ] . set_title ( 'Empirical FC' , pad = 10 ); sns . heatmap ( sim_fc , square = True , ax = ax [ 1 ], cmap = 'YlGnBu' , linewidth = 0.005 , cbar_kws = { \"shrink\" : .5 }) ax [ 1 ] . set_title ( 'Simulated FC' , pad = 10 ); ticks = [ tick [: - 2 ] for tick in emp_labels [:: 2 ]] for ax in ax : ax . set_xticks ( np . arange ( 0 , 80 , 2 )); ax . set_yticks ( np . arange ( 0 , 80 , 2 )) ax . set_xticklabels ( ticks , rotation = 90 , fontsize = 8 ); ax . set_yticklabels ( ticks , rotation = 0 , fontsize = 8 ); Model fit Lastly, we may evaluate the model fit by computing the pearson correlation between our simulated functional connectivity matrix and the empirical one. Additionally we'll also plot the correlation between structural and functional connectivity matrices to have a reference. # Compare structural and simulated connectivity to the empirical functional connectivity struct_emp = np . corrcoef ( emp_fc . flatten (), ds . Cmat . flatten ())[ 0 , 1 ] sim_emp = np . corrcoef ( emp_fc . flatten (), sim_fc . flatten ())[ 0 , 1 ] # Plot fig , ax = plt . subplots ( figsize = ( 6 , 6 )) splot = sns . barplot ( x = [ 'Structural Connectivity' , 'Simulated Connectivity' ], y = [ struct_emp , sim_emp ], ax = ax ) ax . set_title ( 'Correlation to Empiral Functional Connectivity' , pad = 10 ) for p in splot . patches : splot . annotate ( format ( p . get_height (), '.2f' ), ( p . get_x () + p . get_width () / 2. , p . get_height ()), ha = 'center' , va = 'center' , size = 20 , color = 'white' , xytext = ( 0 , - 12 ), textcoords = 'offset points' ) sns . despine () print ( f \"Parameters: \\t Global Coupling: { wc . params [ 'K_gl' ] } \\n\\t\\t Exc. Background Drive: { wc . params [ 'exc_ext' ] } \" ) print ( f \" \\t\\t Noise Level: { wc . params [ 'sigma_ou' ] } \" ) Parameters: Global Coupling: 6.55 Exc. Background Drive: 1.58 Noise Level: 0.02","title":"Example 3 meg functional connectivity"},{"location":"examples/example-3-meg-functional-connectivity/#modeling-resting-state-meg-data","text":"In this example we will learn how to use neurolib to simulate resting state functional connectivity of MEG recordings. In the first part of the notebook, we will compute the frequency specific functional connectivity matrix of an examplary resting state MEG recording from the YouR-Study Uhlhaas, P.J., Gajwani, R., Gross, J. et al. The Youth Mental Health Risk and Resilience Study (YouR-Study). BMC Psychiatry 17, 43 (2017) . To this end we will: Band-Pass filter the signal Apply the hilbert -transformation to extract the signal envelope Orthogonalize the signal envelopes of two examplary regions Low-Pass filter the signal envelopes and compute the pairwise envelope correlations which yields the functional connectivity matrix. We follow the approach presented in Hipp, J., Hawellek, D., Corbetta, M. et al. , Large-scale cortical correlation structure of spontaneous oscillatory activity. Nat Neurosci 15, 884\u2013890 (2012) In the second part of this notebook, we will use a whole-brain model to simulate brain activity and compute functional connectivity matrix of the simulated signal envelope, as was done for the empirical MEG data. The parameters of this model have been previously optimized with neurolib 's evolutionary algorithms (not shown here). Finally, we will compute the fit (Pearson correlation) of the simulated functional connectivity to the empirical MEG data, which was used as a fitting objective in a previous optimization procedure. # change to the root directory of the project import os if os . getcwd () . split ( \"/\" )[ - 1 ] == \"examples\" : os . chdir ( '..' ) # This will reload all imports as soon as the code changes % load_ext autoreload % autoreload 2 import os import numpy as np import xarray as xr import matplotlib.pyplot as plt import seaborn as sns import ipywidgets as widgets from IPython.utils import io import warnings warnings . simplefilter ( action = 'ignore' , category = FutureWarning ) import time import pandas as pd /Users/caglar/anaconda/lib/python3.7/site-packages/pandas/compat/_optional.py:138: UserWarning: Pandas requires version '2.7.0' or newer of 'numexpr' (version '2.6.9' currently installed). warnings.warn(msg, UserWarning)","title":"Modeling resting-state MEG-Data"},{"location":"examples/example-3-meg-functional-connectivity/#empirical-functional-connectivity","text":"","title":"Empirical Functional Connectivity"},{"location":"examples/example-3-meg-functional-connectivity/#load-meg-data","text":"First off, let's load the MEG data using the Signal class from neurolib . Our example data has already been preprocessed and projected into source space using the AAL2 atlas. from neurolib.utils.signal import Signal signal = Signal . from_file ( os . path . join ( 'examples' , 'data' , 'rs-meg.nc' )) region_labels = signal . data . regions . values nr_regions = len ( region_labels ) display ( signal . data ) /* CSS stylesheet for displaying xarray objects in jupyterlab. * */ :root { --xr-font-color0: var(--jp-content-font-color0, rgba(0, 0, 0, 1)); --xr-font-color2: var(--jp-content-font-color2, rgba(0, 0, 0, 0.54)); --xr-font-color3: var(--jp-content-font-color3, rgba(0, 0, 0, 0.38)); --xr-border-color: var(--jp-border-color2, #e0e0e0); --xr-disabled-color: var(--jp-layout-color3, #bdbdbd); --xr-background-color: var(--jp-layout-color0, white); --xr-background-color-row-even: var(--jp-layout-color1, white); --xr-background-color-row-odd: var(--jp-layout-color2, #eeeeee); } html[theme=dark], body.vscode-dark { --xr-font-color0: rgba(255, 255, 255, 1); --xr-font-color2: rgba(255, 255, 255, 0.54); --xr-font-color3: rgba(255, 255, 255, 0.38); --xr-border-color: #1F1F1F; --xr-disabled-color: #515151; --xr-background-color: #111111; --xr-background-color-row-even: #111111; --xr-background-color-row-odd: #313131; } .xr-wrap { display: block; min-width: 300px; max-width: 700px; } .xr-text-repr-fallback { /* fallback to plain text repr when CSS is not injected (untrusted notebook) */ display: none; } .xr-header { padding-top: 6px; padding-bottom: 6px; margin-bottom: 4px; border-bottom: solid 1px var(--xr-border-color); } .xr-header > div, .xr-header > ul { display: inline; margin-top: 0; margin-bottom: 0; } .xr-obj-type, .xr-array-name { margin-left: 2px; margin-right: 10px; } .xr-obj-type { color: var(--xr-font-color2); } .xr-sections { padding-left: 0 !important; display: grid; grid-template-columns: 150px auto auto 1fr 20px 20px; } .xr-section-item { display: contents; } .xr-section-item input { display: none; } .xr-section-item input + label { color: var(--xr-disabled-color); } .xr-section-item input:enabled + label { cursor: pointer; color: var(--xr-font-color2); } .xr-section-item input:enabled + label:hover { color: var(--xr-font-color0); } .xr-section-summary { grid-column: 1; color: var(--xr-font-color2); font-weight: 500; } .xr-section-summary > span { display: inline-block; padding-left: 0.5em; } .xr-section-summary-in:disabled + label { color: var(--xr-font-color2); } .xr-section-summary-in + label:before { display: inline-block; content: '\u25ba'; font-size: 11px; width: 15px; text-align: center; } .xr-section-summary-in:disabled + label:before { color: var(--xr-disabled-color); } .xr-section-summary-in:checked + label:before { content: '\u25bc'; } .xr-section-summary-in:checked + label > span { display: none; } .xr-section-summary, .xr-section-inline-details { padding-top: 4px; padding-bottom: 4px; } .xr-section-inline-details { grid-column: 2 / -1; } .xr-section-details { display: none; grid-column: 1 / -1; margin-bottom: 5px; } .xr-section-summary-in:checked ~ .xr-section-details { display: contents; } .xr-array-wrap { grid-column: 1 / -1; display: grid; grid-template-columns: 20px auto; } .xr-array-wrap > label { grid-column: 1; vertical-align: top; } .xr-preview { color: var(--xr-font-color3); } .xr-array-preview, .xr-array-data { padding: 0 5px !important; grid-column: 2; } .xr-array-data, .xr-array-in:checked ~ .xr-array-preview { display: none; } .xr-array-in:checked ~ .xr-array-data, .xr-array-preview { display: inline-block; } .xr-dim-list { display: inline-block !important; list-style: none; padding: 0 !important; margin: 0; } .xr-dim-list li { display: inline-block; padding: 0; margin: 0; } .xr-dim-list:before { content: '('; } .xr-dim-list:after { content: ')'; } .xr-dim-list li:not(:last-child):after { content: ','; padding-right: 5px; } .xr-has-index { font-weight: bold; } .xr-var-list, .xr-var-item { display: contents; } .xr-var-item > div, .xr-var-item label, .xr-var-item > .xr-var-name span { background-color: var(--xr-background-color-row-even); margin-bottom: 0; } .xr-var-item > .xr-var-name:hover span { padding-right: 5px; } .xr-var-list > li:nth-child(odd) > div, .xr-var-list > li:nth-child(odd) > label, .xr-var-list > li:nth-child(odd) > .xr-var-name span { background-color: var(--xr-background-color-row-odd); } .xr-var-name { grid-column: 1; } .xr-var-dims { grid-column: 2; } .xr-var-dtype { grid-column: 3; text-align: right; color: var(--xr-font-color2); } .xr-var-preview { grid-column: 4; } .xr-var-name, .xr-var-dims, .xr-var-dtype, .xr-preview, .xr-attrs dt { white-space: nowrap; overflow: hidden; text-overflow: ellipsis; padding-right: 10px; } .xr-var-name:hover, .xr-var-dims:hover, .xr-var-dtype:hover, .xr-attrs dt:hover { overflow: visible; width: auto; z-index: 1; } .xr-var-attrs, .xr-var-data { display: none; background-color: var(--xr-background-color) !important; padding-bottom: 5px !important; } .xr-var-attrs-in:checked ~ .xr-var-attrs, .xr-var-data-in:checked ~ .xr-var-data { display: block; } .xr-var-data > table { float: right; } .xr-var-name span, .xr-var-data, .xr-attrs { padding-left: 25px !important; } .xr-attrs, .xr-var-attrs, .xr-var-data { grid-column: 1 / -1; } dl.xr-attrs { padding: 0; margin: 0; display: grid; grid-template-columns: 125px auto; } .xr-attrs dt, .xr-attrs dd { padding: 0; margin: 0; float: left; padding-right: 10px; width: auto; } .xr-attrs dt { font-weight: normal; grid-column: 1; } .xr-attrs dt:hover span { display: inline-block; background: var(--xr-background-color); padding-right: 10px; } .xr-attrs dd { grid-column: 2; white-space: pre-wrap; word-break: break-all; } .xr-icon-database, .xr-icon-file-text2 { display: inline-block; vertical-align: middle; width: 1em; height: 1.5em !important; stroke-width: 0; stroke: currentColor; fill: currentColor; } <xarray.DataArray (regions: 94, time: 6000)> array([[-0.17628077, -0.33449804, -0.27283166, ..., 0.20004052, 0.19379806, 0.0271034 ], [ 0.00513031, 0.0319704 , 0.18478207, ..., 0.22112991, 0.30244658, 0.21108818], [ 0.01999333, -0.1601617 , -0.21931987, ..., 0.01844522, -0.03713842, 0.08175757], ..., [-0.2381615 , -0.34838511, -0.50638238, ..., -0.08763395, -0.05396606, -0.06218967], [-0.09900261, -0.1525903 , -0.16444704, ..., 0.04080438, 0.01664182, 0.15847579], [ 0.13203698, 0.17482835, 0.21212731, ..., -0.19971229, -0.01869223, -0.16379495]]) Coordinates: * time (time) float64 0.0 0.01 0.02 0.03 0.04 ... 59.96 59.97 59.98 59.99 * regions (regions) object 'PreCG.L' 'PreCG.R' 'SFG.L' ... 'ITG.L' 'ITG.R' Attributes: name: rest meg label: signal_type: unit: T description: MEG recording in AAL2 space process_steps_0: resample to 100.0Hz xarray.DataArray regions : 94 time : 6000 -0.1763 -0.3345 -0.2728 -0.1313 ... -0.2128 -0.1997 -0.01869 -0.1638 array([[-0.17628077, -0.33449804, -0.27283166, ..., 0.20004052, 0.19379806, 0.0271034 ], [ 0.00513031, 0.0319704 , 0.18478207, ..., 0.22112991, 0.30244658, 0.21108818], [ 0.01999333, -0.1601617 , -0.21931987, ..., 0.01844522, -0.03713842, 0.08175757], ..., [-0.2381615 , -0.34838511, -0.50638238, ..., -0.08763395, -0.05396606, -0.06218967], [-0.09900261, -0.1525903 , -0.16444704, ..., 0.04080438, 0.01664182, 0.15847579], [ 0.13203698, 0.17482835, 0.21212731, ..., -0.19971229, -0.01869223, -0.16379495]]) Coordinates: (2) time (time) float64 0.0 0.01 0.02 ... 59.97 59.98 59.99 array([0.000e+00, 1.000e-02, 2.000e-02, ..., 5.997e+01, 5.998e+01, 5.999e+01]) regions (regions) object 'PreCG.L' 'PreCG.R' ... 'ITG.R' array(['PreCG.L', 'PreCG.R', 'SFG.L', 'SFG.R', 'MFG.L', 'MFG.R', 'IFGoperc.L', 'IFGoperc.R', 'IFGtriang.L', 'IFGtriang.R', 'IFGorb.L', 'IFGorb.R', 'ROL.L', 'ROL.R', 'SMA.L', 'SMA.R', 'OLF.L', 'OLF.R', 'SFGmed.L', 'SFGmed.R', 'PFCventmed.L', 'PFCventmed.R', 'REC.L', 'REC.R', 'OFCmed.L', 'OFCmed.R', 'OFCant.L', 'OFCant.R', 'OFCpos.L', 'OFCpos.R', 'OFClat.L', 'OFClat.R', 'INS.L', 'INS.R', 'ACC.L', 'ACC.R', 'MCC.L', 'MCC.R', 'PCC.L', 'PCC.R', 'HIP.L', 'HIP.R', 'PHG.L', 'PHG.R', 'AMYG.L', 'AMYG.R', 'CAL.L', 'CAL.R', 'CUN.L', 'CUN.R', 'LING.L', 'LING.R', 'SOG.L', 'SOG.R', 'MOG.L', 'MOG.R', 'IOG.L', 'IOG.R', 'FFG.L', 'FFG.R', 'PoCG.L', 'PoCG.R', 'SPG.L', 'SPG.R', 'IPG.L', 'IPG.R', 'SMG.L', 'SMG.R', 'ANG.L', 'ANG.R', 'PCUN.L', 'PCUN.R', 'PCL.L', 'PCL.R', 'CAU.L', 'CAU.R', 'PUT.L', 'PUT.R', 'PAL.L', 'PAL.R', 'THA.L', 'THA.R', 'HES.L', 'HES.R', 'STG.L', 'STG.R', 'TPOsup.L', 'TPOsup.R', 'MTG.L', 'MTG.R', 'TPOmid.L', 'TPOmid.R', 'ITG.L', 'ITG.R'], dtype=object) Attributes: (6) name : rest meg label : signal_type : unit : T description : MEG recording in AAL2 space process_steps_0 : resample to 100.0Hz","title":"Load MEG-Data"},{"location":"examples/example-3-meg-functional-connectivity/#band-pass-filter-and-hilbert-transform","text":"We will now filter the signal into the desidered frequency band and apply the hilbert transform on the band-passed filtered signal. This will provide us with the analytic representation of the signal, which we can then use to extract the signal's envelope and its phase. In the following, we plot each processing step for an example target region that you can chose using the widgets below (default: left Precentral Gyrus) . Furthermore, we can also choose the frequency range that we'd like to filter the signal in (default: alpha (8-12Hz)) . print ( 'Select a region from the AAL2 atlas and a frequency range' ) # Select a Region target = widgets . Select ( options = region_labels , value = 'PreCG.L' , description = 'Regions' , tooltips = [ 'Description of slow' , 'Description of regular' , 'Description of fast' ], layout = widgets . Layout ( width = '50%' , height = '150px' )) display ( target ) # Select Frequency Range freq = widgets . IntRangeSlider ( min = 1 , max = 46 , description = 'Frequency (Hz)' , value = [ 8 , 12 ], layout = widgets . Layout ( width = '80%' ), style = { 'description_width' : 'initial' }) display ( freq ) Select a region from the AAL2 atlas and a frequency range Select(description='Regions', layout=Layout(height='150px', width='50%'), options=('PreCG.L', 'PreCG.R', 'SFG.\u2026 IntRangeSlider(value=(8, 12), description='Frequency (Hz)', layout=Layout(width='80%'), max=46, min=1, style=S\u2026 # Define how many timepoints you'd like to plot plot_timepoints = 1000 # Plot unfiltered Signal fig , ax = plt . subplots ( 2 , 1 , figsize = ( 12 , 8 ), sharex = True ) sns . lineplot ( x = signal . data . time [: plot_timepoints ] . values , y = signal . data . sel ( regions = target . value )[: plot_timepoints ] . values , ax = ax [ 0 ], color = 'k' , alpha = 0.6 ) ax [ 0 ] . set_title ( f 'Unfiltered Signal ( { target . value } )' ); # Band Pass Filter the Signal signal . filter ( freq . value [ 0 ], freq . value [ 1 ], inplace = True ); # Apply hilbert-transform to extract the signal envelope complex_signal = signal . hilbert_transform ( 'complex' , inplace = False ) signal_env = np . abs ( complex_signal . data ) # Plot filtered Signal and Signal Envelope sns . lineplot ( x = signal . data . time [: plot_timepoints ] . values , y = signal . data . sel ( regions = target . value )[: plot_timepoints ] . values , ax = ax [ 1 ], label = 'Bandpass-Filtered Signal' ) sns . lineplot ( x = signal_env . time [: plot_timepoints ] . values , y = signal_env . sel ( regions = target . value )[: plot_timepoints ] . values , ax = ax [ 1 ], label = 'Signal Envelope' ) ax [ 1 ] . set_title ( f 'Filtered Signal ( { target . value } )' ); ax [ 1 ] . legend ( bbox_to_anchor = ( 1.2 , 1 ), borderaxespad = 0 ) sns . despine ( trim = True ) Setting up band-pass filter from 8 - 12 Hz FIR filter parameters --------------------- Designing a one-pass, zero-phase, non-causal bandpass filter: - Windowed time-domain design (firwin) method - Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation - Lower passband edge: 8.00 - Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 7.00 Hz) - Upper passband edge: 12.00 Hz - Upper transition bandwidth: 3.00 Hz (-6 dB cutoff frequency: 13.50 Hz) - Filter length: 165 samples (1.650 sec)","title":"Band-Pass filter and Hilbert transform"},{"location":"examples/example-3-meg-functional-connectivity/#orthogonalized-signal-envelope","text":"Now we are going to address the main methodological issue of MEG when it comes to the analysis of the cortical functional connectivity structure, i.e. its low spatial resolution. The electric field generated by any given neural source spreads widely over the cortex so that the signal captured at the MEG sensors is a complex mixture of signals from multiple underlying neural sources. To account for the effect of electric field spread on our MEG connectivity measures, we adapted the orthogonalization approach by Hipp, J., Hawellek, D., Corbetta, M. et al. Large-scale cortical correlation structure of spontaneous oscillatory activity. Nat Neurosci 15, 884\u2013890 (2012) link . The basic idea here is that a signal generated by one neural source and measured at two separate sensors must have exactly the same phase at both sensors. In contrast, signals from different neural sources have different phases. And thus it is possible to eliminate the effect of a reference signal on the target signal by removing the signal component that has the same phase as a reference region. Formally, this can be expressed as: \\(Y_{\\perp X}(t,f) = imag\\big(\\ Y(t,f)\\ \\frac{X(t,f)^\\star}{|X(t,f)|}\\ \\big)\\ \\label{eq:orth}\\) . Here, \\(Y\\) represents the analytic signal from our target regions that is being orthogonalized with respect to the signal from region \\(X\\) . Using the widgets below, you can choose the reference region \\(X\\) (default: right Precentral Gyrus) print ( 'Select a reference region for the orthogonalization' ) # Select a Region referenz = widgets . Select ( options = region_labels , value = 'PreCG.R' , description = 'Regions' , tooltips = [ 'Description of slow' , 'Description of regular' , 'Description of fast' ], layout = widgets . Layout ( width = '50%' , height = '150px' )) display ( referenz ) Select a reference region for the orthogonalization Select(description='Regions', index=1, layout=Layout(height='150px', width='50%'), options=('PreCG.L', 'PreCG.\u2026 # Perform Orthogonalization signal_conj = complex_signal . data . conj () conj_div_env = signal_conj / signal_env orth_signal = ( complex_signal . data . sel ( regions = target . value ) * conj_div_env . sel ( regions = referenz . value )) . imag orth_env = np . abs ( orth_signal ) # Plot fig , ax = plt . subplots ( 2 , 1 , figsize = ( 12 , 8 ), sharex = True ) sns . lineplot ( x = signal . data . time [: plot_timepoints ] . values , y = signal . data . sel ( regions = referenz . value )[: plot_timepoints ] . values , ax = ax [ 0 ]) sns . lineplot ( x = signal_env . time [: plot_timepoints ] . values , y = signal_env . sel ( regions = referenz . value )[: plot_timepoints ] . values , ax = ax [ 0 ]) ax [ 0 ] . set_title ( f 'Referenz Region X ( { referenz . value } )' ); sns . lineplot ( x = signal . data . time [: plot_timepoints ] . values , y = signal . data . sel ( regions = target . value )[: plot_timepoints ] . values , ax = ax [ 1 ], label = 'Bandpass-Filtered Signal' ) sns . lineplot ( x = signal_env . time [: plot_timepoints ] . values , y = signal_env . sel ( regions = target . value )[: plot_timepoints ] . values , ax = ax [ 1 ], label = 'Signal Envelope' ) sns . lineplot ( x = orth_env . time [: plot_timepoints ] . values , y = orth_env [: plot_timepoints ] . values , ax = ax [ 1 ], label = 'Orthogonalized Envelope' ) ax [ 1 ] . legend ( bbox_to_anchor = ( 1.2 , 1 ), borderaxespad = 0 ) ax [ 1 ] . set_title ( f 'Target Region Y ( { target . value } )' ); sns . despine ( trim = True )","title":"Orthogonalized signal envelope"},{"location":"examples/example-3-meg-functional-connectivity/#low-pass-filtering-of-the-envelopes","text":"As a last step, before calculating the envelope correlations, we need to low-pass filter the signal envelopes since the connectivity measures of (ultra)-low frequency components of the MEG-signal correspond best to the functional connectivity as measured using fMRI. Below, you can choose the low-pass frequency (default: 0.2 Hz) . low_pass = widgets . FloatSlider ( value = 0.2 , min = 0 , max = 2.0 , step = 0.1 , description = 'Low-Pass Frequency (Hz)' , disabled = False , readout = True , readout_format = '.1f' , layout = widgets . Layout ( width = '80%' ), style = { 'description_width' : 'initial' }) display ( low_pass ) FloatSlider(value=0.2, description='Low-Pass Frequency (Hz)', layout=Layout(width='80%'), max=2.0, readout_for\u2026 with io . capture_output () as captured : low_orth_env = Signal ( orth_env ) . filter ( low_freq = None , high_freq = low_pass . value , inplace = False ) low_signal_env = Signal ( signal_env . sel ( regions = referenz . value )) . filter ( low_freq = None , high_freq = low_pass . value , inplace = False ) # Plot fig , ax = plt . subplots ( 1 , 2 , figsize = ( 15 , 4 ), sharey = True ) sns . lineplot ( x = signal_env . time [: plot_timepoints ] . values , y = signal_env . sel ( regions = referenz . value )[: plot_timepoints ] . values , ax = ax [ 0 ]) sns . lineplot ( x = low_signal_env . data . time [: plot_timepoints ] . values , y = low_signal_env . data [: plot_timepoints ] . values , ax = ax [ 0 ]) ax [ 0 ] . set_title ( f 'Referenz Region X ( { referenz . value } )' ); sns . lineplot ( x = orth_env . time [: plot_timepoints ] . values , y = orth_env [: plot_timepoints ] . values , ax = ax [ 1 ], label = 'Orthogonalized Envelope' ) sns . lineplot ( x = low_orth_env . data . time [: plot_timepoints ] . values , y = low_orth_env . data [: plot_timepoints ] . values , ax = ax [ 1 ], label = 'Low-Passed Orthogonalized Envelope' ) ax [ 1 ] . legend ( bbox_to_anchor = ( 1 , - 0.18 ), borderaxespad = 0 ) ax [ 1 ] . set_title ( f 'Target Region Y ( { target . value } )' ); sns . despine ( trim = True ) print ( f 'Orthogonalized envelope correlation between { referenz . value } and { target . value } : ' , np . round ( np . corrcoef ( low_orth_env . data , low_signal_env . data )[ 0 , 1 ], 2 )) Orthogonalized envelope correlation between PreCG.R and PreCG.L: 0.13","title":"Low-Pass filtering of the envelopes"},{"location":"examples/example-3-meg-functional-connectivity/#computing-the-functional-connectivity-matrix","text":"We will now define a function that iterates over each pair of brain regions and performs the previously presented processing steps, i.e. that extracts the envelopes, performs the orthogonalization, applies the low-pass filter, and returns the functional connectivity matrix that contains the pairwise envelope correlations. This step may take a minute. def orth_fc ( signal , low_pass ): nr_regions = signal . data . shape [ 0 ] progress = widgets . IntProgress ( min = 0 , max = nr_regions , description = ( 'Calculating FC Matrix' ), layout = widgets . Layout ( width = '80%' ), style = { 'description_width' : 'initial' }) display ( progress ) complex_signal = signal . hilbert_transform ( 'complex' , inplace = False ) signal_env = signal . hilbert_transform ( 'amplitude' , inplace = False ); conj_div_env = complex_signal . data . conj () / signal_env . data # Low-pass filter Signal envelope with io . capture_output () as captured : signal_env . filter ( low_freq = None , high_freq = low_pass ) corr = [] for complex_region in complex_signal . data : orth_signal = ( complex_region * conj_div_env ) . imag orth_env = np . abs ( orth_signal ) . T orth_env = Signal ( orth_env ) with io . capture_output () as captured : orth_env . filter ( low_freq = None , high_freq = low_pass ) corr_mat = np . corrcoef ( orth_env . data , signal_env . data ) corr . append ( np . diag ( corr_mat , k = nr_regions )) progress . value += 1 fc = np . array ( corr ) # Since the orthogonalization process is not symmetric we take the mean of both directions. fc = ( fc . T + fc ) / 2. np . fill_diagonal ( fc , 0 ) return fc # Execute Function fc = orth_fc ( signal , low_pass . value ) IntProgress(value=0, description='Calculating FC Matrix', layout=Layout(width='80%'), max=94, style=ProgressSt\u2026 Let's now plot the functional connectivity matrix. We label only every second row/column since right and left regions alternate in the AAL2 atlas. fig , ax = plt . subplots ( figsize = ( 10 , 8 )) sns . heatmap ( fc , square = True , ax = ax , cmap = 'YlGnBu' , linewidth = 0.005 , cbar_kws = { \"shrink\" : .8 }) ticks = [ tick [: - 2 ] for tick in region_labels [:: 2 ]] ax . set_xticks ( np . arange ( 0 , 94 , 2 )); ax . set_yticks ( np . arange ( 0 , 94 , 2 )) ax . set_xticklabels ( ticks , rotation = 90 , fontsize = 8 ); ax . set_yticklabels ( ticks , rotation = 0 , fontsize = 8 );","title":"Computing the functional connectivity matrix"},{"location":"examples/example-3-meg-functional-connectivity/#exclude-subcortical-regions","text":"For the following whole-brain simulation we are only interested in the cortical regions. So we'll now exclude all subcortical regions: * Hippocampus: 41 - 44 * Amygdala: 45-46 * Basal Ganglia: 75-80 * Thalamus: 81-82 Attention: AAL indices start with 1 exclude = list ( range ( 40 , 46 )) + list ( range ( 74 , 82 )) tmp = np . delete ( fc , exclude , axis = 0 ) emp_fc = np . delete ( tmp , exclude , axis = 1 ) # Exclude regions from the list of region labels emp_labels = np . delete ( region_labels , exclude )","title":"Exclude subcortical regions"},{"location":"examples/example-3-meg-functional-connectivity/#whole-brain-model","text":"In this part of the notebook, we will use neurolib to simulate the functional connectivity. We will therefore: Load structural connectivity matrices from the Human Connectome Project and initiate the whole-brain model using the Wilson-Cowan model to simulate each brain region Set the global coupling strength , exc. background input , and the noise strength parameters of the model Run the simulation Compute the functional connectivity using the signal envelopes Please refer to the wc-minimal example for an introduction to the Wilson-Cowan model.","title":"Whole-brain model"},{"location":"examples/example-3-meg-functional-connectivity/#initiate-whole-brain-model","text":"# Let's import the neurolib from neurolib.models.wc import WCModel from neurolib.utils.loadData import Dataset # First we load the structural data set from the Human Connectome Project ds = Dataset ( \"hcp\" ) # We initiate the Wilson-Cowan model wc = WCModel ( Cmat = ds . Cmat , Dmat = ds . Dmat , seed = 0 )","title":"Initiate whole-brain model"},{"location":"examples/example-3-meg-functional-connectivity/#parameter-settings","text":"You may now choose parameters settings for the global coupling , the excitatory background input , and the noise strength , which will be used when we run the model. The final fit between simulated and empirical connectivity matrices will depend on the parameters choosen here. global_coupling = widgets . FloatSlider ( value = 6.55 , min = 0. , max = 20.0 , step = 0.01 , description = 'Global Coupling' , disabled = False , readout = True , readout_format = '.2f' , layout = widgets . Layout ( width = '80%' ), style = { 'description_width' : 'initial' }) exc_drive = widgets . FloatSlider ( value = 1.58 , min = 0.0 , max = 4.0 , step = 0.01 , description = 'Exc. Background Drive' , disabled = False , readout = True , readout_format = '.2f' , layout = widgets . Layout ( width = '80%' ), style = { 'description_width' : 'initial' }) inh_drive = widgets . FloatSlider ( value = 2.83 , min = 0.0 , max = 4.0 , step = 0.01 , description = 'Inh. Background Drive' , disabled = False , readout = True , readout_format = '.2f' , layout = widgets . Layout ( width = '80%' ), style = { 'description_width' : 'initial' }) noise_level = widgets . FloatSlider ( value = 0.02 , min = 0.001 , max = 0.05 , step = 0.001 , description = 'Noise Level' , disabled = False , readout = True , readout_format = '.3f' , layout = widgets . Layout ( width = '80%' ), style = { 'description_width' : 'initial' }) display ( global_coupling ) display ( exc_drive ) display ( inh_drive ) display ( noise_level ) FloatSlider(value=6.55, description='Global Coupling', layout=Layout(width='80%'), max=20.0, step=0.01, style=\u2026 FloatSlider(value=1.58, description='Exc. Background Drive', layout=Layout(width='80%'), max=4.0, step=0.01, s\u2026 FloatSlider(value=2.83, description='Inh. Background Drive', layout=Layout(width='80%'), max=4.0, step=0.01, s\u2026 FloatSlider(value=0.02, description='Noise Level', layout=Layout(width='80%'), max=0.05, min=0.001, readout_fo\u2026","title":"Parameter settings"},{"location":"examples/example-3-meg-functional-connectivity/#run-the-simulation","text":"Let's now run the whole-brain model using the defined parameter settings. This may take some time since we're simulating a complete minute here. # Let's set the previously defined parameters # note: the duraiton here is short for testing: wc . params [ 'duration' ] = 10 * 1000 # use longer simulation for real run: #wc.params['duration'] = 1*60*1000 wc . params [ 'K_gl' ] = global_coupling . value wc . params [ 'exc_ext' ] = exc_drive . value wc . params [ 'inh_ext' ] = inh_drive . value wc . params [ 'sigma_ou' ] = noise_level . value # Run the model wc . run ()","title":"Run the simulation"},{"location":"examples/example-3-meg-functional-connectivity/#simulated-functional-connectivity","text":"We'll now compute the functional connectivity matrix containing the pairwise envelope correlations between all cortical regions of the AAL2 atlas. We'll thus follow the processing steps as before, i.e. band-pass filter the signal, extract the signal envelopes using the hilbert transformation, low-pass filter the envelopes and compute the pairwise pearson correlations. Note that we don't apply the orthogonalization scheme here, since this was only done to account to the electric field spread in the empirical data. # Create xr DataArray from the simulated excitatory timeseries (keeping the region labels) sim_signal = xr . DataArray ( wc . exc [:, int ( 1000 / wc . params . dt ):], dims = ( \"regions\" , \"time\" ), coords = { \"regions\" : emp_labels , \"time\" : wc . t [ int ( 1000 / wc . params . dt ):] / 1000 }, attrs = { 'atlas' : 'AAL2' }) # Initialize Figure fig , ax = plt . subplots ( figsize = ( 12 , 4 )) # Filter signal sim_signal = Signal ( sim_signal ) sim_signal . resample ( to_frequency = 100 ) with io . capture_output () as captured : sim_signal . filter ( freq . value [ 0 ], freq . value [ 1 ], inplace = True ); sns . lineplot ( x = sim_signal . data . time [: plot_timepoints ] . values , y = sim_signal . data . sel ( regions = target . value )[: plot_timepoints ] . values , ax = ax , label = 'Filtered Signal' ) # Extract signal envelope sim_signal . hilbert_transform ( 'amplitude' , inplace = True ) sns . lineplot ( x = sim_signal . data . time [: plot_timepoints ] . values , y = sim_signal . data . sel ( regions = target . value )[: plot_timepoints ] . values , ax = ax , label = 'Signal Envelope' ) # Low-Pass Filter with io . capture_output () as captured : sim_signal . filter ( low_freq = None , high_freq = low_pass . value , inplace = True ) sns . lineplot ( x = sim_signal . data . time [: plot_timepoints ] . values , y = sim_signal . data . sel ( regions = target . value )[: plot_timepoints ] . values , ax = ax , label = 'Low-Pass Signal Envelope' ) ax . legend ( bbox_to_anchor = ( 1.2 , 1 ), borderaxespad = 0 ) ax . set_title ( f 'Simulated Signal of Target Region Y ( { target . value } )' ); sns . despine ( trim = True ) To compute the simulated functional connectivity matrix we use the fc functions from neurolib. import neurolib.utils.functions as func # Compute the functional connectivity matrix sim_fc = func . fc ( sim_signal . data ) # Set diagonal to zero np . fill_diagonal ( sim_fc , 0 ) # Plot Empirical and simulated connectivity matrix fig , ax = plt . subplots ( 1 , 2 , figsize = ( 16 , 10 )) sns . heatmap ( emp_fc , square = True , ax = ax [ 0 ], cmap = 'YlGnBu' , linewidth = 0.005 , cbar_kws = { \"shrink\" : .5 }) ax [ 0 ] . set_title ( 'Empirical FC' , pad = 10 ); sns . heatmap ( sim_fc , square = True , ax = ax [ 1 ], cmap = 'YlGnBu' , linewidth = 0.005 , cbar_kws = { \"shrink\" : .5 }) ax [ 1 ] . set_title ( 'Simulated FC' , pad = 10 ); ticks = [ tick [: - 2 ] for tick in emp_labels [:: 2 ]] for ax in ax : ax . set_xticks ( np . arange ( 0 , 80 , 2 )); ax . set_yticks ( np . arange ( 0 , 80 , 2 )) ax . set_xticklabels ( ticks , rotation = 90 , fontsize = 8 ); ax . set_yticklabels ( ticks , rotation = 0 , fontsize = 8 );","title":"Simulated functional connectivity"},{"location":"examples/example-3-meg-functional-connectivity/#model-fit","text":"Lastly, we may evaluate the model fit by computing the pearson correlation between our simulated functional connectivity matrix and the empirical one. Additionally we'll also plot the correlation between structural and functional connectivity matrices to have a reference. # Compare structural and simulated connectivity to the empirical functional connectivity struct_emp = np . corrcoef ( emp_fc . flatten (), ds . Cmat . flatten ())[ 0 , 1 ] sim_emp = np . corrcoef ( emp_fc . flatten (), sim_fc . flatten ())[ 0 , 1 ] # Plot fig , ax = plt . subplots ( figsize = ( 6 , 6 )) splot = sns . barplot ( x = [ 'Structural Connectivity' , 'Simulated Connectivity' ], y = [ struct_emp , sim_emp ], ax = ax ) ax . set_title ( 'Correlation to Empiral Functional Connectivity' , pad = 10 ) for p in splot . patches : splot . annotate ( format ( p . get_height (), '.2f' ), ( p . get_x () + p . get_width () / 2. , p . get_height ()), ha = 'center' , va = 'center' , size = 20 , color = 'white' , xytext = ( 0 , - 12 ), textcoords = 'offset points' ) sns . despine () print ( f \"Parameters: \\t Global Coupling: { wc . params [ 'K_gl' ] } \\n\\t\\t Exc. Background Drive: { wc . params [ 'exc_ext' ] } \" ) print ( f \" \\t\\t Noise Level: { wc . params [ 'sigma_ou' ] } \" ) Parameters: Global Coupling: 6.55 Exc. Background Drive: 1.58 Noise Level: 0.02","title":"Model fit"},{"location":"examples/example-4-multimodel-intro/","text":"(function() { function addWidgetsRenderer() { var requireJsScript = document.createElement('script'); requireJsScript.src = 'https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js'; var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var jupyterWidgetsScript = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} jupyterWidgetsScript.src = widgetRendererSrc; document.body.appendChild(requireJsScript); document.body.appendChild(jupyterWidgetsScript); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); MultiModel framework Here we showcase the MultiModel framework, a standalone framework within neurolib to create and simulate heterogeneous brain models. By heterogeneous, we mean that a brain network may consist of nodes with totally different dynamics coupled by a single variable. Imagine having a population model for the thalamus, a different model for the hippocampus, and a different model for the cortex. Of course, the parameters and the model dynamics, and the equations would be completely different. This is all possible and even relatively easy in MultiModel . Implemented models To facilitate your heterogeneous experiments, the MultiModel comes with few population models predefined for you. We can mix these into a brain network in many ways. We provide: aln : the adaptive linear-nonlinear population model, it is a mean-field approximation of delay-coupled network of excitatory and inhibitory adaptive exponential integrate-and-fire neurons (AdEx) fitzhugh_nagumo : the FitzHugh-Nagumo model, a two-dimensional slow-fast system, is a simplified version of the famous 4D Hodgkin\u2013Huxley model hopf : the Hopf model (sometimes called a Stuart-Landau oscillator) is a 1D nonlinear model and serves as a normal form of Hopf bifurcation in dynamical systems thalamus : a conductance-based population rate model of the thalamus, it is a Jansen-Rit like population model with current-based voltage evolution, includes adaptation ( K -leak), calcium, and rectifying currents wilson_cowan : the Wilson-Cowan neuronal model is a simple model of interacting interconnected neurons of excitatory and inhibitory subtypes wong_wang : a Wong-Wang model, a model approximating a biophysically-based cortical network model. Our implementation comes in two flavors: original Wong-Wang model with excitatory and inhibitory subtypes reduced Wong-Wang model with simpler dynamics and no EXC/INH distinction Moreover, the MultiModel framework is built in such a way that creating and connecting new models (e.g., Jansen-Rit) is easy and intuitive. An example of how to make a brand new model implementation in MultiModel is provided in the following example notebook ( example-4.1-create-new-model.ipynb ). Modeling hierarchy The MultiModel relies on the modeling hierarchy, which is typically implicit in whole-brain modeling. This hierarchy has three levels: * NeuralMass : represents a single neural population (typically excitatory, inhibitory, or without a subtype) and is defined by a set of parameters and (possibly delayed) (possibly stochastic) differential equations * Node : represents a single brain node, and it is a set of connected neural masses (so, e.g., a single Wilson-Cowan node consists of one excitatory and one inhibitory Wilson-Cowan NeuralMass ) * Network : represents a brain network, and it is a set of connected nodes (can be any type, as long as the coupling variables are the same) Although the magic happens at the level of NeuralMass (by magic, we mean the dynamics), users can only simulate (integrate) a Node or a Network . In other words, even for models without excitatory/inhibitory subtyping (e.g., Hopf or FitzHugh-Nagumo), we create a Node consisting of one NeuralMass . In the case of, e.g., Wilson-Cowan, ALN, or original Wong-Wang model, the Node consists of one excitatory and one inhibitory mass. More info on the modeling hierarchy and how it actually works is provided in the following example notebook ( example-4.1-create-new-model.ipynb ), where we need to subclass the base classes for this hierarchy to build a new model. Basic usage in neurolib (In the following we expect the reader to be mildly familiar with how neurolib works, e.g. how to run a model, how to change it parameters, and how to get model results) # import stuff # try: import matplotlib.pyplot as plt import numpy as np from IPython.display import display # import ALN single node model and neurolib wrapper `MultiModel` from neurolib.models.multimodel import ALNNetwork , ALNNode , MultiModel # except ImportError: # import sys # !{sys.executable} -m pip install matplotlib # import matplotlib.pyplot as plt Simulating the node # create a model and wrap it to `MultiModel` aln = MultiModel . init_node ( ALNNode ()) # 5 seconds run aln . params [ \"duration\" ] = 5.0 * 1000 # in ms # MultiModel offers two integration backends, be default we are using so-called `jitcdde` backend # `jitcdde` is a numerical backend employing adaptive dt scheme for DDEs, therefore we do not care about # actual dt (since it is adaptive), only about the sampling dt and this can be higher # more about this in example-4.2 aln . params [ \"sampling_dt\" ] = 1.0 # in ms # parametrise ALN model in slow limit cycle aln . params [ \"*EXC*input*mu\" ] = 4.2 aln . params [ \"*INH*input*mu\" ] = 1.8 # run aln . run () # plot - default output is firing rates in kHz plt . plot ( aln [ \"t\" ], aln [ \"r_mean_EXC\" ] . T , lw = 2 , c = \"k\" ) plt . xlabel ( \"t [ms]\" ) plt . ylabel ( \"Rate [kHz]\" ) /Users/nikola/.virtualenvs/neurolib/lib/python3.7/site-packages/jitcdde/_jitcdde.py:1491: UserWarning: Your input past does not begin at t=0 but at t=1.0. Values before the beginning of the past will be extrapolated. You very likely do not want this. warn(f\"Your input past does not begin at t=0 but at t={input[0].time}. Values before the beginning of the past will be extrapolated. You very likely do not want this.\") Using default integration parameters. 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5000/5000 [00:00<00:00, 7495.97it/s] Text(0, 0.5, 'Rate [kHz]') As you saw in the previous cell, the internal workings of MultiModel are very similar to the core neurolib . Therefore, for simple runs, you do care about the following: * MultiModel : a wrapper class for all models in MultiModel framework which gives model objects neurolib powers (meaning .params and .run() ). MultiModel class is initialized as follows: * when initialising with Node : model = MultiModel.init_node(<init'd Node class>) * when initialising with Network : model = MultiModel(<init'd Network class>) (see later) MultiModel parameters and other accessible attributes Since MultiModel is able to simulate heterogeneous models, the internals of how parameters work is a bit more complex than in the core neurolib . Each mass has its own parameters, each node then gathers the parameters of each mass within that node, and finally, the network gathers all parameters from each node in the network, etc. So hierarchy again. To make it easier to navigate through MultiModel hierarchies, some attributes are implemented in all hierarchy levels. dummy_sc = np . array ([[ 0.0 , 1.0 ], [ 1.0 , 0.0 ]]) # init MultiModelnetwork with 2 ALN nodes with dummy sc and no delays mm_net = ALNNetwork ( connectivity_matrix = dummy_sc , delay_matrix = None ) print ( mm_net ) # each network is an proper python iterator, i.e. len() is defined print ( f \"Nodes: { len ( mm_net ) } \" ) # as well as __get_item__ print ( mm_net [ 0 ]) print ( mm_net [ 1 ]) # similarly, each node is a python iterator, i.e. print ( f \"Masses in 1. node: { len ( mm_net [ 0 ]) } \" ) print ( mm_net [ 0 ][ 0 ]) print ( mm_net [ 0 ][ 1 ]) # in order to navigate through the hierarchy, each mass, node and net # has its own name and label and index # index of a node is relative within the network # index of a mass is relative within the node print ( f \"This network name: { mm_net . name } \" ) print ( f \"This network label: { mm_net . label } \" ) print ( f \"1st node name: { mm_net [ 0 ] . name } \" ) print ( f \"1st node label: { mm_net [ 0 ] . label } \" ) print ( f \"1st node index: { mm_net [ 0 ] . index } \" ) print ( f \"1st mass in 1st node name: { mm_net [ 0 ][ 0 ] . name } \" ) print ( f \"1st mass in 1st node label: { mm_net [ 0 ][ 0 ] . label } \" ) print ( f \"1st mass in 1st node index: { mm_net [ 0 ][ 0 ] . index } \" ) # you can also check number of variables etc at all levels of hierarchy print ( f \"ALN EXC num. vars: { mm_net [ 0 ][ 0 ] . num_state_variables } \" ) print ( f \"ALN INH num. vars: { mm_net [ 0 ][ 1 ] . num_state_variables } \" ) print ( f \"ALN node num. vars: { mm_net [ 0 ] . num_state_variables } \" ) print ( f \"This network num. vars: { mm_net . num_state_variables } \" ) # similarly you can check number of \"noise variables\", i.e. the number # of stochastic variables entering the simulation print ( f \"ALN EXC noise vars: { mm_net [ 0 ][ 0 ] . num_noise_variables } \" ) # etc # not sure what are the state variables? no problem! print ( f \"ALN EXC state vars: { mm_net [ 0 ][ 0 ] . state_variable_names } \" ) print ( f \"ALN node state vars: { mm_net [ 0 ] . state_variable_names } \" ) print ( f \"This network state vars: { mm_net . state_variable_names } \" ) # if you are unsure what kind of a monster you build in MultiModel, # a function `describe()` is available at all three levels - # it returns a dictionary with basic info about the model object # this is describe of a `NeuralMass` print ( \"\" ) print ( \"Mass `describe`:\" ) display ( mm_net [ 0 ][ 0 ] . describe ()) # describe of a `Node` recursively describes all masses and some more print ( \"\" ) print ( \"Node `describe`:\" ) display ( mm_net [ 0 ] . describe ()) # and finally, describe of a `Network` gives you everything print ( \"\" ) print ( \"Network `describe`:\" ) display ( mm_net . describe ()) # PRO tip: imagine highly heterogeneous network and some long simulation with it; # apart from the results you can dump `net.describe()` dictionary into json and # never forget what you've done! Brain network ALN neural mass network with 2 nodes Nodes: 2 Network node: ALN neural mass node with 2 neural masses: ALN excitatory neural mass EXC, ALN inhibitory neural mass INH Network node: ALN neural mass node with 2 neural masses: ALN excitatory neural mass EXC, ALN inhibitory neural mass INH Masses in 1. node: 2 Neural mass: ALN excitatory neural mass with 7 state variables: I_mu, I_A, I_syn_mu_exc, I_syn_mu_inh, I_syn_sigma_exc, I_syn_sigma_inh, r_mean Neural mass: ALN inhibitory neural mass with 6 state variables: I_mu, I_syn_mu_exc, I_syn_mu_inh, I_syn_sigma_exc, I_syn_sigma_inh, r_mean This network name: ALN neural mass network This network label: ALNNet 1st node name: ALN neural mass node 1st node label: ALNNode 1st node index: 0 1st mass in 1st node name: ALN excitatory neural mass 1st mass in 1st node label: ALNMassEXC 1st mass in 1st node index: 0 ALN EXC num. vars: 7 ALN INH num. vars: 6 ALN node num. vars: 13 This network num. vars: 26 ALN EXC noise vars: 1 ALN EXC state vars: ['I_mu', 'I_A', 'I_syn_mu_exc', 'I_syn_mu_inh', 'I_syn_sigma_exc', 'I_syn_sigma_inh', 'r_mean'] ALN node state vars: [['I_mu_EXC', 'I_A_EXC', 'I_syn_mu_exc_EXC', 'I_syn_mu_inh_EXC', 'I_syn_sigma_exc_EXC', 'I_syn_sigma_inh_EXC', 'r_mean_EXC', 'I_mu_INH', 'I_syn_mu_exc_INH', 'I_syn_mu_inh_INH', 'I_syn_sigma_exc_INH', 'I_syn_sigma_inh_INH', 'r_mean_INH']] This network state vars: [['I_mu_EXC', 'I_A_EXC', 'I_syn_mu_exc_EXC', 'I_syn_mu_inh_EXC', 'I_syn_sigma_exc_EXC', 'I_syn_sigma_inh_EXC', 'r_mean_EXC', 'I_mu_INH', 'I_syn_mu_exc_INH', 'I_syn_mu_inh_INH', 'I_syn_sigma_exc_INH', 'I_syn_sigma_inh_INH', 'r_mean_INH'], ['I_mu_EXC', 'I_A_EXC', 'I_syn_mu_exc_EXC', 'I_syn_mu_inh_EXC', 'I_syn_sigma_exc_EXC', 'I_syn_sigma_inh_EXC', 'r_mean_EXC', 'I_mu_INH', 'I_syn_mu_exc_INH', 'I_syn_mu_inh_INH', 'I_syn_sigma_exc_INH', 'I_syn_sigma_inh_INH', 'r_mean_INH']] Mass `describe`: {'index': 0, 'name': 'ALN excitatory neural mass', 'mass_type': 'EXC', 'num_state_variables': 7, 'num_noise_variables': 1, 'state_variable_names': ['I_mu', 'I_A', 'I_syn_mu_exc', 'I_syn_mu_inh', 'I_syn_sigma_exc', 'I_syn_sigma_inh', 'r_mean'], 'params': {'Ke': 800.0, 'Ki': 200.0, 'c_gl': 0.4, 'Ke_gl': 250.0, 'tau_se': 2.0, 'tau_si': 5.0, 'sigmae_ext': 1.5, 'Jee_max': 2.43, 'Jei_max': -3.3, 'C': 200.0, 'gL': 10.0, 'ext_exc_current': 0.0, 'ext_exc_rate': 0.0, 'a': 15.0, 'b': 40.0, 'EA': -80.0, 'tauA': 200.0, 'lambda': 10.0, 'input_0': {'type': 'OrnsteinUhlenbeckProcess', 'mu': 4.2, 'sigma': 0.0, 'tau': 5.0, 'n': 1, 'seed': None}}, 'lin_nonlin_transfer_function_filename': '/Users/nikola/.virtualenvs/neurolib/lib/python3.7/site-packages/neurolib/models/multimodel/builder/../../aln/aln-precalc/quantities_cascade.h5'} Node `describe`: {'index': 0, 'name': 'ALN neural mass node', 'num_masses': 2, 'num_num_state_variables': 13, 'num_noise_variables': 2, 'masses': [{'index': 0, 'name': 'ALN excitatory neural mass', 'mass_type': 'EXC', 'num_state_variables': 7, 'num_noise_variables': 1, 'state_variable_names': ['I_mu', 'I_A', 'I_syn_mu_exc', 'I_syn_mu_inh', 'I_syn_sigma_exc', 'I_syn_sigma_inh', 'r_mean'], 'params': {'Ke': 800.0, 'Ki': 200.0, 'c_gl': 0.4, 'Ke_gl': 250.0, 'tau_se': 2.0, 'tau_si': 5.0, 'sigmae_ext': 1.5, 'Jee_max': 2.43, 'Jei_max': -3.3, 'C': 200.0, 'gL': 10.0, 'ext_exc_current': 0.0, 'ext_exc_rate': 0.0, 'a': 15.0, 'b': 40.0, 'EA': -80.0, 'tauA': 200.0, 'lambda': 10.0, 'input_0': {'type': 'OrnsteinUhlenbeckProcess', 'mu': 4.2, 'sigma': 0.0, 'tau': 5.0, 'n': 1, 'seed': None}}, 'lin_nonlin_transfer_function_filename': '/Users/nikola/.virtualenvs/neurolib/lib/python3.7/site-packages/neurolib/models/multimodel/builder/../../aln/aln-precalc/quantities_cascade.h5'}, {'index': 1, 'name': 'ALN inhibitory neural mass', 'mass_type': 'INH', 'num_state_variables': 6, 'num_noise_variables': 1, 'state_variable_names': ['I_mu', 'I_syn_mu_exc', 'I_syn_mu_inh', 'I_syn_sigma_exc', 'I_syn_sigma_inh', 'r_mean'], 'params': {'Ke': 800.0, 'Ki': 200.0, 'c_gl': 0.4, 'Ke_gl': 250.0, 'tau_se': 2.0, 'tau_si': 5.0, 'sigmai_ext': 1.5, 'Jie_max': 2.6, 'Jii_max': -1.64, 'C': 200.0, 'gL': 10.0, 'ext_inh_current': 0.0, 'ext_inh_rate': 0.0, 'lambda': 10.0, 'input_0': {'type': 'OrnsteinUhlenbeckProcess', 'mu': 1.8, 'sigma': 0.0, 'tau': 5.0, 'n': 1, 'seed': None}}, 'lin_nonlin_transfer_function_filename': '/Users/nikola/.virtualenvs/neurolib/lib/python3.7/site-packages/neurolib/models/multimodel/builder/../../aln/aln-precalc/quantities_cascade.h5'}], 'local_connectivity': array([[0.24691358, 0.75757576], [0.23076923, 1.52439024]]), 'local_delays': array([[4., 2.], [4., 2.]])} Network `describe`: {'name': 'ALN neural mass network', 'num_nodes': 2, 'num_state_variables': 26, 'num_noise_variables': 4, 'nodes': [{'index': 0, 'name': 'ALN neural mass node', 'num_masses': 2, 'num_num_state_variables': 13, 'num_noise_variables': 2, 'masses': [{'index': 0, 'name': 'ALN excitatory neural mass', 'mass_type': 'EXC', 'num_state_variables': 7, 'num_noise_variables': 1, 'state_variable_names': ['I_mu', 'I_A', 'I_syn_mu_exc', 'I_syn_mu_inh', 'I_syn_sigma_exc', 'I_syn_sigma_inh', 'r_mean'], 'params': {'Ke': 800.0, 'Ki': 200.0, 'c_gl': 0.4, 'Ke_gl': 250.0, 'tau_se': 2.0, 'tau_si': 5.0, 'sigmae_ext': 1.5, 'Jee_max': 2.43, 'Jei_max': -3.3, 'C': 200.0, 'gL': 10.0, 'ext_exc_current': 0.0, 'ext_exc_rate': 0.0, 'a': 15.0, 'b': 40.0, 'EA': -80.0, 'tauA': 200.0, 'lambda': 10.0, 'input_0': {'type': 'OrnsteinUhlenbeckProcess', 'mu': 4.2, 'sigma': 0.0, 'tau': 5.0, 'n': 1, 'seed': None}}, 'lin_nonlin_transfer_function_filename': '/Users/nikola/.virtualenvs/neurolib/lib/python3.7/site-packages/neurolib/models/multimodel/builder/../../aln/aln-precalc/quantities_cascade.h5'}, {'index': 1, 'name': 'ALN inhibitory neural mass', 'mass_type': 'INH', 'num_state_variables': 6, 'num_noise_variables': 1, 'state_variable_names': ['I_mu', 'I_syn_mu_exc', 'I_syn_mu_inh', 'I_syn_sigma_exc', 'I_syn_sigma_inh', 'r_mean'], 'params': {'Ke': 800.0, 'Ki': 200.0, 'c_gl': 0.4, 'Ke_gl': 250.0, 'tau_se': 2.0, 'tau_si': 5.0, 'sigmai_ext': 1.5, 'Jie_max': 2.6, 'Jii_max': -1.64, 'C': 200.0, 'gL': 10.0, 'ext_inh_current': 0.0, 'ext_inh_rate': 0.0, 'lambda': 10.0, 'input_0': {'type': 'OrnsteinUhlenbeckProcess', 'mu': 1.8, 'sigma': 0.0, 'tau': 5.0, 'n': 1, 'seed': None}}, 'lin_nonlin_transfer_function_filename': '/Users/nikola/.virtualenvs/neurolib/lib/python3.7/site-packages/neurolib/models/multimodel/builder/../../aln/aln-precalc/quantities_cascade.h5'}], 'local_connectivity': array([[0.24691358, 0.75757576], [0.23076923, 1.52439024]]), 'local_delays': array([[4., 2.], [4., 2.]])}, {'index': 1, 'name': 'ALN neural mass node', 'num_masses': 2, 'num_num_state_variables': 13, 'num_noise_variables': 2, 'masses': [{'index': 0, 'name': 'ALN excitatory neural mass', 'mass_type': 'EXC', 'num_state_variables': 7, 'num_noise_variables': 1, 'state_variable_names': ['I_mu', 'I_A', 'I_syn_mu_exc', 'I_syn_mu_inh', 'I_syn_sigma_exc', 'I_syn_sigma_inh', 'r_mean'], 'params': {'Ke': 800.0, 'Ki': 200.0, 'c_gl': 0.4, 'Ke_gl': 250.0, 'tau_se': 2.0, 'tau_si': 5.0, 'sigmae_ext': 1.5, 'Jee_max': 2.43, 'Jei_max': -3.3, 'C': 200.0, 'gL': 10.0, 'ext_exc_current': 0.0, 'ext_exc_rate': 0.0, 'a': 15.0, 'b': 40.0, 'EA': -80.0, 'tauA': 200.0, 'lambda': 10.0, 'input_0': {'type': 'OrnsteinUhlenbeckProcess', 'mu': 4.2, 'sigma': 0.0, 'tau': 5.0, 'n': 1, 'seed': None}}, 'lin_nonlin_transfer_function_filename': '/Users/nikola/.virtualenvs/neurolib/lib/python3.7/site-packages/neurolib/models/multimodel/builder/../../aln/aln-precalc/quantities_cascade.h5'}, {'index': 1, 'name': 'ALN inhibitory neural mass', 'mass_type': 'INH', 'num_state_variables': 6, 'num_noise_variables': 1, 'state_variable_names': ['I_mu', 'I_syn_mu_exc', 'I_syn_mu_inh', 'I_syn_sigma_exc', 'I_syn_sigma_inh', 'r_mean'], 'params': {'Ke': 800.0, 'Ki': 200.0, 'c_gl': 0.4, 'Ke_gl': 250.0, 'tau_se': 2.0, 'tau_si': 5.0, 'sigmai_ext': 1.5, 'Jie_max': 2.6, 'Jii_max': -1.64, 'C': 200.0, 'gL': 10.0, 'ext_inh_current': 0.0, 'ext_inh_rate': 0.0, 'lambda': 10.0, 'input_0': {'type': 'OrnsteinUhlenbeckProcess', 'mu': 1.8, 'sigma': 0.0, 'tau': 5.0, 'n': 1, 'seed': None}}, 'lin_nonlin_transfer_function_filename': '/Users/nikola/.virtualenvs/neurolib/lib/python3.7/site-packages/neurolib/models/multimodel/builder/../../aln/aln-precalc/quantities_cascade.h5'}], 'local_connectivity': array([[0.24691358, 0.75757576], [0.23076923, 1.52439024]]), 'local_delays': array([[4., 2.], [4., 2.]])}], 'connectivity': array([[0., 1.], [1., 0.]]), 'delays': array([[0., 0.], [0., 0.]])} # now let us check the parameters.. for this we initialise MultiModel in neurolib's fashion aln_net = MultiModel ( mm_net ) # parameters are accessible via .params aln_net . params # as you can see the parameters are flattened nested dictionary which follows this nomenclature # {\"<network label>.<node label>_index.<mass label>_index.<param name>: param value\"} {'ALNNet.ALNNode_0.ALNMassEXC_0.Ke': 800.0, 'ALNNet.ALNNode_0.ALNMassEXC_0.Ki': 200.0, 'ALNNet.ALNNode_0.ALNMassEXC_0.c_gl': 0.4, 'ALNNet.ALNNode_0.ALNMassEXC_0.Ke_gl': 250.0, 'ALNNet.ALNNode_0.ALNMassEXC_0.tau_se': 2.0, 'ALNNet.ALNNode_0.ALNMassEXC_0.tau_si': 5.0, 'ALNNet.ALNNode_0.ALNMassEXC_0.sigmae_ext': 1.5, 'ALNNet.ALNNode_0.ALNMassEXC_0.Jee_max': 2.43, 'ALNNet.ALNNode_0.ALNMassEXC_0.Jei_max': -3.3, 'ALNNet.ALNNode_0.ALNMassEXC_0.C': 200.0, 'ALNNet.ALNNode_0.ALNMassEXC_0.gL': 10.0, 'ALNNet.ALNNode_0.ALNMassEXC_0.ext_exc_current': 0.0, 'ALNNet.ALNNode_0.ALNMassEXC_0.ext_exc_rate': 0.0, 'ALNNet.ALNNode_0.ALNMassEXC_0.a': 15.0, 'ALNNet.ALNNode_0.ALNMassEXC_0.b': 40.0, 'ALNNet.ALNNode_0.ALNMassEXC_0.EA': -80.0, 'ALNNet.ALNNode_0.ALNMassEXC_0.tauA': 200.0, 'ALNNet.ALNNode_0.ALNMassEXC_0.lambda': 10.0, 'ALNNet.ALNNode_0.ALNMassEXC_0.input_0.type': 'OrnsteinUhlenbeckProcess', 'ALNNet.ALNNode_0.ALNMassEXC_0.input_0.mu': 4.2, 'ALNNet.ALNNode_0.ALNMassEXC_0.input_0.sigma': 0.0, 'ALNNet.ALNNode_0.ALNMassEXC_0.input_0.tau': 5.0, 'ALNNet.ALNNode_0.ALNMassEXC_0.input_0.n': 1, 'ALNNet.ALNNode_0.ALNMassEXC_0.input_0.seed': None, 'ALNNet.ALNNode_0.ALNMassINH_1.Ke': 800.0, 'ALNNet.ALNNode_0.ALNMassINH_1.Ki': 200.0, 'ALNNet.ALNNode_0.ALNMassINH_1.c_gl': 0.4, 'ALNNet.ALNNode_0.ALNMassINH_1.Ke_gl': 250.0, 'ALNNet.ALNNode_0.ALNMassINH_1.tau_se': 2.0, 'ALNNet.ALNNode_0.ALNMassINH_1.tau_si': 5.0, 'ALNNet.ALNNode_0.ALNMassINH_1.sigmai_ext': 1.5, 'ALNNet.ALNNode_0.ALNMassINH_1.Jie_max': 2.6, 'ALNNet.ALNNode_0.ALNMassINH_1.Jii_max': -1.64, 'ALNNet.ALNNode_0.ALNMassINH_1.C': 200.0, 'ALNNet.ALNNode_0.ALNMassINH_1.gL': 10.0, 'ALNNet.ALNNode_0.ALNMassINH_1.ext_inh_current': 0.0, 'ALNNet.ALNNode_0.ALNMassINH_1.ext_inh_rate': 0.0, 'ALNNet.ALNNode_0.ALNMassINH_1.lambda': 10.0, 'ALNNet.ALNNode_0.ALNMassINH_1.input_0.type': 'OrnsteinUhlenbeckProcess', 'ALNNet.ALNNode_0.ALNMassINH_1.input_0.mu': 1.8, 'ALNNet.ALNNode_0.ALNMassINH_1.input_0.sigma': 0.0, 'ALNNet.ALNNode_0.ALNMassINH_1.input_0.tau': 5.0, 'ALNNet.ALNNode_0.ALNMassINH_1.input_0.n': 1, 'ALNNet.ALNNode_0.ALNMassINH_1.input_0.seed': None, 'ALNNet.ALNNode_0.local_connectivity': array([[0.24691358, 0.75757576], [0.23076923, 1.52439024]]), 'ALNNet.ALNNode_0.local_delays': array([[4., 2.], [4., 2.]]), 'ALNNet.ALNNode_1.ALNMassEXC_0.Ke': 800.0, 'ALNNet.ALNNode_1.ALNMassEXC_0.Ki': 200.0, 'ALNNet.ALNNode_1.ALNMassEXC_0.c_gl': 0.4, 'ALNNet.ALNNode_1.ALNMassEXC_0.Ke_gl': 250.0, 'ALNNet.ALNNode_1.ALNMassEXC_0.tau_se': 2.0, 'ALNNet.ALNNode_1.ALNMassEXC_0.tau_si': 5.0, 'ALNNet.ALNNode_1.ALNMassEXC_0.sigmae_ext': 1.5, 'ALNNet.ALNNode_1.ALNMassEXC_0.Jee_max': 2.43, 'ALNNet.ALNNode_1.ALNMassEXC_0.Jei_max': -3.3, 'ALNNet.ALNNode_1.ALNMassEXC_0.C': 200.0, 'ALNNet.ALNNode_1.ALNMassEXC_0.gL': 10.0, 'ALNNet.ALNNode_1.ALNMassEXC_0.ext_exc_current': 0.0, 'ALNNet.ALNNode_1.ALNMassEXC_0.ext_exc_rate': 0.0, 'ALNNet.ALNNode_1.ALNMassEXC_0.a': 15.0, 'ALNNet.ALNNode_1.ALNMassEXC_0.b': 40.0, 'ALNNet.ALNNode_1.ALNMassEXC_0.EA': -80.0, 'ALNNet.ALNNode_1.ALNMassEXC_0.tauA': 200.0, 'ALNNet.ALNNode_1.ALNMassEXC_0.lambda': 10.0, 'ALNNet.ALNNode_1.ALNMassEXC_0.input_0.type': 'OrnsteinUhlenbeckProcess', 'ALNNet.ALNNode_1.ALNMassEXC_0.input_0.mu': 4.2, 'ALNNet.ALNNode_1.ALNMassEXC_0.input_0.sigma': 0.0, 'ALNNet.ALNNode_1.ALNMassEXC_0.input_0.tau': 5.0, 'ALNNet.ALNNode_1.ALNMassEXC_0.input_0.n': 1, 'ALNNet.ALNNode_1.ALNMassEXC_0.input_0.seed': None, 'ALNNet.ALNNode_1.ALNMassINH_1.Ke': 800.0, 'ALNNet.ALNNode_1.ALNMassINH_1.Ki': 200.0, 'ALNNet.ALNNode_1.ALNMassINH_1.c_gl': 0.4, 'ALNNet.ALNNode_1.ALNMassINH_1.Ke_gl': 250.0, 'ALNNet.ALNNode_1.ALNMassINH_1.tau_se': 2.0, 'ALNNet.ALNNode_1.ALNMassINH_1.tau_si': 5.0, 'ALNNet.ALNNode_1.ALNMassINH_1.sigmai_ext': 1.5, 'ALNNet.ALNNode_1.ALNMassINH_1.Jie_max': 2.6, 'ALNNet.ALNNode_1.ALNMassINH_1.Jii_max': -1.64, 'ALNNet.ALNNode_1.ALNMassINH_1.C': 200.0, 'ALNNet.ALNNode_1.ALNMassINH_1.gL': 10.0, 'ALNNet.ALNNode_1.ALNMassINH_1.ext_inh_current': 0.0, 'ALNNet.ALNNode_1.ALNMassINH_1.ext_inh_rate': 0.0, 'ALNNet.ALNNode_1.ALNMassINH_1.lambda': 10.0, 'ALNNet.ALNNode_1.ALNMassINH_1.input_0.type': 'OrnsteinUhlenbeckProcess', 'ALNNet.ALNNode_1.ALNMassINH_1.input_0.mu': 1.8, 'ALNNet.ALNNode_1.ALNMassINH_1.input_0.sigma': 0.0, 'ALNNet.ALNNode_1.ALNMassINH_1.input_0.tau': 5.0, 'ALNNet.ALNNode_1.ALNMassINH_1.input_0.n': 1, 'ALNNet.ALNNode_1.ALNMassINH_1.input_0.seed': None, 'ALNNet.ALNNode_1.local_connectivity': array([[0.24691358, 0.75757576], [0.23076923, 1.52439024]]), 'ALNNet.ALNNode_1.local_delays': array([[4., 2.], [4., 2.]]), 'ALNNet.connectivity': array([[0., 1.], [1., 0.]]), 'ALNNet.delays': array([[0., 0.], [0., 0.]]), 'duration': 2000, 'dt': 0.1, 'seed': None, 'backend': 'jitcdde', 'name': 'ALNNet', 'description': 'ALN neural mass network', 'N': 2, 'Cmat': array([[0., 1.], [1., 0.]]), 'sampling_dt': 0.1} # as you can see there are a lot of parameters for simple 2-node network of ALN models # typically you want to change parameters of all nodes at the same time # fortunately, model.params is not your basic dictionary, it's a special one, we call it `star` dictionary, # because you can do this: display ( aln_net . params [ \"*tau\" ]) print ( \"\" ) # so yes, star works as a glob identifier, so by selecting \"*tau\" I want all parameters named tau # (I dont care from which mass or node it comes) # what if I want to change taus only in EXC masses? easy: display ( aln_net . params [ \"*EXC*tau\" ]) print ( \"\" ) # or maybe I want to change taus only in the first node? display ( aln_net . params [ \"*Node_0*tau\" ]) print ( \"\" ) # of course, you can change a param value with this aln_net . params [ \"*Node_0*tau\" ] = 13.2 display ( aln_net . params [ \"*Node_0*tau\" ]) aln_net . params [ \"*Node_0*tau\" ] = 5.0 {'ALNNet.ALNNode_0.ALNMassEXC_0.input_0.tau': 5.0, 'ALNNet.ALNNode_0.ALNMassINH_1.input_0.tau': 5.0, 'ALNNet.ALNNode_1.ALNMassEXC_0.input_0.tau': 5.0, 'ALNNet.ALNNode_1.ALNMassINH_1.input_0.tau': 5.0} {'ALNNet.ALNNode_0.ALNMassEXC_0.input_0.tau': 5.0, 'ALNNet.ALNNode_1.ALNMassEXC_0.input_0.tau': 5.0} {'ALNNet.ALNNode_0.ALNMassEXC_0.input_0.tau': 5.0, 'ALNNet.ALNNode_0.ALNMassINH_1.input_0.tau': 5.0} {'ALNNet.ALNNode_0.ALNMassEXC_0.input_0.tau': 13.2, 'ALNNet.ALNNode_0.ALNMassINH_1.input_0.tau': 13.2} # case: I want to change all taus except \"noise\" taus # this gives all the taus, including \"noise\" display ( aln_net . params [ \"*tau*\" ]) print ( \"\" ) # pipe symbol filters out unwanted keys - here we have only taus which key does NOT include \"input\" display ( aln_net . params [ \"*tau*|input\" ]) {'ALNNet.ALNNode_0.ALNMassEXC_0.tau_se': 2.0, 'ALNNet.ALNNode_0.ALNMassEXC_0.tau_si': 5.0, 'ALNNet.ALNNode_0.ALNMassEXC_0.tauA': 200.0, 'ALNNet.ALNNode_0.ALNMassEXC_0.input_0.tau': 5.0, 'ALNNet.ALNNode_0.ALNMassINH_1.tau_se': 2.0, 'ALNNet.ALNNode_0.ALNMassINH_1.tau_si': 5.0, 'ALNNet.ALNNode_0.ALNMassINH_1.input_0.tau': 5.0, 'ALNNet.ALNNode_1.ALNMassEXC_0.tau_se': 2.0, 'ALNNet.ALNNode_1.ALNMassEXC_0.tau_si': 5.0, 'ALNNet.ALNNode_1.ALNMassEXC_0.tauA': 200.0, 'ALNNet.ALNNode_1.ALNMassEXC_0.input_0.tau': 5.0, 'ALNNet.ALNNode_1.ALNMassINH_1.tau_se': 2.0, 'ALNNet.ALNNode_1.ALNMassINH_1.tau_si': 5.0, 'ALNNet.ALNNode_1.ALNMassINH_1.input_0.tau': 5.0} {'ALNNet.ALNNode_0.ALNMassEXC_0.tau_se': 2.0, 'ALNNet.ALNNode_0.ALNMassEXC_0.tau_si': 5.0, 'ALNNet.ALNNode_0.ALNMassEXC_0.tauA': 200.0, 'ALNNet.ALNNode_0.ALNMassINH_1.tau_se': 2.0, 'ALNNet.ALNNode_0.ALNMassINH_1.tau_si': 5.0, 'ALNNet.ALNNode_1.ALNMassEXC_0.tau_se': 2.0, 'ALNNet.ALNNode_1.ALNMassEXC_0.tau_si': 5.0, 'ALNNet.ALNNode_1.ALNMassEXC_0.tauA': 200.0, 'ALNNet.ALNNode_1.ALNMassINH_1.tau_se': 2.0, 'ALNNet.ALNNode_1.ALNMassINH_1.tau_si': 5.0} max_rate_e = [] min_rate_e = [] # number low for testing: mue_inputs = np . linspace ( 0 , 2 , 2 ) # use: mue_inputs = np.linspace(0, 2, 20) # not let's match ALN parameters to those in example-0-aln-minimal and recreate # the 1D bif. diagram aln . params [ \"*INH*input*mu\" ] = 0.5 aln . params [ \"*b\" ] = 0.0 aln . params [ \"ALNNode_0.ALNMassEXC_0.a\" ] = 0.0 for mue in mue_inputs : aln . params [ \"*EXC*input*mu\" ] = mue display ( aln . params [ \"*EXC*input*mu\" ]) aln . run () max_rate_e . append ( np . max ( aln . output [ 0 , - int ( 1000 / aln . params [ \"sampling_dt\" ]) :])) min_rate_e . append ( np . min ( aln . output [ 0 , - int ( 1000 / aln . params [ \"sampling_dt\" ]) :])) {'ALNNode_0.ALNMassEXC_0.input_0.mu': 0.0} /Users/nikola/.virtualenvs/neurolib/lib/python3.7/site-packages/jitcdde/_jitcdde.py:1491: UserWarning: Your input past does not begin at t=0 but at t=1.0. Values before the beginning of the past will be extrapolated. You very likely do not want this. warn(f\"Your input past does not begin at t=0 but at t={input[0].time}. Values before the beginning of the past will be extrapolated. You very likely do not want this.\") Using default integration parameters. 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5000/5000 [00:00<00:00, 12088.04it/s] {'ALNNode_0.ALNMassEXC_0.input_0.mu': 0.1} Using default integration parameters. 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5000/5000 [00:00<00:00, 11923.41it/s] {'ALNNode_0.ALNMassEXC_0.input_0.mu': 0.2} Using default integration parameters. 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5000/5000 [00:00<00:00, 11831.34it/s] {'ALNNode_0.ALNMassEXC_0.input_0.mu': 0.30000000000000004} Using default integration parameters. 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5000/5000 [00:00<00:00, 11601.52it/s] {'ALNNode_0.ALNMassEXC_0.input_0.mu': 0.4} Using default integration parameters. 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5000/5000 [00:00<00:00, 11838.99it/s] {'ALNNode_0.ALNMassEXC_0.input_0.mu': 0.5} Using default integration parameters. 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5000/5000 [00:00<00:00, 11134.30it/s] {'ALNNode_0.ALNMassEXC_0.input_0.mu': 0.6000000000000001} Using default integration parameters. 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5000/5000 [00:01<00:00, 4698.40it/s] {'ALNNode_0.ALNMassEXC_0.input_0.mu': 0.7000000000000001} Using default integration parameters. 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5000/5000 [00:01<00:00, 3559.94it/s] {'ALNNode_0.ALNMassEXC_0.input_0.mu': 0.8} Using default integration parameters. 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5000/5000 [00:01<00:00, 3242.48it/s] {'ALNNode_0.ALNMassEXC_0.input_0.mu': 0.9} Using default integration parameters. 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5000/5000 [00:01<00:00, 3419.71it/s] {'ALNNode_0.ALNMassEXC_0.input_0.mu': 1.0} Using default integration parameters. 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5000/5000 [00:01<00:00, 3356.80it/s] {'ALNNode_0.ALNMassEXC_0.input_0.mu': 1.1} Using default integration parameters. 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5000/5000 [00:01<00:00, 3586.59it/s] {'ALNNode_0.ALNMassEXC_0.input_0.mu': 1.2000000000000002} Using default integration parameters. 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5000/5000 [00:01<00:00, 4160.26it/s] {'ALNNode_0.ALNMassEXC_0.input_0.mu': 1.3} Using default integration parameters. 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5000/5000 [00:00<00:00, 5574.75it/s] {'ALNNode_0.ALNMassEXC_0.input_0.mu': 1.4000000000000001} Using default integration parameters. 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5000/5000 [00:00<00:00, 9851.36it/s] {'ALNNode_0.ALNMassEXC_0.input_0.mu': 1.5} Using default integration parameters. 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5000/5000 [00:00<00:00, 10735.54it/s] {'ALNNode_0.ALNMassEXC_0.input_0.mu': 1.6} Using default integration parameters. 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5000/5000 [00:00<00:00, 11248.32it/s] {'ALNNode_0.ALNMassEXC_0.input_0.mu': 1.7000000000000002} Using default integration parameters. 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5000/5000 [00:00<00:00, 11078.22it/s] {'ALNNode_0.ALNMassEXC_0.input_0.mu': 1.8} Using default integration parameters. 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5000/5000 [00:00<00:00, 11982.51it/s] {'ALNNode_0.ALNMassEXC_0.input_0.mu': 1.9000000000000001} Using default integration parameters. 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5000/5000 [00:00<00:00, 12192.60it/s] {'ALNNode_0.ALNMassEXC_0.input_0.mu': 2.0} Using default integration parameters. 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5000/5000 [00:00<00:00, 11837.18it/s] plt . plot ( mue_inputs , max_rate_e , c = \"k\" , lw = 2 ) plt . plot ( mue_inputs , min_rate_e , c = \"k\" , lw = 2 ) plt . title ( \"Bifurcation diagram of the aln model\" ) plt . xlabel ( \"Input to excitatory population\" ) plt . ylabel ( \"Min / max firing rate [kHz]\" ) Text(0, 0.5, 'Min / max firing rate [kHz]') Connecting two models So far, we only showed how to use MultiModel with a single dynamical model (ALN), and that is no fun. I mean, all this is already possible in core neurolib , and it the core, it is much faster. However, the real strength of MultiModel is combining different models into one network. Let us build a thalamocortical model using one node of the thalamic population model and one node of ALN, representing the cortex. # first - imports from neurolib.models.multimodel import ALNNode , ThalamicNode from neurolib.models.multimodel.builder.base.constants import EXC , INH from neurolib.models.multimodel.builder.base.network import Network # let us start by subclassing the Network class ALNThalamusMiniNetwork ( Network ): \"\"\" Simple thalamocortical motif: 1 cortical node ALN + 1 NMM thalamus. \"\"\" # provide basic attributes as name and label name = \"ALN 1 node + Thalamus\" label = \"ALNThlmNet\" # define which variables are used to sync, i.e. what coupling variables our nodes need sync_variables = [ # both nodes are connected via excitatory synapses \"network_exc_exc\" , # ALN requires also squared coupling \"network_exc_exc_sq\" , # and INH mass in thalamus also receives excitatory coupling \"network_inh_exc\" , ] # lastly, we need to define what is default output of the network (this has to be the # variable present in all nodes) # for us it is excitatory firing rates default_output = f \"r_mean_ { EXC } \" # define all output vars of any interest to us - EXC and INH firing rates and adaptive current in ALN output_vars = [ f \"r_mean_ { EXC } \" , f \"r_mean_ { INH } \" , f \"I_A_ { EXC } \" ] def __init__ ( self , connectivity_matrix , delay_matrix ): # self connections are resolved within nodes, so zeroes at the diagonal assert np . all ( np . diag ( connectivity_matrix ) == 0.0 ) # init ALN node with index 0 aln_node = ALNNode () aln_node . index = 0 # index where the state variables start - for first node it is always 0 aln_node . idx_state_var = 0 # set correct indices for noise input for mass in aln_node : mass . noise_input_idx = [ mass . index ] # init thalamus node with index 1 thalamus = ThalamicNode () thalamus . index = 1 # thalamic state variables start where ALN state variables end - easy thalamus . idx_state_var = aln_node . num_state_variables # set correct indices of noise input - one per mass, after ALN noise # indices for mass in thalamus : mass . noise_input_idx = [ aln_node . num_noise_variables + mass . index ] # now super.__init__ network with these two nodes: super () . __init__ ( nodes = [ aln_node , thalamus ], connectivity_matrix = connectivity_matrix , delay_matrix = delay_matrix , ) # done! the only other thing we need to do, is to set the coupling variables # thalamus vs. ALN are coupled via their firing rates and here we setup the # coupling matrices; the super class `Network` comes with some convenient # functions for this def _sync ( self ): \"\"\" Set coupling variables - the ones we defined in `sync_variables` _sync returns a list of tuples where the first element in each tuple is the coupling \"symbol\" and the second is the actual mathematical expression for the ease of doing this, `Network` class contains convenience functions for this: - _additive_coupling - _diffusive_coupling - _no_coupling here we use additive coupling only \"\"\" # get indices of coupling variables from all nodes exc_indices = [ next ( iter ( node . all_couplings ( mass_indices = node . excitatory_masses . tolist () ) ) ) for node in self ] assert len ( exc_indices ) == len ( self ) return ( # basic EXC <-> EXC coupling # within_node_idx is a list of len 2 (because we have two nodes) # with indices of coupling variables within the respective state vectors self . _additive_coupling ( within_node_idx = exc_indices , symbol = \"network_exc_exc\" ) # squared EXC <-> EXC coupling (only to ALN) + self . _additive_coupling ( within_node_idx = exc_indices , symbol = \"network_exc_exc_sq\" , # square connectivity connectivity = self . connectivity * self . connectivity , ) # EXC -> INH coupling (only to thalamus) + self . _additive_coupling ( within_node_idx = exc_indices , symbol = \"network_inh_exc\" , connectivity = self . connectivity , ) + super () . _sync () ) # lets check what we have SC = np . array ([[ 0.0 , 0.15 ], [ 1.2 , 0.0 ]]) delays = np . array ([[ 0.0 , 13.0 ], [ 13.0 , 0.0 ]]) # thalamocortical delay = 13ms thalamocortical = MultiModel ( ALNThalamusMiniNetwork ( connectivity_matrix = SC , delay_matrix = delays )) # original `MultiModel` instance is always accessible as `MultiModel.model_instance` display ( thalamocortical . model_instance . describe ()) {'name': 'ALN 1 node + Thalamus', 'num_nodes': 2, 'num_state_variables': 30, 'num_noise_variables': 4, 'nodes': [{'index': 0, 'name': 'ALN neural mass node', 'num_masses': 2, 'num_num_state_variables': 13, 'num_noise_variables': 2, 'masses': [{'index': 0, 'name': 'ALN excitatory neural mass', 'mass_type': 'EXC', 'num_state_variables': 7, 'num_noise_variables': 1, 'state_variable_names': ['I_mu', 'I_A', 'I_syn_mu_exc', 'I_syn_mu_inh', 'I_syn_sigma_exc', 'I_syn_sigma_inh', 'r_mean'], 'params': {'Ke': 800.0, 'Ki': 200.0, 'c_gl': 0.4, 'Ke_gl': 250.0, 'tau_se': 2.0, 'tau_si': 5.0, 'sigmae_ext': 1.5, 'Jee_max': 2.43, 'Jei_max': -3.3, 'C': 200.0, 'gL': 10.0, 'ext_exc_current': 0.0, 'ext_exc_rate': 0.0, 'a': 15.0, 'b': 40.0, 'EA': -80.0, 'tauA': 200.0, 'lambda': 10.0, 'input_0': {'type': 'OrnsteinUhlenbeckProcess', 'mu': 2.0, 'sigma': 0.0, 'tau': 5.0, 'n': 1, 'seed': None}}, 'lin_nonlin_transfer_function_filename': '/Users/nikola/.virtualenvs/neurolib/lib/python3.7/site-packages/neurolib/models/multimodel/builder/../../aln/aln-precalc/quantities_cascade.h5'}, {'index': 1, 'name': 'ALN inhibitory neural mass', 'mass_type': 'INH', 'num_state_variables': 6, 'num_noise_variables': 1, 'state_variable_names': ['I_mu', 'I_syn_mu_exc', 'I_syn_mu_inh', 'I_syn_sigma_exc', 'I_syn_sigma_inh', 'r_mean'], 'params': {'Ke': 800.0, 'Ki': 200.0, 'c_gl': 0.4, 'Ke_gl': 250.0, 'tau_se': 2.0, 'tau_si': 5.0, 'sigmai_ext': 1.5, 'Jie_max': 2.6, 'Jii_max': -1.64, 'C': 200.0, 'gL': 10.0, 'ext_inh_current': 0.0, 'ext_inh_rate': 0.0, 'lambda': 10.0, 'input_0': {'type': 'OrnsteinUhlenbeckProcess', 'mu': 0.5, 'sigma': 0.0, 'tau': 5.0, 'n': 1, 'seed': None}}, 'lin_nonlin_transfer_function_filename': '/Users/nikola/.virtualenvs/neurolib/lib/python3.7/site-packages/neurolib/models/multimodel/builder/../../aln/aln-precalc/quantities_cascade.h5'}], 'local_connectivity': array([[0.24691358, 0.75757576], [0.23076923, 1.52439024]]), 'local_delays': array([[4., 2.], [4., 2.]])}, {'index': 1, 'name': 'Thalamic mass model node', 'num_masses': 2, 'num_num_state_variables': 17, 'num_noise_variables': 2, 'masses': [{'index': 0, 'name': 'Thalamocortical relay mass', 'mass_type': 'EXC', 'num_state_variables': 10, 'num_noise_variables': 1, 'state_variable_names': ['V', 'Ca', 'h_T', 'm_h1', 'm_h2', 's_e', 's_i', 'ds_e', 'ds_i', 'r_mean'], 'params': {'tau': 20.0, 'Q_max': 0.4, 'theta': -58.5, 'sigma': 6.0, 'C1': 1.8137993642, 'C_m': 1.0, 'gamma_e': 0.07, 'gamma_r': 0.1, 'g_L': 1.0, 'g_GABA': 1.0, 'g_AMPA': 1.0, 'g_LK': 0.018, 'g_T': 3.0, 'g_h': 0.062, 'E_AMPA': 0.0, 'E_GABA': -70.0, 'E_L': -70.0, 'E_K': -100.0, 'E_Ca': 120.0, 'E_h': -40.0, 'alpha_Ca': -5.18e-05, 'tau_Ca': 10.0, 'Ca_0': 0.00024, 'k1': 25000000.0, 'k2': 0.0004, 'k3': 0.1, 'k4': 0.001, 'n_P': 4.0, 'g_inc': 2.0, 'ext_current': 0.0, 'lambda': 10.0, 'input_0': {'type': 'OrnsteinUhlenbeckProcess', 'mu': 0.0, 'sigma': 0.0, 'tau': 5.0, 'n': 1, 'seed': None}}}, {'index': 1, 'name': 'Thalamic reticular nuclei mass', 'mass_type': 'INH', 'num_state_variables': 7, 'num_noise_variables': 1, 'state_variable_names': ['V', 'h_T', 's_e', 's_i', 'ds_e', 'ds_i', 'r_mean'], 'params': {'tau': 20.0, 'Q_max': 0.4, 'theta': -58.5, 'sigma': 6.0, 'C1': 1.8137993642, 'C_m': 1.0, 'gamma_e': 0.07, 'gamma_r': 0.1, 'g_L': 1.0, 'g_GABA': 1.0, 'g_AMPA': 1.0, 'g_LK': 0.018, 'g_T': 2.3, 'E_AMPA': 0.0, 'E_GABA': -70.0, 'E_L': -70.0, 'E_K': -100.0, 'E_Ca': 120.0, 'ext_current': 0.0, 'lambda': 10.0, 'input_0': {'type': 'ZeroInput', 'n': 1, 'seed': None}}}], 'local_connectivity': array([[ 0., 5.], [ 3., 25.]]), 'local_delays': array([[0., 0.], [0., 0.]])}], 'connectivity': array([[0. , 0.15], [1.2 , 0. ]]), 'delays': array([[ 0., 13.], [13., 0.]])} # fix parameters for interesting regime thalamocortical . params [ \"*g_LK\" ] = 0.032 # K-leak conductance in thalamus thalamocortical . params [ \"ALNThlmNet.ALNNode_0.ALNMassEXC_0.a\" ] = 0.0 # no firing rate adaptation thalamocortical . params [ \"*b\" ] = 15.0 # spike adaptation thalamocortical . params [ \"*tauA\" ] = 1000.0 # slow adaptation timescale thalamocortical . params [ \"*EXC*mu\" ] = 3.4 # background excitation to ALN thalamocortical . params [ \"*INH*mu\" ] = 3.5 # background inhibition to ALN thalamocortical . params [ \"*ALNMass*input*sigma\" ] = 0.05 # noise in ALN thalamocortical . params [ \"*TCR*input*sigma\" ] = 0.005 # noise in thalamus thalamocortical . params [ \"*input*tau\" ] = 5.0 # timescale of OU process # number low for testing: thalamocortical . params [ \"duration\" ] = 2000. # use: thalamocortical.params[\"duration\"] = 20000. # 20 seconds simulation thalamocortical . params [ \"sampling_dt\" ] = 1.0 thalamocortical . run () /Users/nikola/.virtualenvs/neurolib/lib/python3.7/site-packages/jitcdde/_jitcdde.py:1491: UserWarning: Your input past does not begin at t=0 but at t=1.0. Values before the beginning of the past will be extrapolated. You very likely do not want this. warn(f\"Your input past does not begin at t=0 but at t={input[0].time}. Values before the beginning of the past will be extrapolated. You very likely do not want this.\") Using default integration parameters. 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 2000/2000 [00:00<00:00, 2994.08it/s] _ , axs = plt . subplots ( nrows = 2 , ncols = 1 , sharex = True , figsize = ( 12 , 6 )) axs [ 0 ] . plot ( thalamocortical . t , thalamocortical . r_mean_EXC [ 0 , :] . T ) axs [ 0 ] . set_ylabel ( \"ALN firing rate [kHz]\" ) axs [ 1 ] . plot ( thalamocortical . t , thalamocortical . r_mean_EXC [ 1 , :] . T , color = \"C1\" ) axs [ 1 ] . set_ylabel ( \"thalamus firing rate [kHz]\" ) axs [ 1 ] . set_xlabel ( \"time [sec]\" ) Text(0.5, 0, 'time [sec]') We can nicely see the interplay between cortical UP and DOWN states (with UP state being dominant and irregular DOWN state excursions) and thalamic spindles. Combining different models might seem hard at first, but it is actually kind of intuitive and works as you would connect models with pen and paper. The only necessary thing is to define and initialize individual nodes in the network (done in __init__ function) and then specify the type of coupling between these nodes (in _sync() function). That's it! For more information on how to build a network and for a deeper understanding of how exactly MultiModel works, please check out our following example, where we will build the Jansen-Rit network from scratch!","title":"Example 4 multimodel intro"},{"location":"examples/example-4-multimodel-intro/#multimodel-framework","text":"Here we showcase the MultiModel framework, a standalone framework within neurolib to create and simulate heterogeneous brain models. By heterogeneous, we mean that a brain network may consist of nodes with totally different dynamics coupled by a single variable. Imagine having a population model for the thalamus, a different model for the hippocampus, and a different model for the cortex. Of course, the parameters and the model dynamics, and the equations would be completely different. This is all possible and even relatively easy in MultiModel .","title":"MultiModel framework"},{"location":"examples/example-4-multimodel-intro/#implemented-models","text":"To facilitate your heterogeneous experiments, the MultiModel comes with few population models predefined for you. We can mix these into a brain network in many ways. We provide: aln : the adaptive linear-nonlinear population model, it is a mean-field approximation of delay-coupled network of excitatory and inhibitory adaptive exponential integrate-and-fire neurons (AdEx) fitzhugh_nagumo : the FitzHugh-Nagumo model, a two-dimensional slow-fast system, is a simplified version of the famous 4D Hodgkin\u2013Huxley model hopf : the Hopf model (sometimes called a Stuart-Landau oscillator) is a 1D nonlinear model and serves as a normal form of Hopf bifurcation in dynamical systems thalamus : a conductance-based population rate model of the thalamus, it is a Jansen-Rit like population model with current-based voltage evolution, includes adaptation ( K -leak), calcium, and rectifying currents wilson_cowan : the Wilson-Cowan neuronal model is a simple model of interacting interconnected neurons of excitatory and inhibitory subtypes wong_wang : a Wong-Wang model, a model approximating a biophysically-based cortical network model. Our implementation comes in two flavors: original Wong-Wang model with excitatory and inhibitory subtypes reduced Wong-Wang model with simpler dynamics and no EXC/INH distinction Moreover, the MultiModel framework is built in such a way that creating and connecting new models (e.g., Jansen-Rit) is easy and intuitive. An example of how to make a brand new model implementation in MultiModel is provided in the following example notebook ( example-4.1-create-new-model.ipynb ).","title":"Implemented models"},{"location":"examples/example-4-multimodel-intro/#modeling-hierarchy","text":"The MultiModel relies on the modeling hierarchy, which is typically implicit in whole-brain modeling. This hierarchy has three levels: * NeuralMass : represents a single neural population (typically excitatory, inhibitory, or without a subtype) and is defined by a set of parameters and (possibly delayed) (possibly stochastic) differential equations * Node : represents a single brain node, and it is a set of connected neural masses (so, e.g., a single Wilson-Cowan node consists of one excitatory and one inhibitory Wilson-Cowan NeuralMass ) * Network : represents a brain network, and it is a set of connected nodes (can be any type, as long as the coupling variables are the same) Although the magic happens at the level of NeuralMass (by magic, we mean the dynamics), users can only simulate (integrate) a Node or a Network . In other words, even for models without excitatory/inhibitory subtyping (e.g., Hopf or FitzHugh-Nagumo), we create a Node consisting of one NeuralMass . In the case of, e.g., Wilson-Cowan, ALN, or original Wong-Wang model, the Node consists of one excitatory and one inhibitory mass. More info on the modeling hierarchy and how it actually works is provided in the following example notebook ( example-4.1-create-new-model.ipynb ), where we need to subclass the base classes for this hierarchy to build a new model.","title":"Modeling hierarchy"},{"location":"examples/example-4-multimodel-intro/#basic-usage-in-neurolib","text":"(In the following we expect the reader to be mildly familiar with how neurolib works, e.g. how to run a model, how to change it parameters, and how to get model results) # import stuff # try: import matplotlib.pyplot as plt import numpy as np from IPython.display import display # import ALN single node model and neurolib wrapper `MultiModel` from neurolib.models.multimodel import ALNNetwork , ALNNode , MultiModel # except ImportError: # import sys # !{sys.executable} -m pip install matplotlib # import matplotlib.pyplot as plt","title":"Basic usage in neurolib"},{"location":"examples/example-4-multimodel-intro/#simulating-the-node","text":"# create a model and wrap it to `MultiModel` aln = MultiModel . init_node ( ALNNode ()) # 5 seconds run aln . params [ \"duration\" ] = 5.0 * 1000 # in ms # MultiModel offers two integration backends, be default we are using so-called `jitcdde` backend # `jitcdde` is a numerical backend employing adaptive dt scheme for DDEs, therefore we do not care about # actual dt (since it is adaptive), only about the sampling dt and this can be higher # more about this in example-4.2 aln . params [ \"sampling_dt\" ] = 1.0 # in ms # parametrise ALN model in slow limit cycle aln . params [ \"*EXC*input*mu\" ] = 4.2 aln . params [ \"*INH*input*mu\" ] = 1.8 # run aln . run () # plot - default output is firing rates in kHz plt . plot ( aln [ \"t\" ], aln [ \"r_mean_EXC\" ] . T , lw = 2 , c = \"k\" ) plt . xlabel ( \"t [ms]\" ) plt . ylabel ( \"Rate [kHz]\" ) /Users/nikola/.virtualenvs/neurolib/lib/python3.7/site-packages/jitcdde/_jitcdde.py:1491: UserWarning: Your input past does not begin at t=0 but at t=1.0. Values before the beginning of the past will be extrapolated. You very likely do not want this. warn(f\"Your input past does not begin at t=0 but at t={input[0].time}. Values before the beginning of the past will be extrapolated. You very likely do not want this.\") Using default integration parameters. 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5000/5000 [00:00<00:00, 7495.97it/s] Text(0, 0.5, 'Rate [kHz]') As you saw in the previous cell, the internal workings of MultiModel are very similar to the core neurolib . Therefore, for simple runs, you do care about the following: * MultiModel : a wrapper class for all models in MultiModel framework which gives model objects neurolib powers (meaning .params and .run() ). MultiModel class is initialized as follows: * when initialising with Node : model = MultiModel.init_node(<init'd Node class>) * when initialising with Network : model = MultiModel(<init'd Network class>) (see later)","title":"Simulating the node"},{"location":"examples/example-4-multimodel-intro/#multimodel-parameters-and-other-accessible-attributes","text":"Since MultiModel is able to simulate heterogeneous models, the internals of how parameters work is a bit more complex than in the core neurolib . Each mass has its own parameters, each node then gathers the parameters of each mass within that node, and finally, the network gathers all parameters from each node in the network, etc. So hierarchy again. To make it easier to navigate through MultiModel hierarchies, some attributes are implemented in all hierarchy levels. dummy_sc = np . array ([[ 0.0 , 1.0 ], [ 1.0 , 0.0 ]]) # init MultiModelnetwork with 2 ALN nodes with dummy sc and no delays mm_net = ALNNetwork ( connectivity_matrix = dummy_sc , delay_matrix = None ) print ( mm_net ) # each network is an proper python iterator, i.e. len() is defined print ( f \"Nodes: { len ( mm_net ) } \" ) # as well as __get_item__ print ( mm_net [ 0 ]) print ( mm_net [ 1 ]) # similarly, each node is a python iterator, i.e. print ( f \"Masses in 1. node: { len ( mm_net [ 0 ]) } \" ) print ( mm_net [ 0 ][ 0 ]) print ( mm_net [ 0 ][ 1 ]) # in order to navigate through the hierarchy, each mass, node and net # has its own name and label and index # index of a node is relative within the network # index of a mass is relative within the node print ( f \"This network name: { mm_net . name } \" ) print ( f \"This network label: { mm_net . label } \" ) print ( f \"1st node name: { mm_net [ 0 ] . name } \" ) print ( f \"1st node label: { mm_net [ 0 ] . label } \" ) print ( f \"1st node index: { mm_net [ 0 ] . index } \" ) print ( f \"1st mass in 1st node name: { mm_net [ 0 ][ 0 ] . name } \" ) print ( f \"1st mass in 1st node label: { mm_net [ 0 ][ 0 ] . label } \" ) print ( f \"1st mass in 1st node index: { mm_net [ 0 ][ 0 ] . index } \" ) # you can also check number of variables etc at all levels of hierarchy print ( f \"ALN EXC num. vars: { mm_net [ 0 ][ 0 ] . num_state_variables } \" ) print ( f \"ALN INH num. vars: { mm_net [ 0 ][ 1 ] . num_state_variables } \" ) print ( f \"ALN node num. vars: { mm_net [ 0 ] . num_state_variables } \" ) print ( f \"This network num. vars: { mm_net . num_state_variables } \" ) # similarly you can check number of \"noise variables\", i.e. the number # of stochastic variables entering the simulation print ( f \"ALN EXC noise vars: { mm_net [ 0 ][ 0 ] . num_noise_variables } \" ) # etc # not sure what are the state variables? no problem! print ( f \"ALN EXC state vars: { mm_net [ 0 ][ 0 ] . state_variable_names } \" ) print ( f \"ALN node state vars: { mm_net [ 0 ] . state_variable_names } \" ) print ( f \"This network state vars: { mm_net . state_variable_names } \" ) # if you are unsure what kind of a monster you build in MultiModel, # a function `describe()` is available at all three levels - # it returns a dictionary with basic info about the model object # this is describe of a `NeuralMass` print ( \"\" ) print ( \"Mass `describe`:\" ) display ( mm_net [ 0 ][ 0 ] . describe ()) # describe of a `Node` recursively describes all masses and some more print ( \"\" ) print ( \"Node `describe`:\" ) display ( mm_net [ 0 ] . describe ()) # and finally, describe of a `Network` gives you everything print ( \"\" ) print ( \"Network `describe`:\" ) display ( mm_net . describe ()) # PRO tip: imagine highly heterogeneous network and some long simulation with it; # apart from the results you can dump `net.describe()` dictionary into json and # never forget what you've done! Brain network ALN neural mass network with 2 nodes Nodes: 2 Network node: ALN neural mass node with 2 neural masses: ALN excitatory neural mass EXC, ALN inhibitory neural mass INH Network node: ALN neural mass node with 2 neural masses: ALN excitatory neural mass EXC, ALN inhibitory neural mass INH Masses in 1. node: 2 Neural mass: ALN excitatory neural mass with 7 state variables: I_mu, I_A, I_syn_mu_exc, I_syn_mu_inh, I_syn_sigma_exc, I_syn_sigma_inh, r_mean Neural mass: ALN inhibitory neural mass with 6 state variables: I_mu, I_syn_mu_exc, I_syn_mu_inh, I_syn_sigma_exc, I_syn_sigma_inh, r_mean This network name: ALN neural mass network This network label: ALNNet 1st node name: ALN neural mass node 1st node label: ALNNode 1st node index: 0 1st mass in 1st node name: ALN excitatory neural mass 1st mass in 1st node label: ALNMassEXC 1st mass in 1st node index: 0 ALN EXC num. vars: 7 ALN INH num. vars: 6 ALN node num. vars: 13 This network num. vars: 26 ALN EXC noise vars: 1 ALN EXC state vars: ['I_mu', 'I_A', 'I_syn_mu_exc', 'I_syn_mu_inh', 'I_syn_sigma_exc', 'I_syn_sigma_inh', 'r_mean'] ALN node state vars: [['I_mu_EXC', 'I_A_EXC', 'I_syn_mu_exc_EXC', 'I_syn_mu_inh_EXC', 'I_syn_sigma_exc_EXC', 'I_syn_sigma_inh_EXC', 'r_mean_EXC', 'I_mu_INH', 'I_syn_mu_exc_INH', 'I_syn_mu_inh_INH', 'I_syn_sigma_exc_INH', 'I_syn_sigma_inh_INH', 'r_mean_INH']] This network state vars: [['I_mu_EXC', 'I_A_EXC', 'I_syn_mu_exc_EXC', 'I_syn_mu_inh_EXC', 'I_syn_sigma_exc_EXC', 'I_syn_sigma_inh_EXC', 'r_mean_EXC', 'I_mu_INH', 'I_syn_mu_exc_INH', 'I_syn_mu_inh_INH', 'I_syn_sigma_exc_INH', 'I_syn_sigma_inh_INH', 'r_mean_INH'], ['I_mu_EXC', 'I_A_EXC', 'I_syn_mu_exc_EXC', 'I_syn_mu_inh_EXC', 'I_syn_sigma_exc_EXC', 'I_syn_sigma_inh_EXC', 'r_mean_EXC', 'I_mu_INH', 'I_syn_mu_exc_INH', 'I_syn_mu_inh_INH', 'I_syn_sigma_exc_INH', 'I_syn_sigma_inh_INH', 'r_mean_INH']] Mass `describe`: {'index': 0, 'name': 'ALN excitatory neural mass', 'mass_type': 'EXC', 'num_state_variables': 7, 'num_noise_variables': 1, 'state_variable_names': ['I_mu', 'I_A', 'I_syn_mu_exc', 'I_syn_mu_inh', 'I_syn_sigma_exc', 'I_syn_sigma_inh', 'r_mean'], 'params': {'Ke': 800.0, 'Ki': 200.0, 'c_gl': 0.4, 'Ke_gl': 250.0, 'tau_se': 2.0, 'tau_si': 5.0, 'sigmae_ext': 1.5, 'Jee_max': 2.43, 'Jei_max': -3.3, 'C': 200.0, 'gL': 10.0, 'ext_exc_current': 0.0, 'ext_exc_rate': 0.0, 'a': 15.0, 'b': 40.0, 'EA': -80.0, 'tauA': 200.0, 'lambda': 10.0, 'input_0': {'type': 'OrnsteinUhlenbeckProcess', 'mu': 4.2, 'sigma': 0.0, 'tau': 5.0, 'n': 1, 'seed': None}}, 'lin_nonlin_transfer_function_filename': '/Users/nikola/.virtualenvs/neurolib/lib/python3.7/site-packages/neurolib/models/multimodel/builder/../../aln/aln-precalc/quantities_cascade.h5'} Node `describe`: {'index': 0, 'name': 'ALN neural mass node', 'num_masses': 2, 'num_num_state_variables': 13, 'num_noise_variables': 2, 'masses': [{'index': 0, 'name': 'ALN excitatory neural mass', 'mass_type': 'EXC', 'num_state_variables': 7, 'num_noise_variables': 1, 'state_variable_names': ['I_mu', 'I_A', 'I_syn_mu_exc', 'I_syn_mu_inh', 'I_syn_sigma_exc', 'I_syn_sigma_inh', 'r_mean'], 'params': {'Ke': 800.0, 'Ki': 200.0, 'c_gl': 0.4, 'Ke_gl': 250.0, 'tau_se': 2.0, 'tau_si': 5.0, 'sigmae_ext': 1.5, 'Jee_max': 2.43, 'Jei_max': -3.3, 'C': 200.0, 'gL': 10.0, 'ext_exc_current': 0.0, 'ext_exc_rate': 0.0, 'a': 15.0, 'b': 40.0, 'EA': -80.0, 'tauA': 200.0, 'lambda': 10.0, 'input_0': {'type': 'OrnsteinUhlenbeckProcess', 'mu': 4.2, 'sigma': 0.0, 'tau': 5.0, 'n': 1, 'seed': None}}, 'lin_nonlin_transfer_function_filename': '/Users/nikola/.virtualenvs/neurolib/lib/python3.7/site-packages/neurolib/models/multimodel/builder/../../aln/aln-precalc/quantities_cascade.h5'}, {'index': 1, 'name': 'ALN inhibitory neural mass', 'mass_type': 'INH', 'num_state_variables': 6, 'num_noise_variables': 1, 'state_variable_names': ['I_mu', 'I_syn_mu_exc', 'I_syn_mu_inh', 'I_syn_sigma_exc', 'I_syn_sigma_inh', 'r_mean'], 'params': {'Ke': 800.0, 'Ki': 200.0, 'c_gl': 0.4, 'Ke_gl': 250.0, 'tau_se': 2.0, 'tau_si': 5.0, 'sigmai_ext': 1.5, 'Jie_max': 2.6, 'Jii_max': -1.64, 'C': 200.0, 'gL': 10.0, 'ext_inh_current': 0.0, 'ext_inh_rate': 0.0, 'lambda': 10.0, 'input_0': {'type': 'OrnsteinUhlenbeckProcess', 'mu': 1.8, 'sigma': 0.0, 'tau': 5.0, 'n': 1, 'seed': None}}, 'lin_nonlin_transfer_function_filename': '/Users/nikola/.virtualenvs/neurolib/lib/python3.7/site-packages/neurolib/models/multimodel/builder/../../aln/aln-precalc/quantities_cascade.h5'}], 'local_connectivity': array([[0.24691358, 0.75757576], [0.23076923, 1.52439024]]), 'local_delays': array([[4., 2.], [4., 2.]])} Network `describe`: {'name': 'ALN neural mass network', 'num_nodes': 2, 'num_state_variables': 26, 'num_noise_variables': 4, 'nodes': [{'index': 0, 'name': 'ALN neural mass node', 'num_masses': 2, 'num_num_state_variables': 13, 'num_noise_variables': 2, 'masses': [{'index': 0, 'name': 'ALN excitatory neural mass', 'mass_type': 'EXC', 'num_state_variables': 7, 'num_noise_variables': 1, 'state_variable_names': ['I_mu', 'I_A', 'I_syn_mu_exc', 'I_syn_mu_inh', 'I_syn_sigma_exc', 'I_syn_sigma_inh', 'r_mean'], 'params': {'Ke': 800.0, 'Ki': 200.0, 'c_gl': 0.4, 'Ke_gl': 250.0, 'tau_se': 2.0, 'tau_si': 5.0, 'sigmae_ext': 1.5, 'Jee_max': 2.43, 'Jei_max': -3.3, 'C': 200.0, 'gL': 10.0, 'ext_exc_current': 0.0, 'ext_exc_rate': 0.0, 'a': 15.0, 'b': 40.0, 'EA': -80.0, 'tauA': 200.0, 'lambda': 10.0, 'input_0': {'type': 'OrnsteinUhlenbeckProcess', 'mu': 4.2, 'sigma': 0.0, 'tau': 5.0, 'n': 1, 'seed': None}}, 'lin_nonlin_transfer_function_filename': '/Users/nikola/.virtualenvs/neurolib/lib/python3.7/site-packages/neurolib/models/multimodel/builder/../../aln/aln-precalc/quantities_cascade.h5'}, {'index': 1, 'name': 'ALN inhibitory neural mass', 'mass_type': 'INH', 'num_state_variables': 6, 'num_noise_variables': 1, 'state_variable_names': ['I_mu', 'I_syn_mu_exc', 'I_syn_mu_inh', 'I_syn_sigma_exc', 'I_syn_sigma_inh', 'r_mean'], 'params': {'Ke': 800.0, 'Ki': 200.0, 'c_gl': 0.4, 'Ke_gl': 250.0, 'tau_se': 2.0, 'tau_si': 5.0, 'sigmai_ext': 1.5, 'Jie_max': 2.6, 'Jii_max': -1.64, 'C': 200.0, 'gL': 10.0, 'ext_inh_current': 0.0, 'ext_inh_rate': 0.0, 'lambda': 10.0, 'input_0': {'type': 'OrnsteinUhlenbeckProcess', 'mu': 1.8, 'sigma': 0.0, 'tau': 5.0, 'n': 1, 'seed': None}}, 'lin_nonlin_transfer_function_filename': '/Users/nikola/.virtualenvs/neurolib/lib/python3.7/site-packages/neurolib/models/multimodel/builder/../../aln/aln-precalc/quantities_cascade.h5'}], 'local_connectivity': array([[0.24691358, 0.75757576], [0.23076923, 1.52439024]]), 'local_delays': array([[4., 2.], [4., 2.]])}, {'index': 1, 'name': 'ALN neural mass node', 'num_masses': 2, 'num_num_state_variables': 13, 'num_noise_variables': 2, 'masses': [{'index': 0, 'name': 'ALN excitatory neural mass', 'mass_type': 'EXC', 'num_state_variables': 7, 'num_noise_variables': 1, 'state_variable_names': ['I_mu', 'I_A', 'I_syn_mu_exc', 'I_syn_mu_inh', 'I_syn_sigma_exc', 'I_syn_sigma_inh', 'r_mean'], 'params': {'Ke': 800.0, 'Ki': 200.0, 'c_gl': 0.4, 'Ke_gl': 250.0, 'tau_se': 2.0, 'tau_si': 5.0, 'sigmae_ext': 1.5, 'Jee_max': 2.43, 'Jei_max': -3.3, 'C': 200.0, 'gL': 10.0, 'ext_exc_current': 0.0, 'ext_exc_rate': 0.0, 'a': 15.0, 'b': 40.0, 'EA': -80.0, 'tauA': 200.0, 'lambda': 10.0, 'input_0': {'type': 'OrnsteinUhlenbeckProcess', 'mu': 4.2, 'sigma': 0.0, 'tau': 5.0, 'n': 1, 'seed': None}}, 'lin_nonlin_transfer_function_filename': '/Users/nikola/.virtualenvs/neurolib/lib/python3.7/site-packages/neurolib/models/multimodel/builder/../../aln/aln-precalc/quantities_cascade.h5'}, {'index': 1, 'name': 'ALN inhibitory neural mass', 'mass_type': 'INH', 'num_state_variables': 6, 'num_noise_variables': 1, 'state_variable_names': ['I_mu', 'I_syn_mu_exc', 'I_syn_mu_inh', 'I_syn_sigma_exc', 'I_syn_sigma_inh', 'r_mean'], 'params': {'Ke': 800.0, 'Ki': 200.0, 'c_gl': 0.4, 'Ke_gl': 250.0, 'tau_se': 2.0, 'tau_si': 5.0, 'sigmai_ext': 1.5, 'Jie_max': 2.6, 'Jii_max': -1.64, 'C': 200.0, 'gL': 10.0, 'ext_inh_current': 0.0, 'ext_inh_rate': 0.0, 'lambda': 10.0, 'input_0': {'type': 'OrnsteinUhlenbeckProcess', 'mu': 1.8, 'sigma': 0.0, 'tau': 5.0, 'n': 1, 'seed': None}}, 'lin_nonlin_transfer_function_filename': '/Users/nikola/.virtualenvs/neurolib/lib/python3.7/site-packages/neurolib/models/multimodel/builder/../../aln/aln-precalc/quantities_cascade.h5'}], 'local_connectivity': array([[0.24691358, 0.75757576], [0.23076923, 1.52439024]]), 'local_delays': array([[4., 2.], [4., 2.]])}], 'connectivity': array([[0., 1.], [1., 0.]]), 'delays': array([[0., 0.], [0., 0.]])} # now let us check the parameters.. for this we initialise MultiModel in neurolib's fashion aln_net = MultiModel ( mm_net ) # parameters are accessible via .params aln_net . params # as you can see the parameters are flattened nested dictionary which follows this nomenclature # {\"<network label>.<node label>_index.<mass label>_index.<param name>: param value\"} {'ALNNet.ALNNode_0.ALNMassEXC_0.Ke': 800.0, 'ALNNet.ALNNode_0.ALNMassEXC_0.Ki': 200.0, 'ALNNet.ALNNode_0.ALNMassEXC_0.c_gl': 0.4, 'ALNNet.ALNNode_0.ALNMassEXC_0.Ke_gl': 250.0, 'ALNNet.ALNNode_0.ALNMassEXC_0.tau_se': 2.0, 'ALNNet.ALNNode_0.ALNMassEXC_0.tau_si': 5.0, 'ALNNet.ALNNode_0.ALNMassEXC_0.sigmae_ext': 1.5, 'ALNNet.ALNNode_0.ALNMassEXC_0.Jee_max': 2.43, 'ALNNet.ALNNode_0.ALNMassEXC_0.Jei_max': -3.3, 'ALNNet.ALNNode_0.ALNMassEXC_0.C': 200.0, 'ALNNet.ALNNode_0.ALNMassEXC_0.gL': 10.0, 'ALNNet.ALNNode_0.ALNMassEXC_0.ext_exc_current': 0.0, 'ALNNet.ALNNode_0.ALNMassEXC_0.ext_exc_rate': 0.0, 'ALNNet.ALNNode_0.ALNMassEXC_0.a': 15.0, 'ALNNet.ALNNode_0.ALNMassEXC_0.b': 40.0, 'ALNNet.ALNNode_0.ALNMassEXC_0.EA': -80.0, 'ALNNet.ALNNode_0.ALNMassEXC_0.tauA': 200.0, 'ALNNet.ALNNode_0.ALNMassEXC_0.lambda': 10.0, 'ALNNet.ALNNode_0.ALNMassEXC_0.input_0.type': 'OrnsteinUhlenbeckProcess', 'ALNNet.ALNNode_0.ALNMassEXC_0.input_0.mu': 4.2, 'ALNNet.ALNNode_0.ALNMassEXC_0.input_0.sigma': 0.0, 'ALNNet.ALNNode_0.ALNMassEXC_0.input_0.tau': 5.0, 'ALNNet.ALNNode_0.ALNMassEXC_0.input_0.n': 1, 'ALNNet.ALNNode_0.ALNMassEXC_0.input_0.seed': None, 'ALNNet.ALNNode_0.ALNMassINH_1.Ke': 800.0, 'ALNNet.ALNNode_0.ALNMassINH_1.Ki': 200.0, 'ALNNet.ALNNode_0.ALNMassINH_1.c_gl': 0.4, 'ALNNet.ALNNode_0.ALNMassINH_1.Ke_gl': 250.0, 'ALNNet.ALNNode_0.ALNMassINH_1.tau_se': 2.0, 'ALNNet.ALNNode_0.ALNMassINH_1.tau_si': 5.0, 'ALNNet.ALNNode_0.ALNMassINH_1.sigmai_ext': 1.5, 'ALNNet.ALNNode_0.ALNMassINH_1.Jie_max': 2.6, 'ALNNet.ALNNode_0.ALNMassINH_1.Jii_max': -1.64, 'ALNNet.ALNNode_0.ALNMassINH_1.C': 200.0, 'ALNNet.ALNNode_0.ALNMassINH_1.gL': 10.0, 'ALNNet.ALNNode_0.ALNMassINH_1.ext_inh_current': 0.0, 'ALNNet.ALNNode_0.ALNMassINH_1.ext_inh_rate': 0.0, 'ALNNet.ALNNode_0.ALNMassINH_1.lambda': 10.0, 'ALNNet.ALNNode_0.ALNMassINH_1.input_0.type': 'OrnsteinUhlenbeckProcess', 'ALNNet.ALNNode_0.ALNMassINH_1.input_0.mu': 1.8, 'ALNNet.ALNNode_0.ALNMassINH_1.input_0.sigma': 0.0, 'ALNNet.ALNNode_0.ALNMassINH_1.input_0.tau': 5.0, 'ALNNet.ALNNode_0.ALNMassINH_1.input_0.n': 1, 'ALNNet.ALNNode_0.ALNMassINH_1.input_0.seed': None, 'ALNNet.ALNNode_0.local_connectivity': array([[0.24691358, 0.75757576], [0.23076923, 1.52439024]]), 'ALNNet.ALNNode_0.local_delays': array([[4., 2.], [4., 2.]]), 'ALNNet.ALNNode_1.ALNMassEXC_0.Ke': 800.0, 'ALNNet.ALNNode_1.ALNMassEXC_0.Ki': 200.0, 'ALNNet.ALNNode_1.ALNMassEXC_0.c_gl': 0.4, 'ALNNet.ALNNode_1.ALNMassEXC_0.Ke_gl': 250.0, 'ALNNet.ALNNode_1.ALNMassEXC_0.tau_se': 2.0, 'ALNNet.ALNNode_1.ALNMassEXC_0.tau_si': 5.0, 'ALNNet.ALNNode_1.ALNMassEXC_0.sigmae_ext': 1.5, 'ALNNet.ALNNode_1.ALNMassEXC_0.Jee_max': 2.43, 'ALNNet.ALNNode_1.ALNMassEXC_0.Jei_max': -3.3, 'ALNNet.ALNNode_1.ALNMassEXC_0.C': 200.0, 'ALNNet.ALNNode_1.ALNMassEXC_0.gL': 10.0, 'ALNNet.ALNNode_1.ALNMassEXC_0.ext_exc_current': 0.0, 'ALNNet.ALNNode_1.ALNMassEXC_0.ext_exc_rate': 0.0, 'ALNNet.ALNNode_1.ALNMassEXC_0.a': 15.0, 'ALNNet.ALNNode_1.ALNMassEXC_0.b': 40.0, 'ALNNet.ALNNode_1.ALNMassEXC_0.EA': -80.0, 'ALNNet.ALNNode_1.ALNMassEXC_0.tauA': 200.0, 'ALNNet.ALNNode_1.ALNMassEXC_0.lambda': 10.0, 'ALNNet.ALNNode_1.ALNMassEXC_0.input_0.type': 'OrnsteinUhlenbeckProcess', 'ALNNet.ALNNode_1.ALNMassEXC_0.input_0.mu': 4.2, 'ALNNet.ALNNode_1.ALNMassEXC_0.input_0.sigma': 0.0, 'ALNNet.ALNNode_1.ALNMassEXC_0.input_0.tau': 5.0, 'ALNNet.ALNNode_1.ALNMassEXC_0.input_0.n': 1, 'ALNNet.ALNNode_1.ALNMassEXC_0.input_0.seed': None, 'ALNNet.ALNNode_1.ALNMassINH_1.Ke': 800.0, 'ALNNet.ALNNode_1.ALNMassINH_1.Ki': 200.0, 'ALNNet.ALNNode_1.ALNMassINH_1.c_gl': 0.4, 'ALNNet.ALNNode_1.ALNMassINH_1.Ke_gl': 250.0, 'ALNNet.ALNNode_1.ALNMassINH_1.tau_se': 2.0, 'ALNNet.ALNNode_1.ALNMassINH_1.tau_si': 5.0, 'ALNNet.ALNNode_1.ALNMassINH_1.sigmai_ext': 1.5, 'ALNNet.ALNNode_1.ALNMassINH_1.Jie_max': 2.6, 'ALNNet.ALNNode_1.ALNMassINH_1.Jii_max': -1.64, 'ALNNet.ALNNode_1.ALNMassINH_1.C': 200.0, 'ALNNet.ALNNode_1.ALNMassINH_1.gL': 10.0, 'ALNNet.ALNNode_1.ALNMassINH_1.ext_inh_current': 0.0, 'ALNNet.ALNNode_1.ALNMassINH_1.ext_inh_rate': 0.0, 'ALNNet.ALNNode_1.ALNMassINH_1.lambda': 10.0, 'ALNNet.ALNNode_1.ALNMassINH_1.input_0.type': 'OrnsteinUhlenbeckProcess', 'ALNNet.ALNNode_1.ALNMassINH_1.input_0.mu': 1.8, 'ALNNet.ALNNode_1.ALNMassINH_1.input_0.sigma': 0.0, 'ALNNet.ALNNode_1.ALNMassINH_1.input_0.tau': 5.0, 'ALNNet.ALNNode_1.ALNMassINH_1.input_0.n': 1, 'ALNNet.ALNNode_1.ALNMassINH_1.input_0.seed': None, 'ALNNet.ALNNode_1.local_connectivity': array([[0.24691358, 0.75757576], [0.23076923, 1.52439024]]), 'ALNNet.ALNNode_1.local_delays': array([[4., 2.], [4., 2.]]), 'ALNNet.connectivity': array([[0., 1.], [1., 0.]]), 'ALNNet.delays': array([[0., 0.], [0., 0.]]), 'duration': 2000, 'dt': 0.1, 'seed': None, 'backend': 'jitcdde', 'name': 'ALNNet', 'description': 'ALN neural mass network', 'N': 2, 'Cmat': array([[0., 1.], [1., 0.]]), 'sampling_dt': 0.1} # as you can see there are a lot of parameters for simple 2-node network of ALN models # typically you want to change parameters of all nodes at the same time # fortunately, model.params is not your basic dictionary, it's a special one, we call it `star` dictionary, # because you can do this: display ( aln_net . params [ \"*tau\" ]) print ( \"\" ) # so yes, star works as a glob identifier, so by selecting \"*tau\" I want all parameters named tau # (I dont care from which mass or node it comes) # what if I want to change taus only in EXC masses? easy: display ( aln_net . params [ \"*EXC*tau\" ]) print ( \"\" ) # or maybe I want to change taus only in the first node? display ( aln_net . params [ \"*Node_0*tau\" ]) print ( \"\" ) # of course, you can change a param value with this aln_net . params [ \"*Node_0*tau\" ] = 13.2 display ( aln_net . params [ \"*Node_0*tau\" ]) aln_net . params [ \"*Node_0*tau\" ] = 5.0 {'ALNNet.ALNNode_0.ALNMassEXC_0.input_0.tau': 5.0, 'ALNNet.ALNNode_0.ALNMassINH_1.input_0.tau': 5.0, 'ALNNet.ALNNode_1.ALNMassEXC_0.input_0.tau': 5.0, 'ALNNet.ALNNode_1.ALNMassINH_1.input_0.tau': 5.0} {'ALNNet.ALNNode_0.ALNMassEXC_0.input_0.tau': 5.0, 'ALNNet.ALNNode_1.ALNMassEXC_0.input_0.tau': 5.0} {'ALNNet.ALNNode_0.ALNMassEXC_0.input_0.tau': 5.0, 'ALNNet.ALNNode_0.ALNMassINH_1.input_0.tau': 5.0} {'ALNNet.ALNNode_0.ALNMassEXC_0.input_0.tau': 13.2, 'ALNNet.ALNNode_0.ALNMassINH_1.input_0.tau': 13.2} # case: I want to change all taus except \"noise\" taus # this gives all the taus, including \"noise\" display ( aln_net . params [ \"*tau*\" ]) print ( \"\" ) # pipe symbol filters out unwanted keys - here we have only taus which key does NOT include \"input\" display ( aln_net . params [ \"*tau*|input\" ]) {'ALNNet.ALNNode_0.ALNMassEXC_0.tau_se': 2.0, 'ALNNet.ALNNode_0.ALNMassEXC_0.tau_si': 5.0, 'ALNNet.ALNNode_0.ALNMassEXC_0.tauA': 200.0, 'ALNNet.ALNNode_0.ALNMassEXC_0.input_0.tau': 5.0, 'ALNNet.ALNNode_0.ALNMassINH_1.tau_se': 2.0, 'ALNNet.ALNNode_0.ALNMassINH_1.tau_si': 5.0, 'ALNNet.ALNNode_0.ALNMassINH_1.input_0.tau': 5.0, 'ALNNet.ALNNode_1.ALNMassEXC_0.tau_se': 2.0, 'ALNNet.ALNNode_1.ALNMassEXC_0.tau_si': 5.0, 'ALNNet.ALNNode_1.ALNMassEXC_0.tauA': 200.0, 'ALNNet.ALNNode_1.ALNMassEXC_0.input_0.tau': 5.0, 'ALNNet.ALNNode_1.ALNMassINH_1.tau_se': 2.0, 'ALNNet.ALNNode_1.ALNMassINH_1.tau_si': 5.0, 'ALNNet.ALNNode_1.ALNMassINH_1.input_0.tau': 5.0} {'ALNNet.ALNNode_0.ALNMassEXC_0.tau_se': 2.0, 'ALNNet.ALNNode_0.ALNMassEXC_0.tau_si': 5.0, 'ALNNet.ALNNode_0.ALNMassEXC_0.tauA': 200.0, 'ALNNet.ALNNode_0.ALNMassINH_1.tau_se': 2.0, 'ALNNet.ALNNode_0.ALNMassINH_1.tau_si': 5.0, 'ALNNet.ALNNode_1.ALNMassEXC_0.tau_se': 2.0, 'ALNNet.ALNNode_1.ALNMassEXC_0.tau_si': 5.0, 'ALNNet.ALNNode_1.ALNMassEXC_0.tauA': 200.0, 'ALNNet.ALNNode_1.ALNMassINH_1.tau_se': 2.0, 'ALNNet.ALNNode_1.ALNMassINH_1.tau_si': 5.0} max_rate_e = [] min_rate_e = [] # number low for testing: mue_inputs = np . linspace ( 0 , 2 , 2 ) # use: mue_inputs = np.linspace(0, 2, 20) # not let's match ALN parameters to those in example-0-aln-minimal and recreate # the 1D bif. diagram aln . params [ \"*INH*input*mu\" ] = 0.5 aln . params [ \"*b\" ] = 0.0 aln . params [ \"ALNNode_0.ALNMassEXC_0.a\" ] = 0.0 for mue in mue_inputs : aln . params [ \"*EXC*input*mu\" ] = mue display ( aln . params [ \"*EXC*input*mu\" ]) aln . run () max_rate_e . append ( np . max ( aln . output [ 0 , - int ( 1000 / aln . params [ \"sampling_dt\" ]) :])) min_rate_e . append ( np . min ( aln . output [ 0 , - int ( 1000 / aln . params [ \"sampling_dt\" ]) :])) {'ALNNode_0.ALNMassEXC_0.input_0.mu': 0.0} /Users/nikola/.virtualenvs/neurolib/lib/python3.7/site-packages/jitcdde/_jitcdde.py:1491: UserWarning: Your input past does not begin at t=0 but at t=1.0. Values before the beginning of the past will be extrapolated. You very likely do not want this. warn(f\"Your input past does not begin at t=0 but at t={input[0].time}. Values before the beginning of the past will be extrapolated. You very likely do not want this.\") Using default integration parameters. 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5000/5000 [00:00<00:00, 12088.04it/s] {'ALNNode_0.ALNMassEXC_0.input_0.mu': 0.1} Using default integration parameters. 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5000/5000 [00:00<00:00, 11923.41it/s] {'ALNNode_0.ALNMassEXC_0.input_0.mu': 0.2} Using default integration parameters. 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5000/5000 [00:00<00:00, 11831.34it/s] {'ALNNode_0.ALNMassEXC_0.input_0.mu': 0.30000000000000004} Using default integration parameters. 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5000/5000 [00:00<00:00, 11601.52it/s] {'ALNNode_0.ALNMassEXC_0.input_0.mu': 0.4} Using default integration parameters. 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5000/5000 [00:00<00:00, 11838.99it/s] {'ALNNode_0.ALNMassEXC_0.input_0.mu': 0.5} Using default integration parameters. 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5000/5000 [00:00<00:00, 11134.30it/s] {'ALNNode_0.ALNMassEXC_0.input_0.mu': 0.6000000000000001} Using default integration parameters. 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5000/5000 [00:01<00:00, 4698.40it/s] {'ALNNode_0.ALNMassEXC_0.input_0.mu': 0.7000000000000001} Using default integration parameters. 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5000/5000 [00:01<00:00, 3559.94it/s] {'ALNNode_0.ALNMassEXC_0.input_0.mu': 0.8} Using default integration parameters. 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5000/5000 [00:01<00:00, 3242.48it/s] {'ALNNode_0.ALNMassEXC_0.input_0.mu': 0.9} Using default integration parameters. 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5000/5000 [00:01<00:00, 3419.71it/s] {'ALNNode_0.ALNMassEXC_0.input_0.mu': 1.0} Using default integration parameters. 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5000/5000 [00:01<00:00, 3356.80it/s] {'ALNNode_0.ALNMassEXC_0.input_0.mu': 1.1} Using default integration parameters. 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5000/5000 [00:01<00:00, 3586.59it/s] {'ALNNode_0.ALNMassEXC_0.input_0.mu': 1.2000000000000002} Using default integration parameters. 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5000/5000 [00:01<00:00, 4160.26it/s] {'ALNNode_0.ALNMassEXC_0.input_0.mu': 1.3} Using default integration parameters. 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5000/5000 [00:00<00:00, 5574.75it/s] {'ALNNode_0.ALNMassEXC_0.input_0.mu': 1.4000000000000001} Using default integration parameters. 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5000/5000 [00:00<00:00, 9851.36it/s] {'ALNNode_0.ALNMassEXC_0.input_0.mu': 1.5} Using default integration parameters. 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5000/5000 [00:00<00:00, 10735.54it/s] {'ALNNode_0.ALNMassEXC_0.input_0.mu': 1.6} Using default integration parameters. 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5000/5000 [00:00<00:00, 11248.32it/s] {'ALNNode_0.ALNMassEXC_0.input_0.mu': 1.7000000000000002} Using default integration parameters. 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5000/5000 [00:00<00:00, 11078.22it/s] {'ALNNode_0.ALNMassEXC_0.input_0.mu': 1.8} Using default integration parameters. 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5000/5000 [00:00<00:00, 11982.51it/s] {'ALNNode_0.ALNMassEXC_0.input_0.mu': 1.9000000000000001} Using default integration parameters. 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5000/5000 [00:00<00:00, 12192.60it/s] {'ALNNode_0.ALNMassEXC_0.input_0.mu': 2.0} Using default integration parameters. 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5000/5000 [00:00<00:00, 11837.18it/s] plt . plot ( mue_inputs , max_rate_e , c = \"k\" , lw = 2 ) plt . plot ( mue_inputs , min_rate_e , c = \"k\" , lw = 2 ) plt . title ( \"Bifurcation diagram of the aln model\" ) plt . xlabel ( \"Input to excitatory population\" ) plt . ylabel ( \"Min / max firing rate [kHz]\" ) Text(0, 0.5, 'Min / max firing rate [kHz]')","title":"MultiModel parameters and other accessible attributes"},{"location":"examples/example-4-multimodel-intro/#connecting-two-models","text":"So far, we only showed how to use MultiModel with a single dynamical model (ALN), and that is no fun. I mean, all this is already possible in core neurolib , and it the core, it is much faster. However, the real strength of MultiModel is combining different models into one network. Let us build a thalamocortical model using one node of the thalamic population model and one node of ALN, representing the cortex. # first - imports from neurolib.models.multimodel import ALNNode , ThalamicNode from neurolib.models.multimodel.builder.base.constants import EXC , INH from neurolib.models.multimodel.builder.base.network import Network # let us start by subclassing the Network class ALNThalamusMiniNetwork ( Network ): \"\"\" Simple thalamocortical motif: 1 cortical node ALN + 1 NMM thalamus. \"\"\" # provide basic attributes as name and label name = \"ALN 1 node + Thalamus\" label = \"ALNThlmNet\" # define which variables are used to sync, i.e. what coupling variables our nodes need sync_variables = [ # both nodes are connected via excitatory synapses \"network_exc_exc\" , # ALN requires also squared coupling \"network_exc_exc_sq\" , # and INH mass in thalamus also receives excitatory coupling \"network_inh_exc\" , ] # lastly, we need to define what is default output of the network (this has to be the # variable present in all nodes) # for us it is excitatory firing rates default_output = f \"r_mean_ { EXC } \" # define all output vars of any interest to us - EXC and INH firing rates and adaptive current in ALN output_vars = [ f \"r_mean_ { EXC } \" , f \"r_mean_ { INH } \" , f \"I_A_ { EXC } \" ] def __init__ ( self , connectivity_matrix , delay_matrix ): # self connections are resolved within nodes, so zeroes at the diagonal assert np . all ( np . diag ( connectivity_matrix ) == 0.0 ) # init ALN node with index 0 aln_node = ALNNode () aln_node . index = 0 # index where the state variables start - for first node it is always 0 aln_node . idx_state_var = 0 # set correct indices for noise input for mass in aln_node : mass . noise_input_idx = [ mass . index ] # init thalamus node with index 1 thalamus = ThalamicNode () thalamus . index = 1 # thalamic state variables start where ALN state variables end - easy thalamus . idx_state_var = aln_node . num_state_variables # set correct indices of noise input - one per mass, after ALN noise # indices for mass in thalamus : mass . noise_input_idx = [ aln_node . num_noise_variables + mass . index ] # now super.__init__ network with these two nodes: super () . __init__ ( nodes = [ aln_node , thalamus ], connectivity_matrix = connectivity_matrix , delay_matrix = delay_matrix , ) # done! the only other thing we need to do, is to set the coupling variables # thalamus vs. ALN are coupled via their firing rates and here we setup the # coupling matrices; the super class `Network` comes with some convenient # functions for this def _sync ( self ): \"\"\" Set coupling variables - the ones we defined in `sync_variables` _sync returns a list of tuples where the first element in each tuple is the coupling \"symbol\" and the second is the actual mathematical expression for the ease of doing this, `Network` class contains convenience functions for this: - _additive_coupling - _diffusive_coupling - _no_coupling here we use additive coupling only \"\"\" # get indices of coupling variables from all nodes exc_indices = [ next ( iter ( node . all_couplings ( mass_indices = node . excitatory_masses . tolist () ) ) ) for node in self ] assert len ( exc_indices ) == len ( self ) return ( # basic EXC <-> EXC coupling # within_node_idx is a list of len 2 (because we have two nodes) # with indices of coupling variables within the respective state vectors self . _additive_coupling ( within_node_idx = exc_indices , symbol = \"network_exc_exc\" ) # squared EXC <-> EXC coupling (only to ALN) + self . _additive_coupling ( within_node_idx = exc_indices , symbol = \"network_exc_exc_sq\" , # square connectivity connectivity = self . connectivity * self . connectivity , ) # EXC -> INH coupling (only to thalamus) + self . _additive_coupling ( within_node_idx = exc_indices , symbol = \"network_inh_exc\" , connectivity = self . connectivity , ) + super () . _sync () ) # lets check what we have SC = np . array ([[ 0.0 , 0.15 ], [ 1.2 , 0.0 ]]) delays = np . array ([[ 0.0 , 13.0 ], [ 13.0 , 0.0 ]]) # thalamocortical delay = 13ms thalamocortical = MultiModel ( ALNThalamusMiniNetwork ( connectivity_matrix = SC , delay_matrix = delays )) # original `MultiModel` instance is always accessible as `MultiModel.model_instance` display ( thalamocortical . model_instance . describe ()) {'name': 'ALN 1 node + Thalamus', 'num_nodes': 2, 'num_state_variables': 30, 'num_noise_variables': 4, 'nodes': [{'index': 0, 'name': 'ALN neural mass node', 'num_masses': 2, 'num_num_state_variables': 13, 'num_noise_variables': 2, 'masses': [{'index': 0, 'name': 'ALN excitatory neural mass', 'mass_type': 'EXC', 'num_state_variables': 7, 'num_noise_variables': 1, 'state_variable_names': ['I_mu', 'I_A', 'I_syn_mu_exc', 'I_syn_mu_inh', 'I_syn_sigma_exc', 'I_syn_sigma_inh', 'r_mean'], 'params': {'Ke': 800.0, 'Ki': 200.0, 'c_gl': 0.4, 'Ke_gl': 250.0, 'tau_se': 2.0, 'tau_si': 5.0, 'sigmae_ext': 1.5, 'Jee_max': 2.43, 'Jei_max': -3.3, 'C': 200.0, 'gL': 10.0, 'ext_exc_current': 0.0, 'ext_exc_rate': 0.0, 'a': 15.0, 'b': 40.0, 'EA': -80.0, 'tauA': 200.0, 'lambda': 10.0, 'input_0': {'type': 'OrnsteinUhlenbeckProcess', 'mu': 2.0, 'sigma': 0.0, 'tau': 5.0, 'n': 1, 'seed': None}}, 'lin_nonlin_transfer_function_filename': '/Users/nikola/.virtualenvs/neurolib/lib/python3.7/site-packages/neurolib/models/multimodel/builder/../../aln/aln-precalc/quantities_cascade.h5'}, {'index': 1, 'name': 'ALN inhibitory neural mass', 'mass_type': 'INH', 'num_state_variables': 6, 'num_noise_variables': 1, 'state_variable_names': ['I_mu', 'I_syn_mu_exc', 'I_syn_mu_inh', 'I_syn_sigma_exc', 'I_syn_sigma_inh', 'r_mean'], 'params': {'Ke': 800.0, 'Ki': 200.0, 'c_gl': 0.4, 'Ke_gl': 250.0, 'tau_se': 2.0, 'tau_si': 5.0, 'sigmai_ext': 1.5, 'Jie_max': 2.6, 'Jii_max': -1.64, 'C': 200.0, 'gL': 10.0, 'ext_inh_current': 0.0, 'ext_inh_rate': 0.0, 'lambda': 10.0, 'input_0': {'type': 'OrnsteinUhlenbeckProcess', 'mu': 0.5, 'sigma': 0.0, 'tau': 5.0, 'n': 1, 'seed': None}}, 'lin_nonlin_transfer_function_filename': '/Users/nikola/.virtualenvs/neurolib/lib/python3.7/site-packages/neurolib/models/multimodel/builder/../../aln/aln-precalc/quantities_cascade.h5'}], 'local_connectivity': array([[0.24691358, 0.75757576], [0.23076923, 1.52439024]]), 'local_delays': array([[4., 2.], [4., 2.]])}, {'index': 1, 'name': 'Thalamic mass model node', 'num_masses': 2, 'num_num_state_variables': 17, 'num_noise_variables': 2, 'masses': [{'index': 0, 'name': 'Thalamocortical relay mass', 'mass_type': 'EXC', 'num_state_variables': 10, 'num_noise_variables': 1, 'state_variable_names': ['V', 'Ca', 'h_T', 'm_h1', 'm_h2', 's_e', 's_i', 'ds_e', 'ds_i', 'r_mean'], 'params': {'tau': 20.0, 'Q_max': 0.4, 'theta': -58.5, 'sigma': 6.0, 'C1': 1.8137993642, 'C_m': 1.0, 'gamma_e': 0.07, 'gamma_r': 0.1, 'g_L': 1.0, 'g_GABA': 1.0, 'g_AMPA': 1.0, 'g_LK': 0.018, 'g_T': 3.0, 'g_h': 0.062, 'E_AMPA': 0.0, 'E_GABA': -70.0, 'E_L': -70.0, 'E_K': -100.0, 'E_Ca': 120.0, 'E_h': -40.0, 'alpha_Ca': -5.18e-05, 'tau_Ca': 10.0, 'Ca_0': 0.00024, 'k1': 25000000.0, 'k2': 0.0004, 'k3': 0.1, 'k4': 0.001, 'n_P': 4.0, 'g_inc': 2.0, 'ext_current': 0.0, 'lambda': 10.0, 'input_0': {'type': 'OrnsteinUhlenbeckProcess', 'mu': 0.0, 'sigma': 0.0, 'tau': 5.0, 'n': 1, 'seed': None}}}, {'index': 1, 'name': 'Thalamic reticular nuclei mass', 'mass_type': 'INH', 'num_state_variables': 7, 'num_noise_variables': 1, 'state_variable_names': ['V', 'h_T', 's_e', 's_i', 'ds_e', 'ds_i', 'r_mean'], 'params': {'tau': 20.0, 'Q_max': 0.4, 'theta': -58.5, 'sigma': 6.0, 'C1': 1.8137993642, 'C_m': 1.0, 'gamma_e': 0.07, 'gamma_r': 0.1, 'g_L': 1.0, 'g_GABA': 1.0, 'g_AMPA': 1.0, 'g_LK': 0.018, 'g_T': 2.3, 'E_AMPA': 0.0, 'E_GABA': -70.0, 'E_L': -70.0, 'E_K': -100.0, 'E_Ca': 120.0, 'ext_current': 0.0, 'lambda': 10.0, 'input_0': {'type': 'ZeroInput', 'n': 1, 'seed': None}}}], 'local_connectivity': array([[ 0., 5.], [ 3., 25.]]), 'local_delays': array([[0., 0.], [0., 0.]])}], 'connectivity': array([[0. , 0.15], [1.2 , 0. ]]), 'delays': array([[ 0., 13.], [13., 0.]])} # fix parameters for interesting regime thalamocortical . params [ \"*g_LK\" ] = 0.032 # K-leak conductance in thalamus thalamocortical . params [ \"ALNThlmNet.ALNNode_0.ALNMassEXC_0.a\" ] = 0.0 # no firing rate adaptation thalamocortical . params [ \"*b\" ] = 15.0 # spike adaptation thalamocortical . params [ \"*tauA\" ] = 1000.0 # slow adaptation timescale thalamocortical . params [ \"*EXC*mu\" ] = 3.4 # background excitation to ALN thalamocortical . params [ \"*INH*mu\" ] = 3.5 # background inhibition to ALN thalamocortical . params [ \"*ALNMass*input*sigma\" ] = 0.05 # noise in ALN thalamocortical . params [ \"*TCR*input*sigma\" ] = 0.005 # noise in thalamus thalamocortical . params [ \"*input*tau\" ] = 5.0 # timescale of OU process # number low for testing: thalamocortical . params [ \"duration\" ] = 2000. # use: thalamocortical.params[\"duration\"] = 20000. # 20 seconds simulation thalamocortical . params [ \"sampling_dt\" ] = 1.0 thalamocortical . run () /Users/nikola/.virtualenvs/neurolib/lib/python3.7/site-packages/jitcdde/_jitcdde.py:1491: UserWarning: Your input past does not begin at t=0 but at t=1.0. Values before the beginning of the past will be extrapolated. You very likely do not want this. warn(f\"Your input past does not begin at t=0 but at t={input[0].time}. Values before the beginning of the past will be extrapolated. You very likely do not want this.\") Using default integration parameters. 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 2000/2000 [00:00<00:00, 2994.08it/s] _ , axs = plt . subplots ( nrows = 2 , ncols = 1 , sharex = True , figsize = ( 12 , 6 )) axs [ 0 ] . plot ( thalamocortical . t , thalamocortical . r_mean_EXC [ 0 , :] . T ) axs [ 0 ] . set_ylabel ( \"ALN firing rate [kHz]\" ) axs [ 1 ] . plot ( thalamocortical . t , thalamocortical . r_mean_EXC [ 1 , :] . T , color = \"C1\" ) axs [ 1 ] . set_ylabel ( \"thalamus firing rate [kHz]\" ) axs [ 1 ] . set_xlabel ( \"time [sec]\" ) Text(0.5, 0, 'time [sec]') We can nicely see the interplay between cortical UP and DOWN states (with UP state being dominant and irregular DOWN state excursions) and thalamic spindles. Combining different models might seem hard at first, but it is actually kind of intuitive and works as you would connect models with pen and paper. The only necessary thing is to define and initialize individual nodes in the network (done in __init__ function) and then specify the type of coupling between these nodes (in _sync() function). That's it! For more information on how to build a network and for a deeper understanding of how exactly MultiModel works, please check out our following example, where we will build the Jansen-Rit network from scratch!","title":"Connecting two models"},{"location":"examples/example-4.1-multimodel-custom-model/","text":"(function() { function addWidgetsRenderer() { var requireJsScript = document.createElement('script'); requireJsScript.src = 'https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js'; var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var jupyterWidgetsScript = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} jupyterWidgetsScript.src = widgetRendererSrc; document.body.appendChild(requireJsScript); document.body.appendChild(jupyterWidgetsScript); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); Creating new model from scratch The real power of MultiModel framework is in fast prototyping of heterogeneous models. To showcase this, in this notebook we create a brand new model in the framework (the famous Jansen-Rit model), and then create a thalamocortical mini network with 1 node representing a thalamus and 1 node Jansen-Rit model representing a cortical column. Jansen-Rit model The Jansen-Rit model is a neural population model of a local cortical circuit. It contains three interconnected neural populations: one for the pyramidal projection neurons and two for excitatory and inhibitory interneurons forming feedback loops. The equations for Jansen-Rit model reads: \\begin{align} \\ddot{x} {0} & = Aa\\cdot\\mathrm{Sigm}\\left(x {1} - x_{2}\\right) - 2a\\dot{x} {0} - a^{2}x {0} \\ \\ddot{x} {1} & = Aa[p + C {2}\\mathrm{Sigm}\\left(C_{1}x_{0}\\right)] - 2a\\dot{x} {1} - a^2x {1} \\ \\ddot{x} {2} & = BbC {4}\\mathrm{Sigm}\\left( C_{3}x_{o} \\right) - 2b\\dot{x} {2} - b^2x {2} \\ \\mathrm{Sigm}(x) & = \\frac{v_{max}}{1 + \\mathrm{e}^{r(v_{0} - x)}} \\end{align} Of course, in order to implement the above equations numerically, the system of three second-order ODEs will be rewritten into a system of six first-order ODEs. MultiModel strategy The actual implementation will be a bit more involved than simply writing down the above equations. The building block of any proper MultiModel is a NeuralMass . Jansen-Rit model actually summarises an activity of a cortical column consisting of three populations: a population of pyramidal cells interacting with two populations of interneurons - one excitatory and one inhibitory. Moreover, the \\(x\\) represent the average membrane potential, but typically, neuronal models (at least in neurolib ) are coupled via firing rate. For this reason, our main output variable would actually be a firing rate of a main, pyramidal population. The average membrane potential of a pyramidal population is \\(x = x_{1} - x_{2}\\) and its firing rate is then \\(r = \\mathrm{Sigm}(x) = \\mathrm{Sigm}(x_{1} - x_{2})\\) . Similar strategy (sigmoidal transfer function for average membrane potential) is used for the thalamic model. The coupling variable in MultiModel must be the same across all hierarchical levels. Individial populations in Jansen-Rit model are coupled via their average membrane potentials \\(x_{i}\\) , \\(i\\in[0, 1, 2]\\) . However, the \"global\" coupling variable for the node would be the firing rate of pyramidal population \\(r\\) , introduced in the paragraph above. To reconcile this, two options exists in MultiModel : * create a NeuralMass representing a pyramidal population with two coupling variables: \\(x_{0}\\) and \\(r\\) ; NeuralMass representing interneurons would have one coupling variable, \\(x_{1,2}\\) * advantages: cleaner (implementation), more modular (can create J-R Node with more masses than 3 very easily) * disadvantages: more code, might be harder to navigate for the beginner * create one NeuralMass representing all three populations with one coupling variable \\(r\\) , since the others are not really coupling since the whole dynamics is contained in one object * advantages: less code, easier to grasp * disadvantages: less modular, cannot simply edit J-R model, since everything is \"hardcoded\" into one NeuralMass object In order to build a basic understanding of building blocks, we will follow the second option here (less code, easier to grasp). For interested readers, the first option (modular one) will be implemented in MultiModel , so you can follow the model files. Our strategy for this notebook then would be: 1. implement single NeuralMass object representing all three populations in the Jansen-Rit model, with single coupling variable \\(r\\) 2. implement a \"dummy\" Node with single NeuralMass (requirement, one cannot couple Node to a NeuralMass to build a network) 3. experiment with connecting this Jansen-Rit cortical model to the thalamic population model Last note, all model's dynamics and parameters in MultiModel are defined in milliseconds, therefore we will scale the default parameters. Let us start with the imports: import matplotlib.pyplot as plt import numpy as np import symengine as se from IPython.display import display from jitcdde import input as system_input from neurolib.models.multimodel import MultiModel , ThalamicNode from neurolib.models.multimodel.builder.base.constants import LAMBDA_SPEED from neurolib.models.multimodel.builder.base.network import Network , Node from neurolib.models.multimodel.builder.base.neural_mass import NeuralMass from neurolib.utils.functions import getPowerSpectrum from neurolib.utils.stimulus import Input , OrnsteinUhlenbeckProcess , StepInput A quick detour before we dive into the model itself. Jansen-Rit model is typically driven with a uniformly distributed noise, as the authors wanted to model nonspecific input (they used the term background spontaneous activity ). For this we quickly create our model input using the ModelInput class (the tutorial on how to use stimuli in neurolib is given elsewhere). class UniformlyDistributedNoise ( Input ): \"\"\" Uniformly distributed noise process between two values. \"\"\" def __init__ ( self , low , high , n = 1 , seed = None ): # save arguments as attributes for later self . low = low self . high = high # init super super () . __init__ ( n = n , seed = seed ) def generate_input ( self , duration , dt ): # generate time vector self . _get_times ( duration = duration , dt = dt ) # generate noise process itself with the correct shape # as (time steps x num. processes) return np . random . uniform ( self . low , self . high , ( self . n , self . times . shape [ 0 ]) ) # let us build a proper hierarchy, i.e. we firstly build a Jansen-Rit mass class SingleJansenRitMass ( NeuralMass ): \"\"\" Single Jansen-Rit mass implementing whole three population dynamics. Reference: Jansen, B. H., & Rit, V. G. (1995). Electroencephalogram and visual evoked potential generation in a mathematical model of coupled cortical columns. Biological cybernetics, 73(4), 357-366. \"\"\" # all these attributes are compulsory to fill in name = \"Jansen-Rit mass\" label = \"JRmass\" num_state_variables = 7 # 6 ODEs + firing rate coupling variable num_noise_variables = 1 # single external input # NOTE # external inputs (so-called noise_variables) are typically background noise drive in models, # however, this can be any type of stimulus - periodic stimulus, step stimulus, square pulse, # anything. Therefore you may want to add more stimuli, e.g. for Jansen-Rit model three to each # of its population. Here we do not stimulate our Jansen-Rit model, so only use actual noise # drive to excitatory interneuron population. # as dictionary {index of state var: it's name} coupling_variables = { 6 : \"r_mean_EXC\" } # as list state_variable_names = [ \"v_pyr\" , \"dv_pyr\" , \"v_exc\" , \"dv_exc\" , \"v_inh\" , \"dv_inh\" , # to comply with other `MultiModel` nodes \"r_mean_EXC\" , ] # as list # note on parameters C1 - C4 - all papers use one C and C1-C4 are # defined as various rations of C, typically: C1 = C, C2 = 0.8*C # C3 = C4 = 0.25*C, therefore we use only `C` and scale it in the # dynamics definition required_params = [ \"A\" , \"a\" , \"B\" , \"b\" , \"C\" , \"v_max\" , \"v0\" , \"r\" , \"lambda\" , ] # list of required couplings when part of a `Node` or `Network` # `network_exc_exc` is the default excitatory coupling between nodes required_couplings = [ \"network_exc_exc\" ] # here we define the default noise input to Jansen-Rit model (this can be changed later) # for a quick test, we follow the original Jansen and Rit paper and use uniformly distributed # noise between 120 - 320 Hz; but we do it in kHz, hence 0.12 - 0.32 # fix seed for reproducibility _noise_input = [ UniformlyDistributedNoise ( low = 0.12 , high = 0.32 , seed = 42 )] def _sigmoid ( self , x ): \"\"\" Sigmoidal transfer function which is the same for all populations. \"\"\" # notes: # - all parameters are accessible as self.params - it is a dictionary # - mathematical definition (ODEs) is done in symbolic mathematics - all functions have to be # imported from `symengine` module, hence se.exp which is a symbolic exponential function return self . params [ \"v_max\" ] / ( 1.0 + se . exp ( self . params [ \"r\" ] * ( self . params [ \"v0\" ] - x )) ) def __init__ ( self , params = None , seed = None ): # init this `NeuralMass` - use passed parameters or default ones # parameters are now accessible as self.params, seed as self.seed super () . __init__ ( params = params or JR_DEFAULT_PARAMS , seed = seed ) def _initialize_state_vector ( self ): \"\"\" Initialize state vector. \"\"\" np . random . seed ( self . seed ) # random in average potentials around zero self . initial_state = ( np . random . normal ( size = self . num_state_variables ) # * np.array([10.0, 0.0, 10.0, 0.0, 10.0, 0.0, 0.0]) ) . tolist () def _derivatives ( self , coupling_variables ): \"\"\" Here the magic happens: dynamics is defined here using symbolic maths package symengine. \"\"\" # first, we need to unwrap state vector ( v_pyr , dv_pyr , v_exc , dv_exc , v_inh , dv_inh , firing_rate , ) = self . _unwrap_state_vector () # this function does everything for us # now we need to write down our dynamics # PYR dynamics d_v_pyr = dv_pyr d_dv_pyr = ( self . params [ \"A\" ] * self . params [ \"a\" ] * self . _sigmoid ( v_exc - v_inh ) - 2 * self . params [ \"a\" ] * dv_pyr - self . params [ \"a\" ] ** 2 * v_pyr ) # EXC dynamics: system input comes into play here d_v_exc = dv_exc d_dv_exc = ( self . params [ \"A\" ] * self . params [ \"a\" ] * ( # system input as function from jitcdde (also in symengine) with proper index: # in our case we have only one noise input (can be more), so index 0 system_input ( self . noise_input_idx [ 0 ]) # C2 = 0.8*C, C1 = C + ( 0.8 * self . params [ \"C\" ]) * self . _sigmoid ( self . params [ \"C\" ] * v_pyr ) ) - 2 * self . params [ \"a\" ] * dv_exc - self . params [ \"a\" ] ** 2 * v_exc ) # INH dynamics d_v_inh = dv_inh d_dv_inh = ( self . params [ \"B\" ] * self . params [ \"b\" ] # C3 = C4 = 0.25 * C * ( 0.25 * self . params [ \"C\" ]) * self . _sigmoid (( 0.25 * self . params [ \"C\" ]) * v_pyr ) - 2 * self . params [ \"b\" ] * dv_inh - self . params [ \"b\" ] ** 2 * v_inh ) # firing rate computation # firing rate as dummy dynamical variable with infinitely fast # fixed point dynamics firing_rate_now = self . _sigmoid ( v_exc - v_inh ) d_firing_rate = - self . params [ \"lambda\" ] * ( firing_rate - firing_rate_now ) # now just return a list of derivatives in the correct order return [ d_v_pyr , d_dv_pyr , d_v_exc , d_dv_exc , d_v_inh , d_dv_inh , d_firing_rate ] And we are done with the basics! Only thing we really need is to define attributes (such as how many variables we have, what couplings we have, what about noise, etc.) and the actual dynamics as symbolic expressions. Symbolic expressions are easy: are basic operators like + , - , * , / , or ** are overloaded, which means you can simply use them and do not think about. Functions such as sin , log , or exp must be imported from symengine and used. Now we define a default set of parameters. Do not forget - MultiModel defines all in ms, therefore the parameters needs to be in ms, kHz, and similar. JR_DEFAULT_PARAMS = { \"A\" : 3.25 , # mV \"B\" : 22.0 , # mV # `a` and `b` are originally 100Hz and 50Hz \"a\" : 0.1 , # kHz \"b\" : 0.05 , # kHz \"v0\" : 6.0 , # mV # v_max is originally 5Hz \"v_max\" : 0.005 , # kHz \"r\" : 0.56 , # m/V \"C\" : 135.0 , # parameter for dummy `r` dynamics \"lambda\" : LAMBDA_SPEED , } The next step is to create a Node . Node is second level in the hierarchy and already it can be wrapped into MultiModel and treated as any other neurolib model. On our case, creating the Node is really simple: it has only one mass, no delays, and no connectivity. class JansenRitNode ( Node ): \"\"\" Jansen-Rit node with 1 neural mass representing 3 population model. \"\"\" name = \"Jansen-Rit node\" label = \"JRnode\" # if Node is integrated isolated, what network input we should use # zero by default = no network input for one-node model default_network_coupling = { \"network_exc_exc\" : 0.0 } # default output is the firing rate of pyramidal population default_output = \"r_mean_EXC\" # list of all variables that are accessible as outputs output_vars = [ \"r_mean_EXC\" , \"v_pyr\" , \"v_exc\" , \"v_inh\" ] def __init__ ( self , params = None , seed = None ): # in `Node` __init__, the list of masses is created and passed jr_mass = SingleJansenRitMass ( params = params , seed = seed ) # each mass has to have index, in this case it is simply 0 jr_mass . index = 0 # call super and properly initialize a Node super () . __init__ ( neural_masses = [ jr_mass ]) self . excitatory_masses = np . array ([ 0 ]) def _sync ( self ): # this function typically defines the coupling between masses # within one node, but in our case there is nothing to define return [] And we are done. At this point, we can integrate our Jansen-Rit model and see some results. Test and simulate Jansen-Rit model In order to simulate our newly created model, we just need to wrap it with MultiModel as in the last example and see how it goes. # init model - fix seed for reproducibility (random init. conditions) jr_model = MultiModel . init_node ( JansenRitNode ( seed = 42 )) # see parameters print ( \"Parameters:\" ) display ( jr_model . params ) print ( \"\" ) # see describe print ( \"Describe:\" ) display ( jr_model . model_instance . describe ()) Parameters: {'JRnode_0.JRmass_0.A': 3.25, 'JRnode_0.JRmass_0.B': 22.0, 'JRnode_0.JRmass_0.a': 0.1, 'JRnode_0.JRmass_0.b': 0.05, 'JRnode_0.JRmass_0.v0': 6.0, 'JRnode_0.JRmass_0.v_max': 0.005, 'JRnode_0.JRmass_0.r': 0.56, 'JRnode_0.JRmass_0.C': 135.0, 'JRnode_0.JRmass_0.lambda': 10.0, 'JRnode_0.JRmass_0.input_0.type': 'UniformlyDistributedNoise', 'JRnode_0.JRmass_0.input_0.low': 0.12, 'JRnode_0.JRmass_0.input_0.high': 0.32, 'JRnode_0.JRmass_0.input_0.n': 1, 'JRnode_0.JRmass_0.input_0.seed': 42, 'duration': 2000, 'dt': 0.1, 'seed': None, 'backend': 'jitcdde', 'name': 'JRnode', 'description': 'Jansen-Rit node', 'N': 1, 'Cmat': array([[0.]]), 'sampling_dt': 0.1} Describe: {'index': 0, 'name': 'Jansen-Rit node', 'num_masses': 1, 'num_num_state_variables': 7, 'num_noise_variables': 1, 'masses': [{'index': 0, 'name': 'Jansen-Rit mass', 'mass_type': None, 'num_state_variables': 7, 'num_noise_variables': 1, 'state_variable_names': ['v_pyr', 'dv_pyr', 'v_exc', 'dv_exc', 'v_inh', 'dv_inh', 'r_mean_EXC'], 'params': {'A': 3.25, 'B': 22.0, 'a': 0.1, 'b': 0.05, 'v0': 6.0, 'v_max': 0.005, 'r': 0.56, 'C': 135.0, 'lambda': 10.0, 'input_0': {'type': 'UniformlyDistributedNoise', 'low': 0.12, 'high': 0.32, 'n': 1, 'seed': 42}}}]} # run model for 5 seconds - all in ms jr_model . params [ \"sampling_dt\" ] = 1.0 jr_model . params [ \"duration\" ] = 5000 jr_model . params [ \"backend\" ] = \"jitcdde\" jr_model . run () /Users/nikola/.virtualenvs/neurolib/lib/python3.7/site-packages/jitcdde/_jitcdde.py:1491: UserWarning: Your input past does not begin at t=0 but at t=1.0. Values before the beginning of the past will be extrapolated. You very likely do not want this. warn(f\"Your input past does not begin at t=0 but at t={input[0].time}. Values before the beginning of the past will be extrapolated. You very likely do not want this.\") Using default integration parameters. 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5000/5000 [00:00<00:00, 26901.12it/s] _ , axs = plt . subplots ( nrows = 2 , ncols = 2 , figsize = ( 12 , 6 ), gridspec_kw = { \"width_ratios\" : [ 2 , 1 ]} ) axs [ 0 , 0 ] . plot ( jr_model . t , jr_model . v_exc . T - jr_model . v_inh . T , color = \"k\" ) axs [ 0 , 0 ] . set_ylabel ( \"LFP\" ) axs [ 1 , 0 ] . plot ( jr_model . t , jr_model . r_mean_EXC . T * 1000 , color = \"navy\" ) axs [ 1 , 0 ] . set_ylabel ( \"PYR r [Hz]\" ) axs [ 1 , 0 ] . set_xlabel ( \"time [sec]\" ) fr , po = getPowerSpectrum ( ( jr_model . v_exc . T - jr_model . v_inh . T ) . squeeze (), dt = jr_model . params [ \"sampling_dt\" ], maxfr = 40.0 , ) axs [ 0 , 1 ] . semilogy ( fr , po , color = \"indianred\" ) axs [ 0 , 1 ] . set_xlabel ( \"frequency [Hz]\" ) axs [ 0 , 1 ] . set_ylabel ( \"log power\" ) axs [ 1 , 1 ] . hist ( jr_model . v_exc . T - jr_model . v_inh . T , bins = 15 , color = \"gray\" ) axs [ 1 , 1 ] . set_xlabel ( \"LFP\" ) axs [ 1 , 1 ] . set_ylabel ( \"#\" ) plt . suptitle ( \"`jitcdde` backend\" ) Text(0.5, 0.98, '`jitcdde` backend') The results looks good! With the same parameters as original Jansen and Rit paper, we got the \\(\\alpha\\) activity with spectral peak around 10 Hz. Just as a proof of concept - let us try the second MultiModel backend. # run model for 5 seconds - all in ms jr_model . params [ \"sampling_dt\" ] = 1.0 jr_model . params [ \"dt\" ] = 0.1 jr_model . params [ \"duration\" ] = 5000 jr_model . params [ \"backend\" ] = \"numba\" jr_model . run () _ , axs = plt . subplots ( nrows = 2 , ncols = 2 , figsize = ( 12 , 6 ), gridspec_kw = { \"width_ratios\" : [ 2 , 1 ]} ) axs [ 0 , 0 ] . plot ( jr_model . t , jr_model . v_exc . T - jr_model . v_inh . T , color = \"k\" ) axs [ 0 , 0 ] . set_ylabel ( \"LFP\" ) axs [ 1 , 0 ] . plot ( jr_model . t , jr_model . r_mean_EXC . T * 1000 , color = \"navy\" ) axs [ 1 , 0 ] . set_ylabel ( \"PYR r [Hz]\" ) axs [ 1 , 0 ] . set_xlabel ( \"time [sec]\" ) fr , po = getPowerSpectrum ( ( jr_model . v_exc . T - jr_model . v_inh . T ) . squeeze (), dt = jr_model . params [ \"sampling_dt\" ], maxfr = 40.0 , ) axs [ 0 , 1 ] . semilogy ( fr , po , color = \"indianred\" ) axs [ 0 , 1 ] . set_xlabel ( \"frequency [Hz]\" ) axs [ 0 , 1 ] . set_ylabel ( \"log power\" ) axs [ 1 , 1 ] . hist ( jr_model . v_exc . T - jr_model . v_inh . T , bins = 15 , color = \"gray\" ) axs [ 1 , 1 ] . set_xlabel ( \"LFP\" ) axs [ 1 , 1 ] . set_ylabel ( \"#\" ) plt . suptitle ( \"`numba` backend\" ) Text(0.5, 0.98, '`numba` backend') All works as it should, we have our Jansen-Rit model! In the next step, we will showcase how the new model can be connected and coupled to other models (similar as in the first example). Couple Jansen-Rit to thalamic model Here we practically copy the previous example where we coupled ALN node with a thalamic node, but instead of ALN representing a cortical column, we use our brand new Jansen-Rit model. # let us start by subclassing the Network class JansenRitThalamusMiniNetwork ( Network ): \"\"\" Simple thalamocortical motif: 1 cortical node Jansen-Rit + 1 NMM thalamus. \"\"\" # provide basic attributes as name and label name = \"Jansen-Rit 1 node + Thalamus\" label = \"JRThlmNet\" # define which variables are used to sync, i.e. what coupling variables our nodes need sync_variables = [ # both nodes are connected via excitatory synapses \"network_exc_exc\" , # and INH mass in thalamus also receives excitatory coupling \"network_inh_exc\" , ] # lastly, we need to define what is default output of the network (this has to be the # variable present in all nodes) # for us it is excitatory firing rates default_output = f \"r_mean_EXC\" # define all output vars of any interest to us - EXC and INH firing rates output_vars = [ f \"r_mean_EXC\" , f \"r_mean_INH\" ] def __init__ ( self , connectivity_matrix , delay_matrix , seed = None ): # self connections are resolved within nodes, so zeroes at the diagonal assert np . all ( np . diag ( connectivity_matrix ) == 0.0 ) # init Jansen-Rit node with index 0 jr_node = JansenRitNode ( seed = seed ) jr_node . index = 0 # index where the state variables start - for first node it is always 0 jr_node . idx_state_var = 0 # set correct indices for noise input - in JR we have only one noise source jr_node [ 0 ] . noise_input_idx = [ 0 ] # init thalamus node with index 1 thalamus = ThalamicNode () thalamus . index = 1 # thalamic state variables start where ALN state variables end - easy thalamus . idx_state_var = jr_node . num_state_variables # set correct indices of noise input - one per mass, after ALN noise # indices for mass in thalamus : mass . noise_input_idx = [ jr_node . num_noise_variables + mass . index ] # now super.__init__ network with these two nodes: super () . __init__ ( nodes = [ jr_node , thalamus ], connectivity_matrix = connectivity_matrix , delay_matrix = delay_matrix , ) # done! the only other thing we need to do, is to set the coupling variables # thalamus vs. Jansen-Rit are coupled via their firing rates and here we setup the # coupling matrices; the super class `Network` comes with some convenient # functions for this def _sync ( self ): \"\"\" Set coupling variables - the ones we defined in `sync_variables` _sync returns a list of tuples where the first element in each tuple is the coupling \"symbol\" and the second is the actual mathematical expression for the ease of doing this, `Network` class contains convenience functions for this: - _additive_coupling - _diffusive_coupling - _no_coupling here we use additive coupling only \"\"\" # get indices of coupling variables from all nodes exc_indices = [ next ( iter ( node . all_couplings ( mass_indices = node . excitatory_masses . tolist () ) ) ) for node in self ] assert len ( exc_indices ) == len ( self ) return ( # basic EXC <-> EXC coupling # within_node_idx is a list of len 2 (because we have two nodes) # with indices of coupling variables within the respective state vectors self . _additive_coupling ( within_node_idx = exc_indices , symbol = \"network_exc_exc\" ) # EXC -> INH coupling (only to thalamus) + self . _additive_coupling ( within_node_idx = exc_indices , symbol = \"network_inh_exc\" , connectivity = self . connectivity , ) + super () . _sync () ) # lets check what we have # in the ALN-thalamus case the matrix was [0.0, 0.15], [1.2, 0.0] - JR produces firing rates around 5Hz (5 times lower than ALN) SC = np . array ([[ 0.0 , 0.15 ], [ 6. , 0.0 ]]) delays = np . array ([[ 0.0 , 13.0 ], [ 13.0 , 0.0 ]]) # thalamocortical delay = 13ms thalamocortical = MultiModel ( JansenRitThalamusMiniNetwork ( connectivity_matrix = SC , delay_matrix = delays , seed = 42 )) # original `MultiModel` instance is always accessible as `MultiModel.model_instance` display ( thalamocortical . model_instance . describe ()) {'name': 'Jansen-Rit 1 node + Thalamus', 'num_nodes': 2, 'num_state_variables': 24, 'num_noise_variables': 3, 'nodes': [{'index': 0, 'name': 'Jansen-Rit node', 'num_masses': 1, 'num_num_state_variables': 7, 'num_noise_variables': 1, 'masses': [{'index': 0, 'name': 'Jansen-Rit mass', 'mass_type': None, 'num_state_variables': 7, 'num_noise_variables': 1, 'state_variable_names': ['v_pyr', 'dv_pyr', 'v_exc', 'dv_exc', 'v_inh', 'dv_inh', 'r_mean_EXC'], 'params': {'A': 3.25, 'B': 22.0, 'a': 0.1, 'b': 0.05, 'v0': 6.0, 'v_max': 0.005, 'r': 0.56, 'C': 135.0, 'lambda': 10.0, 'input_0': {'type': 'UniformlyDistributedNoise', 'low': 0.12, 'high': 0.32, 'n': 1, 'seed': 42}}}]}, {'index': 1, 'name': 'Thalamic mass model node', 'num_masses': 2, 'num_num_state_variables': 17, 'num_noise_variables': 2, 'masses': [{'index': 0, 'name': 'Thalamocortical relay mass', 'mass_type': 'EXC', 'num_state_variables': 10, 'num_noise_variables': 1, 'state_variable_names': ['V', 'Ca', 'h_T', 'm_h1', 'm_h2', 's_e', 's_i', 'ds_e', 'ds_i', 'r_mean'], 'params': {'tau': 20.0, 'Q_max': 0.4, 'theta': -58.5, 'sigma': 6.0, 'C1': 1.8137993642, 'C_m': 1.0, 'gamma_e': 0.07, 'gamma_r': 0.1, 'g_L': 1.0, 'g_GABA': 1.0, 'g_AMPA': 1.0, 'g_LK': 0.018, 'g_T': 3.0, 'g_h': 0.062, 'E_AMPA': 0.0, 'E_GABA': -70.0, 'E_L': -70.0, 'E_K': -100.0, 'E_Ca': 120.0, 'E_h': -40.0, 'alpha_Ca': -5.18e-05, 'tau_Ca': 10.0, 'Ca_0': 0.00024, 'k1': 25000000.0, 'k2': 0.0004, 'k3': 0.1, 'k4': 0.001, 'n_P': 4.0, 'g_inc': 2.0, 'ext_current': 0.0, 'lambda': 10.0, 'input_0': {'type': 'OrnsteinUhlenbeckProcess', 'mu': 0.0, 'sigma': 0.0, 'tau': 5.0, 'n': 1, 'seed': None}}}, {'index': 1, 'name': 'Thalamic reticular nuclei mass', 'mass_type': 'INH', 'num_state_variables': 7, 'num_noise_variables': 1, 'state_variable_names': ['V', 'h_T', 's_e', 's_i', 'ds_e', 'ds_i', 'r_mean'], 'params': {'tau': 20.0, 'Q_max': 0.4, 'theta': -58.5, 'sigma': 6.0, 'C1': 1.8137993642, 'C_m': 1.0, 'gamma_e': 0.07, 'gamma_r': 0.1, 'g_L': 1.0, 'g_GABA': 1.0, 'g_AMPA': 1.0, 'g_LK': 0.018, 'g_T': 2.3, 'E_AMPA': 0.0, 'E_GABA': -70.0, 'E_L': -70.0, 'E_K': -100.0, 'E_Ca': 120.0, 'ext_current': 0.0, 'lambda': 10.0, 'input_0': {'type': 'ZeroInput', 'n': 1, 'seed': None}}}], 'local_connectivity': array([[ 0., 5.], [ 3., 25.]]), 'local_delays': array([[0., 0.], [0., 0.]])}], 'connectivity': array([[0. , 0.15], [6. , 0. ]]), 'delays': array([[ 0., 13.], [13., 0.]])} # fix parameters for interesting regime thalamocortical . params [ \"*g_LK\" ] = 0.032 # K-leak conductance in thalamus thalamocortical . params [ \"*TCR*input*sigma\" ] = 0.005 # noise in thalamus thalamocortical . params [ \"*input*tau\" ] = 5.0 # timescale of OU process thalamocortical . params [ \"duration\" ] = 20000. # 20 seconds simulation thalamocortical . params [ \"sampling_dt\" ] = 1.0 thalamocortical . run () /Users/nikola/.virtualenvs/neurolib/lib/python3.7/site-packages/jitcdde/_jitcdde.py:1491: UserWarning: Your input past does not begin at t=0 but at t=1.0. Values before the beginning of the past will be extrapolated. You very likely do not want this. warn(f\"Your input past does not begin at t=0 but at t={input[0].time}. Values before the beginning of the past will be extrapolated. You very likely do not want this.\") Using default integration parameters. 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 20000/20000 [00:01<00:00, 18832.12it/s] _ , axs = plt . subplots ( nrows = 2 , ncols = 1 , sharex = True , figsize = ( 12 , 6 )) axs [ 0 ] . plot ( thalamocortical . t , thalamocortical . r_mean_EXC [ 0 , :] . T ) axs [ 0 ] . set_ylabel ( \"Jansen-Rit firing rate [kHz]\" ) axs [ 1 ] . plot ( thalamocortical . t , thalamocortical . r_mean_EXC [ 1 , :] . T , color = \"C1\" ) axs [ 1 ] . set_ylabel ( \"thalamus firing rate [kHz]\" ) axs [ 1 ] . set_xlabel ( \"time [sec]\" ) Text(0.5, 0, 'time [sec]') So the model works, just like that! Of course, in this case we do not see anything interesting in the modelled dynamics, since we would need to proper investigation of various parameters. Consider this as a proof-of-concept, where we can very easily couple two very different population models.","title":"Example 4.1 multimodel custom model"},{"location":"examples/example-4.1-multimodel-custom-model/#creating-new-model-from-scratch","text":"The real power of MultiModel framework is in fast prototyping of heterogeneous models. To showcase this, in this notebook we create a brand new model in the framework (the famous Jansen-Rit model), and then create a thalamocortical mini network with 1 node representing a thalamus and 1 node Jansen-Rit model representing a cortical column.","title":"Creating new model from scratch"},{"location":"examples/example-4.1-multimodel-custom-model/#jansen-rit-model","text":"The Jansen-Rit model is a neural population model of a local cortical circuit. It contains three interconnected neural populations: one for the pyramidal projection neurons and two for excitatory and inhibitory interneurons forming feedback loops. The equations for Jansen-Rit model reads: \\begin{align} \\ddot{x} {0} & = Aa\\cdot\\mathrm{Sigm}\\left(x {1} - x_{2}\\right) - 2a\\dot{x} {0} - a^{2}x {0} \\ \\ddot{x} {1} & = Aa[p + C {2}\\mathrm{Sigm}\\left(C_{1}x_{0}\\right)] - 2a\\dot{x} {1} - a^2x {1} \\ \\ddot{x} {2} & = BbC {4}\\mathrm{Sigm}\\left( C_{3}x_{o} \\right) - 2b\\dot{x} {2} - b^2x {2} \\ \\mathrm{Sigm}(x) & = \\frac{v_{max}}{1 + \\mathrm{e}^{r(v_{0} - x)}} \\end{align} Of course, in order to implement the above equations numerically, the system of three second-order ODEs will be rewritten into a system of six first-order ODEs.","title":"Jansen-Rit model"},{"location":"examples/example-4.1-multimodel-custom-model/#multimodel-strategy","text":"The actual implementation will be a bit more involved than simply writing down the above equations. The building block of any proper MultiModel is a NeuralMass . Jansen-Rit model actually summarises an activity of a cortical column consisting of three populations: a population of pyramidal cells interacting with two populations of interneurons - one excitatory and one inhibitory. Moreover, the \\(x\\) represent the average membrane potential, but typically, neuronal models (at least in neurolib ) are coupled via firing rate. For this reason, our main output variable would actually be a firing rate of a main, pyramidal population. The average membrane potential of a pyramidal population is \\(x = x_{1} - x_{2}\\) and its firing rate is then \\(r = \\mathrm{Sigm}(x) = \\mathrm{Sigm}(x_{1} - x_{2})\\) . Similar strategy (sigmoidal transfer function for average membrane potential) is used for the thalamic model. The coupling variable in MultiModel must be the same across all hierarchical levels. Individial populations in Jansen-Rit model are coupled via their average membrane potentials \\(x_{i}\\) , \\(i\\in[0, 1, 2]\\) . However, the \"global\" coupling variable for the node would be the firing rate of pyramidal population \\(r\\) , introduced in the paragraph above. To reconcile this, two options exists in MultiModel : * create a NeuralMass representing a pyramidal population with two coupling variables: \\(x_{0}\\) and \\(r\\) ; NeuralMass representing interneurons would have one coupling variable, \\(x_{1,2}\\) * advantages: cleaner (implementation), more modular (can create J-R Node with more masses than 3 very easily) * disadvantages: more code, might be harder to navigate for the beginner * create one NeuralMass representing all three populations with one coupling variable \\(r\\) , since the others are not really coupling since the whole dynamics is contained in one object * advantages: less code, easier to grasp * disadvantages: less modular, cannot simply edit J-R model, since everything is \"hardcoded\" into one NeuralMass object In order to build a basic understanding of building blocks, we will follow the second option here (less code, easier to grasp). For interested readers, the first option (modular one) will be implemented in MultiModel , so you can follow the model files. Our strategy for this notebook then would be: 1. implement single NeuralMass object representing all three populations in the Jansen-Rit model, with single coupling variable \\(r\\) 2. implement a \"dummy\" Node with single NeuralMass (requirement, one cannot couple Node to a NeuralMass to build a network) 3. experiment with connecting this Jansen-Rit cortical model to the thalamic population model Last note, all model's dynamics and parameters in MultiModel are defined in milliseconds, therefore we will scale the default parameters. Let us start with the imports: import matplotlib.pyplot as plt import numpy as np import symengine as se from IPython.display import display from jitcdde import input as system_input from neurolib.models.multimodel import MultiModel , ThalamicNode from neurolib.models.multimodel.builder.base.constants import LAMBDA_SPEED from neurolib.models.multimodel.builder.base.network import Network , Node from neurolib.models.multimodel.builder.base.neural_mass import NeuralMass from neurolib.utils.functions import getPowerSpectrum from neurolib.utils.stimulus import Input , OrnsteinUhlenbeckProcess , StepInput A quick detour before we dive into the model itself. Jansen-Rit model is typically driven with a uniformly distributed noise, as the authors wanted to model nonspecific input (they used the term background spontaneous activity ). For this we quickly create our model input using the ModelInput class (the tutorial on how to use stimuli in neurolib is given elsewhere). class UniformlyDistributedNoise ( Input ): \"\"\" Uniformly distributed noise process between two values. \"\"\" def __init__ ( self , low , high , n = 1 , seed = None ): # save arguments as attributes for later self . low = low self . high = high # init super super () . __init__ ( n = n , seed = seed ) def generate_input ( self , duration , dt ): # generate time vector self . _get_times ( duration = duration , dt = dt ) # generate noise process itself with the correct shape # as (time steps x num. processes) return np . random . uniform ( self . low , self . high , ( self . n , self . times . shape [ 0 ]) ) # let us build a proper hierarchy, i.e. we firstly build a Jansen-Rit mass class SingleJansenRitMass ( NeuralMass ): \"\"\" Single Jansen-Rit mass implementing whole three population dynamics. Reference: Jansen, B. H., & Rit, V. G. (1995). Electroencephalogram and visual evoked potential generation in a mathematical model of coupled cortical columns. Biological cybernetics, 73(4), 357-366. \"\"\" # all these attributes are compulsory to fill in name = \"Jansen-Rit mass\" label = \"JRmass\" num_state_variables = 7 # 6 ODEs + firing rate coupling variable num_noise_variables = 1 # single external input # NOTE # external inputs (so-called noise_variables) are typically background noise drive in models, # however, this can be any type of stimulus - periodic stimulus, step stimulus, square pulse, # anything. Therefore you may want to add more stimuli, e.g. for Jansen-Rit model three to each # of its population. Here we do not stimulate our Jansen-Rit model, so only use actual noise # drive to excitatory interneuron population. # as dictionary {index of state var: it's name} coupling_variables = { 6 : \"r_mean_EXC\" } # as list state_variable_names = [ \"v_pyr\" , \"dv_pyr\" , \"v_exc\" , \"dv_exc\" , \"v_inh\" , \"dv_inh\" , # to comply with other `MultiModel` nodes \"r_mean_EXC\" , ] # as list # note on parameters C1 - C4 - all papers use one C and C1-C4 are # defined as various rations of C, typically: C1 = C, C2 = 0.8*C # C3 = C4 = 0.25*C, therefore we use only `C` and scale it in the # dynamics definition required_params = [ \"A\" , \"a\" , \"B\" , \"b\" , \"C\" , \"v_max\" , \"v0\" , \"r\" , \"lambda\" , ] # list of required couplings when part of a `Node` or `Network` # `network_exc_exc` is the default excitatory coupling between nodes required_couplings = [ \"network_exc_exc\" ] # here we define the default noise input to Jansen-Rit model (this can be changed later) # for a quick test, we follow the original Jansen and Rit paper and use uniformly distributed # noise between 120 - 320 Hz; but we do it in kHz, hence 0.12 - 0.32 # fix seed for reproducibility _noise_input = [ UniformlyDistributedNoise ( low = 0.12 , high = 0.32 , seed = 42 )] def _sigmoid ( self , x ): \"\"\" Sigmoidal transfer function which is the same for all populations. \"\"\" # notes: # - all parameters are accessible as self.params - it is a dictionary # - mathematical definition (ODEs) is done in symbolic mathematics - all functions have to be # imported from `symengine` module, hence se.exp which is a symbolic exponential function return self . params [ \"v_max\" ] / ( 1.0 + se . exp ( self . params [ \"r\" ] * ( self . params [ \"v0\" ] - x )) ) def __init__ ( self , params = None , seed = None ): # init this `NeuralMass` - use passed parameters or default ones # parameters are now accessible as self.params, seed as self.seed super () . __init__ ( params = params or JR_DEFAULT_PARAMS , seed = seed ) def _initialize_state_vector ( self ): \"\"\" Initialize state vector. \"\"\" np . random . seed ( self . seed ) # random in average potentials around zero self . initial_state = ( np . random . normal ( size = self . num_state_variables ) # * np.array([10.0, 0.0, 10.0, 0.0, 10.0, 0.0, 0.0]) ) . tolist () def _derivatives ( self , coupling_variables ): \"\"\" Here the magic happens: dynamics is defined here using symbolic maths package symengine. \"\"\" # first, we need to unwrap state vector ( v_pyr , dv_pyr , v_exc , dv_exc , v_inh , dv_inh , firing_rate , ) = self . _unwrap_state_vector () # this function does everything for us # now we need to write down our dynamics # PYR dynamics d_v_pyr = dv_pyr d_dv_pyr = ( self . params [ \"A\" ] * self . params [ \"a\" ] * self . _sigmoid ( v_exc - v_inh ) - 2 * self . params [ \"a\" ] * dv_pyr - self . params [ \"a\" ] ** 2 * v_pyr ) # EXC dynamics: system input comes into play here d_v_exc = dv_exc d_dv_exc = ( self . params [ \"A\" ] * self . params [ \"a\" ] * ( # system input as function from jitcdde (also in symengine) with proper index: # in our case we have only one noise input (can be more), so index 0 system_input ( self . noise_input_idx [ 0 ]) # C2 = 0.8*C, C1 = C + ( 0.8 * self . params [ \"C\" ]) * self . _sigmoid ( self . params [ \"C\" ] * v_pyr ) ) - 2 * self . params [ \"a\" ] * dv_exc - self . params [ \"a\" ] ** 2 * v_exc ) # INH dynamics d_v_inh = dv_inh d_dv_inh = ( self . params [ \"B\" ] * self . params [ \"b\" ] # C3 = C4 = 0.25 * C * ( 0.25 * self . params [ \"C\" ]) * self . _sigmoid (( 0.25 * self . params [ \"C\" ]) * v_pyr ) - 2 * self . params [ \"b\" ] * dv_inh - self . params [ \"b\" ] ** 2 * v_inh ) # firing rate computation # firing rate as dummy dynamical variable with infinitely fast # fixed point dynamics firing_rate_now = self . _sigmoid ( v_exc - v_inh ) d_firing_rate = - self . params [ \"lambda\" ] * ( firing_rate - firing_rate_now ) # now just return a list of derivatives in the correct order return [ d_v_pyr , d_dv_pyr , d_v_exc , d_dv_exc , d_v_inh , d_dv_inh , d_firing_rate ] And we are done with the basics! Only thing we really need is to define attributes (such as how many variables we have, what couplings we have, what about noise, etc.) and the actual dynamics as symbolic expressions. Symbolic expressions are easy: are basic operators like + , - , * , / , or ** are overloaded, which means you can simply use them and do not think about. Functions such as sin , log , or exp must be imported from symengine and used. Now we define a default set of parameters. Do not forget - MultiModel defines all in ms, therefore the parameters needs to be in ms, kHz, and similar. JR_DEFAULT_PARAMS = { \"A\" : 3.25 , # mV \"B\" : 22.0 , # mV # `a` and `b` are originally 100Hz and 50Hz \"a\" : 0.1 , # kHz \"b\" : 0.05 , # kHz \"v0\" : 6.0 , # mV # v_max is originally 5Hz \"v_max\" : 0.005 , # kHz \"r\" : 0.56 , # m/V \"C\" : 135.0 , # parameter for dummy `r` dynamics \"lambda\" : LAMBDA_SPEED , } The next step is to create a Node . Node is second level in the hierarchy and already it can be wrapped into MultiModel and treated as any other neurolib model. On our case, creating the Node is really simple: it has only one mass, no delays, and no connectivity. class JansenRitNode ( Node ): \"\"\" Jansen-Rit node with 1 neural mass representing 3 population model. \"\"\" name = \"Jansen-Rit node\" label = \"JRnode\" # if Node is integrated isolated, what network input we should use # zero by default = no network input for one-node model default_network_coupling = { \"network_exc_exc\" : 0.0 } # default output is the firing rate of pyramidal population default_output = \"r_mean_EXC\" # list of all variables that are accessible as outputs output_vars = [ \"r_mean_EXC\" , \"v_pyr\" , \"v_exc\" , \"v_inh\" ] def __init__ ( self , params = None , seed = None ): # in `Node` __init__, the list of masses is created and passed jr_mass = SingleJansenRitMass ( params = params , seed = seed ) # each mass has to have index, in this case it is simply 0 jr_mass . index = 0 # call super and properly initialize a Node super () . __init__ ( neural_masses = [ jr_mass ]) self . excitatory_masses = np . array ([ 0 ]) def _sync ( self ): # this function typically defines the coupling between masses # within one node, but in our case there is nothing to define return [] And we are done. At this point, we can integrate our Jansen-Rit model and see some results.","title":"MultiModel strategy"},{"location":"examples/example-4.1-multimodel-custom-model/#test-and-simulate-jansen-rit-model","text":"In order to simulate our newly created model, we just need to wrap it with MultiModel as in the last example and see how it goes. # init model - fix seed for reproducibility (random init. conditions) jr_model = MultiModel . init_node ( JansenRitNode ( seed = 42 )) # see parameters print ( \"Parameters:\" ) display ( jr_model . params ) print ( \"\" ) # see describe print ( \"Describe:\" ) display ( jr_model . model_instance . describe ()) Parameters: {'JRnode_0.JRmass_0.A': 3.25, 'JRnode_0.JRmass_0.B': 22.0, 'JRnode_0.JRmass_0.a': 0.1, 'JRnode_0.JRmass_0.b': 0.05, 'JRnode_0.JRmass_0.v0': 6.0, 'JRnode_0.JRmass_0.v_max': 0.005, 'JRnode_0.JRmass_0.r': 0.56, 'JRnode_0.JRmass_0.C': 135.0, 'JRnode_0.JRmass_0.lambda': 10.0, 'JRnode_0.JRmass_0.input_0.type': 'UniformlyDistributedNoise', 'JRnode_0.JRmass_0.input_0.low': 0.12, 'JRnode_0.JRmass_0.input_0.high': 0.32, 'JRnode_0.JRmass_0.input_0.n': 1, 'JRnode_0.JRmass_0.input_0.seed': 42, 'duration': 2000, 'dt': 0.1, 'seed': None, 'backend': 'jitcdde', 'name': 'JRnode', 'description': 'Jansen-Rit node', 'N': 1, 'Cmat': array([[0.]]), 'sampling_dt': 0.1} Describe: {'index': 0, 'name': 'Jansen-Rit node', 'num_masses': 1, 'num_num_state_variables': 7, 'num_noise_variables': 1, 'masses': [{'index': 0, 'name': 'Jansen-Rit mass', 'mass_type': None, 'num_state_variables': 7, 'num_noise_variables': 1, 'state_variable_names': ['v_pyr', 'dv_pyr', 'v_exc', 'dv_exc', 'v_inh', 'dv_inh', 'r_mean_EXC'], 'params': {'A': 3.25, 'B': 22.0, 'a': 0.1, 'b': 0.05, 'v0': 6.0, 'v_max': 0.005, 'r': 0.56, 'C': 135.0, 'lambda': 10.0, 'input_0': {'type': 'UniformlyDistributedNoise', 'low': 0.12, 'high': 0.32, 'n': 1, 'seed': 42}}}]} # run model for 5 seconds - all in ms jr_model . params [ \"sampling_dt\" ] = 1.0 jr_model . params [ \"duration\" ] = 5000 jr_model . params [ \"backend\" ] = \"jitcdde\" jr_model . run () /Users/nikola/.virtualenvs/neurolib/lib/python3.7/site-packages/jitcdde/_jitcdde.py:1491: UserWarning: Your input past does not begin at t=0 but at t=1.0. Values before the beginning of the past will be extrapolated. You very likely do not want this. warn(f\"Your input past does not begin at t=0 but at t={input[0].time}. Values before the beginning of the past will be extrapolated. You very likely do not want this.\") Using default integration parameters. 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5000/5000 [00:00<00:00, 26901.12it/s] _ , axs = plt . subplots ( nrows = 2 , ncols = 2 , figsize = ( 12 , 6 ), gridspec_kw = { \"width_ratios\" : [ 2 , 1 ]} ) axs [ 0 , 0 ] . plot ( jr_model . t , jr_model . v_exc . T - jr_model . v_inh . T , color = \"k\" ) axs [ 0 , 0 ] . set_ylabel ( \"LFP\" ) axs [ 1 , 0 ] . plot ( jr_model . t , jr_model . r_mean_EXC . T * 1000 , color = \"navy\" ) axs [ 1 , 0 ] . set_ylabel ( \"PYR r [Hz]\" ) axs [ 1 , 0 ] . set_xlabel ( \"time [sec]\" ) fr , po = getPowerSpectrum ( ( jr_model . v_exc . T - jr_model . v_inh . T ) . squeeze (), dt = jr_model . params [ \"sampling_dt\" ], maxfr = 40.0 , ) axs [ 0 , 1 ] . semilogy ( fr , po , color = \"indianred\" ) axs [ 0 , 1 ] . set_xlabel ( \"frequency [Hz]\" ) axs [ 0 , 1 ] . set_ylabel ( \"log power\" ) axs [ 1 , 1 ] . hist ( jr_model . v_exc . T - jr_model . v_inh . T , bins = 15 , color = \"gray\" ) axs [ 1 , 1 ] . set_xlabel ( \"LFP\" ) axs [ 1 , 1 ] . set_ylabel ( \"#\" ) plt . suptitle ( \"`jitcdde` backend\" ) Text(0.5, 0.98, '`jitcdde` backend') The results looks good! With the same parameters as original Jansen and Rit paper, we got the \\(\\alpha\\) activity with spectral peak around 10 Hz. Just as a proof of concept - let us try the second MultiModel backend. # run model for 5 seconds - all in ms jr_model . params [ \"sampling_dt\" ] = 1.0 jr_model . params [ \"dt\" ] = 0.1 jr_model . params [ \"duration\" ] = 5000 jr_model . params [ \"backend\" ] = \"numba\" jr_model . run () _ , axs = plt . subplots ( nrows = 2 , ncols = 2 , figsize = ( 12 , 6 ), gridspec_kw = { \"width_ratios\" : [ 2 , 1 ]} ) axs [ 0 , 0 ] . plot ( jr_model . t , jr_model . v_exc . T - jr_model . v_inh . T , color = \"k\" ) axs [ 0 , 0 ] . set_ylabel ( \"LFP\" ) axs [ 1 , 0 ] . plot ( jr_model . t , jr_model . r_mean_EXC . T * 1000 , color = \"navy\" ) axs [ 1 , 0 ] . set_ylabel ( \"PYR r [Hz]\" ) axs [ 1 , 0 ] . set_xlabel ( \"time [sec]\" ) fr , po = getPowerSpectrum ( ( jr_model . v_exc . T - jr_model . v_inh . T ) . squeeze (), dt = jr_model . params [ \"sampling_dt\" ], maxfr = 40.0 , ) axs [ 0 , 1 ] . semilogy ( fr , po , color = \"indianred\" ) axs [ 0 , 1 ] . set_xlabel ( \"frequency [Hz]\" ) axs [ 0 , 1 ] . set_ylabel ( \"log power\" ) axs [ 1 , 1 ] . hist ( jr_model . v_exc . T - jr_model . v_inh . T , bins = 15 , color = \"gray\" ) axs [ 1 , 1 ] . set_xlabel ( \"LFP\" ) axs [ 1 , 1 ] . set_ylabel ( \"#\" ) plt . suptitle ( \"`numba` backend\" ) Text(0.5, 0.98, '`numba` backend') All works as it should, we have our Jansen-Rit model! In the next step, we will showcase how the new model can be connected and coupled to other models (similar as in the first example).","title":"Test and simulate Jansen-Rit model"},{"location":"examples/example-4.1-multimodel-custom-model/#couple-jansen-rit-to-thalamic-model","text":"Here we practically copy the previous example where we coupled ALN node with a thalamic node, but instead of ALN representing a cortical column, we use our brand new Jansen-Rit model. # let us start by subclassing the Network class JansenRitThalamusMiniNetwork ( Network ): \"\"\" Simple thalamocortical motif: 1 cortical node Jansen-Rit + 1 NMM thalamus. \"\"\" # provide basic attributes as name and label name = \"Jansen-Rit 1 node + Thalamus\" label = \"JRThlmNet\" # define which variables are used to sync, i.e. what coupling variables our nodes need sync_variables = [ # both nodes are connected via excitatory synapses \"network_exc_exc\" , # and INH mass in thalamus also receives excitatory coupling \"network_inh_exc\" , ] # lastly, we need to define what is default output of the network (this has to be the # variable present in all nodes) # for us it is excitatory firing rates default_output = f \"r_mean_EXC\" # define all output vars of any interest to us - EXC and INH firing rates output_vars = [ f \"r_mean_EXC\" , f \"r_mean_INH\" ] def __init__ ( self , connectivity_matrix , delay_matrix , seed = None ): # self connections are resolved within nodes, so zeroes at the diagonal assert np . all ( np . diag ( connectivity_matrix ) == 0.0 ) # init Jansen-Rit node with index 0 jr_node = JansenRitNode ( seed = seed ) jr_node . index = 0 # index where the state variables start - for first node it is always 0 jr_node . idx_state_var = 0 # set correct indices for noise input - in JR we have only one noise source jr_node [ 0 ] . noise_input_idx = [ 0 ] # init thalamus node with index 1 thalamus = ThalamicNode () thalamus . index = 1 # thalamic state variables start where ALN state variables end - easy thalamus . idx_state_var = jr_node . num_state_variables # set correct indices of noise input - one per mass, after ALN noise # indices for mass in thalamus : mass . noise_input_idx = [ jr_node . num_noise_variables + mass . index ] # now super.__init__ network with these two nodes: super () . __init__ ( nodes = [ jr_node , thalamus ], connectivity_matrix = connectivity_matrix , delay_matrix = delay_matrix , ) # done! the only other thing we need to do, is to set the coupling variables # thalamus vs. Jansen-Rit are coupled via their firing rates and here we setup the # coupling matrices; the super class `Network` comes with some convenient # functions for this def _sync ( self ): \"\"\" Set coupling variables - the ones we defined in `sync_variables` _sync returns a list of tuples where the first element in each tuple is the coupling \"symbol\" and the second is the actual mathematical expression for the ease of doing this, `Network` class contains convenience functions for this: - _additive_coupling - _diffusive_coupling - _no_coupling here we use additive coupling only \"\"\" # get indices of coupling variables from all nodes exc_indices = [ next ( iter ( node . all_couplings ( mass_indices = node . excitatory_masses . tolist () ) ) ) for node in self ] assert len ( exc_indices ) == len ( self ) return ( # basic EXC <-> EXC coupling # within_node_idx is a list of len 2 (because we have two nodes) # with indices of coupling variables within the respective state vectors self . _additive_coupling ( within_node_idx = exc_indices , symbol = \"network_exc_exc\" ) # EXC -> INH coupling (only to thalamus) + self . _additive_coupling ( within_node_idx = exc_indices , symbol = \"network_inh_exc\" , connectivity = self . connectivity , ) + super () . _sync () ) # lets check what we have # in the ALN-thalamus case the matrix was [0.0, 0.15], [1.2, 0.0] - JR produces firing rates around 5Hz (5 times lower than ALN) SC = np . array ([[ 0.0 , 0.15 ], [ 6. , 0.0 ]]) delays = np . array ([[ 0.0 , 13.0 ], [ 13.0 , 0.0 ]]) # thalamocortical delay = 13ms thalamocortical = MultiModel ( JansenRitThalamusMiniNetwork ( connectivity_matrix = SC , delay_matrix = delays , seed = 42 )) # original `MultiModel` instance is always accessible as `MultiModel.model_instance` display ( thalamocortical . model_instance . describe ()) {'name': 'Jansen-Rit 1 node + Thalamus', 'num_nodes': 2, 'num_state_variables': 24, 'num_noise_variables': 3, 'nodes': [{'index': 0, 'name': 'Jansen-Rit node', 'num_masses': 1, 'num_num_state_variables': 7, 'num_noise_variables': 1, 'masses': [{'index': 0, 'name': 'Jansen-Rit mass', 'mass_type': None, 'num_state_variables': 7, 'num_noise_variables': 1, 'state_variable_names': ['v_pyr', 'dv_pyr', 'v_exc', 'dv_exc', 'v_inh', 'dv_inh', 'r_mean_EXC'], 'params': {'A': 3.25, 'B': 22.0, 'a': 0.1, 'b': 0.05, 'v0': 6.0, 'v_max': 0.005, 'r': 0.56, 'C': 135.0, 'lambda': 10.0, 'input_0': {'type': 'UniformlyDistributedNoise', 'low': 0.12, 'high': 0.32, 'n': 1, 'seed': 42}}}]}, {'index': 1, 'name': 'Thalamic mass model node', 'num_masses': 2, 'num_num_state_variables': 17, 'num_noise_variables': 2, 'masses': [{'index': 0, 'name': 'Thalamocortical relay mass', 'mass_type': 'EXC', 'num_state_variables': 10, 'num_noise_variables': 1, 'state_variable_names': ['V', 'Ca', 'h_T', 'm_h1', 'm_h2', 's_e', 's_i', 'ds_e', 'ds_i', 'r_mean'], 'params': {'tau': 20.0, 'Q_max': 0.4, 'theta': -58.5, 'sigma': 6.0, 'C1': 1.8137993642, 'C_m': 1.0, 'gamma_e': 0.07, 'gamma_r': 0.1, 'g_L': 1.0, 'g_GABA': 1.0, 'g_AMPA': 1.0, 'g_LK': 0.018, 'g_T': 3.0, 'g_h': 0.062, 'E_AMPA': 0.0, 'E_GABA': -70.0, 'E_L': -70.0, 'E_K': -100.0, 'E_Ca': 120.0, 'E_h': -40.0, 'alpha_Ca': -5.18e-05, 'tau_Ca': 10.0, 'Ca_0': 0.00024, 'k1': 25000000.0, 'k2': 0.0004, 'k3': 0.1, 'k4': 0.001, 'n_P': 4.0, 'g_inc': 2.0, 'ext_current': 0.0, 'lambda': 10.0, 'input_0': {'type': 'OrnsteinUhlenbeckProcess', 'mu': 0.0, 'sigma': 0.0, 'tau': 5.0, 'n': 1, 'seed': None}}}, {'index': 1, 'name': 'Thalamic reticular nuclei mass', 'mass_type': 'INH', 'num_state_variables': 7, 'num_noise_variables': 1, 'state_variable_names': ['V', 'h_T', 's_e', 's_i', 'ds_e', 'ds_i', 'r_mean'], 'params': {'tau': 20.0, 'Q_max': 0.4, 'theta': -58.5, 'sigma': 6.0, 'C1': 1.8137993642, 'C_m': 1.0, 'gamma_e': 0.07, 'gamma_r': 0.1, 'g_L': 1.0, 'g_GABA': 1.0, 'g_AMPA': 1.0, 'g_LK': 0.018, 'g_T': 2.3, 'E_AMPA': 0.0, 'E_GABA': -70.0, 'E_L': -70.0, 'E_K': -100.0, 'E_Ca': 120.0, 'ext_current': 0.0, 'lambda': 10.0, 'input_0': {'type': 'ZeroInput', 'n': 1, 'seed': None}}}], 'local_connectivity': array([[ 0., 5.], [ 3., 25.]]), 'local_delays': array([[0., 0.], [0., 0.]])}], 'connectivity': array([[0. , 0.15], [6. , 0. ]]), 'delays': array([[ 0., 13.], [13., 0.]])} # fix parameters for interesting regime thalamocortical . params [ \"*g_LK\" ] = 0.032 # K-leak conductance in thalamus thalamocortical . params [ \"*TCR*input*sigma\" ] = 0.005 # noise in thalamus thalamocortical . params [ \"*input*tau\" ] = 5.0 # timescale of OU process thalamocortical . params [ \"duration\" ] = 20000. # 20 seconds simulation thalamocortical . params [ \"sampling_dt\" ] = 1.0 thalamocortical . run () /Users/nikola/.virtualenvs/neurolib/lib/python3.7/site-packages/jitcdde/_jitcdde.py:1491: UserWarning: Your input past does not begin at t=0 but at t=1.0. Values before the beginning of the past will be extrapolated. You very likely do not want this. warn(f\"Your input past does not begin at t=0 but at t={input[0].time}. Values before the beginning of the past will be extrapolated. You very likely do not want this.\") Using default integration parameters. 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 20000/20000 [00:01<00:00, 18832.12it/s] _ , axs = plt . subplots ( nrows = 2 , ncols = 1 , sharex = True , figsize = ( 12 , 6 )) axs [ 0 ] . plot ( thalamocortical . t , thalamocortical . r_mean_EXC [ 0 , :] . T ) axs [ 0 ] . set_ylabel ( \"Jansen-Rit firing rate [kHz]\" ) axs [ 1 ] . plot ( thalamocortical . t , thalamocortical . r_mean_EXC [ 1 , :] . T , color = \"C1\" ) axs [ 1 ] . set_ylabel ( \"thalamus firing rate [kHz]\" ) axs [ 1 ] . set_xlabel ( \"time [sec]\" ) Text(0.5, 0, 'time [sec]') So the model works, just like that! Of course, in this case we do not see anything interesting in the modelled dynamics, since we would need to proper investigation of various parameters. Consider this as a proof-of-concept, where we can very easily couple two very different population models.","title":"Couple Jansen-Rit to thalamic model"},{"location":"examples/example-4.2-multimodel-backends-and-optimization/","text":"(function() { function addWidgetsRenderer() { var requireJsScript = document.createElement('script'); requireJsScript.src = 'https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js'; var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var jupyterWidgetsScript = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} jupyterWidgetsScript.src = widgetRendererSrc; document.body.appendChild(requireJsScript); document.body.appendChild(jupyterWidgetsScript); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); import matplotlib.pyplot as plt import neurolib.utils.functions as func import numpy as np from IPython.display import display from neurolib.models.multimodel import ( ALNNode , FitzHughNagumoNetwork , FitzHughNagumoNode , MultiModel , ) from neurolib.optimize.evolution import Evolution from neurolib.optimize.exploration import BoxSearch from neurolib.utils.parameterSpace import ParameterSpace # a nice color map plt . rcParams [ \"image.cmap\" ] = \"plasma\" MultiModel advanced topics In the last two examples we showcased the basics of MultiModel framework and how to create a new model from scratch. Now we will look at some advanced topics such as how exactly the integration works, why we have two integration backends, and how to run optimisation and exploration with MultiModel . The tale of two backends In the current implementation of MultiModel , users may choose from two different integration backends. Before diving into the details of both backends, let us quickly revise how exactly MultiModel integrates the model equations. The how Almost all whole-brain simulators works in the sense, that you define the dynamics of single brain area and then we have a double loop for integration: one over time, the second over brain areas. In other words, all brain areas have the same dynamics. In pseudo-code it would look something like: for t in range ( time_total ): for n in range ( num_areas ): x [ t , n ] = integrate_step ( x [ t - max_delay : t - 1 , :]) Since all areas are the same, the integrate_step function would simply take the history of state vector and apply one integration step in any scheme. This won't work in MultiModel , since it allows building heterogeneous models. The internal workings of MultiModel can be explained in couple of steps. State vector Since the inner loop in the pseudocode above is not doable in MultiModel due to heterogeneity, we solve it simply by concatenating all individual equations into one big state vector (that is also the reason why all NeuralMass and Node objects have their indices). When the model is ready for simulation, we iterate over Nodes and NeuralMasses within these nodes and stack their equations into a single list. The concatenation is done using the _derivatives() function. - in NeuralMass , the _derivatives() function implements the actual dynamics as delay differential equations - in Node , the _derivatives() function stacks all equations from NeuralMasses within this Node into one list - in Network , the _derivatives() function stacks all equations from Nodes within this Network . Let us see how it looks like: # create a FitzHugh-Nagumo Node fhn_node = FitzHughNagumoNode () # necessary attributes when creating a Node from scratch fhn_node . index = 0 fhn_node . idx_state_var = 0 fhn_node . init_node () display ( fhn_node . _derivatives ()) display ( len ( fhn_node . _derivatives ()), fhn_node . num_state_variables ) [1.0 + 4.0*current_y(0)**2 - 3.0*current_y(0)**3 - 1.5*current_y(0) - current_y(1) + past_y(-external_input + t, input_base_n, anchors(-external_input + t)), 0.05*(current_y(0) - 0.5*current_y(1)) + past_y(-external_input + t, 1 + input_base_n, anchors(-external_input + t))] 2 2 As we see, the _derivatives() function return a list of equations, in this case of length 2 (which is, of course, equal to fhn.num_state_variables ). The current_y(<index>) lingo is taken from jitcdde . As written above, all equations are symbolic and therefore current_y(<index>) is a symengine Symbol representing state vector with index <index> at current time t . In other words, current_y(0) is the first variable (in FitzHugh-Nagumo model, this is the \\(x\\) ), while current_y(1) is the second variable (the \\(y\\) ). The past_y() lingo is the same, but encodes either the past of the state vector, i.e. delayed interactions, or the external input (noise or stimulus). In this case it represents the external input (you can tell since it is past_y(-external_input...) ). Now let us see how it looks like for network: # create 2 node FHN network SC = np . array ([[ 0.0 , 1.43 ], [ 0.64 , 0.0 ]]) delays = np . array ([[ 0.0 , 10.0 ], [ 10.0 , 0.0 ]]) fhn_net = FitzHughNagumoNetwork ( SC , delays ) display ( len ( fhn_net . _derivatives ()), fhn_net . num_state_variables ) display ( fhn_net . _derivatives ()) 4 4 [1.0 + network_x_0 + 4.0*current_y(0)**2 - 3.0*current_y(0)**3 - 1.5*current_y(0) - current_y(1) + past_y(-external_input + t, input_base_n, anchors(-external_input + t)), network_y_0 + 0.05*(current_y(0) - 0.5*current_y(1)) + past_y(-external_input + t, 1 + input_base_n, anchors(-external_input + t)), 1.0 + network_x_1 + 4.0*current_y(2)**2 - 3.0*current_y(2)**3 - 1.5*current_y(2) - current_y(3) + past_y(-external_input + t, 2 + input_base_n, anchors(-external_input + t)), network_y_1 + 0.05*(current_y(2) - 0.5*current_y(3)) + past_y(-external_input + t, 3 + input_base_n, anchors(-external_input + t))] Now, since we have 2 nodes, the total number of state variables is 4. And now, we see equations for the whole network as a list of 4 symbolic equations. In the network equations we see a new symbol: network_x_0 and network_x_1 . At this time, these are really just symengine symbols, but they actually represent the coupling between the nodes. And that is also a topic of the next section. Coupling As we have seen before, the state vector encodes the whole dynamics of the brain model, but the coupling is crypted as symbol. To make things easier for simulating, we had to separate the individual internal dynamics from the coupling terms. The coupling comes in two flavours, reflecting the three levels of hierarchy: node coupling takes care of coupling between NeuralMasses within one Node , and network coupling takes care of coupling between Nodes in one Network . The coupling is implemented as _sync() function. This function returns a list, where each item is a tuple of length two: (name_of_the_symbol, symbolic_term_representing_the_coupling) . The FitzHugh-Nagumo model only has one mass per node, hence there are no node couplings, but we can inspect the network coupling: display ( fhn_net . _sync ()) [(network_x_0, 1.43*(-current_y(0) + past_y(-10.0 + t, 2, anchors(-10.0 + t)))), (network_x_1, 0.64*(-current_y(2) + past_y(-10.0 + t, 0, anchors(-10.0 + t)))), (network_y_0, 0.0), (network_y_1, 0.0)] In this particular case, we have 2 coupling variables and 2 nodes, hence 4 coupling terms. The coupling of \\(y\\) is zero. As per the coupling of \\(x\\) variables between nodes, you can now see how it works: network_x_0 just means that we are about to define a network coupling of variable x for the first node, and it is just 1.43 (this is the SC matrix we passed when creating FHN network) times state variable with index 2 at time -10 milliseconds minus current state variable index 0 (diffusive coupling). Similarly for node 1 (with different coupling strength and state variable indices, of course). Now when symbols from _sync() function are inserted into _derivatives() at the proper places, we have a full definition of a model. This is exactly what both backends do: they gather the equations ( _derivatives() ), look up the coupling terms ( _sync() ) and integrate the model forward in time. jitcdde backend The jitcdde backend was the first integration backend in MultiModel . The name stems from the fact that we use wonderful jitcdde python package. It employs just-in-time compilation of symbolic derivatives into C and then uses DDE integration method proposed by Shampine and Thompson, which in turn employs the Bogacki\u2013Shampine Runge\u2013Kutta pair. This is the reason why the definition of dynamics in MultiModel is done using symbolic derivatives written in symengine . It uses adaptive dt scheme, hence is very useful for stiff problems. Also, if you are implementing a new model and have no idea how stiff the dynamics are, this is the backend to try first. It has reasonable speed, but for large networks and long simulations it is not the best. The internal workings of jitcdde package served as an inspiration when creating MultiModel . jitcdde naturally works with dynamics defined as symbolic equations ( _derivatives() ) and it also supports the use of \"helpers\" - the helpers in our case are the coupling terms ( _sync() ). fhn_mm = MultiModel ( fhn_net ) # 2 second run fhn_mm . params [ \"duration\" ] = 2000.0 fhn_mm . params [ \"backend\" ] = \"jitcdde\" # jitcdde works with adaptive dt, you only set sampling dt fhn_mm . params [ \"sampling_dt\" ] = 1.0 fhn_mm . run () plt . plot ( fhn_mm . x . T ) /Users/nikola/.virtualenvs/neurolib/lib/python3.7/site-packages/jitcdde/_jitcdde.py:1491: UserWarning: Your input past does not begin at t=0 but at t=1.0. Values before the beginning of the past will be extrapolated. You very likely do not want this. warn(f\"Your input past does not begin at t=0 but at t={input[0].time}. Values before the beginning of the past will be extrapolated. You very likely do not want this.\") 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 2000/2000 [00:00<00:00, 85415.01it/s] Using default integration parameters. [<matplotlib.lines.Line2D at 0x15aa79950>, <matplotlib.lines.Line2D at 0x15aa63690>] numba backend Since jitcdde is rather slow, in particular for long runs or large networks, we created a numba backend. It was tricky - the whole code around MultiModel was creating with jitcdde in mind with the symbolic equations, helpers, etc. However, the advantage of symbolic equations is also - they are purely symbolic, so you can \"print\" them. By printing, you really just obtain the string with equations. So what numba backend actually does? 1. gather all symbolic equations with _derivatives() 2. substitute coupling symbols with functional terms in _sync() 3. substitute current and past state vector symbols ( current_y() and past_y() ) with state vector y with correct indices and time delays 4. now we have a complete description of dy 5. \"print\" out this dy into prepared function template (string) inside the time for loop, you can imagine it as for t in range ( 1 , t_max ): dy = np . array ({ dy }) # <- `dy` is printed here y [:, t ] = y [:, t - 1 ] + dt * dy 6. compile the prepared string template into an actual python function (yes, python can do this) 7. wrap the compiled function with numba.njit() to get the speed boots 8. profit And yes, the numba backend simply employs Euler integration scheme, which means that you need to think about dt. fhn_mm = MultiModel ( fhn_net ) # 2 second run fhn_mm . params [ \"duration\" ] = 2000.0 fhn_mm . params [ \"backend\" ] = \"numba\" # numba uses Euler scheme so dt is important! fhn_mm . params [ \"dt\" ] = 0.1 fhn_mm . params [ \"sampling_dt\" ] = 1.0 fhn_mm . run () plt . plot ( fhn_mm . x . T ) [<matplotlib.lines.Line2D at 0x15a44fad0>, <matplotlib.lines.Line2D at 0x15a2a0e10>] Which backend to use and when? By default numba backend is almost always faster (with the exception of small network and not too long runs, when they perform similarly). However, for prototyping new models, or connecting couple of models into a heterogeneous network, it is always a good idea to do a couple of short simulations with jitcdde . The reason is - it uses an adaptive dt, so you do not need to worry about setting a correct dt. When you have an idea about what the dynamics should look like and how fast it is, you can switch to numba and try couple of different dt and select the one, when the results are closest to jitcdde results. For exploration and optimisation with evolution, always use numba . numba backend is actually compiling a jit'ed function with all the parameters as arguments, hence for exploration, only one compilation is necessary and then even when changing parameters, the model runs at high speed. Exploration with MultiModel So we all love neurolib not only for its speed, efficiency, and ease of use, but also for its built-in exploration and evolution frameworks. These two makes studying the population models a real breeze! And naturally, MultiModel supports both. Firtsly, we will showcase how we can explore parameters of MultiModel using the BoxSearch class and we will replicate the ALN exploration from example-1-aln-parameter-exploration.ipynb . # first init multimodel aln_mm = MultiModel . init_node ( ALNNode ()) display ( aln_mm . params ) {'ALNNode_0.ALNMassEXC_0.Ke': 800.0, 'ALNNode_0.ALNMassEXC_0.Ki': 200.0, 'ALNNode_0.ALNMassEXC_0.c_gl': 0.4, 'ALNNode_0.ALNMassEXC_0.Ke_gl': 250.0, 'ALNNode_0.ALNMassEXC_0.tau_se': 2.0, 'ALNNode_0.ALNMassEXC_0.tau_si': 5.0, 'ALNNode_0.ALNMassEXC_0.sigmae_ext': 1.5, 'ALNNode_0.ALNMassEXC_0.Jee_max': 2.43, 'ALNNode_0.ALNMassEXC_0.Jei_max': -3.3, 'ALNNode_0.ALNMassEXC_0.C': 200.0, 'ALNNode_0.ALNMassEXC_0.gL': 10.0, 'ALNNode_0.ALNMassEXC_0.ext_exc_current': 0.0, 'ALNNode_0.ALNMassEXC_0.ext_exc_rate': 0.0, 'ALNNode_0.ALNMassEXC_0.a': 15.0, 'ALNNode_0.ALNMassEXC_0.b': 40.0, 'ALNNode_0.ALNMassEXC_0.EA': -80.0, 'ALNNode_0.ALNMassEXC_0.tauA': 200.0, 'ALNNode_0.ALNMassEXC_0.lambda': 10.0, 'ALNNode_0.ALNMassEXC_0.noise_0.type': 'OrnsteinUhlenbeckProcess', 'ALNNode_0.ALNMassEXC_0.noise_0.mu': 0.4, 'ALNNode_0.ALNMassEXC_0.noise_0.sigma': 0.0, 'ALNNode_0.ALNMassEXC_0.noise_0.tau': 5.0, 'ALNNode_0.ALNMassEXC_0.noise_0.num_iid': 1, 'ALNNode_0.ALNMassEXC_0.noise_0.seed': None, 'ALNNode_0.ALNMassINH_1.Ke': 800.0, 'ALNNode_0.ALNMassINH_1.Ki': 200.0, 'ALNNode_0.ALNMassINH_1.c_gl': 0.4, 'ALNNode_0.ALNMassINH_1.Ke_gl': 250.0, 'ALNNode_0.ALNMassINH_1.tau_se': 2.0, 'ALNNode_0.ALNMassINH_1.tau_si': 5.0, 'ALNNode_0.ALNMassINH_1.sigmai_ext': 1.5, 'ALNNode_0.ALNMassINH_1.Jie_max': 2.6, 'ALNNode_0.ALNMassINH_1.Jii_max': -1.64, 'ALNNode_0.ALNMassINH_1.C': 200.0, 'ALNNode_0.ALNMassINH_1.gL': 10.0, 'ALNNode_0.ALNMassINH_1.ext_inh_current': 0.0, 'ALNNode_0.ALNMassINH_1.ext_inh_rate': 0.0, 'ALNNode_0.ALNMassINH_1.lambda': 10.0, 'ALNNode_0.ALNMassINH_1.noise_0.type': 'OrnsteinUhlenbeckProcess', 'ALNNode_0.ALNMassINH_1.noise_0.mu': 0.3, 'ALNNode_0.ALNMassINH_1.noise_0.sigma': 0.0, 'ALNNode_0.ALNMassINH_1.noise_0.tau': 5.0, 'ALNNode_0.ALNMassINH_1.noise_0.num_iid': 1, 'ALNNode_0.ALNMassINH_1.noise_0.seed': None, 'ALNNode_0.local_connectivity': array([[0.24691358, 0.75757576], [0.23076923, 1.52439024]]), 'ALNNode_0.local_delays': array([[4., 2.], [4., 2.]]), 'duration': 2000, 'dt': 0.1, 'seed': None, 'backend': 'jitcdde', 'name': 'ALNNode', 'description': 'ALN neural mass node', 'N': 1, 'Cmat': array([[0.]]), 'sampling_dt': 0.1} Note on parameters when exploring or optimising If you remember, the MultiModel has an option for true heterogeneous parameters, i.e. each brain node can have different parameters. This allows you to explore paramaters one-by-one (truly different parameters for each node), or in bulk. As an example, consider this: parameters1 = ParameterSpace ({ \"*Ke\" : [ 400 , 800 , 1200 ]}, allow_star_notation = True ) parameters2 = ParameterSpace ( { \"*EXC*Ke\" : [ 400 , 800 , 1200 ], \"*INH*Ke\" : [ 400 , 800 , 1200 ]}, allow_star_notation = True ) parameters2 = ParameterSpace ( { \"*Node_0*EXC*Ke\" : [ 400 , 800 , 1200 ], \"*Node_1*EXC*Ke\" : [ 400 , 800 , 1200 ]}, allow_star_notation = True ) In the first example ( parameters1 ), we explore Ke parameter and set this for all nodes and for all masses the same. In the end, we run three simulations with homogeneous Ke for all nodes/masses. In the second example, we explore Ke individually for excitatory masses and inhibitory masses, however, for all nodes these would be the same. In total, we will run 9 simulations with heterogeneous Ke within one node, but the same values for Ke_exc and Ke_inh would be used in all nodes. Finally, in the last example, we would explore only excitatory Ke parameters, but for two nodes differently, hence we can study how excitatory Ke affects 2-node network. Of course, we can always call parameters by their full name (glob path), like: parameters3 = ParameterSpace ( { \"ALNNode_0.ALNMassINH_1.Ke\" : [ 400 , 800 , 1200 ]}, allow_star_notation = True # due to \".\" in the param names ) and we will simply explore over one particular Ke of inhibitory mass in first node within a network. All other Ke parameters will remain constant. # match params to core ALN model aln_mm . params [ \"backend\" ] = \"numba\" aln_mm . params [ \"dt\" ] = 0.1 # ms aln_mm . params [ \"*c_gl\" ] = 0.3 aln_mm . params [ \"*b\" ] = 0.0 aln_mm . params [ \"ALNNode_0.ALNMassEXC_0.a\" ] = 0.0 # set up exploration - using star # parameters = ParameterSpace( # { # \"*EXC*input*mu\": np.linspace(0, 3, 21), # \"*INH*input*mu\": np.linspace(0, 3, 21), # }, # allow_star_notation=True, # ) # set up exploration - using exact parameter names # in this case (one node, search over noise mu) -> these two are equivalent! parameters = ParameterSpace ( { # 2 values per dimension is for quick testing only, for real exploration use e.g. 21 or rather much more \"ALNNode_0.ALNMassEXC_0.input_0.mu\" : np . linspace ( 0 , 3 , 2 ), \"ALNNode_0.ALNMassINH_1.input_0.mu\" : np . linspace ( 0 , 3 , 2 ), # \"ALNNode_0.ALNMassEXC_0.input_0.mu\": np.linspace(0, 3, 21), # \"ALNNode_0.ALNMassINH_1.input_0.mu\": np.linspace(0, 3, 21), }, allow_star_notation = True , ) search = BoxSearch ( aln_mm , parameters , filename = \"example-4.2-exploration.hdf\" ) MainProcess pypet.storageservice.HDF5StorageService INFO I will use the hdf5 file `./data/hdf/example-4.2-exploration.hdf`. MainProcess pypet.environment.Environment INFO Environment initialized. /Users/nikola/.virtualenvs/neurolib/lib/python3.7/site-packages/pypet/naturalnaming.py:1473: SyntaxWarning: `lambda` is a python keyword, you may not be able to access it via natural naming but only by using `[]` square bracket notation. category=SyntaxWarning) MainProcess root INFO Number of parameter configurations: 441 MainProcess root INFO BoxSearch: Environment initialized. search . run () MainProcess pypet.environment.Environment INFO I am preparing the Trajectory for the experiment and initialise the store. MainProcess pypet.environment.Environment INFO Initialising the storage for the trajectory. MainProcess pypet.storageservice.HDF5StorageService INFO Initialising storage or updating meta data of Trajectory `results-2021-07-07-16H-40M-57S`. MainProcess pypet.storageservice.HDF5StorageService INFO Finished init or meta data update for `results-2021-07-07-16H-40M-57S`. MainProcess pypet.environment.Environment INFO ************************************************************ STARTING runs of trajectory `results-2021-07-07-16H-40M-57S`. ************************************************************ MainProcess pypet.storageservice.HDF5StorageService INFO Initialising storage or updating meta data of Trajectory `results-2021-07-07-16H-40M-57S`. MainProcess pypet.storageservice.HDF5StorageService INFO Finished init or meta data update for `results-2021-07-07-16H-40M-57S`. MainProcess pypet.environment.Environment INFO Starting multiprocessing with at most 8 processes running at the same time. MainProcess pypet INFO PROGRESS: Finished 0/441 runs [ ] 0.0% MainProcess pypet INFO PROGRESS: Finished 23/441 runs [= ] 5.2%, remaining: 0:05:32 MainProcess pypet INFO PROGRESS: Finished 45/441 runs [== ] 10.2%, remaining: 0:04:55 MainProcess pypet INFO PROGRESS: Finished 67/441 runs [=== ] 15.2%, remaining: 0:04:32 MainProcess pypet INFO PROGRESS: Finished 89/441 runs [==== ] 20.2%, remaining: 0:04:11 MainProcess pypet INFO PROGRESS: Finished 111/441 runs [===== ] 25.2%, remaining: 0:03:45 MainProcess pypet INFO PROGRESS: Finished 133/441 runs [====== ] 30.2%, remaining: 0:03:29 MainProcess pypet INFO PROGRESS: Finished 155/441 runs [======= ] 35.1%, remaining: 0:03:14 MainProcess pypet INFO PROGRESS: Finished 177/441 runs [======== ] 40.1%, remaining: 0:02:59 MainProcess pypet INFO PROGRESS: Finished 199/441 runs [========= ] 45.1%, remaining: 0:02:41 MainProcess pypet INFO PROGRESS: Finished 221/441 runs [========== ] 50.1%, remaining: 0:02:28 MainProcess pypet INFO PROGRESS: Finished 243/441 runs [=========== ] 55.1%, remaining: 0:02:14 MainProcess pypet INFO PROGRESS: Finished 265/441 runs [============ ] 60.1%, remaining: 0:02:01 MainProcess pypet INFO PROGRESS: Finished 287/441 runs [============= ] 65.1%, remaining: 0:01:44 MainProcess pypet INFO PROGRESS: Finished 309/441 runs [============== ] 70.1%, remaining: 0:01:29 MainProcess pypet INFO PROGRESS: Finished 331/441 runs [=============== ] 75.1%, remaining: 0:01:14 MainProcess pypet INFO PROGRESS: Finished 353/441 runs [================ ] 80.0%, remaining: 0:00:59 MainProcess pypet INFO PROGRESS: Finished 375/441 runs [================= ] 85.0%, remaining: 0:00:43 MainProcess pypet INFO PROGRESS: Finished 397/441 runs [================== ] 90.0%, remaining: 0:00:29 MainProcess pypet INFO PROGRESS: Finished 419/441 runs [=================== ] 95.0%, remaining: 0:00:14 MainProcess pypet INFO PROGRESS: Finished 441/441 runs [====================]100.0% MainProcess pypet.storageservice.HDF5StorageService INFO Initialising storage or updating meta data of Trajectory `results-2021-07-07-16H-40M-57S`. MainProcess pypet.storageservice.HDF5StorageService INFO Finished init or meta data update for `results-2021-07-07-16H-40M-57S`. MainProcess pypet.environment.Environment INFO ************************************************************ FINISHED all runs of trajectory `results-2021-07-07-16H-40M-57S`. ************************************************************ MainProcess pypet.environment.Environment INFO ************************************************************ STARTING FINAL STORING of trajectory `results-2021-07-07-16H-40M-57S` ************************************************************ MainProcess pypet.storageservice.HDF5StorageService INFO Start storing Trajectory `results-2021-07-07-16H-40M-57S`. MainProcess pypet.storageservice.HDF5StorageService INFO Storing branch `config`. MainProcess pypet.storageservice.HDF5StorageService INFO Storing branch `parameters`. MainProcess pypet.storageservice.HDF5StorageService INFO Finished storing Trajectory `results-2021-07-07-16H-40M-57S`. MainProcess pypet.environment.Environment INFO ************************************************************ FINISHED FINAL STORING of trajectory `results-2021-07-07-16H-40M-57S`. ************************************************************ MainProcess pypet.environment.Environment INFO All runs of trajectory `results-2021-07-07-16H-40M-57S` were completed successfully. search . loadResults () MainProcess root INFO Loading results from ./data/hdf/example-4.2-exploration.hdf MainProcess root INFO Analyzing trajectory results-2021-07-07-16H-40M-57S MainProcess pypet.storageservice.HDF5StorageService INFO I will use the hdf5 file `./data/hdf/example-4.2-exploration.hdf`. MainProcess pypet.storageservice.HDF5StorageService INFO Loading trajectory `results-2021-07-07-16H-40M-57S`. MainProcess pypet.storageservice.HDF5StorageService INFO Loading branch `config` in mode `2`. MainProcess pypet.storageservice.HDF5StorageService INFO Loading branch `parameters` in mode `2`. MainProcess pypet.storageservice.HDF5StorageService INFO Loading branch `results` in mode `1`. MainProcess root INFO Creating `dfResults` dataframe ... MainProcess root INFO Loading all results to `results` dictionary ... 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 441/441 [00:02<00:00, 219.34it/s] MainProcess root INFO Aggregating results to `dfResults` ... 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 441/441 [00:00<00:00, 3745.83it/s] MainProcess root INFO All results loaded. print ( f \"Number of results: { len ( search . results ) } \" ) Number of results: 441 # Example analysis of the results # The .results attribute is a list and can be indexed by the run # number (which is also the index of the pandas dataframe .dfResults). # Here we compute the maximum firing rate of the node in the last second # and add the result (a float) to the pandas dataframe. for i in search . dfResults . index : search . dfResults . loc [ i , \"max_r\" ] = np . max ( search . results [ i ][ \"r_mean_EXC\" ][:, - int ( 1000 / aln_mm . params [ \"dt\" ]) :] ) plt . imshow ( search . dfResults . pivot_table ( values = \"max_r\" , index = \"ALNNode_0.ALNMassINH_1.input_0.mu\" , columns = \"ALNNode_0.ALNMassEXC_0.input_0.mu\" , ), extent = [ min ( search . dfResults [ \"ALNNode_0.ALNMassEXC_0.input_0.mu\" ]), max ( search . dfResults [ \"ALNNode_0.ALNMassEXC_0.input_0.mu\" ]), min ( search . dfResults [ \"ALNNode_0.ALNMassINH_1.input_0.mu\" ]), max ( search . dfResults [ \"ALNNode_0.ALNMassINH_1.input_0.mu\" ]), ], origin = \"lower\" , ) plt . colorbar ( label = \"Maximum rate [kHz]\" ) plt . xlabel ( \"Input to E\" ) plt . ylabel ( \"Input to I\" ) Text(0, 0.5, 'Input to I') Evolution with MultiModel If you're familiar with how Evolution works in core neurolib , and now you know the perks of MultiModel with respect to exploration - that's all you need to know when doing optimisation using evolutionary algorithms using MultiModel . Parameters are passed via ParameterSpace with allow_star_notation=True . Below, we will reproduce the example-2.1-evolutionary-optimization-aln with the MultiModel version of ALN model. # reinit fresh model aln_mm = MultiModel . init_node ( ALNNode ()) # match params to core ALN model aln_mm . params [ \"backend\" ] = \"numba\" aln_mm . params [ \"dt\" ] = 0.1 # ms aln_mm . params [ \"*c_gl\" ] = 0.3 aln_mm . params [ \"*b\" ] = 0.0 aln_mm . params [ \"ALNNode_0.ALNMassEXC_0.a\" ] = 0.0 MainProcess root INFO Loading precomputed transfer functions from /Users/nikola/.virtualenvs/neurolib/lib/python3.7/site-packages/neurolib/models/multimodel/builder/../../aln/aln-precalc/quantities_cascade.h5 MainProcess root INFO All transfer functions loaded. MainProcess root INFO Loading precomputed transfer functions from /Users/nikola/.virtualenvs/neurolib/lib/python3.7/site-packages/neurolib/models/multimodel/builder/../../aln/aln-precalc/quantities_cascade.h5 MainProcess root INFO All transfer functions loaded. MainProcess root INFO ALNNode: Model initialized. # use the same loss function as example-2.1 def evaluateSimulation ( traj ): # The trajectory id is provided as an attribute rid = traj . id # this function provides the a model with the partuclar # parameter set for this given run model = evolution . getModelFromTraj ( traj ) # parameters can also be modified after loading model . params [ \"dt\" ] = 0.1 model . params [ \"duration\" ] = 2 * 1000.0 # and the simulation is run model . run () # compute power spectrum frs , powers = func . getPowerSpectrum ( model . r_mean_EXC [:, - int ( 1000 / model . params [ \"dt\" ]) :], dt = model . params [ \"dt\" ] ) # find the peak frequency domfr = frs [ np . argmax ( powers )] # fitness evaluation: let's try to find a 25 Hz oscillation fitness = abs ( domfr - 25 ) # deap needs a fitness *tuple*! fitness_tuple = () # more fitness values could be added fitness_tuple += ( fitness ,) # we need to return the fitness tuple and the outputs of the model return fitness_tuple , model . outputs pars = ParameterSpace ( [ \"*EXC*input*mu\" , \"*INH*input*mu\" ], [[ 0.0 , 4.0 ], [ 0.0 , 4.0 ]], allow_star_notation = True , ) weightList = [ - 1.0 ] evolution = Evolution ( evalFunction = evaluateSimulation , parameterSpace = pars , model = aln_mm , # use our `MultiModel` here weightList = [ - 1.0 ], # POP_INIT_SIZE=16, # mutiple of number of cores # POP_SIZE=16, # low numbers for testing, for real evolution use higher number of runs POP_INIT_SIZE = 4 , # mutiple of number of cores POP_SIZE = 4 , # low numbers for testing, for real evolution use higher number NGEN = 2 , filename = \"example-4.2-evolution.hdf\" , ) MainProcess root INFO Trajectory Name: results-2021-07-07-16H-45M-51S MainProcess root INFO Storing data to: ./data/hdf/example-4.2-evolution.hdf MainProcess root INFO Trajectory Name: results-2021-07-07-16H-45M-51S MainProcess root INFO Number of cores: 8 MainProcess pypet.storageservice.HDF5StorageService INFO I will use the hdf5 file `./data/hdf/example-4.2-evolution.hdf`. MainProcess pypet.environment.Environment INFO Environment initialized. MainProcess root INFO Evolution: Using algorithm: adaptive MainProcess root INFO Evolution: Individual generation: <function randomParametersAdaptive at 0x159a6df80> MainProcess root INFO Evolution: Mating operator: <function cxBlend at 0x159a43560> MainProcess root INFO Evolution: Mutation operator: <function gaussianAdaptiveMutation_nStepSizes at 0x159a70440> MainProcess root INFO Evolution: Parent selection: <function selRank at 0x159a70170> MainProcess root INFO Evolution: Selection operator: <function selBest_multiObj at 0x159a70200> evolution . run ( verbose = False ) MainProcess root INFO Evaluating initial population of size 16 ... MainProcess pypet.trajectory.Trajectory INFO Your trajectory has not been explored, yet. I will call `f_explore` instead. MainProcess pypet.environment.Environment INFO I am preparing the Trajectory for the experiment and initialise the store. MainProcess pypet.environment.Environment INFO Initialising the storage for the trajectory. MainProcess pypet.storageservice.HDF5StorageService INFO Initialising storage or updating meta data of Trajectory `results-2021-07-07-16H-45M-51S`. MainProcess pypet.storageservice.HDF5StorageService INFO Finished init or meta data update for `results-2021-07-07-16H-45M-51S`. MainProcess pypet.environment.Environment INFO ************************************************************ STARTING runs of trajectory `results-2021-07-07-16H-45M-51S`. ************************************************************ MainProcess pypet.storageservice.HDF5StorageService INFO Initialising storage or updating meta data of Trajectory `results-2021-07-07-16H-45M-51S`. MainProcess pypet.storageservice.HDF5StorageService INFO Finished init or meta data update for `results-2021-07-07-16H-45M-51S`. MainProcess pypet.environment.Environment INFO Starting multiprocessing with at most 8 processes running at the same time. MainProcess pypet INFO PROGRESS: Finished 0/16 runs [ ] 0.0% MainProcess pypet INFO PROGRESS: Finished 1/16 runs [= ] 6.2%, remaining: 0:01:22 MainProcess pypet INFO PROGRESS: Finished 2/16 runs [== ] 12.5%, remaining: 0:00:39 MainProcess pypet INFO PROGRESS: Finished 3/16 runs [=== ] 18.8%, remaining: 0:00:24 MainProcess pypet INFO PROGRESS: Finished 4/16 runs [===== ] 25.0%, remaining: 0:00:17 MainProcess pypet INFO PROGRESS: Finished 5/16 runs [====== ] 31.2%, remaining: 0:00:12 MainProcess pypet INFO PROGRESS: Finished 6/16 runs [======= ] 37.5%, remaining: 0:00:09 MainProcess pypet INFO PROGRESS: Finished 7/16 runs [======== ] 43.8%, remaining: 0:00:07 MainProcess pypet INFO PROGRESS: Finished 8/16 runs [========== ] 50.0%, remaining: 0:00:05 MainProcess pypet INFO PROGRESS: Finished 9/16 runs [=========== ] 56.2%, remaining: 0:00:08 MainProcess pypet INFO PROGRESS: Finished 10/16 runs [============ ] 62.5%, remaining: 0:00:06 MainProcess pypet INFO PROGRESS: Finished 11/16 runs [============= ] 68.8%, remaining: 0:00:04 MainProcess pypet INFO PROGRESS: Finished 12/16 runs [=============== ] 75.0%, remaining: 0:00:03 MainProcess pypet INFO PROGRESS: Finished 13/16 runs [================ ] 81.2%, remaining: 0:00:02 MainProcess pypet INFO PROGRESS: Finished 14/16 runs [================= ] 87.5%, remaining: 0:00:01 MainProcess pypet INFO PROGRESS: Finished 15/16 runs [================== ] 93.8%, remaining: 0:00:00 MainProcess pypet INFO PROGRESS: Finished 16/16 runs [====================]100.0% MainProcess pypet.storageservice.HDF5StorageService INFO Initialising storage or updating meta data of Trajectory `results-2021-07-07-16H-45M-51S`. MainProcess pypet.storageservice.HDF5StorageService INFO Finished init or meta data update for `results-2021-07-07-16H-45M-51S`. MainProcess pypet.environment.Environment INFO ************************************************************ FINISHED all runs of trajectory `results-2021-07-07-16H-45M-51S`. ************************************************************ MainProcess pypet.environment.Environment INFO ************************************************************ STARTING FINAL STORING of trajectory `results-2021-07-07-16H-45M-51S` ************************************************************ MainProcess pypet.storageservice.HDF5StorageService INFO Start storing Trajectory `results-2021-07-07-16H-45M-51S`. MainProcess pypet.storageservice.HDF5StorageService INFO Storing branch `config`. MainProcess pypet.storageservice.HDF5StorageService INFO Storing branch `parameters`. MainProcess pypet.storageservice.HDF5StorageService INFO Storing branch `results`. MainProcess pypet.storageservice.HDF5StorageService INFO Storing branch `derived_parameters`. MainProcess pypet.storageservice.HDF5StorageService INFO Finished storing Trajectory `results-2021-07-07-16H-45M-51S`. MainProcess pypet.environment.Environment INFO ************************************************************ FINISHED FINAL STORING of trajectory `results-2021-07-07-16H-45M-51S`. ************************************************************ MainProcess pypet.environment.Environment INFO All runs of trajectory `results-2021-07-07-16H-45M-51S` were completed successfully. MainProcess pypet.storageservice.HDF5StorageService INFO Start storing Trajectory `results-2021-07-07-16H-45M-51S`. MainProcess pypet.storageservice.HDF5StorageService INFO Storing branch `config`. MainProcess pypet.storageservice.HDF5StorageService INFO Storing branch `parameters`. MainProcess pypet.storageservice.HDF5StorageService INFO Storing branch `results`. MainProcess pypet.storageservice.HDF5StorageService INFO Storing branch `derived_parameters`. MainProcess pypet.storageservice.HDF5StorageService INFO Finished storing Trajectory `results-2021-07-07-16H-45M-51S`. MainProcess root INFO Start of evolution MainProcess root INFO Replacing 0 invalid individuals. MainProcess pypet.environment.Environment INFO I am preparing the Trajectory for the experiment and initialise the store. MainProcess pypet.environment.Environment INFO Initialising the storage for the trajectory. MainProcess pypet.storageservice.HDF5StorageService INFO Initialising storage or updating meta data of Trajectory `results-2021-07-07-16H-45M-51S`. MainProcess pypet.storageservice.HDF5StorageService INFO Finished init or meta data update for `results-2021-07-07-16H-45M-51S`. MainProcess pypet.environment.Environment INFO ************************************************************ STARTING runs of trajectory `results-2021-07-07-16H-45M-51S`. ************************************************************ MainProcess pypet.storageservice.HDF5StorageService INFO Initialising storage or updating meta data of Trajectory `results-2021-07-07-16H-45M-51S`. MainProcess pypet.storageservice.HDF5StorageService INFO Finished init or meta data update for `results-2021-07-07-16H-45M-51S`. MainProcess pypet.environment.Environment INFO Starting multiprocessing with at most 8 processes running at the same time. MainProcess pypet INFO PROGRESS: Finished 16/32 runs [========== ] 50.0% MainProcess pypet INFO PROGRESS: Finished 18/32 runs [=========== ] 56.2%, remaining: 0:00:33 MainProcess pypet INFO PROGRESS: Finished 20/32 runs [============ ] 62.5%, remaining: 0:00:15 MainProcess pypet INFO PROGRESS: Finished 21/32 runs [============= ] 65.6%, remaining: 0:00:11 MainProcess pypet INFO PROGRESS: Finished 23/32 runs [============== ] 71.9%, remaining: 0:00:06 MainProcess pypet INFO PROGRESS: Finished 24/32 runs [=============== ] 75.0%, remaining: 0:00:05 MainProcess pypet INFO PROGRESS: Finished 26/32 runs [================ ] 81.2%, remaining: 0:00:05 MainProcess pypet INFO PROGRESS: Finished 28/32 runs [================= ] 87.5%, remaining: 0:00:03 MainProcess pypet INFO PROGRESS: Finished 29/32 runs [================== ] 90.6%, remaining: 0:00:02 MainProcess pypet INFO PROGRESS: Finished 31/32 runs [=================== ] 96.9%, remaining: 0:00:00 MainProcess pypet INFO PROGRESS: Finished 32/32 runs [====================]100.0% MainProcess pypet.storageservice.HDF5StorageService INFO Initialising storage or updating meta data of Trajectory `results-2021-07-07-16H-45M-51S`. MainProcess pypet.storageservice.HDF5StorageService INFO Finished init or meta data update for `results-2021-07-07-16H-45M-51S`. MainProcess pypet.environment.Environment INFO ************************************************************ FINISHED all runs of trajectory `results-2021-07-07-16H-45M-51S`. ************************************************************ MainProcess pypet.environment.Environment INFO ************************************************************ STARTING FINAL STORING of trajectory `results-2021-07-07-16H-45M-51S` ************************************************************ MainProcess pypet.storageservice.HDF5StorageService INFO Start storing Trajectory `results-2021-07-07-16H-45M-51S`. MainProcess pypet.storageservice.HDF5StorageService INFO Storing branch `config`. MainProcess pypet.storageservice.HDF5StorageService INFO Storing branch `parameters`. MainProcess pypet.storageservice.HDF5StorageService INFO Storing branch `results`. MainProcess pypet.storageservice.HDF5StorageService INFO Storing branch `derived_parameters`. MainProcess pypet.storageservice.HDF5StorageService INFO Finished storing Trajectory `results-2021-07-07-16H-45M-51S`. MainProcess pypet.environment.Environment INFO ************************************************************ FINISHED FINAL STORING of trajectory `results-2021-07-07-16H-45M-51S`. ************************************************************ MainProcess pypet.environment.Environment INFO All runs of trajectory `results-2021-07-07-16H-45M-51S` were completed successfully. MainProcess pypet.storageservice.HDF5StorageService INFO Start storing Trajectory `results-2021-07-07-16H-45M-51S`. MainProcess pypet.storageservice.HDF5StorageService INFO Storing branch `config`. MainProcess pypet.storageservice.HDF5StorageService INFO Storing branch `parameters`. MainProcess pypet.storageservice.HDF5StorageService INFO Storing branch `results`. MainProcess pypet.storageservice.HDF5StorageService INFO Storing branch `derived_parameters`. MainProcess pypet.storageservice.HDF5StorageService INFO Finished storing Trajectory `results-2021-07-07-16H-45M-51S`. MainProcess root INFO ----------- Generation 1 ----------- MainProcess root INFO Best individual is [1.2026081698319384, 0.7330736886493492, 1.3333333333333333, 1.3333333333333333] MainProcess root INFO Score: -5.0 MainProcess root INFO Fitness: (5.0,) MainProcess root INFO --- Population statistics --- MainProcess root INFO Replacing 0 invalid individuals. MainProcess pypet.environment.Environment INFO I am preparing the Trajectory for the experiment and initialise the store. MainProcess pypet.environment.Environment INFO Initialising the storage for the trajectory. MainProcess pypet.storageservice.HDF5StorageService INFO Initialising storage or updating meta data of Trajectory `results-2021-07-07-16H-45M-51S`. MainProcess pypet.storageservice.HDF5StorageService INFO Finished init or meta data update for `results-2021-07-07-16H-45M-51S`. MainProcess pypet.environment.Environment INFO ************************************************************ STARTING runs of trajectory `results-2021-07-07-16H-45M-51S`. ************************************************************ MainProcess pypet.storageservice.HDF5StorageService INFO Initialising storage or updating meta data of Trajectory `results-2021-07-07-16H-45M-51S`. MainProcess pypet.storageservice.HDF5StorageService INFO Finished init or meta data update for `results-2021-07-07-16H-45M-51S`. MainProcess pypet.environment.Environment INFO Starting multiprocessing with at most 8 processes running at the same time. MainProcess pypet INFO PROGRESS: Finished 32/48 runs [============= ] 66.7% MainProcess pypet INFO PROGRESS: Finished 34/48 runs [============== ] 70.8%, remaining: 0:00:33 MainProcess pypet INFO PROGRESS: Finished 36/48 runs [=============== ] 75.0%, remaining: 0:00:14 MainProcess pypet INFO PROGRESS: Finished 39/48 runs [================ ] 81.2%, remaining: 0:00:06 MainProcess pypet INFO PROGRESS: Finished 41/48 runs [================= ] 85.4%, remaining: 0:00:07 MainProcess pypet INFO PROGRESS: Finished 44/48 runs [================== ] 91.7%, remaining: 0:00:03 MainProcess pypet INFO PROGRESS: Finished 46/48 runs [=================== ] 95.8%, remaining: 0:00:01 MainProcess pypet INFO PROGRESS: Finished 48/48 runs [====================]100.0% MainProcess pypet.storageservice.HDF5StorageService INFO Initialising storage or updating meta data of Trajectory `results-2021-07-07-16H-45M-51S`. MainProcess pypet.storageservice.HDF5StorageService INFO Finished init or meta data update for `results-2021-07-07-16H-45M-51S`. MainProcess pypet.environment.Environment INFO ************************************************************ FINISHED all runs of trajectory `results-2021-07-07-16H-45M-51S`. ************************************************************ MainProcess pypet.environment.Environment INFO ************************************************************ STARTING FINAL STORING of trajectory `results-2021-07-07-16H-45M-51S` ************************************************************ MainProcess pypet.storageservice.HDF5StorageService INFO Start storing Trajectory `results-2021-07-07-16H-45M-51S`. MainProcess pypet.storageservice.HDF5StorageService INFO Storing branch `config`. MainProcess pypet.storageservice.HDF5StorageService INFO Storing branch `parameters`. MainProcess pypet.storageservice.HDF5StorageService INFO Storing branch `results`. MainProcess pypet.storageservice.HDF5StorageService INFO Storing branch `derived_parameters`. MainProcess pypet.storageservice.HDF5StorageService INFO Finished storing Trajectory `results-2021-07-07-16H-45M-51S`. MainProcess pypet.environment.Environment INFO ************************************************************ FINISHED FINAL STORING of trajectory `results-2021-07-07-16H-45M-51S`. ************************************************************ MainProcess pypet.environment.Environment INFO All runs of trajectory `results-2021-07-07-16H-45M-51S` were completed successfully. MainProcess pypet.storageservice.HDF5StorageService INFO Start storing Trajectory `results-2021-07-07-16H-45M-51S`. MainProcess pypet.storageservice.HDF5StorageService INFO Storing branch `config`. MainProcess pypet.storageservice.HDF5StorageService INFO Storing branch `parameters`. MainProcess pypet.storageservice.HDF5StorageService INFO Storing branch `results`. MainProcess pypet.storageservice.HDF5StorageService INFO Storing branch `derived_parameters`. MainProcess pypet.storageservice.HDF5StorageService INFO Finished storing Trajectory `results-2021-07-07-16H-45M-51S`. MainProcess root INFO ----------- Generation 2 ----------- MainProcess root INFO Best individual is [1.2026081698319384, 0.7330736886493492, 1.3333333333333333, 1.3333333333333333] MainProcess root INFO Score: -5.0 MainProcess root INFO Fitness: (5.0,) MainProcess root INFO --- Population statistics --- MainProcess root INFO Replacing 0 invalid individuals. MainProcess pypet.environment.Environment INFO I am preparing the Trajectory for the experiment and initialise the store. MainProcess pypet.environment.Environment INFO Initialising the storage for the trajectory. MainProcess pypet.storageservice.HDF5StorageService INFO Initialising storage or updating meta data of Trajectory `results-2021-07-07-16H-45M-51S`. MainProcess pypet.storageservice.HDF5StorageService INFO Finished init or meta data update for `results-2021-07-07-16H-45M-51S`. MainProcess pypet.environment.Environment INFO ************************************************************ STARTING runs of trajectory `results-2021-07-07-16H-45M-51S`. ************************************************************ MainProcess pypet.storageservice.HDF5StorageService INFO Initialising storage or updating meta data of Trajectory `results-2021-07-07-16H-45M-51S`. MainProcess pypet.storageservice.HDF5StorageService INFO Finished init or meta data update for `results-2021-07-07-16H-45M-51S`. MainProcess pypet.environment.Environment INFO Starting multiprocessing with at most 8 processes running at the same time. MainProcess pypet INFO PROGRESS: Finished 48/64 runs [=============== ] 75.0% MainProcess pypet INFO PROGRESS: Finished 52/64 runs [================ ] 81.2%, remaining: 0:00:14 MainProcess pypet INFO PROGRESS: Finished 55/64 runs [================= ] 85.9%, remaining: 0:00:06 MainProcess pypet INFO PROGRESS: Finished 58/64 runs [================== ] 90.6%, remaining: 0:00:05 MainProcess pypet INFO PROGRESS: Finished 61/64 runs [=================== ] 95.3%, remaining: 0:00:02 MainProcess pypet INFO PROGRESS: Finished 64/64 runs [====================]100.0% MainProcess pypet.storageservice.HDF5StorageService INFO Initialising storage or updating meta data of Trajectory `results-2021-07-07-16H-45M-51S`. MainProcess pypet.storageservice.HDF5StorageService INFO Finished init or meta data update for `results-2021-07-07-16H-45M-51S`. MainProcess pypet.environment.Environment INFO ************************************************************ FINISHED all runs of trajectory `results-2021-07-07-16H-45M-51S`. ************************************************************ MainProcess pypet.environment.Environment INFO ************************************************************ STARTING FINAL STORING of trajectory `results-2021-07-07-16H-45M-51S` ************************************************************ MainProcess pypet.storageservice.HDF5StorageService INFO Start storing Trajectory `results-2021-07-07-16H-45M-51S`. MainProcess pypet.storageservice.HDF5StorageService INFO Storing branch `config`. MainProcess pypet.storageservice.HDF5StorageService INFO Storing branch `parameters`. MainProcess pypet.storageservice.HDF5StorageService INFO Storing branch `results`. MainProcess pypet.storageservice.HDF5StorageService INFO Storing branch `derived_parameters`. MainProcess pypet.storageservice.HDF5StorageService INFO Finished storing Trajectory `results-2021-07-07-16H-45M-51S`. MainProcess pypet.environment.Environment INFO ************************************************************ FINISHED FINAL STORING of trajectory `results-2021-07-07-16H-45M-51S`. ************************************************************ MainProcess pypet.environment.Environment INFO All runs of trajectory `results-2021-07-07-16H-45M-51S` were completed successfully. MainProcess pypet.storageservice.HDF5StorageService INFO Start storing Trajectory `results-2021-07-07-16H-45M-51S`. MainProcess pypet.storageservice.HDF5StorageService INFO Storing branch `config`. MainProcess pypet.storageservice.HDF5StorageService INFO Storing branch `parameters`. MainProcess pypet.storageservice.HDF5StorageService INFO Storing branch `results`. MainProcess pypet.storageservice.HDF5StorageService INFO Storing branch `derived_parameters`. MainProcess pypet.storageservice.HDF5StorageService INFO Finished storing Trajectory `results-2021-07-07-16H-45M-51S`. MainProcess root INFO ----------- Generation 3 ----------- MainProcess root INFO Best individual is [1.3018429030776317, 0.4613335264234024, 1.2708417799029919, 0.3261423030366109] MainProcess root INFO Score: -2.0 MainProcess root INFO Fitness: (2.0,) MainProcess root INFO --- Population statistics --- MainProcess root INFO Replacing 0 invalid individuals. MainProcess pypet.environment.Environment INFO I am preparing the Trajectory for the experiment and initialise the store. MainProcess pypet.environment.Environment INFO Initialising the storage for the trajectory. MainProcess pypet.storageservice.HDF5StorageService INFO Initialising storage or updating meta data of Trajectory `results-2021-07-07-16H-45M-51S`. MainProcess pypet.storageservice.HDF5StorageService INFO Finished init or meta data update for `results-2021-07-07-16H-45M-51S`. MainProcess pypet.environment.Environment INFO ************************************************************ STARTING runs of trajectory `results-2021-07-07-16H-45M-51S`. ************************************************************ MainProcess pypet.storageservice.HDF5StorageService INFO Initialising storage or updating meta data of Trajectory `results-2021-07-07-16H-45M-51S`. MainProcess pypet.storageservice.HDF5StorageService INFO Finished init or meta data update for `results-2021-07-07-16H-45M-51S`. MainProcess pypet.environment.Environment INFO Starting multiprocessing with at most 8 processes running at the same time. MainProcess pypet INFO PROGRESS: Finished 64/80 runs [================ ] 80.0% MainProcess pypet INFO PROGRESS: Finished 68/80 runs [================= ] 85.0%, remaining: 0:00:14 MainProcess pypet INFO PROGRESS: Finished 72/80 runs [================== ] 90.0%, remaining: 0:00:05 MainProcess pypet INFO PROGRESS: Finished 76/80 runs [=================== ] 95.0%, remaining: 0:00:03 MainProcess pypet INFO PROGRESS: Finished 80/80 runs [====================]100.0% MainProcess pypet.storageservice.HDF5StorageService INFO Initialising storage or updating meta data of Trajectory `results-2021-07-07-16H-45M-51S`. MainProcess pypet.storageservice.HDF5StorageService INFO Finished init or meta data update for `results-2021-07-07-16H-45M-51S`. MainProcess pypet.environment.Environment INFO ************************************************************ FINISHED all runs of trajectory `results-2021-07-07-16H-45M-51S`. ************************************************************ MainProcess pypet.environment.Environment INFO ************************************************************ STARTING FINAL STORING of trajectory `results-2021-07-07-16H-45M-51S` ************************************************************ MainProcess pypet.storageservice.HDF5StorageService INFO Start storing Trajectory `results-2021-07-07-16H-45M-51S`. MainProcess pypet.storageservice.HDF5StorageService INFO Storing branch `config`. MainProcess pypet.storageservice.HDF5StorageService INFO Storing branch `parameters`. MainProcess pypet.storageservice.HDF5StorageService INFO Storing branch `results`. MainProcess pypet.storageservice.HDF5StorageService INFO Storing branch `derived_parameters`. MainProcess pypet.storageservice.HDF5StorageService INFO Finished storing Trajectory `results-2021-07-07-16H-45M-51S`. MainProcess pypet.environment.Environment INFO ************************************************************ FINISHED FINAL STORING of trajectory `results-2021-07-07-16H-45M-51S`. ************************************************************ MainProcess pypet.environment.Environment INFO All runs of trajectory `results-2021-07-07-16H-45M-51S` were completed successfully. MainProcess pypet.storageservice.HDF5StorageService INFO Start storing Trajectory `results-2021-07-07-16H-45M-51S`. MainProcess pypet.storageservice.HDF5StorageService INFO Storing branch `config`. MainProcess pypet.storageservice.HDF5StorageService INFO Storing branch `parameters`. MainProcess pypet.storageservice.HDF5StorageService INFO Storing branch `results`. MainProcess pypet.storageservice.HDF5StorageService INFO Storing branch `derived_parameters`. MainProcess pypet.storageservice.HDF5StorageService INFO Finished storing Trajectory `results-2021-07-07-16H-45M-51S`. MainProcess root INFO ----------- Generation 4 ----------- MainProcess root INFO Best individual is [1.3018429030776317, 0.4613335264234024, 1.2708417799029919, 0.3261423030366109] MainProcess root INFO Score: -2.0 MainProcess root INFO Fitness: (2.0,) MainProcess root INFO --- Population statistics --- MainProcess root INFO Replacing 0 invalid individuals. MainProcess pypet.environment.Environment INFO I am preparing the Trajectory for the experiment and initialise the store. MainProcess pypet.environment.Environment INFO Initialising the storage for the trajectory. MainProcess pypet.storageservice.HDF5StorageService INFO Initialising storage or updating meta data of Trajectory `results-2021-07-07-16H-45M-51S`. MainProcess pypet.storageservice.HDF5StorageService INFO Finished init or meta data update for `results-2021-07-07-16H-45M-51S`. MainProcess pypet.environment.Environment INFO ************************************************************ STARTING runs of trajectory `results-2021-07-07-16H-45M-51S`. ************************************************************ MainProcess pypet.storageservice.HDF5StorageService INFO Initialising storage or updating meta data of Trajectory `results-2021-07-07-16H-45M-51S`. MainProcess pypet.storageservice.HDF5StorageService INFO Finished init or meta data update for `results-2021-07-07-16H-45M-51S`. MainProcess pypet.environment.Environment INFO Starting multiprocessing with at most 8 processes running at the same time. MainProcess pypet INFO PROGRESS: Finished 80/96 runs [================ ] 83.3% MainProcess pypet INFO PROGRESS: Finished 82/96 runs [================= ] 85.4%, remaining: 0:00:33 MainProcess pypet INFO PROGRESS: Finished 87/96 runs [================== ] 90.6%, remaining: 0:00:06 MainProcess pypet INFO PROGRESS: Finished 92/96 runs [=================== ] 95.8%, remaining: 0:00:03 MainProcess pypet INFO PROGRESS: Finished 96/96 runs [====================]100.0% MainProcess pypet.storageservice.HDF5StorageService INFO Initialising storage or updating meta data of Trajectory `results-2021-07-07-16H-45M-51S`. MainProcess pypet.storageservice.HDF5StorageService INFO Finished init or meta data update for `results-2021-07-07-16H-45M-51S`. MainProcess pypet.environment.Environment INFO ************************************************************ FINISHED all runs of trajectory `results-2021-07-07-16H-45M-51S`. ************************************************************ MainProcess pypet.environment.Environment INFO ************************************************************ STARTING FINAL STORING of trajectory `results-2021-07-07-16H-45M-51S` ************************************************************ MainProcess pypet.storageservice.HDF5StorageService INFO Start storing Trajectory `results-2021-07-07-16H-45M-51S`. MainProcess pypet.storageservice.HDF5StorageService INFO Storing branch `config`. MainProcess pypet.storageservice.HDF5StorageService INFO Storing branch `parameters`. MainProcess pypet.storageservice.HDF5StorageService INFO Storing branch `results`. MainProcess pypet.storageservice.HDF5StorageService INFO Storing branch `derived_parameters`. MainProcess pypet.storageservice.HDF5StorageService INFO Finished storing Trajectory `results-2021-07-07-16H-45M-51S`. MainProcess pypet.environment.Environment INFO ************************************************************ FINISHED FINAL STORING of trajectory `results-2021-07-07-16H-45M-51S`. ************************************************************ MainProcess pypet.environment.Environment INFO All runs of trajectory `results-2021-07-07-16H-45M-51S` were completed successfully. MainProcess pypet.storageservice.HDF5StorageService INFO Start storing Trajectory `results-2021-07-07-16H-45M-51S`. MainProcess pypet.storageservice.HDF5StorageService INFO Storing branch `config`. MainProcess pypet.storageservice.HDF5StorageService INFO Storing branch `parameters`. MainProcess pypet.storageservice.HDF5StorageService INFO Storing branch `results`. MainProcess pypet.storageservice.HDF5StorageService INFO Storing branch `derived_parameters`. MainProcess pypet.storageservice.HDF5StorageService INFO Finished storing Trajectory `results-2021-07-07-16H-45M-51S`. MainProcess root INFO ----------- Generation 5 ----------- MainProcess root INFO Best individual is [1.3018429030776317, 0.4613335264234024, 1.2708417799029919, 0.3261423030366109] MainProcess root INFO Score: -2.0 MainProcess root INFO Fitness: (2.0,) MainProcess root INFO --- Population statistics --- MainProcess root INFO Replacing 0 invalid individuals. MainProcess pypet.environment.Environment INFO I am preparing the Trajectory for the experiment and initialise the store. MainProcess pypet.environment.Environment INFO Initialising the storage for the trajectory. MainProcess pypet.storageservice.HDF5StorageService INFO Initialising storage or updating meta data of Trajectory `results-2021-07-07-16H-45M-51S`. MainProcess pypet.storageservice.HDF5StorageService INFO Finished init or meta data update for `results-2021-07-07-16H-45M-51S`. MainProcess pypet.environment.Environment INFO ************************************************************ STARTING runs of trajectory `results-2021-07-07-16H-45M-51S`. ************************************************************ MainProcess pypet.storageservice.HDF5StorageService INFO Initialising storage or updating meta data of Trajectory `results-2021-07-07-16H-45M-51S`. MainProcess pypet.storageservice.HDF5StorageService INFO Finished init or meta data update for `results-2021-07-07-16H-45M-51S`. MainProcess pypet.environment.Environment INFO Starting multiprocessing with at most 8 processes running at the same time. MainProcess pypet INFO PROGRESS: Finished 96/112 runs [================= ] 85.7% MainProcess pypet INFO PROGRESS: Finished 101/112 runs [================== ] 90.2%, remaining: 0:00:10 MainProcess pypet INFO PROGRESS: Finished 107/112 runs [=================== ] 95.5%, remaining: 0:00:04 MainProcess pypet INFO PROGRESS: Finished 112/112 runs [====================]100.0% MainProcess pypet.storageservice.HDF5StorageService INFO Initialising storage or updating meta data of Trajectory `results-2021-07-07-16H-45M-51S`. MainProcess pypet.storageservice.HDF5StorageService INFO Finished init or meta data update for `results-2021-07-07-16H-45M-51S`. MainProcess pypet.environment.Environment INFO ************************************************************ FINISHED all runs of trajectory `results-2021-07-07-16H-45M-51S`. ************************************************************ MainProcess pypet.environment.Environment INFO ************************************************************ STARTING FINAL STORING of trajectory `results-2021-07-07-16H-45M-51S` ************************************************************ MainProcess pypet.storageservice.HDF5StorageService INFO Start storing Trajectory `results-2021-07-07-16H-45M-51S`. MainProcess pypet.storageservice.HDF5StorageService INFO Storing branch `config`. MainProcess pypet.storageservice.HDF5StorageService INFO Storing branch `parameters`. MainProcess pypet.storageservice.HDF5StorageService INFO Storing branch `results`. MainProcess pypet.storageservice.HDF5StorageService INFO Storing branch `derived_parameters`. MainProcess pypet.storageservice.HDF5StorageService INFO Finished storing Trajectory `results-2021-07-07-16H-45M-51S`. MainProcess pypet.environment.Environment INFO ************************************************************ FINISHED FINAL STORING of trajectory `results-2021-07-07-16H-45M-51S`. ************************************************************ MainProcess pypet.environment.Environment INFO All runs of trajectory `results-2021-07-07-16H-45M-51S` were completed successfully. MainProcess pypet.storageservice.HDF5StorageService INFO Start storing Trajectory `results-2021-07-07-16H-45M-51S`. MainProcess pypet.storageservice.HDF5StorageService INFO Storing branch `config`. MainProcess pypet.storageservice.HDF5StorageService INFO Storing branch `parameters`. MainProcess pypet.storageservice.HDF5StorageService INFO Storing branch `results`. MainProcess pypet.storageservice.HDF5StorageService INFO Storing branch `derived_parameters`. MainProcess pypet.storageservice.HDF5StorageService INFO Finished storing Trajectory `results-2021-07-07-16H-45M-51S`. MainProcess root INFO ----------- Generation 6 ----------- MainProcess root INFO Best individual is [1.3018429030776317, 0.4613335264234024, 1.2708417799029919, 0.3261423030366109] MainProcess root INFO Score: -2.0 MainProcess root INFO Fitness: (2.0,) MainProcess root INFO --- Population statistics --- MainProcess root INFO Replacing 0 invalid individuals. MainProcess pypet.environment.Environment INFO I am preparing the Trajectory for the experiment and initialise the store. MainProcess pypet.environment.Environment INFO Initialising the storage for the trajectory. MainProcess pypet.storageservice.HDF5StorageService INFO Initialising storage or updating meta data of Trajectory `results-2021-07-07-16H-45M-51S`. MainProcess pypet.storageservice.HDF5StorageService INFO Finished init or meta data update for `results-2021-07-07-16H-45M-51S`. MainProcess pypet.environment.Environment INFO ************************************************************ STARTING runs of trajectory `results-2021-07-07-16H-45M-51S`. ************************************************************ MainProcess pypet.storageservice.HDF5StorageService INFO Initialising storage or updating meta data of Trajectory `results-2021-07-07-16H-45M-51S`. MainProcess pypet.storageservice.HDF5StorageService INFO Finished init or meta data update for `results-2021-07-07-16H-45M-51S`. MainProcess pypet.environment.Environment INFO Starting multiprocessing with at most 8 processes running at the same time. MainProcess pypet INFO PROGRESS: Finished 112/128 runs [================= ] 87.5% MainProcess pypet INFO PROGRESS: Finished 116/128 runs [================== ] 90.6%, remaining: 0:00:14 MainProcess pypet INFO PROGRESS: Finished 122/128 runs [=================== ] 95.3%, remaining: 0:00:05 MainProcess pypet INFO PROGRESS: Finished 128/128 runs [====================]100.0% MainProcess pypet.storageservice.HDF5StorageService INFO Initialising storage or updating meta data of Trajectory `results-2021-07-07-16H-45M-51S`. MainProcess pypet.storageservice.HDF5StorageService INFO Finished init or meta data update for `results-2021-07-07-16H-45M-51S`. MainProcess pypet.environment.Environment INFO ************************************************************ FINISHED all runs of trajectory `results-2021-07-07-16H-45M-51S`. ************************************************************ MainProcess pypet.environment.Environment INFO ************************************************************ STARTING FINAL STORING of trajectory `results-2021-07-07-16H-45M-51S` ************************************************************ MainProcess pypet.storageservice.HDF5StorageService INFO Start storing Trajectory `results-2021-07-07-16H-45M-51S`. MainProcess pypet.storageservice.HDF5StorageService INFO Storing branch `config`. MainProcess pypet.storageservice.HDF5StorageService INFO Storing branch `parameters`. MainProcess pypet.storageservice.HDF5StorageService INFO Storing branch `results`. MainProcess pypet.storageservice.HDF5StorageService INFO Storing branch `derived_parameters`. MainProcess pypet.storageservice.HDF5StorageService INFO Finished storing Trajectory `results-2021-07-07-16H-45M-51S`. MainProcess pypet.environment.Environment INFO ************************************************************ FINISHED FINAL STORING of trajectory `results-2021-07-07-16H-45M-51S`. ************************************************************ MainProcess pypet.environment.Environment INFO All runs of trajectory `results-2021-07-07-16H-45M-51S` were completed successfully. MainProcess pypet.storageservice.HDF5StorageService INFO Start storing Trajectory `results-2021-07-07-16H-45M-51S`. MainProcess pypet.storageservice.HDF5StorageService INFO Storing branch `config`. MainProcess pypet.storageservice.HDF5StorageService INFO Storing branch `parameters`. MainProcess pypet.storageservice.HDF5StorageService INFO Storing branch `results`. MainProcess pypet.storageservice.HDF5StorageService INFO Storing branch `derived_parameters`. MainProcess pypet.storageservice.HDF5StorageService INFO Finished storing Trajectory `results-2021-07-07-16H-45M-51S`. MainProcess root INFO ----------- Generation 7 ----------- MainProcess root INFO Best individual is [0.8975385309150987, 0.11079193956336597, 0.23750510019720242, 0.2003002444648563] MainProcess root INFO Score: -1.0 MainProcess root INFO Fitness: (1.0,) MainProcess root INFO --- Population statistics --- MainProcess root INFO Replacing 0 invalid individuals. MainProcess pypet.environment.Environment INFO I am preparing the Trajectory for the experiment and initialise the store. MainProcess pypet.environment.Environment INFO Initialising the storage for the trajectory. MainProcess pypet.storageservice.HDF5StorageService INFO Initialising storage or updating meta data of Trajectory `results-2021-07-07-16H-45M-51S`. MainProcess pypet.storageservice.HDF5StorageService INFO Finished init or meta data update for `results-2021-07-07-16H-45M-51S`. MainProcess pypet.environment.Environment INFO ************************************************************ STARTING runs of trajectory `results-2021-07-07-16H-45M-51S`. ************************************************************ MainProcess pypet.storageservice.HDF5StorageService INFO Initialising storage or updating meta data of Trajectory `results-2021-07-07-16H-45M-51S`. MainProcess pypet.storageservice.HDF5StorageService INFO Finished init or meta data update for `results-2021-07-07-16H-45M-51S`. MainProcess pypet.environment.Environment INFO Starting multiprocessing with at most 8 processes running at the same time. MainProcess pypet INFO PROGRESS: Finished 128/144 runs [================= ] 88.9% MainProcess pypet INFO PROGRESS: Finished 130/144 runs [================== ] 90.3%, remaining: 0:00:32 MainProcess pypet INFO PROGRESS: Finished 137/144 runs [=================== ] 95.1%, remaining: 0:00:07 MainProcess pypet INFO PROGRESS: Finished 144/144 runs [====================]100.0% MainProcess pypet.storageservice.HDF5StorageService INFO Initialising storage or updating meta data of Trajectory `results-2021-07-07-16H-45M-51S`. MainProcess pypet.storageservice.HDF5StorageService INFO Finished init or meta data update for `results-2021-07-07-16H-45M-51S`. MainProcess pypet.environment.Environment INFO ************************************************************ FINISHED all runs of trajectory `results-2021-07-07-16H-45M-51S`. ************************************************************ MainProcess pypet.environment.Environment INFO ************************************************************ STARTING FINAL STORING of trajectory `results-2021-07-07-16H-45M-51S` ************************************************************ MainProcess pypet.storageservice.HDF5StorageService INFO Start storing Trajectory `results-2021-07-07-16H-45M-51S`. MainProcess pypet.storageservice.HDF5StorageService INFO Storing branch `config`. MainProcess pypet.storageservice.HDF5StorageService INFO Storing branch `parameters`. MainProcess pypet.storageservice.HDF5StorageService INFO Storing branch `results`. MainProcess pypet.storageservice.HDF5StorageService INFO Storing branch `derived_parameters`. MainProcess pypet.storageservice.HDF5StorageService INFO Finished storing Trajectory `results-2021-07-07-16H-45M-51S`. MainProcess pypet.environment.Environment INFO ************************************************************ FINISHED FINAL STORING of trajectory `results-2021-07-07-16H-45M-51S`. ************************************************************ MainProcess pypet.environment.Environment INFO All runs of trajectory `results-2021-07-07-16H-45M-51S` were completed successfully. MainProcess pypet.storageservice.HDF5StorageService INFO Start storing Trajectory `results-2021-07-07-16H-45M-51S`. MainProcess pypet.storageservice.HDF5StorageService INFO Storing branch `config`. MainProcess pypet.storageservice.HDF5StorageService INFO Storing branch `parameters`. MainProcess pypet.storageservice.HDF5StorageService INFO Storing branch `results`. MainProcess pypet.storageservice.HDF5StorageService INFO Storing branch `derived_parameters`. MainProcess pypet.storageservice.HDF5StorageService INFO Finished storing Trajectory `results-2021-07-07-16H-45M-51S`. MainProcess root INFO ----------- Generation 8 ----------- MainProcess root INFO Best individual is [1.2018893263483494, 0.26004390251897785, 0.24989089918822285, 0.08052584592439692] MainProcess root INFO Score: 0.0 MainProcess root INFO Fitness: (0.0,) MainProcess root INFO --- Population statistics --- MainProcess root INFO Replacing 0 invalid individuals. MainProcess pypet.environment.Environment INFO I am preparing the Trajectory for the experiment and initialise the store. MainProcess pypet.environment.Environment INFO Initialising the storage for the trajectory. MainProcess pypet.storageservice.HDF5StorageService INFO Initialising storage or updating meta data of Trajectory `results-2021-07-07-16H-45M-51S`. MainProcess pypet.storageservice.HDF5StorageService INFO Finished init or meta data update for `results-2021-07-07-16H-45M-51S`. MainProcess pypet.environment.Environment INFO ************************************************************ STARTING runs of trajectory `results-2021-07-07-16H-45M-51S`. ************************************************************ MainProcess pypet.storageservice.HDF5StorageService INFO Initialising storage or updating meta data of Trajectory `results-2021-07-07-16H-45M-51S`. MainProcess pypet.storageservice.HDF5StorageService INFO Finished init or meta data update for `results-2021-07-07-16H-45M-51S`. MainProcess pypet.environment.Environment INFO Starting multiprocessing with at most 8 processes running at the same time. MainProcess pypet INFO PROGRESS: Finished 144/160 runs [================== ] 90.0% MainProcess pypet INFO PROGRESS: Finished 152/160 runs [=================== ] 95.0%, remaining: 0:00:05 MainProcess pypet INFO PROGRESS: Finished 160/160 runs [====================]100.0% MainProcess pypet.storageservice.HDF5StorageService INFO Initialising storage or updating meta data of Trajectory `results-2021-07-07-16H-45M-51S`. MainProcess pypet.storageservice.HDF5StorageService INFO Finished init or meta data update for `results-2021-07-07-16H-45M-51S`. MainProcess pypet.environment.Environment INFO ************************************************************ FINISHED all runs of trajectory `results-2021-07-07-16H-45M-51S`. ************************************************************ MainProcess pypet.environment.Environment INFO ************************************************************ STARTING FINAL STORING of trajectory `results-2021-07-07-16H-45M-51S` ************************************************************ MainProcess pypet.storageservice.HDF5StorageService INFO Start storing Trajectory `results-2021-07-07-16H-45M-51S`. MainProcess pypet.storageservice.HDF5StorageService INFO Storing branch `config`. MainProcess pypet.storageservice.HDF5StorageService INFO Storing branch `parameters`. MainProcess pypet.storageservice.HDF5StorageService INFO Storing branch `results`. MainProcess pypet.storageservice.HDF5StorageService INFO Storing branch `derived_parameters`. MainProcess pypet.storageservice.HDF5StorageService INFO Finished storing Trajectory `results-2021-07-07-16H-45M-51S`. MainProcess pypet.environment.Environment INFO ************************************************************ FINISHED FINAL STORING of trajectory `results-2021-07-07-16H-45M-51S`. ************************************************************ MainProcess pypet.environment.Environment INFO All runs of trajectory `results-2021-07-07-16H-45M-51S` were completed successfully. MainProcess pypet.storageservice.HDF5StorageService INFO Start storing Trajectory `results-2021-07-07-16H-45M-51S`. MainProcess pypet.storageservice.HDF5StorageService INFO Storing branch `config`. MainProcess pypet.storageservice.HDF5StorageService INFO Storing branch `parameters`. MainProcess pypet.storageservice.HDF5StorageService INFO Storing branch `results`. MainProcess pypet.storageservice.HDF5StorageService INFO Storing branch `derived_parameters`. MainProcess pypet.storageservice.HDF5StorageService INFO Finished storing Trajectory `results-2021-07-07-16H-45M-51S`. MainProcess root INFO ----------- Generation 9 ----------- MainProcess root INFO Best individual is [1.2018893263483494, 0.26004390251897785, 0.24989089918822285, 0.08052584592439692] MainProcess root INFO Score: 0.0 MainProcess root INFO Fitness: (0.0,) MainProcess root INFO --- Population statistics --- MainProcess root INFO --- End of evolution --- MainProcess root INFO Best individual is [1.2018893263483494, 0.26004390251897785, 0.24989089918822285, 0.08052584592439692], (0.0,) MainProcess root INFO --- End of evolution --- MainProcess pypet.storageservice.HDF5StorageService INFO Start storing Trajectory `results-2021-07-07-16H-45M-51S`. MainProcess pypet.storageservice.HDF5StorageService INFO Storing branch `config`. MainProcess pypet.storageservice.HDF5StorageService INFO Storing branch `parameters`. MainProcess pypet.storageservice.HDF5StorageService INFO Storing branch `results`. MainProcess pypet.storageservice.HDF5StorageService INFO Storing branch `derived_parameters`. MainProcess pypet.storageservice.HDF5StorageService INFO Finished storing Trajectory `results-2021-07-07-16H-45M-51S`. evolution . info ( plot = True ) /Users/nikola/.virtualenvs/neurolib/lib/python3.7/site-packages/neurolib/optimize/evolution/evolutionaryUtils.py:212: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect. plt.tight_layout() > Simulation parameters HDF file storage: ./data/hdf/example-4.2-evolution.hdf Trajectory Name: results-2021-07-07-16H-45M-51S Duration of evaluating initial population 0:00:11.681965 Duration of evolution 0:01:31.868614 Model: <class 'neurolib.models.multimodel.model.MultiModel'> Model name: ALNNode Eval function: <function evaluateSimulation at 0x15b06a830> Parameter space: {'*EXC*noise*mu': [0.0, 4.0], '*INH*noise*mu': [0.0, 4.0]} > Evolution parameters Number of generations: 10 Initial population size: 16 Population size: 16 > Evolutionary operators Mating operator: <function cxBlend at 0x159a43560> Mating paramter: {'alpha': 0.5} Selection operator: <function selBest_multiObj at 0x159a70200> Selection paramter: {} Parent selection operator: <function selRank at 0x159a70170> Comments: no comments --- Info summary --- Valid: 16 Mean score (weighted fitness): -3.6 Parameter distribution (Generation 9): STAREXCSTARnoiseSTARmu: mean: 1.1141, std: 0.2046 STARINHSTARnoiseSTARmu: mean: 0.4791, std: 0.2361 -------------------- Best 5 individuals: Printing 5 individuals Individual 0 Fitness values: 0.0 Score: 0.0 Weighted fitness: -0.0 Stats mean 0.00 std 0.00 min 0.00 max 0.00 model.params[\"STAREXCSTARnoiseSTARmu\"] = 1.20 model.params[\"STARINHSTARnoiseSTARmu\"] = 0.26 Individual 1 Fitness values: 0.0 Score: 0.0 Weighted fitness: -0.0 Stats mean 0.00 std 0.00 min 0.00 max 0.00 model.params[\"STAREXCSTARnoiseSTARmu\"] = 1.01 model.params[\"STARINHSTARnoiseSTARmu\"] = 0.16 Individual 2 Fitness values: 1.0 Score: -1.0 Weighted fitness: -1.0 Stats mean 1.00 std 0.00 min 1.00 max 1.00 model.params[\"STAREXCSTARnoiseSTARmu\"] = 0.90 model.params[\"STARINHSTARnoiseSTARmu\"] = 0.11 Individual 3 Fitness values: 2.0 Score: -2.0 Weighted fitness: -2.0 Stats mean 2.00 std 0.00 min 2.00 max 2.00 model.params[\"STAREXCSTARnoiseSTARmu\"] = 1.30 model.params[\"STARINHSTARnoiseSTARmu\"] = 0.46 Individual 4 Fitness values: 2.0 Score: -2.0 Weighted fitness: -2.0 Stats mean 2.00 std 0.00 min 2.00 max 2.00 model.params[\"STAREXCSTARnoiseSTARmu\"] = 0.96 model.params[\"STARINHSTARnoiseSTARmu\"] = 0.25 -------------------- There are 16 valid individuals Mean score across population: -3.6 MainProcess root INFO Saving plot to ./data/figures/results-2021-07-07-16H-45M-51S_hist_9.png <Figure size 432x288 with 0 Axes> Adapting existing models in MultiModel framework MultiModel comes with a few implemented models so you can play with models right away. Due to the hierarchical architecture based on class inheritence in python, it is also very easy to adapt existing models. As an example - MultiModel comes with an implementation of Wilson-Cowan model. In our version, there are excitatory and inhibitory masses in one node. Let's say, you want to add an adaptation current inside excitatory mass in Wilson-Cowan model. # imports from jitcdde import input as system_input from neurolib.models.multimodel.builder.base.constants import EXC from neurolib.models.multimodel.builder.wilson_cowan import ( WC_EXC_DEFAULT_PARAMS , WC_NODE_DEFAULT_CONNECTIVITY , ExcitatoryWilsonCowanMass , InhibitoryWilsonCowanMass , WilsonCowanNode , ) Here is just a copy-paste code of ExcitatoryWilsonCowanMass: class ExcitatoryWilsonCowanMass ( WilsonCowanMass ): \"\"\" Excitatory Wilson-Cowan neural mass. \"\"\" name = \"Wilson-Cowan excitatory mass\" label = f \"WCmass { EXC } \" coupling_variables = { 0 : f \"q_mean_ { EXC } \" } state_variable_names = [ f \"q_mean_ { EXC } \" ] mass_type = EXC required_couplings = [ \"node_exc_exc\" , \"node_exc_inh\" , \"network_exc_exc\" ] def __init__ ( self , params = None , seed = None ): super () . __init__ ( params = params or WC_EXC_DEFAULT_PARAMS , seed = seed ) def _derivatives ( self , coupling_variables ): [ x ] = self . _unwrap_state_vector () d_x = ( - x + ( 1.0 - x ) * self . _sigmoid ( coupling_variables [ \"node_exc_exc\" ] - coupling_variables [ \"node_exc_inh\" ] + coupling_variables [ \"network_exc_exc\" ] + self . params [ \"ext_input\" ] ) + system_input ( self . noise_input_idx [ 0 ]) ) / self . params [ \"tau\" ] return [ d_x ] Since everything in MultiModel is a class, we will simply subclass the ExcitatoryWilsonCowanMass and edit / add things we need to. Our adaptation current will come in as: \\( \\(\\dot{w} = -\\frac{w}{\\tau_{A}} + b*r\\) \\) class AdaptationExcitatoryWilsonCowanMass ( ExcitatoryWilsonCowanMass ): # here we only edit attributes that will change! # slightly edit name and label name = \"Wilson-Cowan excitatory mass with adaptation\" label = f \"WCmass { EXC } _adapt\" num_state_variables = 2 # same number of noise variables # coupling variables - the same, no need to do anything # add w as a variable state_variable_names = [ f \"q_mean_ { EXC } \" , \"w\" ] # mass type and couplings are the same # add parameters for adaptation current - b and tauA required_params = [ \"a\" , \"mu\" , \"tau\" , \"ext_drive\" , \"b\" , \"tauA\" ] # same input noise def __init__ ( self , params = None , seed = None ): # edit init and pass default parameters for adaptation super () . __init__ ( params = params or WC_ADAPT_EXC_DEFAULT_PARAMS , seed = seed ) def _initialize_state_vector ( self ): # need to add init for adaptation variable w np . random . seed ( self . seed ) self . initial_state = [ 0.05 * np . random . uniform ( 0 , 1 ), 0.0 ] def _derivatives ( self , coupling_variables ): # edit derivatives [ x , w ] = self . _unwrap_state_vector () d_x = ( - x + ( 1.0 - x ) * self . _sigmoid ( coupling_variables [ \"node_exc_exc\" ] - coupling_variables [ \"node_exc_inh\" ] + coupling_variables [ \"network_exc_exc\" ] + self . params [ \"ext_drive\" ] - w # subtract adaptation current ) + system_input ( self . noise_input_idx [ 0 ]) ) / self . params [ \"tau\" ] # now define adaptation dynamics d_w = - w / self . params [ \"tauA\" ] + self . params [ \"b\" ] * x return [ d_x , d_w ] # define default set of parameters WC_ADAPT_EXC_DEFAULT_PARAMS = { # just copy all default parameters from non-adaptation version ** WC_EXC_DEFAULT_PARAMS , # add adaptation parameters \"tauA\" : 500.0 , # ms \"b\" : 1.0 , } That's it! Now we have our shiny excitatory Wilson-Cowan mass with adaptation. Now, we need to create a Node with one exctitatory WC mass with adaptation and one good old inhibitory mass without adaptation. The basic inhibitory mass is already implemented, no need to do anything. Below we will create our Node with adaptation. class WilsonCowanNodeWithAdaptation ( WilsonCowanNode ): # start by subclassing the basic WilsonCowanNode and, again, # just change what has to be changed name = \"Wilson-Cowan node with adaptation\" label = \"WCnode_adapt\" # default coupling and outputs are the same def __init__ ( self , exc_params = None , inh_params = None , connectivity = WC_NODE_DEFAULT_CONNECTIVITY , ): # here we just pass our new `AdaptationExcitatoryWilsonCowanMass` instead of # `ExcitatoryWilsonCowanMass`, otherwise it is the same excitatory_mass = AdaptationExcitatoryWilsonCowanMass ( exc_params ) excitatory_mass . index = 0 inhibitory_mass = InhibitoryWilsonCowanMass ( inh_params ) inhibitory_mass . index = 1 # the only trick is, we want to call super() and init Node class, BUT # just calling super().__init__() will actually call parent's init, and in # this case, our parent is `WilsonCowanNode`... we need to call grandparent's # __init__.. fortunately, this can be done in python no problemo # instead of calling super().__init__(), we need to call # super(<current parent>, self).__init__() super ( WilsonCowanNode , self ) . __init__ ( neural_masses = [ excitatory_mass , inhibitory_mass ], local_connectivity = connectivity , # within W-C node there are no local delays local_delays = None , ) And done. Now we can run and compare WC node with and without adaptation. wc_basic = MultiModel . init_node ( WilsonCowanNode ()) wc_adapt = MultiModel . init_node ( WilsonCowanNodeWithAdaptation ()) MainProcess root INFO WCnode: Model initialized. MainProcess root INFO WCnode_adapt: Model initialized. # set parameters wc_basic . params [ \"*EXC*ext_drive\" ] = 0.8 wc_basic . params [ \"duration\" ] = 2000.0 wc_basic . params [ \"sampling_dt\" ] = 1.0 # higher external input due to adaptation wc_adapt . params [ \"*EXC*ext_drive\" ] = 5.5 wc_adapt . params [ \"duration\" ] = 2000.0 wc_adapt . params [ \"sampling_dt\" ] = 1.0 wc_adapt . params [ \"*b\" ] = 0.1 wc_basic . run () wc_adapt . run () MainProcess root INFO Initialising jitcdde backend... MainProcess root INFO Setting up the DDE system... /Users/nikola/.virtualenvs/neurolib/lib/python3.7/site-packages/jitcdde/_jitcdde.py:1491: UserWarning: Your input past does not begin at t=0 but at t=1.0. Values before the beginning of the past will be extrapolated. You very likely do not want this. warn(f\"Your input past does not begin at t=0 but at t={input[0].time}. Values before the beginning of the past will be extrapolated. You very likely do not want this.\") MainProcess root INFO Compiling to C... MainProcess root INFO Setting past of the state vector... MainProcess root INFO Integrating for 2000 time steps... 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 2000/2000 [00:00<00:00, 153705.07it/s] MainProcess root INFO Integration done. MainProcess root INFO `run` call took 1.24 s MainProcess root INFO Initialising jitcdde backend... MainProcess root INFO Setting up the DDE system... MainProcess root INFO Compiling to C... Using default integration parameters. MainProcess root INFO Setting past of the state vector... MainProcess root INFO Integrating for 2000 time steps... 0%| | 0/2000 [00:00<?, ?it/s]/Users/nikola/.virtualenvs/neurolib/lib/python3.7/site-packages/jitcdde/_jitcdde.py:791: UserWarning: The target time is smaller than the current time. No integration step will happen. The returned state will be extrapolated from the interpolating Hermite polynomial for the last integration step. You may see this because you try to integrate backwards in time, in which case you did something wrong. You may see this just because your sampling step is small, in which case there is no need to worry. warn(\"The target time is smaller than the current time. No integration step will happen. The returned state will be extrapolated from the interpolating Hermite polynomial for the last integration step. You may see this because you try to integrate backwards in time, in which case you did something wrong. You may see this just because your sampling step is small, in which case there is no need to worry.\") 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 2000/2000 [00:00<00:00, 100000.10it/s] MainProcess root INFO Integration done. MainProcess root INFO `run` call took 0.79 s Using default integration parameters. plt . plot ( wc_adapt . t , wc_adapt . q_mean_EXC . T , label = \"with adaptation\" ) plt . plot ( wc_basic . t , wc_basic . q_mean_EXC . T , label = \"vanilla\" ) plt . legend () <matplotlib.legend.Legend at 0x15afa6710> All done. Now we can study adaptation dynamics in Wilson-Cowan model by e.g. running exploration over adaptation parameters and eventually evolution with the target of having slow oscillations (i.e. oscillations with frequency ~1Hz) and optimising with respect to parameters such as b , tauA , ext_input and others. Happy hacking!","title":"Example 4.2 multimodel backends and optimization"},{"location":"examples/example-4.2-multimodel-backends-and-optimization/#multimodel-advanced-topics","text":"In the last two examples we showcased the basics of MultiModel framework and how to create a new model from scratch. Now we will look at some advanced topics such as how exactly the integration works, why we have two integration backends, and how to run optimisation and exploration with MultiModel .","title":"MultiModel advanced topics"},{"location":"examples/example-4.2-multimodel-backends-and-optimization/#the-tale-of-two-backends","text":"In the current implementation of MultiModel , users may choose from two different integration backends. Before diving into the details of both backends, let us quickly revise how exactly MultiModel integrates the model equations.","title":"The tale of two backends"},{"location":"examples/example-4.2-multimodel-backends-and-optimization/#the-how","text":"Almost all whole-brain simulators works in the sense, that you define the dynamics of single brain area and then we have a double loop for integration: one over time, the second over brain areas. In other words, all brain areas have the same dynamics. In pseudo-code it would look something like: for t in range ( time_total ): for n in range ( num_areas ): x [ t , n ] = integrate_step ( x [ t - max_delay : t - 1 , :]) Since all areas are the same, the integrate_step function would simply take the history of state vector and apply one integration step in any scheme. This won't work in MultiModel , since it allows building heterogeneous models. The internal workings of MultiModel can be explained in couple of steps.","title":"The how"},{"location":"examples/example-4.2-multimodel-backends-and-optimization/#state-vector","text":"Since the inner loop in the pseudocode above is not doable in MultiModel due to heterogeneity, we solve it simply by concatenating all individual equations into one big state vector (that is also the reason why all NeuralMass and Node objects have their indices). When the model is ready for simulation, we iterate over Nodes and NeuralMasses within these nodes and stack their equations into a single list. The concatenation is done using the _derivatives() function. - in NeuralMass , the _derivatives() function implements the actual dynamics as delay differential equations - in Node , the _derivatives() function stacks all equations from NeuralMasses within this Node into one list - in Network , the _derivatives() function stacks all equations from Nodes within this Network . Let us see how it looks like: # create a FitzHugh-Nagumo Node fhn_node = FitzHughNagumoNode () # necessary attributes when creating a Node from scratch fhn_node . index = 0 fhn_node . idx_state_var = 0 fhn_node . init_node () display ( fhn_node . _derivatives ()) display ( len ( fhn_node . _derivatives ()), fhn_node . num_state_variables ) [1.0 + 4.0*current_y(0)**2 - 3.0*current_y(0)**3 - 1.5*current_y(0) - current_y(1) + past_y(-external_input + t, input_base_n, anchors(-external_input + t)), 0.05*(current_y(0) - 0.5*current_y(1)) + past_y(-external_input + t, 1 + input_base_n, anchors(-external_input + t))] 2 2 As we see, the _derivatives() function return a list of equations, in this case of length 2 (which is, of course, equal to fhn.num_state_variables ). The current_y(<index>) lingo is taken from jitcdde . As written above, all equations are symbolic and therefore current_y(<index>) is a symengine Symbol representing state vector with index <index> at current time t . In other words, current_y(0) is the first variable (in FitzHugh-Nagumo model, this is the \\(x\\) ), while current_y(1) is the second variable (the \\(y\\) ). The past_y() lingo is the same, but encodes either the past of the state vector, i.e. delayed interactions, or the external input (noise or stimulus). In this case it represents the external input (you can tell since it is past_y(-external_input...) ). Now let us see how it looks like for network: # create 2 node FHN network SC = np . array ([[ 0.0 , 1.43 ], [ 0.64 , 0.0 ]]) delays = np . array ([[ 0.0 , 10.0 ], [ 10.0 , 0.0 ]]) fhn_net = FitzHughNagumoNetwork ( SC , delays ) display ( len ( fhn_net . _derivatives ()), fhn_net . num_state_variables ) display ( fhn_net . _derivatives ()) 4 4 [1.0 + network_x_0 + 4.0*current_y(0)**2 - 3.0*current_y(0)**3 - 1.5*current_y(0) - current_y(1) + past_y(-external_input + t, input_base_n, anchors(-external_input + t)), network_y_0 + 0.05*(current_y(0) - 0.5*current_y(1)) + past_y(-external_input + t, 1 + input_base_n, anchors(-external_input + t)), 1.0 + network_x_1 + 4.0*current_y(2)**2 - 3.0*current_y(2)**3 - 1.5*current_y(2) - current_y(3) + past_y(-external_input + t, 2 + input_base_n, anchors(-external_input + t)), network_y_1 + 0.05*(current_y(2) - 0.5*current_y(3)) + past_y(-external_input + t, 3 + input_base_n, anchors(-external_input + t))] Now, since we have 2 nodes, the total number of state variables is 4. And now, we see equations for the whole network as a list of 4 symbolic equations. In the network equations we see a new symbol: network_x_0 and network_x_1 . At this time, these are really just symengine symbols, but they actually represent the coupling between the nodes. And that is also a topic of the next section.","title":"State vector"},{"location":"examples/example-4.2-multimodel-backends-and-optimization/#coupling","text":"As we have seen before, the state vector encodes the whole dynamics of the brain model, but the coupling is crypted as symbol. To make things easier for simulating, we had to separate the individual internal dynamics from the coupling terms. The coupling comes in two flavours, reflecting the three levels of hierarchy: node coupling takes care of coupling between NeuralMasses within one Node , and network coupling takes care of coupling between Nodes in one Network . The coupling is implemented as _sync() function. This function returns a list, where each item is a tuple of length two: (name_of_the_symbol, symbolic_term_representing_the_coupling) . The FitzHugh-Nagumo model only has one mass per node, hence there are no node couplings, but we can inspect the network coupling: display ( fhn_net . _sync ()) [(network_x_0, 1.43*(-current_y(0) + past_y(-10.0 + t, 2, anchors(-10.0 + t)))), (network_x_1, 0.64*(-current_y(2) + past_y(-10.0 + t, 0, anchors(-10.0 + t)))), (network_y_0, 0.0), (network_y_1, 0.0)] In this particular case, we have 2 coupling variables and 2 nodes, hence 4 coupling terms. The coupling of \\(y\\) is zero. As per the coupling of \\(x\\) variables between nodes, you can now see how it works: network_x_0 just means that we are about to define a network coupling of variable x for the first node, and it is just 1.43 (this is the SC matrix we passed when creating FHN network) times state variable with index 2 at time -10 milliseconds minus current state variable index 0 (diffusive coupling). Similarly for node 1 (with different coupling strength and state variable indices, of course). Now when symbols from _sync() function are inserted into _derivatives() at the proper places, we have a full definition of a model. This is exactly what both backends do: they gather the equations ( _derivatives() ), look up the coupling terms ( _sync() ) and integrate the model forward in time.","title":"Coupling"},{"location":"examples/example-4.2-multimodel-backends-and-optimization/#jitcdde-backend","text":"The jitcdde backend was the first integration backend in MultiModel . The name stems from the fact that we use wonderful jitcdde python package. It employs just-in-time compilation of symbolic derivatives into C and then uses DDE integration method proposed by Shampine and Thompson, which in turn employs the Bogacki\u2013Shampine Runge\u2013Kutta pair. This is the reason why the definition of dynamics in MultiModel is done using symbolic derivatives written in symengine . It uses adaptive dt scheme, hence is very useful for stiff problems. Also, if you are implementing a new model and have no idea how stiff the dynamics are, this is the backend to try first. It has reasonable speed, but for large networks and long simulations it is not the best. The internal workings of jitcdde package served as an inspiration when creating MultiModel . jitcdde naturally works with dynamics defined as symbolic equations ( _derivatives() ) and it also supports the use of \"helpers\" - the helpers in our case are the coupling terms ( _sync() ). fhn_mm = MultiModel ( fhn_net ) # 2 second run fhn_mm . params [ \"duration\" ] = 2000.0 fhn_mm . params [ \"backend\" ] = \"jitcdde\" # jitcdde works with adaptive dt, you only set sampling dt fhn_mm . params [ \"sampling_dt\" ] = 1.0 fhn_mm . run () plt . plot ( fhn_mm . x . T ) /Users/nikola/.virtualenvs/neurolib/lib/python3.7/site-packages/jitcdde/_jitcdde.py:1491: UserWarning: Your input past does not begin at t=0 but at t=1.0. Values before the beginning of the past will be extrapolated. You very likely do not want this. warn(f\"Your input past does not begin at t=0 but at t={input[0].time}. Values before the beginning of the past will be extrapolated. You very likely do not want this.\") 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 2000/2000 [00:00<00:00, 85415.01it/s] Using default integration parameters. [<matplotlib.lines.Line2D at 0x15aa79950>, <matplotlib.lines.Line2D at 0x15aa63690>]","title":"jitcdde backend"},{"location":"examples/example-4.2-multimodel-backends-and-optimization/#numba-backend","text":"Since jitcdde is rather slow, in particular for long runs or large networks, we created a numba backend. It was tricky - the whole code around MultiModel was creating with jitcdde in mind with the symbolic equations, helpers, etc. However, the advantage of symbolic equations is also - they are purely symbolic, so you can \"print\" them. By printing, you really just obtain the string with equations. So what numba backend actually does? 1. gather all symbolic equations with _derivatives() 2. substitute coupling symbols with functional terms in _sync() 3. substitute current and past state vector symbols ( current_y() and past_y() ) with state vector y with correct indices and time delays 4. now we have a complete description of dy 5. \"print\" out this dy into prepared function template (string) inside the time for loop, you can imagine it as for t in range ( 1 , t_max ): dy = np . array ({ dy }) # <- `dy` is printed here y [:, t ] = y [:, t - 1 ] + dt * dy 6. compile the prepared string template into an actual python function (yes, python can do this) 7. wrap the compiled function with numba.njit() to get the speed boots 8. profit And yes, the numba backend simply employs Euler integration scheme, which means that you need to think about dt. fhn_mm = MultiModel ( fhn_net ) # 2 second run fhn_mm . params [ \"duration\" ] = 2000.0 fhn_mm . params [ \"backend\" ] = \"numba\" # numba uses Euler scheme so dt is important! fhn_mm . params [ \"dt\" ] = 0.1 fhn_mm . params [ \"sampling_dt\" ] = 1.0 fhn_mm . run () plt . plot ( fhn_mm . x . T ) [<matplotlib.lines.Line2D at 0x15a44fad0>, <matplotlib.lines.Line2D at 0x15a2a0e10>]","title":"numba backend"},{"location":"examples/example-4.2-multimodel-backends-and-optimization/#which-backend-to-use-and-when","text":"By default numba backend is almost always faster (with the exception of small network and not too long runs, when they perform similarly). However, for prototyping new models, or connecting couple of models into a heterogeneous network, it is always a good idea to do a couple of short simulations with jitcdde . The reason is - it uses an adaptive dt, so you do not need to worry about setting a correct dt. When you have an idea about what the dynamics should look like and how fast it is, you can switch to numba and try couple of different dt and select the one, when the results are closest to jitcdde results. For exploration and optimisation with evolution, always use numba . numba backend is actually compiling a jit'ed function with all the parameters as arguments, hence for exploration, only one compilation is necessary and then even when changing parameters, the model runs at high speed.","title":"Which backend to use and when?"},{"location":"examples/example-4.2-multimodel-backends-and-optimization/#exploration-with-multimodel","text":"So we all love neurolib not only for its speed, efficiency, and ease of use, but also for its built-in exploration and evolution frameworks. These two makes studying the population models a real breeze! And naturally, MultiModel supports both. Firtsly, we will showcase how we can explore parameters of MultiModel using the BoxSearch class and we will replicate the ALN exploration from example-1-aln-parameter-exploration.ipynb . # first init multimodel aln_mm = MultiModel . init_node ( ALNNode ()) display ( aln_mm . params ) {'ALNNode_0.ALNMassEXC_0.Ke': 800.0, 'ALNNode_0.ALNMassEXC_0.Ki': 200.0, 'ALNNode_0.ALNMassEXC_0.c_gl': 0.4, 'ALNNode_0.ALNMassEXC_0.Ke_gl': 250.0, 'ALNNode_0.ALNMassEXC_0.tau_se': 2.0, 'ALNNode_0.ALNMassEXC_0.tau_si': 5.0, 'ALNNode_0.ALNMassEXC_0.sigmae_ext': 1.5, 'ALNNode_0.ALNMassEXC_0.Jee_max': 2.43, 'ALNNode_0.ALNMassEXC_0.Jei_max': -3.3, 'ALNNode_0.ALNMassEXC_0.C': 200.0, 'ALNNode_0.ALNMassEXC_0.gL': 10.0, 'ALNNode_0.ALNMassEXC_0.ext_exc_current': 0.0, 'ALNNode_0.ALNMassEXC_0.ext_exc_rate': 0.0, 'ALNNode_0.ALNMassEXC_0.a': 15.0, 'ALNNode_0.ALNMassEXC_0.b': 40.0, 'ALNNode_0.ALNMassEXC_0.EA': -80.0, 'ALNNode_0.ALNMassEXC_0.tauA': 200.0, 'ALNNode_0.ALNMassEXC_0.lambda': 10.0, 'ALNNode_0.ALNMassEXC_0.noise_0.type': 'OrnsteinUhlenbeckProcess', 'ALNNode_0.ALNMassEXC_0.noise_0.mu': 0.4, 'ALNNode_0.ALNMassEXC_0.noise_0.sigma': 0.0, 'ALNNode_0.ALNMassEXC_0.noise_0.tau': 5.0, 'ALNNode_0.ALNMassEXC_0.noise_0.num_iid': 1, 'ALNNode_0.ALNMassEXC_0.noise_0.seed': None, 'ALNNode_0.ALNMassINH_1.Ke': 800.0, 'ALNNode_0.ALNMassINH_1.Ki': 200.0, 'ALNNode_0.ALNMassINH_1.c_gl': 0.4, 'ALNNode_0.ALNMassINH_1.Ke_gl': 250.0, 'ALNNode_0.ALNMassINH_1.tau_se': 2.0, 'ALNNode_0.ALNMassINH_1.tau_si': 5.0, 'ALNNode_0.ALNMassINH_1.sigmai_ext': 1.5, 'ALNNode_0.ALNMassINH_1.Jie_max': 2.6, 'ALNNode_0.ALNMassINH_1.Jii_max': -1.64, 'ALNNode_0.ALNMassINH_1.C': 200.0, 'ALNNode_0.ALNMassINH_1.gL': 10.0, 'ALNNode_0.ALNMassINH_1.ext_inh_current': 0.0, 'ALNNode_0.ALNMassINH_1.ext_inh_rate': 0.0, 'ALNNode_0.ALNMassINH_1.lambda': 10.0, 'ALNNode_0.ALNMassINH_1.noise_0.type': 'OrnsteinUhlenbeckProcess', 'ALNNode_0.ALNMassINH_1.noise_0.mu': 0.3, 'ALNNode_0.ALNMassINH_1.noise_0.sigma': 0.0, 'ALNNode_0.ALNMassINH_1.noise_0.tau': 5.0, 'ALNNode_0.ALNMassINH_1.noise_0.num_iid': 1, 'ALNNode_0.ALNMassINH_1.noise_0.seed': None, 'ALNNode_0.local_connectivity': array([[0.24691358, 0.75757576], [0.23076923, 1.52439024]]), 'ALNNode_0.local_delays': array([[4., 2.], [4., 2.]]), 'duration': 2000, 'dt': 0.1, 'seed': None, 'backend': 'jitcdde', 'name': 'ALNNode', 'description': 'ALN neural mass node', 'N': 1, 'Cmat': array([[0.]]), 'sampling_dt': 0.1}","title":"Exploration with MultiModel"},{"location":"examples/example-4.2-multimodel-backends-and-optimization/#note-on-parameters-when-exploring-or-optimising","text":"If you remember, the MultiModel has an option for true heterogeneous parameters, i.e. each brain node can have different parameters. This allows you to explore paramaters one-by-one (truly different parameters for each node), or in bulk. As an example, consider this: parameters1 = ParameterSpace ({ \"*Ke\" : [ 400 , 800 , 1200 ]}, allow_star_notation = True ) parameters2 = ParameterSpace ( { \"*EXC*Ke\" : [ 400 , 800 , 1200 ], \"*INH*Ke\" : [ 400 , 800 , 1200 ]}, allow_star_notation = True ) parameters2 = ParameterSpace ( { \"*Node_0*EXC*Ke\" : [ 400 , 800 , 1200 ], \"*Node_1*EXC*Ke\" : [ 400 , 800 , 1200 ]}, allow_star_notation = True ) In the first example ( parameters1 ), we explore Ke parameter and set this for all nodes and for all masses the same. In the end, we run three simulations with homogeneous Ke for all nodes/masses. In the second example, we explore Ke individually for excitatory masses and inhibitory masses, however, for all nodes these would be the same. In total, we will run 9 simulations with heterogeneous Ke within one node, but the same values for Ke_exc and Ke_inh would be used in all nodes. Finally, in the last example, we would explore only excitatory Ke parameters, but for two nodes differently, hence we can study how excitatory Ke affects 2-node network. Of course, we can always call parameters by their full name (glob path), like: parameters3 = ParameterSpace ( { \"ALNNode_0.ALNMassINH_1.Ke\" : [ 400 , 800 , 1200 ]}, allow_star_notation = True # due to \".\" in the param names ) and we will simply explore over one particular Ke of inhibitory mass in first node within a network. All other Ke parameters will remain constant. # match params to core ALN model aln_mm . params [ \"backend\" ] = \"numba\" aln_mm . params [ \"dt\" ] = 0.1 # ms aln_mm . params [ \"*c_gl\" ] = 0.3 aln_mm . params [ \"*b\" ] = 0.0 aln_mm . params [ \"ALNNode_0.ALNMassEXC_0.a\" ] = 0.0 # set up exploration - using star # parameters = ParameterSpace( # { # \"*EXC*input*mu\": np.linspace(0, 3, 21), # \"*INH*input*mu\": np.linspace(0, 3, 21), # }, # allow_star_notation=True, # ) # set up exploration - using exact parameter names # in this case (one node, search over noise mu) -> these two are equivalent! parameters = ParameterSpace ( { # 2 values per dimension is for quick testing only, for real exploration use e.g. 21 or rather much more \"ALNNode_0.ALNMassEXC_0.input_0.mu\" : np . linspace ( 0 , 3 , 2 ), \"ALNNode_0.ALNMassINH_1.input_0.mu\" : np . linspace ( 0 , 3 , 2 ), # \"ALNNode_0.ALNMassEXC_0.input_0.mu\": np.linspace(0, 3, 21), # \"ALNNode_0.ALNMassINH_1.input_0.mu\": np.linspace(0, 3, 21), }, allow_star_notation = True , ) search = BoxSearch ( aln_mm , parameters , filename = \"example-4.2-exploration.hdf\" ) MainProcess pypet.storageservice.HDF5StorageService INFO I will use the hdf5 file `./data/hdf/example-4.2-exploration.hdf`. MainProcess pypet.environment.Environment INFO Environment initialized. /Users/nikola/.virtualenvs/neurolib/lib/python3.7/site-packages/pypet/naturalnaming.py:1473: SyntaxWarning: `lambda` is a python keyword, you may not be able to access it via natural naming but only by using `[]` square bracket notation. category=SyntaxWarning) MainProcess root INFO Number of parameter configurations: 441 MainProcess root INFO BoxSearch: Environment initialized. search . run () MainProcess pypet.environment.Environment INFO I am preparing the Trajectory for the experiment and initialise the store. MainProcess pypet.environment.Environment INFO Initialising the storage for the trajectory. MainProcess pypet.storageservice.HDF5StorageService INFO Initialising storage or updating meta data of Trajectory `results-2021-07-07-16H-40M-57S`. MainProcess pypet.storageservice.HDF5StorageService INFO Finished init or meta data update for `results-2021-07-07-16H-40M-57S`. MainProcess pypet.environment.Environment INFO ************************************************************ STARTING runs of trajectory `results-2021-07-07-16H-40M-57S`. ************************************************************ MainProcess pypet.storageservice.HDF5StorageService INFO Initialising storage or updating meta data of Trajectory `results-2021-07-07-16H-40M-57S`. MainProcess pypet.storageservice.HDF5StorageService INFO Finished init or meta data update for `results-2021-07-07-16H-40M-57S`. MainProcess pypet.environment.Environment INFO Starting multiprocessing with at most 8 processes running at the same time. MainProcess pypet INFO PROGRESS: Finished 0/441 runs [ ] 0.0% MainProcess pypet INFO PROGRESS: Finished 23/441 runs [= ] 5.2%, remaining: 0:05:32 MainProcess pypet INFO PROGRESS: Finished 45/441 runs [== ] 10.2%, remaining: 0:04:55 MainProcess pypet INFO PROGRESS: Finished 67/441 runs [=== ] 15.2%, remaining: 0:04:32 MainProcess pypet INFO PROGRESS: Finished 89/441 runs [==== ] 20.2%, remaining: 0:04:11 MainProcess pypet INFO PROGRESS: Finished 111/441 runs [===== ] 25.2%, remaining: 0:03:45 MainProcess pypet INFO PROGRESS: Finished 133/441 runs [====== ] 30.2%, remaining: 0:03:29 MainProcess pypet INFO PROGRESS: Finished 155/441 runs [======= ] 35.1%, remaining: 0:03:14 MainProcess pypet INFO PROGRESS: Finished 177/441 runs [======== ] 40.1%, remaining: 0:02:59 MainProcess pypet INFO PROGRESS: Finished 199/441 runs [========= ] 45.1%, remaining: 0:02:41 MainProcess pypet INFO PROGRESS: Finished 221/441 runs [========== ] 50.1%, remaining: 0:02:28 MainProcess pypet INFO PROGRESS: Finished 243/441 runs [=========== ] 55.1%, remaining: 0:02:14 MainProcess pypet INFO PROGRESS: Finished 265/441 runs [============ ] 60.1%, remaining: 0:02:01 MainProcess pypet INFO PROGRESS: Finished 287/441 runs [============= ] 65.1%, remaining: 0:01:44 MainProcess pypet INFO PROGRESS: Finished 309/441 runs [============== ] 70.1%, remaining: 0:01:29 MainProcess pypet INFO PROGRESS: Finished 331/441 runs [=============== ] 75.1%, remaining: 0:01:14 MainProcess pypet INFO PROGRESS: Finished 353/441 runs [================ ] 80.0%, remaining: 0:00:59 MainProcess pypet INFO PROGRESS: Finished 375/441 runs [================= ] 85.0%, remaining: 0:00:43 MainProcess pypet INFO PROGRESS: Finished 397/441 runs [================== ] 90.0%, remaining: 0:00:29 MainProcess pypet INFO PROGRESS: Finished 419/441 runs [=================== ] 95.0%, remaining: 0:00:14 MainProcess pypet INFO PROGRESS: Finished 441/441 runs [====================]100.0% MainProcess pypet.storageservice.HDF5StorageService INFO Initialising storage or updating meta data of Trajectory `results-2021-07-07-16H-40M-57S`. MainProcess pypet.storageservice.HDF5StorageService INFO Finished init or meta data update for `results-2021-07-07-16H-40M-57S`. MainProcess pypet.environment.Environment INFO ************************************************************ FINISHED all runs of trajectory `results-2021-07-07-16H-40M-57S`. ************************************************************ MainProcess pypet.environment.Environment INFO ************************************************************ STARTING FINAL STORING of trajectory `results-2021-07-07-16H-40M-57S` ************************************************************ MainProcess pypet.storageservice.HDF5StorageService INFO Start storing Trajectory `results-2021-07-07-16H-40M-57S`. MainProcess pypet.storageservice.HDF5StorageService INFO Storing branch `config`. MainProcess pypet.storageservice.HDF5StorageService INFO Storing branch `parameters`. MainProcess pypet.storageservice.HDF5StorageService INFO Finished storing Trajectory `results-2021-07-07-16H-40M-57S`. MainProcess pypet.environment.Environment INFO ************************************************************ FINISHED FINAL STORING of trajectory `results-2021-07-07-16H-40M-57S`. ************************************************************ MainProcess pypet.environment.Environment INFO All runs of trajectory `results-2021-07-07-16H-40M-57S` were completed successfully. search . loadResults () MainProcess root INFO Loading results from ./data/hdf/example-4.2-exploration.hdf MainProcess root INFO Analyzing trajectory results-2021-07-07-16H-40M-57S MainProcess pypet.storageservice.HDF5StorageService INFO I will use the hdf5 file `./data/hdf/example-4.2-exploration.hdf`. MainProcess pypet.storageservice.HDF5StorageService INFO Loading trajectory `results-2021-07-07-16H-40M-57S`. MainProcess pypet.storageservice.HDF5StorageService INFO Loading branch `config` in mode `2`. MainProcess pypet.storageservice.HDF5StorageService INFO Loading branch `parameters` in mode `2`. MainProcess pypet.storageservice.HDF5StorageService INFO Loading branch `results` in mode `1`. MainProcess root INFO Creating `dfResults` dataframe ... MainProcess root INFO Loading all results to `results` dictionary ... 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 441/441 [00:02<00:00, 219.34it/s] MainProcess root INFO Aggregating results to `dfResults` ... 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 441/441 [00:00<00:00, 3745.83it/s] MainProcess root INFO All results loaded. print ( f \"Number of results: { len ( search . results ) } \" ) Number of results: 441 # Example analysis of the results # The .results attribute is a list and can be indexed by the run # number (which is also the index of the pandas dataframe .dfResults). # Here we compute the maximum firing rate of the node in the last second # and add the result (a float) to the pandas dataframe. for i in search . dfResults . index : search . dfResults . loc [ i , \"max_r\" ] = np . max ( search . results [ i ][ \"r_mean_EXC\" ][:, - int ( 1000 / aln_mm . params [ \"dt\" ]) :] ) plt . imshow ( search . dfResults . pivot_table ( values = \"max_r\" , index = \"ALNNode_0.ALNMassINH_1.input_0.mu\" , columns = \"ALNNode_0.ALNMassEXC_0.input_0.mu\" , ), extent = [ min ( search . dfResults [ \"ALNNode_0.ALNMassEXC_0.input_0.mu\" ]), max ( search . dfResults [ \"ALNNode_0.ALNMassEXC_0.input_0.mu\" ]), min ( search . dfResults [ \"ALNNode_0.ALNMassINH_1.input_0.mu\" ]), max ( search . dfResults [ \"ALNNode_0.ALNMassINH_1.input_0.mu\" ]), ], origin = \"lower\" , ) plt . colorbar ( label = \"Maximum rate [kHz]\" ) plt . xlabel ( \"Input to E\" ) plt . ylabel ( \"Input to I\" ) Text(0, 0.5, 'Input to I')","title":"Note on parameters when exploring or optimising"},{"location":"examples/example-4.2-multimodel-backends-and-optimization/#evolution-with-multimodel","text":"If you're familiar with how Evolution works in core neurolib , and now you know the perks of MultiModel with respect to exploration - that's all you need to know when doing optimisation using evolutionary algorithms using MultiModel . Parameters are passed via ParameterSpace with allow_star_notation=True . Below, we will reproduce the example-2.1-evolutionary-optimization-aln with the MultiModel version of ALN model. # reinit fresh model aln_mm = MultiModel . init_node ( ALNNode ()) # match params to core ALN model aln_mm . params [ \"backend\" ] = \"numba\" aln_mm . params [ \"dt\" ] = 0.1 # ms aln_mm . params [ \"*c_gl\" ] = 0.3 aln_mm . params [ \"*b\" ] = 0.0 aln_mm . params [ \"ALNNode_0.ALNMassEXC_0.a\" ] = 0.0 MainProcess root INFO Loading precomputed transfer functions from /Users/nikola/.virtualenvs/neurolib/lib/python3.7/site-packages/neurolib/models/multimodel/builder/../../aln/aln-precalc/quantities_cascade.h5 MainProcess root INFO All transfer functions loaded. MainProcess root INFO Loading precomputed transfer functions from /Users/nikola/.virtualenvs/neurolib/lib/python3.7/site-packages/neurolib/models/multimodel/builder/../../aln/aln-precalc/quantities_cascade.h5 MainProcess root INFO All transfer functions loaded. MainProcess root INFO ALNNode: Model initialized. # use the same loss function as example-2.1 def evaluateSimulation ( traj ): # The trajectory id is provided as an attribute rid = traj . id # this function provides the a model with the partuclar # parameter set for this given run model = evolution . getModelFromTraj ( traj ) # parameters can also be modified after loading model . params [ \"dt\" ] = 0.1 model . params [ \"duration\" ] = 2 * 1000.0 # and the simulation is run model . run () # compute power spectrum frs , powers = func . getPowerSpectrum ( model . r_mean_EXC [:, - int ( 1000 / model . params [ \"dt\" ]) :], dt = model . params [ \"dt\" ] ) # find the peak frequency domfr = frs [ np . argmax ( powers )] # fitness evaluation: let's try to find a 25 Hz oscillation fitness = abs ( domfr - 25 ) # deap needs a fitness *tuple*! fitness_tuple = () # more fitness values could be added fitness_tuple += ( fitness ,) # we need to return the fitness tuple and the outputs of the model return fitness_tuple , model . outputs pars = ParameterSpace ( [ \"*EXC*input*mu\" , \"*INH*input*mu\" ], [[ 0.0 , 4.0 ], [ 0.0 , 4.0 ]], allow_star_notation = True , ) weightList = [ - 1.0 ] evolution = Evolution ( evalFunction = evaluateSimulation , parameterSpace = pars , model = aln_mm , # use our `MultiModel` here weightList = [ - 1.0 ], # POP_INIT_SIZE=16, # mutiple of number of cores # POP_SIZE=16, # low numbers for testing, for real evolution use higher number of runs POP_INIT_SIZE = 4 , # mutiple of number of cores POP_SIZE = 4 , # low numbers for testing, for real evolution use higher number NGEN = 2 , filename = \"example-4.2-evolution.hdf\" , ) MainProcess root INFO Trajectory Name: results-2021-07-07-16H-45M-51S MainProcess root INFO Storing data to: ./data/hdf/example-4.2-evolution.hdf MainProcess root INFO Trajectory Name: results-2021-07-07-16H-45M-51S MainProcess root INFO Number of cores: 8 MainProcess pypet.storageservice.HDF5StorageService INFO I will use the hdf5 file `./data/hdf/example-4.2-evolution.hdf`. MainProcess pypet.environment.Environment INFO Environment initialized. MainProcess root INFO Evolution: Using algorithm: adaptive MainProcess root INFO Evolution: Individual generation: <function randomParametersAdaptive at 0x159a6df80> MainProcess root INFO Evolution: Mating operator: <function cxBlend at 0x159a43560> MainProcess root INFO Evolution: Mutation operator: <function gaussianAdaptiveMutation_nStepSizes at 0x159a70440> MainProcess root INFO Evolution: Parent selection: <function selRank at 0x159a70170> MainProcess root INFO Evolution: Selection operator: <function selBest_multiObj at 0x159a70200> evolution . run ( verbose = False ) MainProcess root INFO Evaluating initial population of size 16 ... MainProcess pypet.trajectory.Trajectory INFO Your trajectory has not been explored, yet. I will call `f_explore` instead. MainProcess pypet.environment.Environment INFO I am preparing the Trajectory for the experiment and initialise the store. MainProcess pypet.environment.Environment INFO Initialising the storage for the trajectory. MainProcess pypet.storageservice.HDF5StorageService INFO Initialising storage or updating meta data of Trajectory `results-2021-07-07-16H-45M-51S`. MainProcess pypet.storageservice.HDF5StorageService INFO Finished init or meta data update for `results-2021-07-07-16H-45M-51S`. MainProcess pypet.environment.Environment INFO ************************************************************ STARTING runs of trajectory `results-2021-07-07-16H-45M-51S`. ************************************************************ MainProcess pypet.storageservice.HDF5StorageService INFO Initialising storage or updating meta data of Trajectory `results-2021-07-07-16H-45M-51S`. MainProcess pypet.storageservice.HDF5StorageService INFO Finished init or meta data update for `results-2021-07-07-16H-45M-51S`. MainProcess pypet.environment.Environment INFO Starting multiprocessing with at most 8 processes running at the same time. MainProcess pypet INFO PROGRESS: Finished 0/16 runs [ ] 0.0% MainProcess pypet INFO PROGRESS: Finished 1/16 runs [= ] 6.2%, remaining: 0:01:22 MainProcess pypet INFO PROGRESS: Finished 2/16 runs [== ] 12.5%, remaining: 0:00:39 MainProcess pypet INFO PROGRESS: Finished 3/16 runs [=== ] 18.8%, remaining: 0:00:24 MainProcess pypet INFO PROGRESS: Finished 4/16 runs [===== ] 25.0%, remaining: 0:00:17 MainProcess pypet INFO PROGRESS: Finished 5/16 runs [====== ] 31.2%, remaining: 0:00:12 MainProcess pypet INFO PROGRESS: Finished 6/16 runs [======= ] 37.5%, remaining: 0:00:09 MainProcess pypet INFO PROGRESS: Finished 7/16 runs [======== ] 43.8%, remaining: 0:00:07 MainProcess pypet INFO PROGRESS: Finished 8/16 runs [========== ] 50.0%, remaining: 0:00:05 MainProcess pypet INFO PROGRESS: Finished 9/16 runs [=========== ] 56.2%, remaining: 0:00:08 MainProcess pypet INFO PROGRESS: Finished 10/16 runs [============ ] 62.5%, remaining: 0:00:06 MainProcess pypet INFO PROGRESS: Finished 11/16 runs [============= ] 68.8%, remaining: 0:00:04 MainProcess pypet INFO PROGRESS: Finished 12/16 runs [=============== ] 75.0%, remaining: 0:00:03 MainProcess pypet INFO PROGRESS: Finished 13/16 runs [================ ] 81.2%, remaining: 0:00:02 MainProcess pypet INFO PROGRESS: Finished 14/16 runs [================= ] 87.5%, remaining: 0:00:01 MainProcess pypet INFO PROGRESS: Finished 15/16 runs [================== ] 93.8%, remaining: 0:00:00 MainProcess pypet INFO PROGRESS: Finished 16/16 runs [====================]100.0% MainProcess pypet.storageservice.HDF5StorageService INFO Initialising storage or updating meta data of Trajectory `results-2021-07-07-16H-45M-51S`. MainProcess pypet.storageservice.HDF5StorageService INFO Finished init or meta data update for `results-2021-07-07-16H-45M-51S`. MainProcess pypet.environment.Environment INFO ************************************************************ FINISHED all runs of trajectory `results-2021-07-07-16H-45M-51S`. ************************************************************ MainProcess pypet.environment.Environment INFO ************************************************************ STARTING FINAL STORING of trajectory `results-2021-07-07-16H-45M-51S` ************************************************************ MainProcess pypet.storageservice.HDF5StorageService INFO Start storing Trajectory `results-2021-07-07-16H-45M-51S`. MainProcess pypet.storageservice.HDF5StorageService INFO Storing branch `config`. MainProcess pypet.storageservice.HDF5StorageService INFO Storing branch `parameters`. MainProcess pypet.storageservice.HDF5StorageService INFO Storing branch `results`. MainProcess pypet.storageservice.HDF5StorageService INFO Storing branch `derived_parameters`. MainProcess pypet.storageservice.HDF5StorageService INFO Finished storing Trajectory `results-2021-07-07-16H-45M-51S`. MainProcess pypet.environment.Environment INFO ************************************************************ FINISHED FINAL STORING of trajectory `results-2021-07-07-16H-45M-51S`. ************************************************************ MainProcess pypet.environment.Environment INFO All runs of trajectory `results-2021-07-07-16H-45M-51S` were completed successfully. MainProcess pypet.storageservice.HDF5StorageService INFO Start storing Trajectory `results-2021-07-07-16H-45M-51S`. MainProcess pypet.storageservice.HDF5StorageService INFO Storing branch `config`. MainProcess pypet.storageservice.HDF5StorageService INFO Storing branch `parameters`. MainProcess pypet.storageservice.HDF5StorageService INFO Storing branch `results`. MainProcess pypet.storageservice.HDF5StorageService INFO Storing branch `derived_parameters`. MainProcess pypet.storageservice.HDF5StorageService INFO Finished storing Trajectory `results-2021-07-07-16H-45M-51S`. MainProcess root INFO Start of evolution MainProcess root INFO Replacing 0 invalid individuals. MainProcess pypet.environment.Environment INFO I am preparing the Trajectory for the experiment and initialise the store. MainProcess pypet.environment.Environment INFO Initialising the storage for the trajectory. MainProcess pypet.storageservice.HDF5StorageService INFO Initialising storage or updating meta data of Trajectory `results-2021-07-07-16H-45M-51S`. MainProcess pypet.storageservice.HDF5StorageService INFO Finished init or meta data update for `results-2021-07-07-16H-45M-51S`. MainProcess pypet.environment.Environment INFO ************************************************************ STARTING runs of trajectory `results-2021-07-07-16H-45M-51S`. ************************************************************ MainProcess pypet.storageservice.HDF5StorageService INFO Initialising storage or updating meta data of Trajectory `results-2021-07-07-16H-45M-51S`. MainProcess pypet.storageservice.HDF5StorageService INFO Finished init or meta data update for `results-2021-07-07-16H-45M-51S`. MainProcess pypet.environment.Environment INFO Starting multiprocessing with at most 8 processes running at the same time. MainProcess pypet INFO PROGRESS: Finished 16/32 runs [========== ] 50.0% MainProcess pypet INFO PROGRESS: Finished 18/32 runs [=========== ] 56.2%, remaining: 0:00:33 MainProcess pypet INFO PROGRESS: Finished 20/32 runs [============ ] 62.5%, remaining: 0:00:15 MainProcess pypet INFO PROGRESS: Finished 21/32 runs [============= ] 65.6%, remaining: 0:00:11 MainProcess pypet INFO PROGRESS: Finished 23/32 runs [============== ] 71.9%, remaining: 0:00:06 MainProcess pypet INFO PROGRESS: Finished 24/32 runs [=============== ] 75.0%, remaining: 0:00:05 MainProcess pypet INFO PROGRESS: Finished 26/32 runs [================ ] 81.2%, remaining: 0:00:05 MainProcess pypet INFO PROGRESS: Finished 28/32 runs [================= ] 87.5%, remaining: 0:00:03 MainProcess pypet INFO PROGRESS: Finished 29/32 runs [================== ] 90.6%, remaining: 0:00:02 MainProcess pypet INFO PROGRESS: Finished 31/32 runs [=================== ] 96.9%, remaining: 0:00:00 MainProcess pypet INFO PROGRESS: Finished 32/32 runs [====================]100.0% MainProcess pypet.storageservice.HDF5StorageService INFO Initialising storage or updating meta data of Trajectory `results-2021-07-07-16H-45M-51S`. MainProcess pypet.storageservice.HDF5StorageService INFO Finished init or meta data update for `results-2021-07-07-16H-45M-51S`. MainProcess pypet.environment.Environment INFO ************************************************************ FINISHED all runs of trajectory `results-2021-07-07-16H-45M-51S`. ************************************************************ MainProcess pypet.environment.Environment INFO ************************************************************ STARTING FINAL STORING of trajectory `results-2021-07-07-16H-45M-51S` ************************************************************ MainProcess pypet.storageservice.HDF5StorageService INFO Start storing Trajectory `results-2021-07-07-16H-45M-51S`. MainProcess pypet.storageservice.HDF5StorageService INFO Storing branch `config`. MainProcess pypet.storageservice.HDF5StorageService INFO Storing branch `parameters`. MainProcess pypet.storageservice.HDF5StorageService INFO Storing branch `results`. MainProcess pypet.storageservice.HDF5StorageService INFO Storing branch `derived_parameters`. MainProcess pypet.storageservice.HDF5StorageService INFO Finished storing Trajectory `results-2021-07-07-16H-45M-51S`. MainProcess pypet.environment.Environment INFO ************************************************************ FINISHED FINAL STORING of trajectory `results-2021-07-07-16H-45M-51S`. ************************************************************ MainProcess pypet.environment.Environment INFO All runs of trajectory `results-2021-07-07-16H-45M-51S` were completed successfully. MainProcess pypet.storageservice.HDF5StorageService INFO Start storing Trajectory `results-2021-07-07-16H-45M-51S`. MainProcess pypet.storageservice.HDF5StorageService INFO Storing branch `config`. MainProcess pypet.storageservice.HDF5StorageService INFO Storing branch `parameters`. MainProcess pypet.storageservice.HDF5StorageService INFO Storing branch `results`. MainProcess pypet.storageservice.HDF5StorageService INFO Storing branch `derived_parameters`. MainProcess pypet.storageservice.HDF5StorageService INFO Finished storing Trajectory `results-2021-07-07-16H-45M-51S`. MainProcess root INFO ----------- Generation 1 ----------- MainProcess root INFO Best individual is [1.2026081698319384, 0.7330736886493492, 1.3333333333333333, 1.3333333333333333] MainProcess root INFO Score: -5.0 MainProcess root INFO Fitness: (5.0,) MainProcess root INFO --- Population statistics --- MainProcess root INFO Replacing 0 invalid individuals. MainProcess pypet.environment.Environment INFO I am preparing the Trajectory for the experiment and initialise the store. MainProcess pypet.environment.Environment INFO Initialising the storage for the trajectory. MainProcess pypet.storageservice.HDF5StorageService INFO Initialising storage or updating meta data of Trajectory `results-2021-07-07-16H-45M-51S`. MainProcess pypet.storageservice.HDF5StorageService INFO Finished init or meta data update for `results-2021-07-07-16H-45M-51S`. MainProcess pypet.environment.Environment INFO ************************************************************ STARTING runs of trajectory `results-2021-07-07-16H-45M-51S`. ************************************************************ MainProcess pypet.storageservice.HDF5StorageService INFO Initialising storage or updating meta data of Trajectory `results-2021-07-07-16H-45M-51S`. MainProcess pypet.storageservice.HDF5StorageService INFO Finished init or meta data update for `results-2021-07-07-16H-45M-51S`. MainProcess pypet.environment.Environment INFO Starting multiprocessing with at most 8 processes running at the same time. MainProcess pypet INFO PROGRESS: Finished 32/48 runs [============= ] 66.7% MainProcess pypet INFO PROGRESS: Finished 34/48 runs [============== ] 70.8%, remaining: 0:00:33 MainProcess pypet INFO PROGRESS: Finished 36/48 runs [=============== ] 75.0%, remaining: 0:00:14 MainProcess pypet INFO PROGRESS: Finished 39/48 runs [================ ] 81.2%, remaining: 0:00:06 MainProcess pypet INFO PROGRESS: Finished 41/48 runs [================= ] 85.4%, remaining: 0:00:07 MainProcess pypet INFO PROGRESS: Finished 44/48 runs [================== ] 91.7%, remaining: 0:00:03 MainProcess pypet INFO PROGRESS: Finished 46/48 runs [=================== ] 95.8%, remaining: 0:00:01 MainProcess pypet INFO PROGRESS: Finished 48/48 runs [====================]100.0% MainProcess pypet.storageservice.HDF5StorageService INFO Initialising storage or updating meta data of Trajectory `results-2021-07-07-16H-45M-51S`. MainProcess pypet.storageservice.HDF5StorageService INFO Finished init or meta data update for `results-2021-07-07-16H-45M-51S`. MainProcess pypet.environment.Environment INFO ************************************************************ FINISHED all runs of trajectory `results-2021-07-07-16H-45M-51S`. ************************************************************ MainProcess pypet.environment.Environment INFO ************************************************************ STARTING FINAL STORING of trajectory `results-2021-07-07-16H-45M-51S` ************************************************************ MainProcess pypet.storageservice.HDF5StorageService INFO Start storing Trajectory `results-2021-07-07-16H-45M-51S`. MainProcess pypet.storageservice.HDF5StorageService INFO Storing branch `config`. MainProcess pypet.storageservice.HDF5StorageService INFO Storing branch `parameters`. MainProcess pypet.storageservice.HDF5StorageService INFO Storing branch `results`. MainProcess pypet.storageservice.HDF5StorageService INFO Storing branch `derived_parameters`. MainProcess pypet.storageservice.HDF5StorageService INFO Finished storing Trajectory `results-2021-07-07-16H-45M-51S`. MainProcess pypet.environment.Environment INFO ************************************************************ FINISHED FINAL STORING of trajectory `results-2021-07-07-16H-45M-51S`. ************************************************************ MainProcess pypet.environment.Environment INFO All runs of trajectory `results-2021-07-07-16H-45M-51S` were completed successfully. MainProcess pypet.storageservice.HDF5StorageService INFO Start storing Trajectory `results-2021-07-07-16H-45M-51S`. MainProcess pypet.storageservice.HDF5StorageService INFO Storing branch `config`. MainProcess pypet.storageservice.HDF5StorageService INFO Storing branch `parameters`. MainProcess pypet.storageservice.HDF5StorageService INFO Storing branch `results`. MainProcess pypet.storageservice.HDF5StorageService INFO Storing branch `derived_parameters`. MainProcess pypet.storageservice.HDF5StorageService INFO Finished storing Trajectory `results-2021-07-07-16H-45M-51S`. MainProcess root INFO ----------- Generation 2 ----------- MainProcess root INFO Best individual is [1.2026081698319384, 0.7330736886493492, 1.3333333333333333, 1.3333333333333333] MainProcess root INFO Score: -5.0 MainProcess root INFO Fitness: (5.0,) MainProcess root INFO --- Population statistics --- MainProcess root INFO Replacing 0 invalid individuals. MainProcess pypet.environment.Environment INFO I am preparing the Trajectory for the experiment and initialise the store. MainProcess pypet.environment.Environment INFO Initialising the storage for the trajectory. MainProcess pypet.storageservice.HDF5StorageService INFO Initialising storage or updating meta data of Trajectory `results-2021-07-07-16H-45M-51S`. MainProcess pypet.storageservice.HDF5StorageService INFO Finished init or meta data update for `results-2021-07-07-16H-45M-51S`. MainProcess pypet.environment.Environment INFO ************************************************************ STARTING runs of trajectory `results-2021-07-07-16H-45M-51S`. ************************************************************ MainProcess pypet.storageservice.HDF5StorageService INFO Initialising storage or updating meta data of Trajectory `results-2021-07-07-16H-45M-51S`. MainProcess pypet.storageservice.HDF5StorageService INFO Finished init or meta data update for `results-2021-07-07-16H-45M-51S`. MainProcess pypet.environment.Environment INFO Starting multiprocessing with at most 8 processes running at the same time. MainProcess pypet INFO PROGRESS: Finished 48/64 runs [=============== ] 75.0% MainProcess pypet INFO PROGRESS: Finished 52/64 runs [================ ] 81.2%, remaining: 0:00:14 MainProcess pypet INFO PROGRESS: Finished 55/64 runs [================= ] 85.9%, remaining: 0:00:06 MainProcess pypet INFO PROGRESS: Finished 58/64 runs [================== ] 90.6%, remaining: 0:00:05 MainProcess pypet INFO PROGRESS: Finished 61/64 runs [=================== ] 95.3%, remaining: 0:00:02 MainProcess pypet INFO PROGRESS: Finished 64/64 runs [====================]100.0% MainProcess pypet.storageservice.HDF5StorageService INFO Initialising storage or updating meta data of Trajectory `results-2021-07-07-16H-45M-51S`. MainProcess pypet.storageservice.HDF5StorageService INFO Finished init or meta data update for `results-2021-07-07-16H-45M-51S`. MainProcess pypet.environment.Environment INFO ************************************************************ FINISHED all runs of trajectory `results-2021-07-07-16H-45M-51S`. ************************************************************ MainProcess pypet.environment.Environment INFO ************************************************************ STARTING FINAL STORING of trajectory `results-2021-07-07-16H-45M-51S` ************************************************************ MainProcess pypet.storageservice.HDF5StorageService INFO Start storing Trajectory `results-2021-07-07-16H-45M-51S`. MainProcess pypet.storageservice.HDF5StorageService INFO Storing branch `config`. MainProcess pypet.storageservice.HDF5StorageService INFO Storing branch `parameters`. MainProcess pypet.storageservice.HDF5StorageService INFO Storing branch `results`. MainProcess pypet.storageservice.HDF5StorageService INFO Storing branch `derived_parameters`. MainProcess pypet.storageservice.HDF5StorageService INFO Finished storing Trajectory `results-2021-07-07-16H-45M-51S`. MainProcess pypet.environment.Environment INFO ************************************************************ FINISHED FINAL STORING of trajectory `results-2021-07-07-16H-45M-51S`. ************************************************************ MainProcess pypet.environment.Environment INFO All runs of trajectory `results-2021-07-07-16H-45M-51S` were completed successfully. MainProcess pypet.storageservice.HDF5StorageService INFO Start storing Trajectory `results-2021-07-07-16H-45M-51S`. MainProcess pypet.storageservice.HDF5StorageService INFO Storing branch `config`. MainProcess pypet.storageservice.HDF5StorageService INFO Storing branch `parameters`. MainProcess pypet.storageservice.HDF5StorageService INFO Storing branch `results`. MainProcess pypet.storageservice.HDF5StorageService INFO Storing branch `derived_parameters`. MainProcess pypet.storageservice.HDF5StorageService INFO Finished storing Trajectory `results-2021-07-07-16H-45M-51S`. MainProcess root INFO ----------- Generation 3 ----------- MainProcess root INFO Best individual is [1.3018429030776317, 0.4613335264234024, 1.2708417799029919, 0.3261423030366109] MainProcess root INFO Score: -2.0 MainProcess root INFO Fitness: (2.0,) MainProcess root INFO --- Population statistics --- MainProcess root INFO Replacing 0 invalid individuals. MainProcess pypet.environment.Environment INFO I am preparing the Trajectory for the experiment and initialise the store. MainProcess pypet.environment.Environment INFO Initialising the storage for the trajectory. MainProcess pypet.storageservice.HDF5StorageService INFO Initialising storage or updating meta data of Trajectory `results-2021-07-07-16H-45M-51S`. MainProcess pypet.storageservice.HDF5StorageService INFO Finished init or meta data update for `results-2021-07-07-16H-45M-51S`. MainProcess pypet.environment.Environment INFO ************************************************************ STARTING runs of trajectory `results-2021-07-07-16H-45M-51S`. ************************************************************ MainProcess pypet.storageservice.HDF5StorageService INFO Initialising storage or updating meta data of Trajectory `results-2021-07-07-16H-45M-51S`. MainProcess pypet.storageservice.HDF5StorageService INFO Finished init or meta data update for `results-2021-07-07-16H-45M-51S`. MainProcess pypet.environment.Environment INFO Starting multiprocessing with at most 8 processes running at the same time. MainProcess pypet INFO PROGRESS: Finished 64/80 runs [================ ] 80.0% MainProcess pypet INFO PROGRESS: Finished 68/80 runs [================= ] 85.0%, remaining: 0:00:14 MainProcess pypet INFO PROGRESS: Finished 72/80 runs [================== ] 90.0%, remaining: 0:00:05 MainProcess pypet INFO PROGRESS: Finished 76/80 runs [=================== ] 95.0%, remaining: 0:00:03 MainProcess pypet INFO PROGRESS: Finished 80/80 runs [====================]100.0% MainProcess pypet.storageservice.HDF5StorageService INFO Initialising storage or updating meta data of Trajectory `results-2021-07-07-16H-45M-51S`. MainProcess pypet.storageservice.HDF5StorageService INFO Finished init or meta data update for `results-2021-07-07-16H-45M-51S`. MainProcess pypet.environment.Environment INFO ************************************************************ FINISHED all runs of trajectory `results-2021-07-07-16H-45M-51S`. ************************************************************ MainProcess pypet.environment.Environment INFO ************************************************************ STARTING FINAL STORING of trajectory `results-2021-07-07-16H-45M-51S` ************************************************************ MainProcess pypet.storageservice.HDF5StorageService INFO Start storing Trajectory `results-2021-07-07-16H-45M-51S`. MainProcess pypet.storageservice.HDF5StorageService INFO Storing branch `config`. MainProcess pypet.storageservice.HDF5StorageService INFO Storing branch `parameters`. MainProcess pypet.storageservice.HDF5StorageService INFO Storing branch `results`. MainProcess pypet.storageservice.HDF5StorageService INFO Storing branch `derived_parameters`. MainProcess pypet.storageservice.HDF5StorageService INFO Finished storing Trajectory `results-2021-07-07-16H-45M-51S`. MainProcess pypet.environment.Environment INFO ************************************************************ FINISHED FINAL STORING of trajectory `results-2021-07-07-16H-45M-51S`. ************************************************************ MainProcess pypet.environment.Environment INFO All runs of trajectory `results-2021-07-07-16H-45M-51S` were completed successfully. MainProcess pypet.storageservice.HDF5StorageService INFO Start storing Trajectory `results-2021-07-07-16H-45M-51S`. MainProcess pypet.storageservice.HDF5StorageService INFO Storing branch `config`. MainProcess pypet.storageservice.HDF5StorageService INFO Storing branch `parameters`. MainProcess pypet.storageservice.HDF5StorageService INFO Storing branch `results`. MainProcess pypet.storageservice.HDF5StorageService INFO Storing branch `derived_parameters`. MainProcess pypet.storageservice.HDF5StorageService INFO Finished storing Trajectory `results-2021-07-07-16H-45M-51S`. MainProcess root INFO ----------- Generation 4 ----------- MainProcess root INFO Best individual is [1.3018429030776317, 0.4613335264234024, 1.2708417799029919, 0.3261423030366109] MainProcess root INFO Score: -2.0 MainProcess root INFO Fitness: (2.0,) MainProcess root INFO --- Population statistics --- MainProcess root INFO Replacing 0 invalid individuals. MainProcess pypet.environment.Environment INFO I am preparing the Trajectory for the experiment and initialise the store. MainProcess pypet.environment.Environment INFO Initialising the storage for the trajectory. MainProcess pypet.storageservice.HDF5StorageService INFO Initialising storage or updating meta data of Trajectory `results-2021-07-07-16H-45M-51S`. MainProcess pypet.storageservice.HDF5StorageService INFO Finished init or meta data update for `results-2021-07-07-16H-45M-51S`. MainProcess pypet.environment.Environment INFO ************************************************************ STARTING runs of trajectory `results-2021-07-07-16H-45M-51S`. ************************************************************ MainProcess pypet.storageservice.HDF5StorageService INFO Initialising storage or updating meta data of Trajectory `results-2021-07-07-16H-45M-51S`. MainProcess pypet.storageservice.HDF5StorageService INFO Finished init or meta data update for `results-2021-07-07-16H-45M-51S`. MainProcess pypet.environment.Environment INFO Starting multiprocessing with at most 8 processes running at the same time. MainProcess pypet INFO PROGRESS: Finished 80/96 runs [================ ] 83.3% MainProcess pypet INFO PROGRESS: Finished 82/96 runs [================= ] 85.4%, remaining: 0:00:33 MainProcess pypet INFO PROGRESS: Finished 87/96 runs [================== ] 90.6%, remaining: 0:00:06 MainProcess pypet INFO PROGRESS: Finished 92/96 runs [=================== ] 95.8%, remaining: 0:00:03 MainProcess pypet INFO PROGRESS: Finished 96/96 runs [====================]100.0% MainProcess pypet.storageservice.HDF5StorageService INFO Initialising storage or updating meta data of Trajectory `results-2021-07-07-16H-45M-51S`. MainProcess pypet.storageservice.HDF5StorageService INFO Finished init or meta data update for `results-2021-07-07-16H-45M-51S`. MainProcess pypet.environment.Environment INFO ************************************************************ FINISHED all runs of trajectory `results-2021-07-07-16H-45M-51S`. ************************************************************ MainProcess pypet.environment.Environment INFO ************************************************************ STARTING FINAL STORING of trajectory `results-2021-07-07-16H-45M-51S` ************************************************************ MainProcess pypet.storageservice.HDF5StorageService INFO Start storing Trajectory `results-2021-07-07-16H-45M-51S`. MainProcess pypet.storageservice.HDF5StorageService INFO Storing branch `config`. MainProcess pypet.storageservice.HDF5StorageService INFO Storing branch `parameters`. MainProcess pypet.storageservice.HDF5StorageService INFO Storing branch `results`. MainProcess pypet.storageservice.HDF5StorageService INFO Storing branch `derived_parameters`. MainProcess pypet.storageservice.HDF5StorageService INFO Finished storing Trajectory `results-2021-07-07-16H-45M-51S`. MainProcess pypet.environment.Environment INFO ************************************************************ FINISHED FINAL STORING of trajectory `results-2021-07-07-16H-45M-51S`. ************************************************************ MainProcess pypet.environment.Environment INFO All runs of trajectory `results-2021-07-07-16H-45M-51S` were completed successfully. MainProcess pypet.storageservice.HDF5StorageService INFO Start storing Trajectory `results-2021-07-07-16H-45M-51S`. MainProcess pypet.storageservice.HDF5StorageService INFO Storing branch `config`. MainProcess pypet.storageservice.HDF5StorageService INFO Storing branch `parameters`. MainProcess pypet.storageservice.HDF5StorageService INFO Storing branch `results`. MainProcess pypet.storageservice.HDF5StorageService INFO Storing branch `derived_parameters`. MainProcess pypet.storageservice.HDF5StorageService INFO Finished storing Trajectory `results-2021-07-07-16H-45M-51S`. MainProcess root INFO ----------- Generation 5 ----------- MainProcess root INFO Best individual is [1.3018429030776317, 0.4613335264234024, 1.2708417799029919, 0.3261423030366109] MainProcess root INFO Score: -2.0 MainProcess root INFO Fitness: (2.0,) MainProcess root INFO --- Population statistics --- MainProcess root INFO Replacing 0 invalid individuals. MainProcess pypet.environment.Environment INFO I am preparing the Trajectory for the experiment and initialise the store. MainProcess pypet.environment.Environment INFO Initialising the storage for the trajectory. MainProcess pypet.storageservice.HDF5StorageService INFO Initialising storage or updating meta data of Trajectory `results-2021-07-07-16H-45M-51S`. MainProcess pypet.storageservice.HDF5StorageService INFO Finished init or meta data update for `results-2021-07-07-16H-45M-51S`. MainProcess pypet.environment.Environment INFO ************************************************************ STARTING runs of trajectory `results-2021-07-07-16H-45M-51S`. ************************************************************ MainProcess pypet.storageservice.HDF5StorageService INFO Initialising storage or updating meta data of Trajectory `results-2021-07-07-16H-45M-51S`. MainProcess pypet.storageservice.HDF5StorageService INFO Finished init or meta data update for `results-2021-07-07-16H-45M-51S`. MainProcess pypet.environment.Environment INFO Starting multiprocessing with at most 8 processes running at the same time. MainProcess pypet INFO PROGRESS: Finished 96/112 runs [================= ] 85.7% MainProcess pypet INFO PROGRESS: Finished 101/112 runs [================== ] 90.2%, remaining: 0:00:10 MainProcess pypet INFO PROGRESS: Finished 107/112 runs [=================== ] 95.5%, remaining: 0:00:04 MainProcess pypet INFO PROGRESS: Finished 112/112 runs [====================]100.0% MainProcess pypet.storageservice.HDF5StorageService INFO Initialising storage or updating meta data of Trajectory `results-2021-07-07-16H-45M-51S`. MainProcess pypet.storageservice.HDF5StorageService INFO Finished init or meta data update for `results-2021-07-07-16H-45M-51S`. MainProcess pypet.environment.Environment INFO ************************************************************ FINISHED all runs of trajectory `results-2021-07-07-16H-45M-51S`. ************************************************************ MainProcess pypet.environment.Environment INFO ************************************************************ STARTING FINAL STORING of trajectory `results-2021-07-07-16H-45M-51S` ************************************************************ MainProcess pypet.storageservice.HDF5StorageService INFO Start storing Trajectory `results-2021-07-07-16H-45M-51S`. MainProcess pypet.storageservice.HDF5StorageService INFO Storing branch `config`. MainProcess pypet.storageservice.HDF5StorageService INFO Storing branch `parameters`. MainProcess pypet.storageservice.HDF5StorageService INFO Storing branch `results`. MainProcess pypet.storageservice.HDF5StorageService INFO Storing branch `derived_parameters`. MainProcess pypet.storageservice.HDF5StorageService INFO Finished storing Trajectory `results-2021-07-07-16H-45M-51S`. MainProcess pypet.environment.Environment INFO ************************************************************ FINISHED FINAL STORING of trajectory `results-2021-07-07-16H-45M-51S`. ************************************************************ MainProcess pypet.environment.Environment INFO All runs of trajectory `results-2021-07-07-16H-45M-51S` were completed successfully. MainProcess pypet.storageservice.HDF5StorageService INFO Start storing Trajectory `results-2021-07-07-16H-45M-51S`. MainProcess pypet.storageservice.HDF5StorageService INFO Storing branch `config`. MainProcess pypet.storageservice.HDF5StorageService INFO Storing branch `parameters`. MainProcess pypet.storageservice.HDF5StorageService INFO Storing branch `results`. MainProcess pypet.storageservice.HDF5StorageService INFO Storing branch `derived_parameters`. MainProcess pypet.storageservice.HDF5StorageService INFO Finished storing Trajectory `results-2021-07-07-16H-45M-51S`. MainProcess root INFO ----------- Generation 6 ----------- MainProcess root INFO Best individual is [1.3018429030776317, 0.4613335264234024, 1.2708417799029919, 0.3261423030366109] MainProcess root INFO Score: -2.0 MainProcess root INFO Fitness: (2.0,) MainProcess root INFO --- Population statistics --- MainProcess root INFO Replacing 0 invalid individuals. MainProcess pypet.environment.Environment INFO I am preparing the Trajectory for the experiment and initialise the store. MainProcess pypet.environment.Environment INFO Initialising the storage for the trajectory. MainProcess pypet.storageservice.HDF5StorageService INFO Initialising storage or updating meta data of Trajectory `results-2021-07-07-16H-45M-51S`. MainProcess pypet.storageservice.HDF5StorageService INFO Finished init or meta data update for `results-2021-07-07-16H-45M-51S`. MainProcess pypet.environment.Environment INFO ************************************************************ STARTING runs of trajectory `results-2021-07-07-16H-45M-51S`. ************************************************************ MainProcess pypet.storageservice.HDF5StorageService INFO Initialising storage or updating meta data of Trajectory `results-2021-07-07-16H-45M-51S`. MainProcess pypet.storageservice.HDF5StorageService INFO Finished init or meta data update for `results-2021-07-07-16H-45M-51S`. MainProcess pypet.environment.Environment INFO Starting multiprocessing with at most 8 processes running at the same time. MainProcess pypet INFO PROGRESS: Finished 112/128 runs [================= ] 87.5% MainProcess pypet INFO PROGRESS: Finished 116/128 runs [================== ] 90.6%, remaining: 0:00:14 MainProcess pypet INFO PROGRESS: Finished 122/128 runs [=================== ] 95.3%, remaining: 0:00:05 MainProcess pypet INFO PROGRESS: Finished 128/128 runs [====================]100.0% MainProcess pypet.storageservice.HDF5StorageService INFO Initialising storage or updating meta data of Trajectory `results-2021-07-07-16H-45M-51S`. MainProcess pypet.storageservice.HDF5StorageService INFO Finished init or meta data update for `results-2021-07-07-16H-45M-51S`. MainProcess pypet.environment.Environment INFO ************************************************************ FINISHED all runs of trajectory `results-2021-07-07-16H-45M-51S`. ************************************************************ MainProcess pypet.environment.Environment INFO ************************************************************ STARTING FINAL STORING of trajectory `results-2021-07-07-16H-45M-51S` ************************************************************ MainProcess pypet.storageservice.HDF5StorageService INFO Start storing Trajectory `results-2021-07-07-16H-45M-51S`. MainProcess pypet.storageservice.HDF5StorageService INFO Storing branch `config`. MainProcess pypet.storageservice.HDF5StorageService INFO Storing branch `parameters`. MainProcess pypet.storageservice.HDF5StorageService INFO Storing branch `results`. MainProcess pypet.storageservice.HDF5StorageService INFO Storing branch `derived_parameters`. MainProcess pypet.storageservice.HDF5StorageService INFO Finished storing Trajectory `results-2021-07-07-16H-45M-51S`. MainProcess pypet.environment.Environment INFO ************************************************************ FINISHED FINAL STORING of trajectory `results-2021-07-07-16H-45M-51S`. ************************************************************ MainProcess pypet.environment.Environment INFO All runs of trajectory `results-2021-07-07-16H-45M-51S` were completed successfully. MainProcess pypet.storageservice.HDF5StorageService INFO Start storing Trajectory `results-2021-07-07-16H-45M-51S`. MainProcess pypet.storageservice.HDF5StorageService INFO Storing branch `config`. MainProcess pypet.storageservice.HDF5StorageService INFO Storing branch `parameters`. MainProcess pypet.storageservice.HDF5StorageService INFO Storing branch `results`. MainProcess pypet.storageservice.HDF5StorageService INFO Storing branch `derived_parameters`. MainProcess pypet.storageservice.HDF5StorageService INFO Finished storing Trajectory `results-2021-07-07-16H-45M-51S`. MainProcess root INFO ----------- Generation 7 ----------- MainProcess root INFO Best individual is [0.8975385309150987, 0.11079193956336597, 0.23750510019720242, 0.2003002444648563] MainProcess root INFO Score: -1.0 MainProcess root INFO Fitness: (1.0,) MainProcess root INFO --- Population statistics --- MainProcess root INFO Replacing 0 invalid individuals. MainProcess pypet.environment.Environment INFO I am preparing the Trajectory for the experiment and initialise the store. MainProcess pypet.environment.Environment INFO Initialising the storage for the trajectory. MainProcess pypet.storageservice.HDF5StorageService INFO Initialising storage or updating meta data of Trajectory `results-2021-07-07-16H-45M-51S`. MainProcess pypet.storageservice.HDF5StorageService INFO Finished init or meta data update for `results-2021-07-07-16H-45M-51S`. MainProcess pypet.environment.Environment INFO ************************************************************ STARTING runs of trajectory `results-2021-07-07-16H-45M-51S`. ************************************************************ MainProcess pypet.storageservice.HDF5StorageService INFO Initialising storage or updating meta data of Trajectory `results-2021-07-07-16H-45M-51S`. MainProcess pypet.storageservice.HDF5StorageService INFO Finished init or meta data update for `results-2021-07-07-16H-45M-51S`. MainProcess pypet.environment.Environment INFO Starting multiprocessing with at most 8 processes running at the same time. MainProcess pypet INFO PROGRESS: Finished 128/144 runs [================= ] 88.9% MainProcess pypet INFO PROGRESS: Finished 130/144 runs [================== ] 90.3%, remaining: 0:00:32 MainProcess pypet INFO PROGRESS: Finished 137/144 runs [=================== ] 95.1%, remaining: 0:00:07 MainProcess pypet INFO PROGRESS: Finished 144/144 runs [====================]100.0% MainProcess pypet.storageservice.HDF5StorageService INFO Initialising storage or updating meta data of Trajectory `results-2021-07-07-16H-45M-51S`. MainProcess pypet.storageservice.HDF5StorageService INFO Finished init or meta data update for `results-2021-07-07-16H-45M-51S`. MainProcess pypet.environment.Environment INFO ************************************************************ FINISHED all runs of trajectory `results-2021-07-07-16H-45M-51S`. ************************************************************ MainProcess pypet.environment.Environment INFO ************************************************************ STARTING FINAL STORING of trajectory `results-2021-07-07-16H-45M-51S` ************************************************************ MainProcess pypet.storageservice.HDF5StorageService INFO Start storing Trajectory `results-2021-07-07-16H-45M-51S`. MainProcess pypet.storageservice.HDF5StorageService INFO Storing branch `config`. MainProcess pypet.storageservice.HDF5StorageService INFO Storing branch `parameters`. MainProcess pypet.storageservice.HDF5StorageService INFO Storing branch `results`. MainProcess pypet.storageservice.HDF5StorageService INFO Storing branch `derived_parameters`. MainProcess pypet.storageservice.HDF5StorageService INFO Finished storing Trajectory `results-2021-07-07-16H-45M-51S`. MainProcess pypet.environment.Environment INFO ************************************************************ FINISHED FINAL STORING of trajectory `results-2021-07-07-16H-45M-51S`. ************************************************************ MainProcess pypet.environment.Environment INFO All runs of trajectory `results-2021-07-07-16H-45M-51S` were completed successfully. MainProcess pypet.storageservice.HDF5StorageService INFO Start storing Trajectory `results-2021-07-07-16H-45M-51S`. MainProcess pypet.storageservice.HDF5StorageService INFO Storing branch `config`. MainProcess pypet.storageservice.HDF5StorageService INFO Storing branch `parameters`. MainProcess pypet.storageservice.HDF5StorageService INFO Storing branch `results`. MainProcess pypet.storageservice.HDF5StorageService INFO Storing branch `derived_parameters`. MainProcess pypet.storageservice.HDF5StorageService INFO Finished storing Trajectory `results-2021-07-07-16H-45M-51S`. MainProcess root INFO ----------- Generation 8 ----------- MainProcess root INFO Best individual is [1.2018893263483494, 0.26004390251897785, 0.24989089918822285, 0.08052584592439692] MainProcess root INFO Score: 0.0 MainProcess root INFO Fitness: (0.0,) MainProcess root INFO --- Population statistics --- MainProcess root INFO Replacing 0 invalid individuals. MainProcess pypet.environment.Environment INFO I am preparing the Trajectory for the experiment and initialise the store. MainProcess pypet.environment.Environment INFO Initialising the storage for the trajectory. MainProcess pypet.storageservice.HDF5StorageService INFO Initialising storage or updating meta data of Trajectory `results-2021-07-07-16H-45M-51S`. MainProcess pypet.storageservice.HDF5StorageService INFO Finished init or meta data update for `results-2021-07-07-16H-45M-51S`. MainProcess pypet.environment.Environment INFO ************************************************************ STARTING runs of trajectory `results-2021-07-07-16H-45M-51S`. ************************************************************ MainProcess pypet.storageservice.HDF5StorageService INFO Initialising storage or updating meta data of Trajectory `results-2021-07-07-16H-45M-51S`. MainProcess pypet.storageservice.HDF5StorageService INFO Finished init or meta data update for `results-2021-07-07-16H-45M-51S`. MainProcess pypet.environment.Environment INFO Starting multiprocessing with at most 8 processes running at the same time. MainProcess pypet INFO PROGRESS: Finished 144/160 runs [================== ] 90.0% MainProcess pypet INFO PROGRESS: Finished 152/160 runs [=================== ] 95.0%, remaining: 0:00:05 MainProcess pypet INFO PROGRESS: Finished 160/160 runs [====================]100.0% MainProcess pypet.storageservice.HDF5StorageService INFO Initialising storage or updating meta data of Trajectory `results-2021-07-07-16H-45M-51S`. MainProcess pypet.storageservice.HDF5StorageService INFO Finished init or meta data update for `results-2021-07-07-16H-45M-51S`. MainProcess pypet.environment.Environment INFO ************************************************************ FINISHED all runs of trajectory `results-2021-07-07-16H-45M-51S`. ************************************************************ MainProcess pypet.environment.Environment INFO ************************************************************ STARTING FINAL STORING of trajectory `results-2021-07-07-16H-45M-51S` ************************************************************ MainProcess pypet.storageservice.HDF5StorageService INFO Start storing Trajectory `results-2021-07-07-16H-45M-51S`. MainProcess pypet.storageservice.HDF5StorageService INFO Storing branch `config`. MainProcess pypet.storageservice.HDF5StorageService INFO Storing branch `parameters`. MainProcess pypet.storageservice.HDF5StorageService INFO Storing branch `results`. MainProcess pypet.storageservice.HDF5StorageService INFO Storing branch `derived_parameters`. MainProcess pypet.storageservice.HDF5StorageService INFO Finished storing Trajectory `results-2021-07-07-16H-45M-51S`. MainProcess pypet.environment.Environment INFO ************************************************************ FINISHED FINAL STORING of trajectory `results-2021-07-07-16H-45M-51S`. ************************************************************ MainProcess pypet.environment.Environment INFO All runs of trajectory `results-2021-07-07-16H-45M-51S` were completed successfully. MainProcess pypet.storageservice.HDF5StorageService INFO Start storing Trajectory `results-2021-07-07-16H-45M-51S`. MainProcess pypet.storageservice.HDF5StorageService INFO Storing branch `config`. MainProcess pypet.storageservice.HDF5StorageService INFO Storing branch `parameters`. MainProcess pypet.storageservice.HDF5StorageService INFO Storing branch `results`. MainProcess pypet.storageservice.HDF5StorageService INFO Storing branch `derived_parameters`. MainProcess pypet.storageservice.HDF5StorageService INFO Finished storing Trajectory `results-2021-07-07-16H-45M-51S`. MainProcess root INFO ----------- Generation 9 ----------- MainProcess root INFO Best individual is [1.2018893263483494, 0.26004390251897785, 0.24989089918822285, 0.08052584592439692] MainProcess root INFO Score: 0.0 MainProcess root INFO Fitness: (0.0,) MainProcess root INFO --- Population statistics --- MainProcess root INFO --- End of evolution --- MainProcess root INFO Best individual is [1.2018893263483494, 0.26004390251897785, 0.24989089918822285, 0.08052584592439692], (0.0,) MainProcess root INFO --- End of evolution --- MainProcess pypet.storageservice.HDF5StorageService INFO Start storing Trajectory `results-2021-07-07-16H-45M-51S`. MainProcess pypet.storageservice.HDF5StorageService INFO Storing branch `config`. MainProcess pypet.storageservice.HDF5StorageService INFO Storing branch `parameters`. MainProcess pypet.storageservice.HDF5StorageService INFO Storing branch `results`. MainProcess pypet.storageservice.HDF5StorageService INFO Storing branch `derived_parameters`. MainProcess pypet.storageservice.HDF5StorageService INFO Finished storing Trajectory `results-2021-07-07-16H-45M-51S`. evolution . info ( plot = True ) /Users/nikola/.virtualenvs/neurolib/lib/python3.7/site-packages/neurolib/optimize/evolution/evolutionaryUtils.py:212: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect. plt.tight_layout() > Simulation parameters HDF file storage: ./data/hdf/example-4.2-evolution.hdf Trajectory Name: results-2021-07-07-16H-45M-51S Duration of evaluating initial population 0:00:11.681965 Duration of evolution 0:01:31.868614 Model: <class 'neurolib.models.multimodel.model.MultiModel'> Model name: ALNNode Eval function: <function evaluateSimulation at 0x15b06a830> Parameter space: {'*EXC*noise*mu': [0.0, 4.0], '*INH*noise*mu': [0.0, 4.0]} > Evolution parameters Number of generations: 10 Initial population size: 16 Population size: 16 > Evolutionary operators Mating operator: <function cxBlend at 0x159a43560> Mating paramter: {'alpha': 0.5} Selection operator: <function selBest_multiObj at 0x159a70200> Selection paramter: {} Parent selection operator: <function selRank at 0x159a70170> Comments: no comments --- Info summary --- Valid: 16 Mean score (weighted fitness): -3.6 Parameter distribution (Generation 9): STAREXCSTARnoiseSTARmu: mean: 1.1141, std: 0.2046 STARINHSTARnoiseSTARmu: mean: 0.4791, std: 0.2361 -------------------- Best 5 individuals: Printing 5 individuals Individual 0 Fitness values: 0.0 Score: 0.0 Weighted fitness: -0.0 Stats mean 0.00 std 0.00 min 0.00 max 0.00 model.params[\"STAREXCSTARnoiseSTARmu\"] = 1.20 model.params[\"STARINHSTARnoiseSTARmu\"] = 0.26 Individual 1 Fitness values: 0.0 Score: 0.0 Weighted fitness: -0.0 Stats mean 0.00 std 0.00 min 0.00 max 0.00 model.params[\"STAREXCSTARnoiseSTARmu\"] = 1.01 model.params[\"STARINHSTARnoiseSTARmu\"] = 0.16 Individual 2 Fitness values: 1.0 Score: -1.0 Weighted fitness: -1.0 Stats mean 1.00 std 0.00 min 1.00 max 1.00 model.params[\"STAREXCSTARnoiseSTARmu\"] = 0.90 model.params[\"STARINHSTARnoiseSTARmu\"] = 0.11 Individual 3 Fitness values: 2.0 Score: -2.0 Weighted fitness: -2.0 Stats mean 2.00 std 0.00 min 2.00 max 2.00 model.params[\"STAREXCSTARnoiseSTARmu\"] = 1.30 model.params[\"STARINHSTARnoiseSTARmu\"] = 0.46 Individual 4 Fitness values: 2.0 Score: -2.0 Weighted fitness: -2.0 Stats mean 2.00 std 0.00 min 2.00 max 2.00 model.params[\"STAREXCSTARnoiseSTARmu\"] = 0.96 model.params[\"STARINHSTARnoiseSTARmu\"] = 0.25 -------------------- There are 16 valid individuals Mean score across population: -3.6 MainProcess root INFO Saving plot to ./data/figures/results-2021-07-07-16H-45M-51S_hist_9.png <Figure size 432x288 with 0 Axes>","title":"Evolution with MultiModel"},{"location":"examples/example-4.2-multimodel-backends-and-optimization/#adapting-existing-models-in-multimodel-framework","text":"MultiModel comes with a few implemented models so you can play with models right away. Due to the hierarchical architecture based on class inheritence in python, it is also very easy to adapt existing models. As an example - MultiModel comes with an implementation of Wilson-Cowan model. In our version, there are excitatory and inhibitory masses in one node. Let's say, you want to add an adaptation current inside excitatory mass in Wilson-Cowan model. # imports from jitcdde import input as system_input from neurolib.models.multimodel.builder.base.constants import EXC from neurolib.models.multimodel.builder.wilson_cowan import ( WC_EXC_DEFAULT_PARAMS , WC_NODE_DEFAULT_CONNECTIVITY , ExcitatoryWilsonCowanMass , InhibitoryWilsonCowanMass , WilsonCowanNode , ) Here is just a copy-paste code of ExcitatoryWilsonCowanMass: class ExcitatoryWilsonCowanMass ( WilsonCowanMass ): \"\"\" Excitatory Wilson-Cowan neural mass. \"\"\" name = \"Wilson-Cowan excitatory mass\" label = f \"WCmass { EXC } \" coupling_variables = { 0 : f \"q_mean_ { EXC } \" } state_variable_names = [ f \"q_mean_ { EXC } \" ] mass_type = EXC required_couplings = [ \"node_exc_exc\" , \"node_exc_inh\" , \"network_exc_exc\" ] def __init__ ( self , params = None , seed = None ): super () . __init__ ( params = params or WC_EXC_DEFAULT_PARAMS , seed = seed ) def _derivatives ( self , coupling_variables ): [ x ] = self . _unwrap_state_vector () d_x = ( - x + ( 1.0 - x ) * self . _sigmoid ( coupling_variables [ \"node_exc_exc\" ] - coupling_variables [ \"node_exc_inh\" ] + coupling_variables [ \"network_exc_exc\" ] + self . params [ \"ext_input\" ] ) + system_input ( self . noise_input_idx [ 0 ]) ) / self . params [ \"tau\" ] return [ d_x ] Since everything in MultiModel is a class, we will simply subclass the ExcitatoryWilsonCowanMass and edit / add things we need to. Our adaptation current will come in as: \\( \\(\\dot{w} = -\\frac{w}{\\tau_{A}} + b*r\\) \\) class AdaptationExcitatoryWilsonCowanMass ( ExcitatoryWilsonCowanMass ): # here we only edit attributes that will change! # slightly edit name and label name = \"Wilson-Cowan excitatory mass with adaptation\" label = f \"WCmass { EXC } _adapt\" num_state_variables = 2 # same number of noise variables # coupling variables - the same, no need to do anything # add w as a variable state_variable_names = [ f \"q_mean_ { EXC } \" , \"w\" ] # mass type and couplings are the same # add parameters for adaptation current - b and tauA required_params = [ \"a\" , \"mu\" , \"tau\" , \"ext_drive\" , \"b\" , \"tauA\" ] # same input noise def __init__ ( self , params = None , seed = None ): # edit init and pass default parameters for adaptation super () . __init__ ( params = params or WC_ADAPT_EXC_DEFAULT_PARAMS , seed = seed ) def _initialize_state_vector ( self ): # need to add init for adaptation variable w np . random . seed ( self . seed ) self . initial_state = [ 0.05 * np . random . uniform ( 0 , 1 ), 0.0 ] def _derivatives ( self , coupling_variables ): # edit derivatives [ x , w ] = self . _unwrap_state_vector () d_x = ( - x + ( 1.0 - x ) * self . _sigmoid ( coupling_variables [ \"node_exc_exc\" ] - coupling_variables [ \"node_exc_inh\" ] + coupling_variables [ \"network_exc_exc\" ] + self . params [ \"ext_drive\" ] - w # subtract adaptation current ) + system_input ( self . noise_input_idx [ 0 ]) ) / self . params [ \"tau\" ] # now define adaptation dynamics d_w = - w / self . params [ \"tauA\" ] + self . params [ \"b\" ] * x return [ d_x , d_w ] # define default set of parameters WC_ADAPT_EXC_DEFAULT_PARAMS = { # just copy all default parameters from non-adaptation version ** WC_EXC_DEFAULT_PARAMS , # add adaptation parameters \"tauA\" : 500.0 , # ms \"b\" : 1.0 , } That's it! Now we have our shiny excitatory Wilson-Cowan mass with adaptation. Now, we need to create a Node with one exctitatory WC mass with adaptation and one good old inhibitory mass without adaptation. The basic inhibitory mass is already implemented, no need to do anything. Below we will create our Node with adaptation. class WilsonCowanNodeWithAdaptation ( WilsonCowanNode ): # start by subclassing the basic WilsonCowanNode and, again, # just change what has to be changed name = \"Wilson-Cowan node with adaptation\" label = \"WCnode_adapt\" # default coupling and outputs are the same def __init__ ( self , exc_params = None , inh_params = None , connectivity = WC_NODE_DEFAULT_CONNECTIVITY , ): # here we just pass our new `AdaptationExcitatoryWilsonCowanMass` instead of # `ExcitatoryWilsonCowanMass`, otherwise it is the same excitatory_mass = AdaptationExcitatoryWilsonCowanMass ( exc_params ) excitatory_mass . index = 0 inhibitory_mass = InhibitoryWilsonCowanMass ( inh_params ) inhibitory_mass . index = 1 # the only trick is, we want to call super() and init Node class, BUT # just calling super().__init__() will actually call parent's init, and in # this case, our parent is `WilsonCowanNode`... we need to call grandparent's # __init__.. fortunately, this can be done in python no problemo # instead of calling super().__init__(), we need to call # super(<current parent>, self).__init__() super ( WilsonCowanNode , self ) . __init__ ( neural_masses = [ excitatory_mass , inhibitory_mass ], local_connectivity = connectivity , # within W-C node there are no local delays local_delays = None , ) And done. Now we can run and compare WC node with and without adaptation. wc_basic = MultiModel . init_node ( WilsonCowanNode ()) wc_adapt = MultiModel . init_node ( WilsonCowanNodeWithAdaptation ()) MainProcess root INFO WCnode: Model initialized. MainProcess root INFO WCnode_adapt: Model initialized. # set parameters wc_basic . params [ \"*EXC*ext_drive\" ] = 0.8 wc_basic . params [ \"duration\" ] = 2000.0 wc_basic . params [ \"sampling_dt\" ] = 1.0 # higher external input due to adaptation wc_adapt . params [ \"*EXC*ext_drive\" ] = 5.5 wc_adapt . params [ \"duration\" ] = 2000.0 wc_adapt . params [ \"sampling_dt\" ] = 1.0 wc_adapt . params [ \"*b\" ] = 0.1 wc_basic . run () wc_adapt . run () MainProcess root INFO Initialising jitcdde backend... MainProcess root INFO Setting up the DDE system... /Users/nikola/.virtualenvs/neurolib/lib/python3.7/site-packages/jitcdde/_jitcdde.py:1491: UserWarning: Your input past does not begin at t=0 but at t=1.0. Values before the beginning of the past will be extrapolated. You very likely do not want this. warn(f\"Your input past does not begin at t=0 but at t={input[0].time}. Values before the beginning of the past will be extrapolated. You very likely do not want this.\") MainProcess root INFO Compiling to C... MainProcess root INFO Setting past of the state vector... MainProcess root INFO Integrating for 2000 time steps... 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 2000/2000 [00:00<00:00, 153705.07it/s] MainProcess root INFO Integration done. MainProcess root INFO `run` call took 1.24 s MainProcess root INFO Initialising jitcdde backend... MainProcess root INFO Setting up the DDE system... MainProcess root INFO Compiling to C... Using default integration parameters. MainProcess root INFO Setting past of the state vector... MainProcess root INFO Integrating for 2000 time steps... 0%| | 0/2000 [00:00<?, ?it/s]/Users/nikola/.virtualenvs/neurolib/lib/python3.7/site-packages/jitcdde/_jitcdde.py:791: UserWarning: The target time is smaller than the current time. No integration step will happen. The returned state will be extrapolated from the interpolating Hermite polynomial for the last integration step. You may see this because you try to integrate backwards in time, in which case you did something wrong. You may see this just because your sampling step is small, in which case there is no need to worry. warn(\"The target time is smaller than the current time. No integration step will happen. The returned state will be extrapolated from the interpolating Hermite polynomial for the last integration step. You may see this because you try to integrate backwards in time, in which case you did something wrong. You may see this just because your sampling step is small, in which case there is no need to worry.\") 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 2000/2000 [00:00<00:00, 100000.10it/s] MainProcess root INFO Integration done. MainProcess root INFO `run` call took 0.79 s Using default integration parameters. plt . plot ( wc_adapt . t , wc_adapt . q_mean_EXC . T , label = \"with adaptation\" ) plt . plot ( wc_basic . t , wc_basic . q_mean_EXC . T , label = \"vanilla\" ) plt . legend () <matplotlib.legend.Legend at 0x15afa6710> All done. Now we can study adaptation dynamics in Wilson-Cowan model by e.g. running exploration over adaptation parameters and eventually evolution with the target of having slow oscillations (i.e. oscillations with frequency ~1Hz) and optimising with respect to parameters such as b , tauA , ext_input and others. Happy hacking!","title":"Adapting existing models in MultiModel framework"},{"location":"exploration/boxsearch/","text":"BoxSearch Paremeter box search for a given model and a range of parameters. Source code in neurolib/optimize/exploration/exploration.py class BoxSearch : \"\"\" Paremeter box search for a given model and a range of parameters. \"\"\" def __init__ ( self , model = None , parameterSpace = None , evalFunction = None , filename = None , saveAllModelOutputs = False , ncores = None , ): \"\"\"Either a model has to be passed, or an evalFunction. If an evalFunction is passed, then the evalFunction will be called and the model is accessible to the evalFunction via `self.getModelFromTraj(traj)`. The parameters of the current run are accessible via `self.getParametersFromTraj(traj)`. If no evaluation function is passed, then the model is simulated using `Model.run()` for every parameter. :param model: Model to run for each parameter (or model to pass to the evaluation function if an evaluation function is used), defaults to None :type model: `neurolib.models.model.Model`, optional :param parameterSpace: Parameter space to explore, defaults to None :type parameterSpace: `neurolib.utils.parameterSpace.ParameterSpace`, optional :param evalFunction: Evaluation function to call for each run., defaults to None :type evalFunction: function, optional :param filename: HDF5 storage file name, if left empty, defaults to ``exploration.hdf`` :type filename: str :param saveAllModelOutputs: If True, save all outputs of model, else only default output of the model will be saved. Note: if saveAllModelOutputs==False and the model's parameter model.params['bold']==True, then BOLD output will be saved as well, defaults to False :type saveAllModelOutputs: bool :param ncores: Number of cores to simulate on (max cores default), defaults to None :type ncores: int, optional \"\"\" self . model = model if evalFunction is None and model is not None : self . evalFunction = self . _runModel elif evalFunction is not None : self . evalFunction = evalFunction assert ( evalFunction is not None ) or ( model is not None ), \"Either a model has to be specified or an evalFunction.\" assert parameterSpace is not None , \"No parameters to explore.\" if parameterSpace . kind == \"sequence\" : assert model is not None , \"Model must be defined for sequential explore\" self . parameterSpace = parameterSpace self . exploreParameters = parameterSpace . dict () # TODO: use random ICs for every explored point or rather reuse the ones that are generated at model # initialization self . useRandomICs = False filename = filename or \"exploration.hdf\" self . filename = filename self . saveAllModelOutputs = saveAllModelOutputs # number of cores if ncores is None : ncores = multiprocessing . cpu_count () self . ncores = ncores logging . info ( \"Number of processes: {} \" . format ( self . ncores )) # bool to check whether pypet was initialized properly self . initialized = False self . _initializeExploration ( self . filename ) self . results = None def _initializeExploration ( self , filename = \"exploration.hdf\" ): \"\"\"Initialize the pypet environment :param filename: hdf filename to store the results in , defaults to \"exploration.hdf\" :type filename: str, optional \"\"\" # create hdf file path if it does not exist yet pathlib . Path ( paths . HDF_DIR ) . mkdir ( parents = True , exist_ok = True ) # set default hdf filename self . HDF_FILE = os . path . join ( paths . HDF_DIR , filename ) # initialize pypet environment trajectoryName = \"results\" + datetime . datetime . now () . strftime ( \"-%Y-%m- %d -%HH-%MM-%SS\" ) trajectoryfilename = self . HDF_FILE # set up the pypet environment env = pypet . Environment ( trajectory = trajectoryName , filename = trajectoryfilename , multiproc = True , ncores = self . ncores , complevel = 9 , log_config = paths . PYPET_LOGGING_CONFIG , ) self . env = env # Get the trajectory from the environment self . traj = env . trajectory self . trajectoryName = self . traj . v_name # Add all parameters to the pypet trajectory if self . model is not None : # if a model is specified, use the default parameter of the # model to initialize pypet self . _addParametersToPypet ( self . traj , self . model . params ) else : # else, use a random parameter of the parameter space self . _addParametersToPypet ( self . traj , self . parameterSpace . getRandom ( safe = True )) # Tell pypet which parameters to explore self . pypetParametrization = self . parameterSpace . get_parametrization () # explicitely add all parameters within star notation, hence unwrap star notation into actual params names if self . parameterSpace . star : assert self . model is not None , \"With star notation, model cannot be None\" self . pypetParametrization = unwrap_star_dotdict ( self . pypetParametrization , self . model ) self . nRuns = len ( self . pypetParametrization [ list ( self . pypetParametrization . keys ())[ 0 ]]) logging . info ( f \"Number of parameter configurations: { self . nRuns } \" ) if self . parameterSpace . kind == \"sequence\" : # if sequential explore, need to fill-in the default parameters instead of None self . pypetParametrization = self . _fillin_default_parameters_for_sequential ( self . pypetParametrization , self . model . params ) self . traj . f_explore ( self . pypetParametrization ) # initialization done logging . info ( \"BoxSearch: Environment initialized.\" ) self . initialized = True @staticmethod def _fillin_default_parameters_for_sequential ( parametrization , model_params ): fresh_dict = {} for k , params in parametrization . items (): fresh_dict [ k ] = [ v if v is not None else model_params [ k ] for v in params ] return fresh_dict def _addParametersToPypet ( self , traj , params ): \"\"\"This function registers the parameters of the model to Pypet. Parameters can be nested dictionaries. They are unpacked and stored recursively. :param traj: Pypet trajectory to store the parameters in :type traj: `pypet.trajectory.Trajectory` :param params: Parameter dictionary :type params: dict, dict[dict,] \"\"\" def addParametersRecursively ( traj , params , current_level ): # make dummy list if just string if isinstance ( current_level , str ): current_level = [ current_level ] # iterate dict for key , value in params . items (): # if another dict - recurse and increase level if isinstance ( value , dict ): addParametersRecursively ( traj , value , current_level + [ key ]) else : param_address = \".\" . join ( current_level + [ key ]) value = \"None\" if value is None else value traj . f_add_parameter ( param_address , value ) addParametersRecursively ( traj , params , []) def saveToPypet ( self , outputs , traj ): \"\"\"This function takes simulation results in the form of a nested dictionary and stores all data into the pypet hdf file. :param outputs: Simulation outputs as a dictionary. :type outputs: dict :param traj: Pypet trajectory :type traj: `pypet.trajectory.Trajectory` \"\"\" def makeSaveStringForPypet ( value , savestr ): \"\"\"Builds the pypet-style results string from the results dictionary's keys. \"\"\" for k , v in value . items (): if isinstance ( v , dict ): _savestr = savestr + k + \".\" makeSaveStringForPypet ( v , _savestr ) else : _savestr = savestr + k self . traj . f_add_result ( _savestr , v ) assert isinstance ( outputs , dict ), \"Outputs must be an instance of dict.\" value = outputs savestr = \"results.$.\" makeSaveStringForPypet ( value , savestr ) def _runModel ( self , traj ): \"\"\"If not evaluation function is given, we assume that a model will be simulated. This function will be called by pypet directly and therefore wants a pypet trajectory as an argument :param traj: Pypet trajectory :type traj: `pypet.trajectory.Trajectory` \"\"\" if self . useRandomICs : logging . warn ( \"Random initial conditions not implemented yet\" ) # get parameters of this run from pypet trajectory runParams = self . getParametersFromTraj ( traj ) if self . parameterSpace . star : runParams = flatten_nested_dict ( flat_dict_to_nested ( runParams )[ \"parameters\" ]) # set the parameters for the model self . model . params . update ( runParams ) # get kwargs from Exploration.run() runKwargs = {} if hasattr ( self , \"runKwargs\" ): runKwargs = self . runKwargs # run it self . model . run ( ** runKwargs ) # save outputs self . _saveModelOutputsToPypet ( traj ) def _saveModelOutputsToPypet ( self , traj ): # save all data to the pypet trajectory if self . saveAllModelOutputs : # save all results from exploration self . saveToPypet ( self . model . outputs , traj ) else : # save only the default output self . saveToPypet ( { self . model . default_output : self . model . output , \"t\" : self . model . outputs [ \"t\" ], }, traj , ) # save BOLD output # if \"bold\" in self.model.params: # if self.model.params[\"bold\"] and \"BOLD\" in self.model.outputs: # self.saveToPypet(self.model.outputs[\"BOLD\"], traj) if \"BOLD\" in self . model . outputs : self . saveToPypet ( self . model . outputs [ \"BOLD\" ], traj ) def _validatePypetParameters ( self , runParams ): \"\"\"Helper to handle None's in pypet parameters (used for random number generator seed) :param runParams: parameters as returned by traj.parameters.f_to_dict() :type runParams: dict of pypet.parameter.Parameter \"\"\" # fix rng seed, which is saved as a string if None if \"seed\" in runParams : if runParams [ \"seed\" ] == \"None\" : runParams [ \"seed\" ] = None return runParams def getParametersFromTraj ( self , traj ): \"\"\"Returns the parameters of the current run as a (dot.able) dictionary :param traj: Pypet trajectory :type traj: `pypet.trajectory.Trajectory` :return: Parameter set of the current run :rtype: dict \"\"\" # DO NOT use short names for star notation dicts runParams = self . traj . parameters . f_to_dict ( short_names = not self . parameterSpace . star , fast_access = True ) runParams = self . _validatePypetParameters ( runParams ) return dotdict ( runParams ) def getModelFromTraj ( self , traj ): \"\"\"Return the appropriate model with parameters for this run :params traj: Pypet trajectory of current run :returns model: Model with the parameters of this run. \"\"\" model = self . model runParams = self . getParametersFromTraj ( traj ) # removes keys with None values # runParams = {k: v for k, v in runParams.items() if v is not None} if self . parameterSpace . star : runParams = flatten_nested_dict ( flat_dict_to_nested ( runParams )[ \"parameters\" ]) model . params . update ( runParams ) return model def run ( self , ** kwargs ): \"\"\" Call this function to run the exploration \"\"\" self . runKwargs = kwargs assert self . initialized , \"Pypet environment not initialized yet.\" self . _t_start_exploration = datetime . datetime . now () self . env . run ( self . evalFunction ) self . _t_end_exploration = datetime . datetime . now () def loadResults ( self , all = True , filename = None , trajectoryName = None , pypetShortNames = True , memory_cap = 95.0 ): \"\"\"Load results from a hdf file of a previous simulation. :param all: Load all simulated results into memory, which will be available as the `.results` attribute. Can use a lot of RAM if your simulation is large, please use this with caution. , defaults to True :type all: bool, optional :param filename: hdf file name in which results are stored, defaults to None :type filename: str, optional :param trajectoryName: Name of the trajectory inside the hdf file, newest will be used if left empty, defaults to None :type trajectoryName: str, optional :param pypetShortNames: Use pypet short names as keys for the results dictionary. Use if you are experiencing errors due to natural naming collisions. :type pypetShortNames: bool :param memory_cap: Percentage memory cap between 0 and 100. If `all=True` is used, a memory cap can be set to avoid filling up the available RAM. Example: use `memory_cap = 95` to avoid loading more data if memory is at 95% use, defaults to 95 :type memory_cap: float, int, optional \"\"\" self . loadDfResults ( filename , trajectoryName ) # make a list of dictionaries with results self . results = dotdict ({}) if all : logging . info ( \"Loading all results to `results` dictionary ...\" ) for rInd in tqdm . tqdm ( range ( self . nResults ), total = self . nResults ): # check if enough memory is available if memory_cap : assert isinstance ( memory_cap , ( int , float )), \"`memory_cap` must be float.\" assert ( memory_cap > 0 ) and ( memory_cap < 100 ), \"`memory_cap` must be between 0 and 100\" # check ram usage with psutil used_memory_percent = psutil . virtual_memory ()[ 2 ] if used_memory_percent > memory_cap : raise MemoryError ( f \"Memory use is at { used_memory_percent } % and capped at { memory_cap } . Aborting.\" ) self . pypetTrajectory . results [ rInd ] . f_load () result = self . pypetTrajectory . results [ rInd ] . f_to_dict ( fast_access = True , short_names = pypetShortNames ) result = dotdict ( result ) self . pypetTrajectory . results [ rInd ] . f_remove () self . results [ rInd ] = copy . deepcopy ( result ) # Postprocess result keys if pypet short names aren't used # Before: results.run_00000001.outputs.rates_inh # After: outputs.rates_inh if not pypetShortNames : for i , r in self . results . items (): new_dict = dotdict ({}) for key , value in r . items (): new_key = \"\" . join ( key . split ( \".\" , 2 )[ 2 :]) new_dict [ new_key ] = r [ key ] self . results [ i ] = copy . deepcopy ( new_dict ) self . aggregateResultsToDfResults () logging . info ( \"All results loaded.\" ) def aggregateResultsToDfResults ( self , arrays = True , fillna = False ): \"\"\"Aggregate all results in to dfResults dataframe. :param arrays: Load array results (like timeseries) if True. If False, only load scalar results, defaults to True :type arrays: bool, optional :param fillna: Fill nan results (for example if they're not returned in a subset of runs) with zeros, default to False :type fillna: bool, optional \"\"\" nan_value = np . nan # defines which variable types will be saved in the results dataframe SUPPORTED_TYPES = ( float , int , np . ndarray , list ) SCALAR_TYPES = ( float , int ) ARRAY_TYPES = ( np . ndarray , list ) logging . info ( \"Aggregating results to `dfResults` ...\" ) for runId , parameters in tqdm . tqdm ( self . dfResults . iterrows (), total = len ( self . dfResults )): # if the results were previously loaded into memory, use them if hasattr ( self , \"results\" ): # only if the length matches the number of results if len ( self . results ) == len ( self . dfResults ): result = self . results [ runId ] # else, load results individually from hdf file else : result = self . getRun ( runId ) # else, load results individually from hdf file else : result = self . getRun ( runId ) for key , value in result . items (): # only save floats, ints and arrays if isinstance ( value , SUPPORTED_TYPES ): # save 1-dim arrays if isinstance ( value , ARRAY_TYPES ) and arrays : # to save a numpy array, convert column to object type if key not in self . dfResults : self . dfResults [ key ] = None self . dfResults [ key ] = self . dfResults [ key ] . astype ( object ) self . dfResults . at [ runId , key ] = value elif isinstance ( value , SCALAR_TYPES ): # save scalars self . dfResults . loc [ runId , key ] = value else : self . dfResults . loc [ runId , key ] = nan_value # drop nan columns self . dfResults = self . dfResults . dropna ( axis = \"columns\" , how = \"all\" ) if fillna : self . dfResults = self . dfResults . fillna ( 0 ) def loadDfResults ( self , filename = None , trajectoryName = None ): \"\"\"Load results from a previous simulation. :param filename: hdf file name in which results are stored, defaults to None :type filename: str, optional :param trajectoryName: Name of the trajectory inside the hdf file, newest will be used if left empty, defaults to None :type trajectoryName: str, optional \"\"\" # chose HDF file to load filename = filename or self . HDF_FILE self . pypetTrajectory = pu . loadPypetTrajectory ( filename , trajectoryName ) self . nResults = len ( self . pypetTrajectory . f_get_run_names ()) exploredParameters = self . pypetTrajectory . f_get_explored_parameters () # create pandas dataframe of all runs with parameters as keys logging . info ( \"Creating `dfResults` dataframe ...\" ) niceParKeys = [ p [ 11 :] for p in exploredParameters . keys ()] if not self . parameterSpace : niceParKeys = [ p . split ( \".\" )[ - 1 ] for p in niceParKeys ] self . dfResults = pd . DataFrame ( columns = niceParKeys , dtype = object ) for nicep , p in zip ( niceParKeys , exploredParameters . keys ()): self . dfResults [ nicep ] = exploredParameters [ p ] . f_get_range () @staticmethod def _filterDictionaryBold ( filt_dict , bold ): \"\"\"Filters result dictionary: either keeps ONLY BOLD results, or remove BOLD results. :param filt_dict: dictionary to filter for BOLD keys :type filt_dict: dict :param bold: whether to remove BOLD keys (bold=False) or keep only BOLD keys (bold=True) :return: filtered dict, without or only BOLD keys :rtype: dict \"\"\" filt_dict = copy . deepcopy ( filt_dict ) if bold : return { k : v for k , v in filt_dict . items () if \"BOLD\" in k } else : return { k : v for k , v in filt_dict . items () if \"BOLD\" not in k } def _getCoordsFromRun ( self , run_dict , bold = False ): \"\"\"Find coordinates of a single run - time, output and space dimensions. :param run_dict: dictionary with run results :type run_dict: dict :param bold: whether to do only BOLD or without BOLD results :type bold: bool :return: dictionary of coordinates for xarray :rtype: dict \"\"\" run_dict = copy . deepcopy ( run_dict ) run_dict = self . _filterDictionaryBold ( run_dict , bold = bold ) timeDictKey = \"\" if \"t\" in run_dict : timeDictKey = \"t\" else : for k in run_dict : if k . startswith ( \"t\" ): timeDictKey = k logging . info ( f \"Assuming { k } to be the time axis.\" ) break assert len ( timeDictKey ) > 0 , \"No time array found (starting with t) in model output.\" t = run_dict [ timeDictKey ] . copy () del run_dict [ timeDictKey ] return timeDictKey , { \"output\" : list ( run_dict . keys ()), \"space\" : list ( range ( next ( iter ( run_dict . values ())) . shape [ 0 ])), \"time\" : t , } def xr ( self , bold = False ): \"\"\" Return `xr.Dataset` from the exploration results. :param bold: if True, will load and return only BOLD output :type bold: bool \"\"\" def _sanitize_nc_key ( k ): return k . replace ( \"*\" , \"_\" ) . replace ( \".\" , \"_\" ) . replace ( \"|\" , \"_\" ) assert self . results is not None , \"Run `loadResults()` first to populate the results\" assert len ( self . results ) == len ( self . dfResults ) # create intrisinsic dims for one run timeDictKey , run_coords = self . _getCoordsFromRun ( self . results [ 0 ], bold = bold ) dataarrays = [] orig_search_coords = self . parameterSpace . get_parametrization () for runId , run_result in self . results . items (): # take exploration coordinates for this run expl_coords = { k : v [ runId ] for k , v in orig_search_coords . items ()} outputs = [] run_result = self . _filterDictionaryBold ( run_result , bold = bold ) for key , value in run_result . items (): if key == timeDictKey : continue outputs . append ( value ) # create DataArray for run only - we need to add exploration coordinates data_temp = xr . DataArray ( np . stack ( outputs ), dims = [ \"output\" , \"space\" , \"time\" ], coords = run_coords , name = \"exploration\" ) expand_coords = {} # iterate exploration coordinates for k , v in expl_coords . items (): # sanitize keys in the case of stars etc k = _sanitize_nc_key ( k ) # if single values, just assign if isinstance ( v , ( str , float , int )): expand_coords [ k ] = [ v ] # if arrays, check whether they can be squeezed into one value elif isinstance ( v , np . ndarray ): if np . unique ( v ) . size == 1 : # if yes, just assign that one value expand_coords [ k ] = [ float ( np . unique ( v ))] else : # if no, sorry - coordinates cannot be array raise ValueError ( \"Cannot squeeze coordinates\" ) # assing exploration coordinates to the DataArray dataarrays . append ( data_temp . expand_dims ( expand_coords )) # finally, combine all arrays into one if self . parameterSpace . kind == \"sequence\" : # when run in sequence, cannot combine to grid, so just concatenate along new dimension combined = xr . concat ( dataarrays , dim = \"run_no\" , coords = \"all\" ) else : # sometimes combining xr.DataArrays does not work, see https://github.com/pydata/xarray/issues/3248#issuecomment-531511177 # resolved by casting them explicitely to xr.Dataset combined = xr . combine_by_coords ([ da . to_dataset () for da in dataarrays ])[ \"exploration\" ] if self . parameterSpace . star : # if we explored over star params, unwrap them into attributes combined . attrs = { _sanitize_nc_key ( k ): list ( self . model . params [ k ] . keys ()) for k in orig_search_coords . keys () if \"*\" in k } return combined def getRun ( self , runId , filename = None , trajectoryName = None , pypetShortNames = True ): \"\"\"Load the simulated data of a run and its parameters from a pypetTrajectory. :param runId: ID of the run :type runId: int :return: Dictionary with simulated data and parameters of the run. :type return: dict \"\"\" # chose HDF file to load filename = self . HDF_FILE or filename # either use loaded pypetTrajectory or load from HDF file if it isn't available pypetTrajectory = ( self . pypetTrajectory if hasattr ( self , \"pypetTrajectory\" ) else pu . loadPypetTrajectory ( filename , trajectoryName ) ) # # if there was no pypetTrajectory loaded before # if pypetTrajectory is None: # # chose HDF file to load # filename = self.HDF_FILE or filename # pypetTrajectory = pu.loadPypetTrajectory(filename, trajectoryName) return pu . getRun ( runId , pypetTrajectory , pypetShortNames = pypetShortNames ) def getResult ( self , runId ): \"\"\"Returns either a loaded result or reads from disk. :param runId: runId of result :type runId: int :return: result :rtype: dict \"\"\" # if hasattr(self, \"results\"): # # load result from either the preloaded .result attribute (from .loadResults) # result = self.results[runId] # else: # # or from disk if results haven't been loaded yet # result = self.getRun(runId) # load result from either the preloaded .result attribute (from .loadResults) # or from disk if results haven't been loaded yet # result = self.results[runId] if hasattr(self, \"results\") else self.getRun(runId) return self . results [ runId ] if hasattr ( self , \"results\" ) else self . getRun ( runId ) def info ( self ): \"\"\"Print info about the current search.\"\"\" now = datetime . datetime . now () . strftime ( \"%Y-%m- %d -%HH-%MM-%SS\" ) print ( f \"Exploration info ( { now } )\" ) print ( f \"HDF name: { self . HDF_FILE } \" ) print ( f \"Trajectory name: { self . trajectoryName } \" ) if self . model is not None : print ( f \"Model: { self . model . name } \" ) if hasattr ( self , \"nRuns\" ): print ( f \"Number of runs { self . nRuns } \" ) print ( f \"Explored parameters: { self . exploreParameters . keys () } \" ) if hasattr ( self , \"_t_end_exploration\" ) and hasattr ( self , \"_t_start_exploration\" ): print ( f \"Duration of exploration: { self . _t_end_exploration - self . _t_start_exploration } \" ) __init__ ( self , model = None , parameterSpace = None , evalFunction = None , filename = None , saveAllModelOutputs = False , ncores = None ) special Either a model has to be passed, or an evalFunction. If an evalFunction is passed, then the evalFunction will be called and the model is accessible to the evalFunction via self.getModelFromTraj(traj) . The parameters of the current run are accessible via self.getParametersFromTraj(traj) . If no evaluation function is passed, then the model is simulated using Model.run() for every parameter. Parameters: Name Type Description Default model `neurolib.models.model.Model`, optional Model to run for each parameter (or model to pass to the evaluation function if an evaluation function is used), defaults to None None parameterSpace `neurolib.utils.parameterSpace.ParameterSpace`, optional Parameter space to explore, defaults to None None evalFunction function, optional Evaluation function to call for each run., defaults to None None filename str HDF5 storage file name, if left empty, defaults to exploration.hdf None saveAllModelOutputs bool If True, save all outputs of model, else only default output of the model will be saved. Note: if saveAllModelOutputs==False and the model's parameter model.params['bold']==True, then BOLD output will be saved as well, defaults to False False ncores int, optional Number of cores to simulate on (max cores default), defaults to None None Source code in neurolib/optimize/exploration/exploration.py def __init__ ( self , model = None , parameterSpace = None , evalFunction = None , filename = None , saveAllModelOutputs = False , ncores = None , ): \"\"\"Either a model has to be passed, or an evalFunction. If an evalFunction is passed, then the evalFunction will be called and the model is accessible to the evalFunction via `self.getModelFromTraj(traj)`. The parameters of the current run are accessible via `self.getParametersFromTraj(traj)`. If no evaluation function is passed, then the model is simulated using `Model.run()` for every parameter. :param model: Model to run for each parameter (or model to pass to the evaluation function if an evaluation function is used), defaults to None :type model: `neurolib.models.model.Model`, optional :param parameterSpace: Parameter space to explore, defaults to None :type parameterSpace: `neurolib.utils.parameterSpace.ParameterSpace`, optional :param evalFunction: Evaluation function to call for each run., defaults to None :type evalFunction: function, optional :param filename: HDF5 storage file name, if left empty, defaults to ``exploration.hdf`` :type filename: str :param saveAllModelOutputs: If True, save all outputs of model, else only default output of the model will be saved. Note: if saveAllModelOutputs==False and the model's parameter model.params['bold']==True, then BOLD output will be saved as well, defaults to False :type saveAllModelOutputs: bool :param ncores: Number of cores to simulate on (max cores default), defaults to None :type ncores: int, optional \"\"\" self . model = model if evalFunction is None and model is not None : self . evalFunction = self . _runModel elif evalFunction is not None : self . evalFunction = evalFunction assert ( evalFunction is not None ) or ( model is not None ), \"Either a model has to be specified or an evalFunction.\" assert parameterSpace is not None , \"No parameters to explore.\" if parameterSpace . kind == \"sequence\" : assert model is not None , \"Model must be defined for sequential explore\" self . parameterSpace = parameterSpace self . exploreParameters = parameterSpace . dict () # TODO: use random ICs for every explored point or rather reuse the ones that are generated at model # initialization self . useRandomICs = False filename = filename or \"exploration.hdf\" self . filename = filename self . saveAllModelOutputs = saveAllModelOutputs # number of cores if ncores is None : ncores = multiprocessing . cpu_count () self . ncores = ncores logging . info ( \"Number of processes: {} \" . format ( self . ncores )) # bool to check whether pypet was initialized properly self . initialized = False self . _initializeExploration ( self . filename ) self . results = None aggregateResultsToDfResults ( self , arrays = True , fillna = False ) Aggregate all results in to dfResults dataframe. Parameters: Name Type Description Default arrays bool, optional Load array results (like timeseries) if True. If False, only load scalar results, defaults to True True fillna bool, optional Fill nan results (for example if they're not returned in a subset of runs) with zeros, default to False False Source code in neurolib/optimize/exploration/exploration.py def aggregateResultsToDfResults ( self , arrays = True , fillna = False ): \"\"\"Aggregate all results in to dfResults dataframe. :param arrays: Load array results (like timeseries) if True. If False, only load scalar results, defaults to True :type arrays: bool, optional :param fillna: Fill nan results (for example if they're not returned in a subset of runs) with zeros, default to False :type fillna: bool, optional \"\"\" nan_value = np . nan # defines which variable types will be saved in the results dataframe SUPPORTED_TYPES = ( float , int , np . ndarray , list ) SCALAR_TYPES = ( float , int ) ARRAY_TYPES = ( np . ndarray , list ) logging . info ( \"Aggregating results to `dfResults` ...\" ) for runId , parameters in tqdm . tqdm ( self . dfResults . iterrows (), total = len ( self . dfResults )): # if the results were previously loaded into memory, use them if hasattr ( self , \"results\" ): # only if the length matches the number of results if len ( self . results ) == len ( self . dfResults ): result = self . results [ runId ] # else, load results individually from hdf file else : result = self . getRun ( runId ) # else, load results individually from hdf file else : result = self . getRun ( runId ) for key , value in result . items (): # only save floats, ints and arrays if isinstance ( value , SUPPORTED_TYPES ): # save 1-dim arrays if isinstance ( value , ARRAY_TYPES ) and arrays : # to save a numpy array, convert column to object type if key not in self . dfResults : self . dfResults [ key ] = None self . dfResults [ key ] = self . dfResults [ key ] . astype ( object ) self . dfResults . at [ runId , key ] = value elif isinstance ( value , SCALAR_TYPES ): # save scalars self . dfResults . loc [ runId , key ] = value else : self . dfResults . loc [ runId , key ] = nan_value # drop nan columns self . dfResults = self . dfResults . dropna ( axis = \"columns\" , how = \"all\" ) if fillna : self . dfResults = self . dfResults . fillna ( 0 ) getModelFromTraj ( self , traj ) Return the appropriate model with parameters for this run Parameters: Name Type Description Default traj Pypet trajectory of current run required Returns: Type Description Model with the parameters of this run. Source code in neurolib/optimize/exploration/exploration.py def getModelFromTraj ( self , traj ): \"\"\"Return the appropriate model with parameters for this run :params traj: Pypet trajectory of current run :returns model: Model with the parameters of this run. \"\"\" model = self . model runParams = self . getParametersFromTraj ( traj ) # removes keys with None values # runParams = {k: v for k, v in runParams.items() if v is not None} if self . parameterSpace . star : runParams = flatten_nested_dict ( flat_dict_to_nested ( runParams )[ \"parameters\" ]) model . params . update ( runParams ) return model getParametersFromTraj ( self , traj ) Returns the parameters of the current run as a (dot.able) dictionary Parameters: Name Type Description Default traj Union[`pypet.traject,y.Traject,y`] Pypet trajectory required Returns: Type Description dict Parameter set of the current run Source code in neurolib/optimize/exploration/exploration.py def getParametersFromTraj ( self , traj ): \"\"\"Returns the parameters of the current run as a (dot.able) dictionary :param traj: Pypet trajectory :type traj: `pypet.trajectory.Trajectory` :return: Parameter set of the current run :rtype: dict \"\"\" # DO NOT use short names for star notation dicts runParams = self . traj . parameters . f_to_dict ( short_names = not self . parameterSpace . star , fast_access = True ) runParams = self . _validatePypetParameters ( runParams ) return dotdict ( runParams ) getResult ( self , runId ) Returns either a loaded result or reads from disk. Parameters: Name Type Description Default runId int runId of result required Returns: Type Description dict result Source code in neurolib/optimize/exploration/exploration.py def getResult ( self , runId ): \"\"\"Returns either a loaded result or reads from disk. :param runId: runId of result :type runId: int :return: result :rtype: dict \"\"\" # if hasattr(self, \"results\"): # # load result from either the preloaded .result attribute (from .loadResults) # result = self.results[runId] # else: # # or from disk if results haven't been loaded yet # result = self.getRun(runId) # load result from either the preloaded .result attribute (from .loadResults) # or from disk if results haven't been loaded yet # result = self.results[runId] if hasattr(self, \"results\") else self.getRun(runId) return self . results [ runId ] if hasattr ( self , \"results\" ) else self . getRun ( runId ) getRun ( self , runId , filename = None , trajectoryName = None , pypetShortNames = True ) Load the simulated data of a run and its parameters from a pypetTrajectory. Parameters: Name Type Description Default runId int ID of the run required Returns: Type Description Dictionary with simulated data and parameters of the run. Source code in neurolib/optimize/exploration/exploration.py def getRun ( self , runId , filename = None , trajectoryName = None , pypetShortNames = True ): \"\"\"Load the simulated data of a run and its parameters from a pypetTrajectory. :param runId: ID of the run :type runId: int :return: Dictionary with simulated data and parameters of the run. :type return: dict \"\"\" # chose HDF file to load filename = self . HDF_FILE or filename # either use loaded pypetTrajectory or load from HDF file if it isn't available pypetTrajectory = ( self . pypetTrajectory if hasattr ( self , \"pypetTrajectory\" ) else pu . loadPypetTrajectory ( filename , trajectoryName ) ) # # if there was no pypetTrajectory loaded before # if pypetTrajectory is None: # # chose HDF file to load # filename = self.HDF_FILE or filename # pypetTrajectory = pu.loadPypetTrajectory(filename, trajectoryName) return pu . getRun ( runId , pypetTrajectory , pypetShortNames = pypetShortNames ) info ( self ) Print info about the current search. Source code in neurolib/optimize/exploration/exploration.py def info ( self ): \"\"\"Print info about the current search.\"\"\" now = datetime . datetime . now () . strftime ( \"%Y-%m- %d -%HH-%MM-%SS\" ) print ( f \"Exploration info ( { now } )\" ) print ( f \"HDF name: { self . HDF_FILE } \" ) print ( f \"Trajectory name: { self . trajectoryName } \" ) if self . model is not None : print ( f \"Model: { self . model . name } \" ) if hasattr ( self , \"nRuns\" ): print ( f \"Number of runs { self . nRuns } \" ) print ( f \"Explored parameters: { self . exploreParameters . keys () } \" ) if hasattr ( self , \"_t_end_exploration\" ) and hasattr ( self , \"_t_start_exploration\" ): print ( f \"Duration of exploration: { self . _t_end_exploration - self . _t_start_exploration } \" ) loadDfResults ( self , filename = None , trajectoryName = None ) Load results from a previous simulation. Parameters: Name Type Description Default filename str, optional hdf file name in which results are stored, defaults to None None trajectoryName str, optional Name of the trajectory inside the hdf file, newest will be used if left empty, defaults to None None Source code in neurolib/optimize/exploration/exploration.py def loadDfResults ( self , filename = None , trajectoryName = None ): \"\"\"Load results from a previous simulation. :param filename: hdf file name in which results are stored, defaults to None :type filename: str, optional :param trajectoryName: Name of the trajectory inside the hdf file, newest will be used if left empty, defaults to None :type trajectoryName: str, optional \"\"\" # chose HDF file to load filename = filename or self . HDF_FILE self . pypetTrajectory = pu . loadPypetTrajectory ( filename , trajectoryName ) self . nResults = len ( self . pypetTrajectory . f_get_run_names ()) exploredParameters = self . pypetTrajectory . f_get_explored_parameters () # create pandas dataframe of all runs with parameters as keys logging . info ( \"Creating `dfResults` dataframe ...\" ) niceParKeys = [ p [ 11 :] for p in exploredParameters . keys ()] if not self . parameterSpace : niceParKeys = [ p . split ( \".\" )[ - 1 ] for p in niceParKeys ] self . dfResults = pd . DataFrame ( columns = niceParKeys , dtype = object ) for nicep , p in zip ( niceParKeys , exploredParameters . keys ()): self . dfResults [ nicep ] = exploredParameters [ p ] . f_get_range () loadResults ( self , all = True , filename = None , trajectoryName = None , pypetShortNames = True , memory_cap = 95.0 ) Load results from a hdf file of a previous simulation. Parameters: Name Type Description Default all bool, optional Load all simulated results into memory, which will be available as the .results attribute. Can use a lot of RAM if your simulation is large, please use this with caution. , defaults to True True filename str, optional hdf file name in which results are stored, defaults to None None trajectoryName str, optional Name of the trajectory inside the hdf file, newest will be used if left empty, defaults to None None pypetShortNames bool Use pypet short names as keys for the results dictionary. Use if you are experiencing errors due to natural naming collisions. True memory_cap float, int, optional Percentage memory cap between 0 and 100. If all=True is used, a memory cap can be set to avoid filling up the available RAM. Example: use memory_cap = 95 to avoid loading more data if memory is at 95% use, defaults to 95 95.0 Source code in neurolib/optimize/exploration/exploration.py def loadResults ( self , all = True , filename = None , trajectoryName = None , pypetShortNames = True , memory_cap = 95.0 ): \"\"\"Load results from a hdf file of a previous simulation. :param all: Load all simulated results into memory, which will be available as the `.results` attribute. Can use a lot of RAM if your simulation is large, please use this with caution. , defaults to True :type all: bool, optional :param filename: hdf file name in which results are stored, defaults to None :type filename: str, optional :param trajectoryName: Name of the trajectory inside the hdf file, newest will be used if left empty, defaults to None :type trajectoryName: str, optional :param pypetShortNames: Use pypet short names as keys for the results dictionary. Use if you are experiencing errors due to natural naming collisions. :type pypetShortNames: bool :param memory_cap: Percentage memory cap between 0 and 100. If `all=True` is used, a memory cap can be set to avoid filling up the available RAM. Example: use `memory_cap = 95` to avoid loading more data if memory is at 95% use, defaults to 95 :type memory_cap: float, int, optional \"\"\" self . loadDfResults ( filename , trajectoryName ) # make a list of dictionaries with results self . results = dotdict ({}) if all : logging . info ( \"Loading all results to `results` dictionary ...\" ) for rInd in tqdm . tqdm ( range ( self . nResults ), total = self . nResults ): # check if enough memory is available if memory_cap : assert isinstance ( memory_cap , ( int , float )), \"`memory_cap` must be float.\" assert ( memory_cap > 0 ) and ( memory_cap < 100 ), \"`memory_cap` must be between 0 and 100\" # check ram usage with psutil used_memory_percent = psutil . virtual_memory ()[ 2 ] if used_memory_percent > memory_cap : raise MemoryError ( f \"Memory use is at { used_memory_percent } % and capped at { memory_cap } . Aborting.\" ) self . pypetTrajectory . results [ rInd ] . f_load () result = self . pypetTrajectory . results [ rInd ] . f_to_dict ( fast_access = True , short_names = pypetShortNames ) result = dotdict ( result ) self . pypetTrajectory . results [ rInd ] . f_remove () self . results [ rInd ] = copy . deepcopy ( result ) # Postprocess result keys if pypet short names aren't used # Before: results.run_00000001.outputs.rates_inh # After: outputs.rates_inh if not pypetShortNames : for i , r in self . results . items (): new_dict = dotdict ({}) for key , value in r . items (): new_key = \"\" . join ( key . split ( \".\" , 2 )[ 2 :]) new_dict [ new_key ] = r [ key ] self . results [ i ] = copy . deepcopy ( new_dict ) self . aggregateResultsToDfResults () logging . info ( \"All results loaded.\" ) run ( self , ** kwargs ) Call this function to run the exploration Source code in neurolib/optimize/exploration/exploration.py def run ( self , ** kwargs ): \"\"\" Call this function to run the exploration \"\"\" self . runKwargs = kwargs assert self . initialized , \"Pypet environment not initialized yet.\" self . _t_start_exploration = datetime . datetime . now () self . env . run ( self . evalFunction ) self . _t_end_exploration = datetime . datetime . now () saveToPypet ( self , outputs , traj ) This function takes simulation results in the form of a nested dictionary and stores all data into the pypet hdf file. Parameters: Name Type Description Default outputs dict Simulation outputs as a dictionary. required traj Union[`pypet.traject,y.Traject,y`] Pypet trajectory required Source code in neurolib/optimize/exploration/exploration.py def saveToPypet ( self , outputs , traj ): \"\"\"This function takes simulation results in the form of a nested dictionary and stores all data into the pypet hdf file. :param outputs: Simulation outputs as a dictionary. :type outputs: dict :param traj: Pypet trajectory :type traj: `pypet.trajectory.Trajectory` \"\"\" def makeSaveStringForPypet ( value , savestr ): \"\"\"Builds the pypet-style results string from the results dictionary's keys. \"\"\" for k , v in value . items (): if isinstance ( v , dict ): _savestr = savestr + k + \".\" makeSaveStringForPypet ( v , _savestr ) else : _savestr = savestr + k self . traj . f_add_result ( _savestr , v ) assert isinstance ( outputs , dict ), \"Outputs must be an instance of dict.\" value = outputs savestr = \"results.$.\" makeSaveStringForPypet ( value , savestr ) xr ( self , bold = False ) Return xr.Dataset from the exploration results. Parameters: Name Type Description Default bold bool if True, will load and return only BOLD output False Source code in neurolib/optimize/exploration/exploration.py def xr ( self , bold = False ): \"\"\" Return `xr.Dataset` from the exploration results. :param bold: if True, will load and return only BOLD output :type bold: bool \"\"\" def _sanitize_nc_key ( k ): return k . replace ( \"*\" , \"_\" ) . replace ( \".\" , \"_\" ) . replace ( \"|\" , \"_\" ) assert self . results is not None , \"Run `loadResults()` first to populate the results\" assert len ( self . results ) == len ( self . dfResults ) # create intrisinsic dims for one run timeDictKey , run_coords = self . _getCoordsFromRun ( self . results [ 0 ], bold = bold ) dataarrays = [] orig_search_coords = self . parameterSpace . get_parametrization () for runId , run_result in self . results . items (): # take exploration coordinates for this run expl_coords = { k : v [ runId ] for k , v in orig_search_coords . items ()} outputs = [] run_result = self . _filterDictionaryBold ( run_result , bold = bold ) for key , value in run_result . items (): if key == timeDictKey : continue outputs . append ( value ) # create DataArray for run only - we need to add exploration coordinates data_temp = xr . DataArray ( np . stack ( outputs ), dims = [ \"output\" , \"space\" , \"time\" ], coords = run_coords , name = \"exploration\" ) expand_coords = {} # iterate exploration coordinates for k , v in expl_coords . items (): # sanitize keys in the case of stars etc k = _sanitize_nc_key ( k ) # if single values, just assign if isinstance ( v , ( str , float , int )): expand_coords [ k ] = [ v ] # if arrays, check whether they can be squeezed into one value elif isinstance ( v , np . ndarray ): if np . unique ( v ) . size == 1 : # if yes, just assign that one value expand_coords [ k ] = [ float ( np . unique ( v ))] else : # if no, sorry - coordinates cannot be array raise ValueError ( \"Cannot squeeze coordinates\" ) # assing exploration coordinates to the DataArray dataarrays . append ( data_temp . expand_dims ( expand_coords )) # finally, combine all arrays into one if self . parameterSpace . kind == \"sequence\" : # when run in sequence, cannot combine to grid, so just concatenate along new dimension combined = xr . concat ( dataarrays , dim = \"run_no\" , coords = \"all\" ) else : # sometimes combining xr.DataArrays does not work, see https://github.com/pydata/xarray/issues/3248#issuecomment-531511177 # resolved by casting them explicitely to xr.Dataset combined = xr . combine_by_coords ([ da . to_dataset () for da in dataarrays ])[ \"exploration\" ] if self . parameterSpace . star : # if we explored over star params, unwrap them into attributes combined . attrs = { _sanitize_nc_key ( k ): list ( self . model . params [ k ] . keys ()) for k in orig_search_coords . keys () if \"*\" in k } return combined","title":"BoxSearch"},{"location":"exploration/boxsearch/#boxsearch","text":"Paremeter box search for a given model and a range of parameters. Source code in neurolib/optimize/exploration/exploration.py class BoxSearch : \"\"\" Paremeter box search for a given model and a range of parameters. \"\"\" def __init__ ( self , model = None , parameterSpace = None , evalFunction = None , filename = None , saveAllModelOutputs = False , ncores = None , ): \"\"\"Either a model has to be passed, or an evalFunction. If an evalFunction is passed, then the evalFunction will be called and the model is accessible to the evalFunction via `self.getModelFromTraj(traj)`. The parameters of the current run are accessible via `self.getParametersFromTraj(traj)`. If no evaluation function is passed, then the model is simulated using `Model.run()` for every parameter. :param model: Model to run for each parameter (or model to pass to the evaluation function if an evaluation function is used), defaults to None :type model: `neurolib.models.model.Model`, optional :param parameterSpace: Parameter space to explore, defaults to None :type parameterSpace: `neurolib.utils.parameterSpace.ParameterSpace`, optional :param evalFunction: Evaluation function to call for each run., defaults to None :type evalFunction: function, optional :param filename: HDF5 storage file name, if left empty, defaults to ``exploration.hdf`` :type filename: str :param saveAllModelOutputs: If True, save all outputs of model, else only default output of the model will be saved. Note: if saveAllModelOutputs==False and the model's parameter model.params['bold']==True, then BOLD output will be saved as well, defaults to False :type saveAllModelOutputs: bool :param ncores: Number of cores to simulate on (max cores default), defaults to None :type ncores: int, optional \"\"\" self . model = model if evalFunction is None and model is not None : self . evalFunction = self . _runModel elif evalFunction is not None : self . evalFunction = evalFunction assert ( evalFunction is not None ) or ( model is not None ), \"Either a model has to be specified or an evalFunction.\" assert parameterSpace is not None , \"No parameters to explore.\" if parameterSpace . kind == \"sequence\" : assert model is not None , \"Model must be defined for sequential explore\" self . parameterSpace = parameterSpace self . exploreParameters = parameterSpace . dict () # TODO: use random ICs for every explored point or rather reuse the ones that are generated at model # initialization self . useRandomICs = False filename = filename or \"exploration.hdf\" self . filename = filename self . saveAllModelOutputs = saveAllModelOutputs # number of cores if ncores is None : ncores = multiprocessing . cpu_count () self . ncores = ncores logging . info ( \"Number of processes: {} \" . format ( self . ncores )) # bool to check whether pypet was initialized properly self . initialized = False self . _initializeExploration ( self . filename ) self . results = None def _initializeExploration ( self , filename = \"exploration.hdf\" ): \"\"\"Initialize the pypet environment :param filename: hdf filename to store the results in , defaults to \"exploration.hdf\" :type filename: str, optional \"\"\" # create hdf file path if it does not exist yet pathlib . Path ( paths . HDF_DIR ) . mkdir ( parents = True , exist_ok = True ) # set default hdf filename self . HDF_FILE = os . path . join ( paths . HDF_DIR , filename ) # initialize pypet environment trajectoryName = \"results\" + datetime . datetime . now () . strftime ( \"-%Y-%m- %d -%HH-%MM-%SS\" ) trajectoryfilename = self . HDF_FILE # set up the pypet environment env = pypet . Environment ( trajectory = trajectoryName , filename = trajectoryfilename , multiproc = True , ncores = self . ncores , complevel = 9 , log_config = paths . PYPET_LOGGING_CONFIG , ) self . env = env # Get the trajectory from the environment self . traj = env . trajectory self . trajectoryName = self . traj . v_name # Add all parameters to the pypet trajectory if self . model is not None : # if a model is specified, use the default parameter of the # model to initialize pypet self . _addParametersToPypet ( self . traj , self . model . params ) else : # else, use a random parameter of the parameter space self . _addParametersToPypet ( self . traj , self . parameterSpace . getRandom ( safe = True )) # Tell pypet which parameters to explore self . pypetParametrization = self . parameterSpace . get_parametrization () # explicitely add all parameters within star notation, hence unwrap star notation into actual params names if self . parameterSpace . star : assert self . model is not None , \"With star notation, model cannot be None\" self . pypetParametrization = unwrap_star_dotdict ( self . pypetParametrization , self . model ) self . nRuns = len ( self . pypetParametrization [ list ( self . pypetParametrization . keys ())[ 0 ]]) logging . info ( f \"Number of parameter configurations: { self . nRuns } \" ) if self . parameterSpace . kind == \"sequence\" : # if sequential explore, need to fill-in the default parameters instead of None self . pypetParametrization = self . _fillin_default_parameters_for_sequential ( self . pypetParametrization , self . model . params ) self . traj . f_explore ( self . pypetParametrization ) # initialization done logging . info ( \"BoxSearch: Environment initialized.\" ) self . initialized = True @staticmethod def _fillin_default_parameters_for_sequential ( parametrization , model_params ): fresh_dict = {} for k , params in parametrization . items (): fresh_dict [ k ] = [ v if v is not None else model_params [ k ] for v in params ] return fresh_dict def _addParametersToPypet ( self , traj , params ): \"\"\"This function registers the parameters of the model to Pypet. Parameters can be nested dictionaries. They are unpacked and stored recursively. :param traj: Pypet trajectory to store the parameters in :type traj: `pypet.trajectory.Trajectory` :param params: Parameter dictionary :type params: dict, dict[dict,] \"\"\" def addParametersRecursively ( traj , params , current_level ): # make dummy list if just string if isinstance ( current_level , str ): current_level = [ current_level ] # iterate dict for key , value in params . items (): # if another dict - recurse and increase level if isinstance ( value , dict ): addParametersRecursively ( traj , value , current_level + [ key ]) else : param_address = \".\" . join ( current_level + [ key ]) value = \"None\" if value is None else value traj . f_add_parameter ( param_address , value ) addParametersRecursively ( traj , params , []) def saveToPypet ( self , outputs , traj ): \"\"\"This function takes simulation results in the form of a nested dictionary and stores all data into the pypet hdf file. :param outputs: Simulation outputs as a dictionary. :type outputs: dict :param traj: Pypet trajectory :type traj: `pypet.trajectory.Trajectory` \"\"\" def makeSaveStringForPypet ( value , savestr ): \"\"\"Builds the pypet-style results string from the results dictionary's keys. \"\"\" for k , v in value . items (): if isinstance ( v , dict ): _savestr = savestr + k + \".\" makeSaveStringForPypet ( v , _savestr ) else : _savestr = savestr + k self . traj . f_add_result ( _savestr , v ) assert isinstance ( outputs , dict ), \"Outputs must be an instance of dict.\" value = outputs savestr = \"results.$.\" makeSaveStringForPypet ( value , savestr ) def _runModel ( self , traj ): \"\"\"If not evaluation function is given, we assume that a model will be simulated. This function will be called by pypet directly and therefore wants a pypet trajectory as an argument :param traj: Pypet trajectory :type traj: `pypet.trajectory.Trajectory` \"\"\" if self . useRandomICs : logging . warn ( \"Random initial conditions not implemented yet\" ) # get parameters of this run from pypet trajectory runParams = self . getParametersFromTraj ( traj ) if self . parameterSpace . star : runParams = flatten_nested_dict ( flat_dict_to_nested ( runParams )[ \"parameters\" ]) # set the parameters for the model self . model . params . update ( runParams ) # get kwargs from Exploration.run() runKwargs = {} if hasattr ( self , \"runKwargs\" ): runKwargs = self . runKwargs # run it self . model . run ( ** runKwargs ) # save outputs self . _saveModelOutputsToPypet ( traj ) def _saveModelOutputsToPypet ( self , traj ): # save all data to the pypet trajectory if self . saveAllModelOutputs : # save all results from exploration self . saveToPypet ( self . model . outputs , traj ) else : # save only the default output self . saveToPypet ( { self . model . default_output : self . model . output , \"t\" : self . model . outputs [ \"t\" ], }, traj , ) # save BOLD output # if \"bold\" in self.model.params: # if self.model.params[\"bold\"] and \"BOLD\" in self.model.outputs: # self.saveToPypet(self.model.outputs[\"BOLD\"], traj) if \"BOLD\" in self . model . outputs : self . saveToPypet ( self . model . outputs [ \"BOLD\" ], traj ) def _validatePypetParameters ( self , runParams ): \"\"\"Helper to handle None's in pypet parameters (used for random number generator seed) :param runParams: parameters as returned by traj.parameters.f_to_dict() :type runParams: dict of pypet.parameter.Parameter \"\"\" # fix rng seed, which is saved as a string if None if \"seed\" in runParams : if runParams [ \"seed\" ] == \"None\" : runParams [ \"seed\" ] = None return runParams def getParametersFromTraj ( self , traj ): \"\"\"Returns the parameters of the current run as a (dot.able) dictionary :param traj: Pypet trajectory :type traj: `pypet.trajectory.Trajectory` :return: Parameter set of the current run :rtype: dict \"\"\" # DO NOT use short names for star notation dicts runParams = self . traj . parameters . f_to_dict ( short_names = not self . parameterSpace . star , fast_access = True ) runParams = self . _validatePypetParameters ( runParams ) return dotdict ( runParams ) def getModelFromTraj ( self , traj ): \"\"\"Return the appropriate model with parameters for this run :params traj: Pypet trajectory of current run :returns model: Model with the parameters of this run. \"\"\" model = self . model runParams = self . getParametersFromTraj ( traj ) # removes keys with None values # runParams = {k: v for k, v in runParams.items() if v is not None} if self . parameterSpace . star : runParams = flatten_nested_dict ( flat_dict_to_nested ( runParams )[ \"parameters\" ]) model . params . update ( runParams ) return model def run ( self , ** kwargs ): \"\"\" Call this function to run the exploration \"\"\" self . runKwargs = kwargs assert self . initialized , \"Pypet environment not initialized yet.\" self . _t_start_exploration = datetime . datetime . now () self . env . run ( self . evalFunction ) self . _t_end_exploration = datetime . datetime . now () def loadResults ( self , all = True , filename = None , trajectoryName = None , pypetShortNames = True , memory_cap = 95.0 ): \"\"\"Load results from a hdf file of a previous simulation. :param all: Load all simulated results into memory, which will be available as the `.results` attribute. Can use a lot of RAM if your simulation is large, please use this with caution. , defaults to True :type all: bool, optional :param filename: hdf file name in which results are stored, defaults to None :type filename: str, optional :param trajectoryName: Name of the trajectory inside the hdf file, newest will be used if left empty, defaults to None :type trajectoryName: str, optional :param pypetShortNames: Use pypet short names as keys for the results dictionary. Use if you are experiencing errors due to natural naming collisions. :type pypetShortNames: bool :param memory_cap: Percentage memory cap between 0 and 100. If `all=True` is used, a memory cap can be set to avoid filling up the available RAM. Example: use `memory_cap = 95` to avoid loading more data if memory is at 95% use, defaults to 95 :type memory_cap: float, int, optional \"\"\" self . loadDfResults ( filename , trajectoryName ) # make a list of dictionaries with results self . results = dotdict ({}) if all : logging . info ( \"Loading all results to `results` dictionary ...\" ) for rInd in tqdm . tqdm ( range ( self . nResults ), total = self . nResults ): # check if enough memory is available if memory_cap : assert isinstance ( memory_cap , ( int , float )), \"`memory_cap` must be float.\" assert ( memory_cap > 0 ) and ( memory_cap < 100 ), \"`memory_cap` must be between 0 and 100\" # check ram usage with psutil used_memory_percent = psutil . virtual_memory ()[ 2 ] if used_memory_percent > memory_cap : raise MemoryError ( f \"Memory use is at { used_memory_percent } % and capped at { memory_cap } . Aborting.\" ) self . pypetTrajectory . results [ rInd ] . f_load () result = self . pypetTrajectory . results [ rInd ] . f_to_dict ( fast_access = True , short_names = pypetShortNames ) result = dotdict ( result ) self . pypetTrajectory . results [ rInd ] . f_remove () self . results [ rInd ] = copy . deepcopy ( result ) # Postprocess result keys if pypet short names aren't used # Before: results.run_00000001.outputs.rates_inh # After: outputs.rates_inh if not pypetShortNames : for i , r in self . results . items (): new_dict = dotdict ({}) for key , value in r . items (): new_key = \"\" . join ( key . split ( \".\" , 2 )[ 2 :]) new_dict [ new_key ] = r [ key ] self . results [ i ] = copy . deepcopy ( new_dict ) self . aggregateResultsToDfResults () logging . info ( \"All results loaded.\" ) def aggregateResultsToDfResults ( self , arrays = True , fillna = False ): \"\"\"Aggregate all results in to dfResults dataframe. :param arrays: Load array results (like timeseries) if True. If False, only load scalar results, defaults to True :type arrays: bool, optional :param fillna: Fill nan results (for example if they're not returned in a subset of runs) with zeros, default to False :type fillna: bool, optional \"\"\" nan_value = np . nan # defines which variable types will be saved in the results dataframe SUPPORTED_TYPES = ( float , int , np . ndarray , list ) SCALAR_TYPES = ( float , int ) ARRAY_TYPES = ( np . ndarray , list ) logging . info ( \"Aggregating results to `dfResults` ...\" ) for runId , parameters in tqdm . tqdm ( self . dfResults . iterrows (), total = len ( self . dfResults )): # if the results were previously loaded into memory, use them if hasattr ( self , \"results\" ): # only if the length matches the number of results if len ( self . results ) == len ( self . dfResults ): result = self . results [ runId ] # else, load results individually from hdf file else : result = self . getRun ( runId ) # else, load results individually from hdf file else : result = self . getRun ( runId ) for key , value in result . items (): # only save floats, ints and arrays if isinstance ( value , SUPPORTED_TYPES ): # save 1-dim arrays if isinstance ( value , ARRAY_TYPES ) and arrays : # to save a numpy array, convert column to object type if key not in self . dfResults : self . dfResults [ key ] = None self . dfResults [ key ] = self . dfResults [ key ] . astype ( object ) self . dfResults . at [ runId , key ] = value elif isinstance ( value , SCALAR_TYPES ): # save scalars self . dfResults . loc [ runId , key ] = value else : self . dfResults . loc [ runId , key ] = nan_value # drop nan columns self . dfResults = self . dfResults . dropna ( axis = \"columns\" , how = \"all\" ) if fillna : self . dfResults = self . dfResults . fillna ( 0 ) def loadDfResults ( self , filename = None , trajectoryName = None ): \"\"\"Load results from a previous simulation. :param filename: hdf file name in which results are stored, defaults to None :type filename: str, optional :param trajectoryName: Name of the trajectory inside the hdf file, newest will be used if left empty, defaults to None :type trajectoryName: str, optional \"\"\" # chose HDF file to load filename = filename or self . HDF_FILE self . pypetTrajectory = pu . loadPypetTrajectory ( filename , trajectoryName ) self . nResults = len ( self . pypetTrajectory . f_get_run_names ()) exploredParameters = self . pypetTrajectory . f_get_explored_parameters () # create pandas dataframe of all runs with parameters as keys logging . info ( \"Creating `dfResults` dataframe ...\" ) niceParKeys = [ p [ 11 :] for p in exploredParameters . keys ()] if not self . parameterSpace : niceParKeys = [ p . split ( \".\" )[ - 1 ] for p in niceParKeys ] self . dfResults = pd . DataFrame ( columns = niceParKeys , dtype = object ) for nicep , p in zip ( niceParKeys , exploredParameters . keys ()): self . dfResults [ nicep ] = exploredParameters [ p ] . f_get_range () @staticmethod def _filterDictionaryBold ( filt_dict , bold ): \"\"\"Filters result dictionary: either keeps ONLY BOLD results, or remove BOLD results. :param filt_dict: dictionary to filter for BOLD keys :type filt_dict: dict :param bold: whether to remove BOLD keys (bold=False) or keep only BOLD keys (bold=True) :return: filtered dict, without or only BOLD keys :rtype: dict \"\"\" filt_dict = copy . deepcopy ( filt_dict ) if bold : return { k : v for k , v in filt_dict . items () if \"BOLD\" in k } else : return { k : v for k , v in filt_dict . items () if \"BOLD\" not in k } def _getCoordsFromRun ( self , run_dict , bold = False ): \"\"\"Find coordinates of a single run - time, output and space dimensions. :param run_dict: dictionary with run results :type run_dict: dict :param bold: whether to do only BOLD or without BOLD results :type bold: bool :return: dictionary of coordinates for xarray :rtype: dict \"\"\" run_dict = copy . deepcopy ( run_dict ) run_dict = self . _filterDictionaryBold ( run_dict , bold = bold ) timeDictKey = \"\" if \"t\" in run_dict : timeDictKey = \"t\" else : for k in run_dict : if k . startswith ( \"t\" ): timeDictKey = k logging . info ( f \"Assuming { k } to be the time axis.\" ) break assert len ( timeDictKey ) > 0 , \"No time array found (starting with t) in model output.\" t = run_dict [ timeDictKey ] . copy () del run_dict [ timeDictKey ] return timeDictKey , { \"output\" : list ( run_dict . keys ()), \"space\" : list ( range ( next ( iter ( run_dict . values ())) . shape [ 0 ])), \"time\" : t , } def xr ( self , bold = False ): \"\"\" Return `xr.Dataset` from the exploration results. :param bold: if True, will load and return only BOLD output :type bold: bool \"\"\" def _sanitize_nc_key ( k ): return k . replace ( \"*\" , \"_\" ) . replace ( \".\" , \"_\" ) . replace ( \"|\" , \"_\" ) assert self . results is not None , \"Run `loadResults()` first to populate the results\" assert len ( self . results ) == len ( self . dfResults ) # create intrisinsic dims for one run timeDictKey , run_coords = self . _getCoordsFromRun ( self . results [ 0 ], bold = bold ) dataarrays = [] orig_search_coords = self . parameterSpace . get_parametrization () for runId , run_result in self . results . items (): # take exploration coordinates for this run expl_coords = { k : v [ runId ] for k , v in orig_search_coords . items ()} outputs = [] run_result = self . _filterDictionaryBold ( run_result , bold = bold ) for key , value in run_result . items (): if key == timeDictKey : continue outputs . append ( value ) # create DataArray for run only - we need to add exploration coordinates data_temp = xr . DataArray ( np . stack ( outputs ), dims = [ \"output\" , \"space\" , \"time\" ], coords = run_coords , name = \"exploration\" ) expand_coords = {} # iterate exploration coordinates for k , v in expl_coords . items (): # sanitize keys in the case of stars etc k = _sanitize_nc_key ( k ) # if single values, just assign if isinstance ( v , ( str , float , int )): expand_coords [ k ] = [ v ] # if arrays, check whether they can be squeezed into one value elif isinstance ( v , np . ndarray ): if np . unique ( v ) . size == 1 : # if yes, just assign that one value expand_coords [ k ] = [ float ( np . unique ( v ))] else : # if no, sorry - coordinates cannot be array raise ValueError ( \"Cannot squeeze coordinates\" ) # assing exploration coordinates to the DataArray dataarrays . append ( data_temp . expand_dims ( expand_coords )) # finally, combine all arrays into one if self . parameterSpace . kind == \"sequence\" : # when run in sequence, cannot combine to grid, so just concatenate along new dimension combined = xr . concat ( dataarrays , dim = \"run_no\" , coords = \"all\" ) else : # sometimes combining xr.DataArrays does not work, see https://github.com/pydata/xarray/issues/3248#issuecomment-531511177 # resolved by casting them explicitely to xr.Dataset combined = xr . combine_by_coords ([ da . to_dataset () for da in dataarrays ])[ \"exploration\" ] if self . parameterSpace . star : # if we explored over star params, unwrap them into attributes combined . attrs = { _sanitize_nc_key ( k ): list ( self . model . params [ k ] . keys ()) for k in orig_search_coords . keys () if \"*\" in k } return combined def getRun ( self , runId , filename = None , trajectoryName = None , pypetShortNames = True ): \"\"\"Load the simulated data of a run and its parameters from a pypetTrajectory. :param runId: ID of the run :type runId: int :return: Dictionary with simulated data and parameters of the run. :type return: dict \"\"\" # chose HDF file to load filename = self . HDF_FILE or filename # either use loaded pypetTrajectory or load from HDF file if it isn't available pypetTrajectory = ( self . pypetTrajectory if hasattr ( self , \"pypetTrajectory\" ) else pu . loadPypetTrajectory ( filename , trajectoryName ) ) # # if there was no pypetTrajectory loaded before # if pypetTrajectory is None: # # chose HDF file to load # filename = self.HDF_FILE or filename # pypetTrajectory = pu.loadPypetTrajectory(filename, trajectoryName) return pu . getRun ( runId , pypetTrajectory , pypetShortNames = pypetShortNames ) def getResult ( self , runId ): \"\"\"Returns either a loaded result or reads from disk. :param runId: runId of result :type runId: int :return: result :rtype: dict \"\"\" # if hasattr(self, \"results\"): # # load result from either the preloaded .result attribute (from .loadResults) # result = self.results[runId] # else: # # or from disk if results haven't been loaded yet # result = self.getRun(runId) # load result from either the preloaded .result attribute (from .loadResults) # or from disk if results haven't been loaded yet # result = self.results[runId] if hasattr(self, \"results\") else self.getRun(runId) return self . results [ runId ] if hasattr ( self , \"results\" ) else self . getRun ( runId ) def info ( self ): \"\"\"Print info about the current search.\"\"\" now = datetime . datetime . now () . strftime ( \"%Y-%m- %d -%HH-%MM-%SS\" ) print ( f \"Exploration info ( { now } )\" ) print ( f \"HDF name: { self . HDF_FILE } \" ) print ( f \"Trajectory name: { self . trajectoryName } \" ) if self . model is not None : print ( f \"Model: { self . model . name } \" ) if hasattr ( self , \"nRuns\" ): print ( f \"Number of runs { self . nRuns } \" ) print ( f \"Explored parameters: { self . exploreParameters . keys () } \" ) if hasattr ( self , \"_t_end_exploration\" ) and hasattr ( self , \"_t_start_exploration\" ): print ( f \"Duration of exploration: { self . _t_end_exploration - self . _t_start_exploration } \" )","title":"BoxSearch"},{"location":"exploration/boxsearch/#neurolib.optimize.exploration.exploration.BoxSearch.__init__","text":"Either a model has to be passed, or an evalFunction. If an evalFunction is passed, then the evalFunction will be called and the model is accessible to the evalFunction via self.getModelFromTraj(traj) . The parameters of the current run are accessible via self.getParametersFromTraj(traj) . If no evaluation function is passed, then the model is simulated using Model.run() for every parameter. Parameters: Name Type Description Default model `neurolib.models.model.Model`, optional Model to run for each parameter (or model to pass to the evaluation function if an evaluation function is used), defaults to None None parameterSpace `neurolib.utils.parameterSpace.ParameterSpace`, optional Parameter space to explore, defaults to None None evalFunction function, optional Evaluation function to call for each run., defaults to None None filename str HDF5 storage file name, if left empty, defaults to exploration.hdf None saveAllModelOutputs bool If True, save all outputs of model, else only default output of the model will be saved. Note: if saveAllModelOutputs==False and the model's parameter model.params['bold']==True, then BOLD output will be saved as well, defaults to False False ncores int, optional Number of cores to simulate on (max cores default), defaults to None None Source code in neurolib/optimize/exploration/exploration.py def __init__ ( self , model = None , parameterSpace = None , evalFunction = None , filename = None , saveAllModelOutputs = False , ncores = None , ): \"\"\"Either a model has to be passed, or an evalFunction. If an evalFunction is passed, then the evalFunction will be called and the model is accessible to the evalFunction via `self.getModelFromTraj(traj)`. The parameters of the current run are accessible via `self.getParametersFromTraj(traj)`. If no evaluation function is passed, then the model is simulated using `Model.run()` for every parameter. :param model: Model to run for each parameter (or model to pass to the evaluation function if an evaluation function is used), defaults to None :type model: `neurolib.models.model.Model`, optional :param parameterSpace: Parameter space to explore, defaults to None :type parameterSpace: `neurolib.utils.parameterSpace.ParameterSpace`, optional :param evalFunction: Evaluation function to call for each run., defaults to None :type evalFunction: function, optional :param filename: HDF5 storage file name, if left empty, defaults to ``exploration.hdf`` :type filename: str :param saveAllModelOutputs: If True, save all outputs of model, else only default output of the model will be saved. Note: if saveAllModelOutputs==False and the model's parameter model.params['bold']==True, then BOLD output will be saved as well, defaults to False :type saveAllModelOutputs: bool :param ncores: Number of cores to simulate on (max cores default), defaults to None :type ncores: int, optional \"\"\" self . model = model if evalFunction is None and model is not None : self . evalFunction = self . _runModel elif evalFunction is not None : self . evalFunction = evalFunction assert ( evalFunction is not None ) or ( model is not None ), \"Either a model has to be specified or an evalFunction.\" assert parameterSpace is not None , \"No parameters to explore.\" if parameterSpace . kind == \"sequence\" : assert model is not None , \"Model must be defined for sequential explore\" self . parameterSpace = parameterSpace self . exploreParameters = parameterSpace . dict () # TODO: use random ICs for every explored point or rather reuse the ones that are generated at model # initialization self . useRandomICs = False filename = filename or \"exploration.hdf\" self . filename = filename self . saveAllModelOutputs = saveAllModelOutputs # number of cores if ncores is None : ncores = multiprocessing . cpu_count () self . ncores = ncores logging . info ( \"Number of processes: {} \" . format ( self . ncores )) # bool to check whether pypet was initialized properly self . initialized = False self . _initializeExploration ( self . filename ) self . results = None","title":"__init__()"},{"location":"exploration/boxsearch/#neurolib.optimize.exploration.exploration.BoxSearch.aggregateResultsToDfResults","text":"Aggregate all results in to dfResults dataframe. Parameters: Name Type Description Default arrays bool, optional Load array results (like timeseries) if True. If False, only load scalar results, defaults to True True fillna bool, optional Fill nan results (for example if they're not returned in a subset of runs) with zeros, default to False False Source code in neurolib/optimize/exploration/exploration.py def aggregateResultsToDfResults ( self , arrays = True , fillna = False ): \"\"\"Aggregate all results in to dfResults dataframe. :param arrays: Load array results (like timeseries) if True. If False, only load scalar results, defaults to True :type arrays: bool, optional :param fillna: Fill nan results (for example if they're not returned in a subset of runs) with zeros, default to False :type fillna: bool, optional \"\"\" nan_value = np . nan # defines which variable types will be saved in the results dataframe SUPPORTED_TYPES = ( float , int , np . ndarray , list ) SCALAR_TYPES = ( float , int ) ARRAY_TYPES = ( np . ndarray , list ) logging . info ( \"Aggregating results to `dfResults` ...\" ) for runId , parameters in tqdm . tqdm ( self . dfResults . iterrows (), total = len ( self . dfResults )): # if the results were previously loaded into memory, use them if hasattr ( self , \"results\" ): # only if the length matches the number of results if len ( self . results ) == len ( self . dfResults ): result = self . results [ runId ] # else, load results individually from hdf file else : result = self . getRun ( runId ) # else, load results individually from hdf file else : result = self . getRun ( runId ) for key , value in result . items (): # only save floats, ints and arrays if isinstance ( value , SUPPORTED_TYPES ): # save 1-dim arrays if isinstance ( value , ARRAY_TYPES ) and arrays : # to save a numpy array, convert column to object type if key not in self . dfResults : self . dfResults [ key ] = None self . dfResults [ key ] = self . dfResults [ key ] . astype ( object ) self . dfResults . at [ runId , key ] = value elif isinstance ( value , SCALAR_TYPES ): # save scalars self . dfResults . loc [ runId , key ] = value else : self . dfResults . loc [ runId , key ] = nan_value # drop nan columns self . dfResults = self . dfResults . dropna ( axis = \"columns\" , how = \"all\" ) if fillna : self . dfResults = self . dfResults . fillna ( 0 )","title":"aggregateResultsToDfResults()"},{"location":"exploration/boxsearch/#neurolib.optimize.exploration.exploration.BoxSearch.getModelFromTraj","text":"Return the appropriate model with parameters for this run Parameters: Name Type Description Default traj Pypet trajectory of current run required Returns: Type Description Model with the parameters of this run. Source code in neurolib/optimize/exploration/exploration.py def getModelFromTraj ( self , traj ): \"\"\"Return the appropriate model with parameters for this run :params traj: Pypet trajectory of current run :returns model: Model with the parameters of this run. \"\"\" model = self . model runParams = self . getParametersFromTraj ( traj ) # removes keys with None values # runParams = {k: v for k, v in runParams.items() if v is not None} if self . parameterSpace . star : runParams = flatten_nested_dict ( flat_dict_to_nested ( runParams )[ \"parameters\" ]) model . params . update ( runParams ) return model","title":"getModelFromTraj()"},{"location":"exploration/boxsearch/#neurolib.optimize.exploration.exploration.BoxSearch.getParametersFromTraj","text":"Returns the parameters of the current run as a (dot.able) dictionary Parameters: Name Type Description Default traj Union[`pypet.traject,y.Traject,y`] Pypet trajectory required Returns: Type Description dict Parameter set of the current run Source code in neurolib/optimize/exploration/exploration.py def getParametersFromTraj ( self , traj ): \"\"\"Returns the parameters of the current run as a (dot.able) dictionary :param traj: Pypet trajectory :type traj: `pypet.trajectory.Trajectory` :return: Parameter set of the current run :rtype: dict \"\"\" # DO NOT use short names for star notation dicts runParams = self . traj . parameters . f_to_dict ( short_names = not self . parameterSpace . star , fast_access = True ) runParams = self . _validatePypetParameters ( runParams ) return dotdict ( runParams )","title":"getParametersFromTraj()"},{"location":"exploration/boxsearch/#neurolib.optimize.exploration.exploration.BoxSearch.getResult","text":"Returns either a loaded result or reads from disk. Parameters: Name Type Description Default runId int runId of result required Returns: Type Description dict result Source code in neurolib/optimize/exploration/exploration.py def getResult ( self , runId ): \"\"\"Returns either a loaded result or reads from disk. :param runId: runId of result :type runId: int :return: result :rtype: dict \"\"\" # if hasattr(self, \"results\"): # # load result from either the preloaded .result attribute (from .loadResults) # result = self.results[runId] # else: # # or from disk if results haven't been loaded yet # result = self.getRun(runId) # load result from either the preloaded .result attribute (from .loadResults) # or from disk if results haven't been loaded yet # result = self.results[runId] if hasattr(self, \"results\") else self.getRun(runId) return self . results [ runId ] if hasattr ( self , \"results\" ) else self . getRun ( runId )","title":"getResult()"},{"location":"exploration/boxsearch/#neurolib.optimize.exploration.exploration.BoxSearch.getRun","text":"Load the simulated data of a run and its parameters from a pypetTrajectory. Parameters: Name Type Description Default runId int ID of the run required Returns: Type Description Dictionary with simulated data and parameters of the run. Source code in neurolib/optimize/exploration/exploration.py def getRun ( self , runId , filename = None , trajectoryName = None , pypetShortNames = True ): \"\"\"Load the simulated data of a run and its parameters from a pypetTrajectory. :param runId: ID of the run :type runId: int :return: Dictionary with simulated data and parameters of the run. :type return: dict \"\"\" # chose HDF file to load filename = self . HDF_FILE or filename # either use loaded pypetTrajectory or load from HDF file if it isn't available pypetTrajectory = ( self . pypetTrajectory if hasattr ( self , \"pypetTrajectory\" ) else pu . loadPypetTrajectory ( filename , trajectoryName ) ) # # if there was no pypetTrajectory loaded before # if pypetTrajectory is None: # # chose HDF file to load # filename = self.HDF_FILE or filename # pypetTrajectory = pu.loadPypetTrajectory(filename, trajectoryName) return pu . getRun ( runId , pypetTrajectory , pypetShortNames = pypetShortNames )","title":"getRun()"},{"location":"exploration/boxsearch/#neurolib.optimize.exploration.exploration.BoxSearch.info","text":"Print info about the current search. Source code in neurolib/optimize/exploration/exploration.py def info ( self ): \"\"\"Print info about the current search.\"\"\" now = datetime . datetime . now () . strftime ( \"%Y-%m- %d -%HH-%MM-%SS\" ) print ( f \"Exploration info ( { now } )\" ) print ( f \"HDF name: { self . HDF_FILE } \" ) print ( f \"Trajectory name: { self . trajectoryName } \" ) if self . model is not None : print ( f \"Model: { self . model . name } \" ) if hasattr ( self , \"nRuns\" ): print ( f \"Number of runs { self . nRuns } \" ) print ( f \"Explored parameters: { self . exploreParameters . keys () } \" ) if hasattr ( self , \"_t_end_exploration\" ) and hasattr ( self , \"_t_start_exploration\" ): print ( f \"Duration of exploration: { self . _t_end_exploration - self . _t_start_exploration } \" )","title":"info()"},{"location":"exploration/boxsearch/#neurolib.optimize.exploration.exploration.BoxSearch.loadDfResults","text":"Load results from a previous simulation. Parameters: Name Type Description Default filename str, optional hdf file name in which results are stored, defaults to None None trajectoryName str, optional Name of the trajectory inside the hdf file, newest will be used if left empty, defaults to None None Source code in neurolib/optimize/exploration/exploration.py def loadDfResults ( self , filename = None , trajectoryName = None ): \"\"\"Load results from a previous simulation. :param filename: hdf file name in which results are stored, defaults to None :type filename: str, optional :param trajectoryName: Name of the trajectory inside the hdf file, newest will be used if left empty, defaults to None :type trajectoryName: str, optional \"\"\" # chose HDF file to load filename = filename or self . HDF_FILE self . pypetTrajectory = pu . loadPypetTrajectory ( filename , trajectoryName ) self . nResults = len ( self . pypetTrajectory . f_get_run_names ()) exploredParameters = self . pypetTrajectory . f_get_explored_parameters () # create pandas dataframe of all runs with parameters as keys logging . info ( \"Creating `dfResults` dataframe ...\" ) niceParKeys = [ p [ 11 :] for p in exploredParameters . keys ()] if not self . parameterSpace : niceParKeys = [ p . split ( \".\" )[ - 1 ] for p in niceParKeys ] self . dfResults = pd . DataFrame ( columns = niceParKeys , dtype = object ) for nicep , p in zip ( niceParKeys , exploredParameters . keys ()): self . dfResults [ nicep ] = exploredParameters [ p ] . f_get_range ()","title":"loadDfResults()"},{"location":"exploration/boxsearch/#neurolib.optimize.exploration.exploration.BoxSearch.loadResults","text":"Load results from a hdf file of a previous simulation. Parameters: Name Type Description Default all bool, optional Load all simulated results into memory, which will be available as the .results attribute. Can use a lot of RAM if your simulation is large, please use this with caution. , defaults to True True filename str, optional hdf file name in which results are stored, defaults to None None trajectoryName str, optional Name of the trajectory inside the hdf file, newest will be used if left empty, defaults to None None pypetShortNames bool Use pypet short names as keys for the results dictionary. Use if you are experiencing errors due to natural naming collisions. True memory_cap float, int, optional Percentage memory cap between 0 and 100. If all=True is used, a memory cap can be set to avoid filling up the available RAM. Example: use memory_cap = 95 to avoid loading more data if memory is at 95% use, defaults to 95 95.0 Source code in neurolib/optimize/exploration/exploration.py def loadResults ( self , all = True , filename = None , trajectoryName = None , pypetShortNames = True , memory_cap = 95.0 ): \"\"\"Load results from a hdf file of a previous simulation. :param all: Load all simulated results into memory, which will be available as the `.results` attribute. Can use a lot of RAM if your simulation is large, please use this with caution. , defaults to True :type all: bool, optional :param filename: hdf file name in which results are stored, defaults to None :type filename: str, optional :param trajectoryName: Name of the trajectory inside the hdf file, newest will be used if left empty, defaults to None :type trajectoryName: str, optional :param pypetShortNames: Use pypet short names as keys for the results dictionary. Use if you are experiencing errors due to natural naming collisions. :type pypetShortNames: bool :param memory_cap: Percentage memory cap between 0 and 100. If `all=True` is used, a memory cap can be set to avoid filling up the available RAM. Example: use `memory_cap = 95` to avoid loading more data if memory is at 95% use, defaults to 95 :type memory_cap: float, int, optional \"\"\" self . loadDfResults ( filename , trajectoryName ) # make a list of dictionaries with results self . results = dotdict ({}) if all : logging . info ( \"Loading all results to `results` dictionary ...\" ) for rInd in tqdm . tqdm ( range ( self . nResults ), total = self . nResults ): # check if enough memory is available if memory_cap : assert isinstance ( memory_cap , ( int , float )), \"`memory_cap` must be float.\" assert ( memory_cap > 0 ) and ( memory_cap < 100 ), \"`memory_cap` must be between 0 and 100\" # check ram usage with psutil used_memory_percent = psutil . virtual_memory ()[ 2 ] if used_memory_percent > memory_cap : raise MemoryError ( f \"Memory use is at { used_memory_percent } % and capped at { memory_cap } . Aborting.\" ) self . pypetTrajectory . results [ rInd ] . f_load () result = self . pypetTrajectory . results [ rInd ] . f_to_dict ( fast_access = True , short_names = pypetShortNames ) result = dotdict ( result ) self . pypetTrajectory . results [ rInd ] . f_remove () self . results [ rInd ] = copy . deepcopy ( result ) # Postprocess result keys if pypet short names aren't used # Before: results.run_00000001.outputs.rates_inh # After: outputs.rates_inh if not pypetShortNames : for i , r in self . results . items (): new_dict = dotdict ({}) for key , value in r . items (): new_key = \"\" . join ( key . split ( \".\" , 2 )[ 2 :]) new_dict [ new_key ] = r [ key ] self . results [ i ] = copy . deepcopy ( new_dict ) self . aggregateResultsToDfResults () logging . info ( \"All results loaded.\" )","title":"loadResults()"},{"location":"exploration/boxsearch/#neurolib.optimize.exploration.exploration.BoxSearch.run","text":"Call this function to run the exploration Source code in neurolib/optimize/exploration/exploration.py def run ( self , ** kwargs ): \"\"\" Call this function to run the exploration \"\"\" self . runKwargs = kwargs assert self . initialized , \"Pypet environment not initialized yet.\" self . _t_start_exploration = datetime . datetime . now () self . env . run ( self . evalFunction ) self . _t_end_exploration = datetime . datetime . now ()","title":"run()"},{"location":"exploration/boxsearch/#neurolib.optimize.exploration.exploration.BoxSearch.saveToPypet","text":"This function takes simulation results in the form of a nested dictionary and stores all data into the pypet hdf file. Parameters: Name Type Description Default outputs dict Simulation outputs as a dictionary. required traj Union[`pypet.traject,y.Traject,y`] Pypet trajectory required Source code in neurolib/optimize/exploration/exploration.py def saveToPypet ( self , outputs , traj ): \"\"\"This function takes simulation results in the form of a nested dictionary and stores all data into the pypet hdf file. :param outputs: Simulation outputs as a dictionary. :type outputs: dict :param traj: Pypet trajectory :type traj: `pypet.trajectory.Trajectory` \"\"\" def makeSaveStringForPypet ( value , savestr ): \"\"\"Builds the pypet-style results string from the results dictionary's keys. \"\"\" for k , v in value . items (): if isinstance ( v , dict ): _savestr = savestr + k + \".\" makeSaveStringForPypet ( v , _savestr ) else : _savestr = savestr + k self . traj . f_add_result ( _savestr , v ) assert isinstance ( outputs , dict ), \"Outputs must be an instance of dict.\" value = outputs savestr = \"results.$.\" makeSaveStringForPypet ( value , savestr )","title":"saveToPypet()"},{"location":"exploration/boxsearch/#neurolib.optimize.exploration.exploration.BoxSearch.xr","text":"Return xr.Dataset from the exploration results. Parameters: Name Type Description Default bold bool if True, will load and return only BOLD output False Source code in neurolib/optimize/exploration/exploration.py def xr ( self , bold = False ): \"\"\" Return `xr.Dataset` from the exploration results. :param bold: if True, will load and return only BOLD output :type bold: bool \"\"\" def _sanitize_nc_key ( k ): return k . replace ( \"*\" , \"_\" ) . replace ( \".\" , \"_\" ) . replace ( \"|\" , \"_\" ) assert self . results is not None , \"Run `loadResults()` first to populate the results\" assert len ( self . results ) == len ( self . dfResults ) # create intrisinsic dims for one run timeDictKey , run_coords = self . _getCoordsFromRun ( self . results [ 0 ], bold = bold ) dataarrays = [] orig_search_coords = self . parameterSpace . get_parametrization () for runId , run_result in self . results . items (): # take exploration coordinates for this run expl_coords = { k : v [ runId ] for k , v in orig_search_coords . items ()} outputs = [] run_result = self . _filterDictionaryBold ( run_result , bold = bold ) for key , value in run_result . items (): if key == timeDictKey : continue outputs . append ( value ) # create DataArray for run only - we need to add exploration coordinates data_temp = xr . DataArray ( np . stack ( outputs ), dims = [ \"output\" , \"space\" , \"time\" ], coords = run_coords , name = \"exploration\" ) expand_coords = {} # iterate exploration coordinates for k , v in expl_coords . items (): # sanitize keys in the case of stars etc k = _sanitize_nc_key ( k ) # if single values, just assign if isinstance ( v , ( str , float , int )): expand_coords [ k ] = [ v ] # if arrays, check whether they can be squeezed into one value elif isinstance ( v , np . ndarray ): if np . unique ( v ) . size == 1 : # if yes, just assign that one value expand_coords [ k ] = [ float ( np . unique ( v ))] else : # if no, sorry - coordinates cannot be array raise ValueError ( \"Cannot squeeze coordinates\" ) # assing exploration coordinates to the DataArray dataarrays . append ( data_temp . expand_dims ( expand_coords )) # finally, combine all arrays into one if self . parameterSpace . kind == \"sequence\" : # when run in sequence, cannot combine to grid, so just concatenate along new dimension combined = xr . concat ( dataarrays , dim = \"run_no\" , coords = \"all\" ) else : # sometimes combining xr.DataArrays does not work, see https://github.com/pydata/xarray/issues/3248#issuecomment-531511177 # resolved by casting them explicitely to xr.Dataset combined = xr . combine_by_coords ([ da . to_dataset () for da in dataarrays ])[ \"exploration\" ] if self . parameterSpace . star : # if we explored over star params, unwrap them into attributes combined . attrs = { _sanitize_nc_key ( k ): list ( self . model . params [ k ] . keys ()) for k in orig_search_coords . keys () if \"*\" in k } return combined","title":"xr()"},{"location":"models/model/","text":"Models Models are the core of neurolib . The Model superclass will help you to load, simulate, and analyse models. It also makes it very easy to implement your own neural mass model (see Example 0.6 custom model ). Loading a model To load a model, we need to import the submodule of a model and instantiate it. This example shows how to load a single node of the ALNModel . See Example 0 aln minimal on how to simulate a whole-brain network using this model. from neurolib.models.aln import ALNModel # Import the model model = ALNModel() # Create an instance model.run() # Run it Model base class methods The Model base class runs models, manages their outputs, parameters and more. This class should serve as the base class for all implemented models. Source code in neurolib/models/model.py class Model : \"\"\"The Model base class runs models, manages their outputs, parameters and more. This class should serve as the base class for all implemented models. \"\"\" def __init__ ( self , integration , params ): if hasattr ( self , \"name\" ): if self . name is not None : assert isinstance ( self . name , str ), f \"Model name is not a string.\" else : self . name = \"Noname\" assert integration is not None , \"Model integration function not given.\" self . integration = integration assert isinstance ( params , dict ), \"Parameters must be a dictionary.\" self . params = dotdict ( params ) # assert self.state_vars not None: assert hasattr ( self , \"state_vars\" ), f \"Model { self . name } has no attribute `state_vars`, which should be alist of strings containing all variable names.\" assert np . all ([ type ( s ) is str for s in self . state_vars ]), \"All entries in state_vars must be strings.\" assert hasattr ( self , \"default_output\" ), f \"Model { self . name } needs to define a default output variable in `default_output`.\" assert isinstance ( self . default_output , str ), \"`default_output` must be a string.\" # if no output_vars is set, it will be replaced by state_vars if not hasattr ( self , \"output_vars\" ): self . output_vars = self . state_vars # create output and state dictionary self . outputs = dotdict ({}) self . state = dotdict ({}) self . maxDelay = None self . initializeRun () self . boldInitialized = False logging . info ( f \" { self . name } : Model initialized.\" ) def initializeBold ( self ): \"\"\"Initialize BOLD model.\"\"\" self . boldInitialized = False # function to transform model state before passing it to the bold model # Note: This can be used like the parameter \\epsilon in Friston2000 # (neural efficacy) by multiplying the input with a constant via # self.boldInputTransform = lambda x: x * epsilon if not hasattr ( self , \"boldInputTransform\" ): self . boldInputTransform = None self . boldModel = bold . BOLDModel ( self . params [ \"N\" ], self . params [ \"dt\" ]) self . boldInitialized = True # logging.info(f\"{self.name}: BOLD model initialized.\") def simulateBold ( self , t , variables , append = False ): \"\"\"Gets the default output of the model and simulates the BOLD model. Adds the simulated BOLD signal to outputs. \"\"\" if self . boldInitialized : # first we loop through all state variables for svn , sv in zip ( self . state_vars , variables ): # the default output is used as the input for the bold model if svn == self . default_output : bold_input = sv [:, self . startindt :] # logging.debug(f\"BOLD input `{svn}` of shape {bold_input.shape}\") if bold_input . shape [ 1 ] >= self . boldModel . samplingRate_NDt : # only if the length of the output has a zero mod to the sampling rate, # the downsampled output from the boldModel can correctly appended to previous data # so: we are lazy here and simply disable appending in that case ... if not bold_input . shape [ 1 ] % self . boldModel . samplingRate_NDt == 0 : append = False logging . warn ( f \"Output size { bold_input . shape [ 1 ] } is not a multiple of BOLD sampling length { self . boldModel . samplingRate_NDt } , will not append data.\" ) logging . debug ( f \"Simulating BOLD: boldModel.run(append= { append } )\" ) # transform bold input according to self.boldInputTransform if self . boldInputTransform : bold_input = self . boldInputTransform ( bold_input ) # simulate bold model self . boldModel . run ( bold_input , append = append ) t_BOLD = self . boldModel . t_BOLD BOLD = self . boldModel . BOLD self . setOutput ( \"BOLD.t_BOLD\" , t_BOLD ) self . setOutput ( \"BOLD.BOLD\" , BOLD ) else : logging . warn ( f \"Will not simulate BOLD if output { bold_input . shape [ 1 ] * self . params [ 'dt' ] } not at least of duration { self . boldModel . samplingRate_NDt * self . params [ 'dt' ] } \" ) else : logging . warn ( \"BOLD model not initialized, not simulating BOLD. Use `run(bold=True)`\" ) def checkChunkwise ( self , chunksize ): \"\"\"Checks if the model fulfills requirements for chunkwise simulation. Checks whether the sampling rate for outputs fits to chunksize and duration. Throws errors if not.\"\"\" assert self . state_vars is not None , \"State variable names not given.\" assert self . init_vars is not None , \"Initial value variable names not given.\" assert len ( self . state_vars ) == len ( self . init_vars ), \"State variables are not same length as initial values.\" # throw a warning if the user is nasty if int ( self . params [ \"duration\" ] / self . params [ \"dt\" ]) % chunksize != 0 : logging . warning ( f \"It is strongly advised to use a `chunksize` ( { chunksize } ) that is a divisor of `duration / dt` ( { int ( self . params [ 'duration' ] / self . params [ 'dt' ]) } ).\" ) # if `sampling_dt` is set, do some checks if self . params . get ( \"sampling_dt\" ) is not None : # sample_dt checks are required after setting chunksize assert ( chunksize * self . params [ \"dt\" ] >= self . params [ \"sampling_dt\" ] ), \"`chunksize * dt` must be >= `sampling_dt`\" # ugly floating point modulo hack: instead of float1%float2==0, we do # (float1/float2)%1==0 assert (( chunksize * self . params [ \"dt\" ]) / self . params [ \"sampling_dt\" ]) % 1 == 0 , ( f \"Chunksize { chunksize * self . params [ 'dt' ] } must be divisible by sampling dt \" f \" { self . params [ 'sampling_dt' ] } \" ) assert ( ( self . params [ \"duration\" ] % ( chunksize * self . params [ \"dt\" ])) / self . params [ \"sampling_dt\" ] ) % 1 == 0 , ( f \"Last chunk of size { self . params [ 'duration' ] % ( chunksize * self . params [ 'dt' ]) } must be divisible by sampling dt \" f \" { self . params [ 'sampling_dt' ] } \" ) def setSamplingDt ( self ): \"\"\"Checks if sampling_dt is set correctly and sets self.`sample_every` 1) Check if sampling_dt is multiple of dt 2) Check if semplind_dt is greater than duration \"\"\" if self . params . get ( \"sampling_dt\" ) is None : self . sample_every = 1 elif self . params . get ( \"sampling_dt\" ) > 0 : assert self . params [ \"sampling_dt\" ] >= self . params [ \"dt\" ], \"`sampling_dt` needs to be >= `dt`\" assert ( self . params [ \"duration\" ] >= self . params [ \"sampling_dt\" ] ), \"`sampling_dt` needs to be lower than `duration`\" self . sample_every = int ( self . params [ \"sampling_dt\" ] / self . params [ \"dt\" ]) else : raise ValueError ( f \"Can't handle `sampling_dt`= { self . params . get ( 'sampling_dt' ) } \" ) def initializeRun ( self , initializeBold = False ): \"\"\"Initialization before each run. :param initializeBold: initialize BOLD model :type initializeBold: bool \"\"\" # get the maxDelay of the system self . maxDelay = self . getMaxDelay () # length of the initial condition self . startindt = self . maxDelay + 1 # check dt / sampling_dt self . setSamplingDt () # force bold if params['bold'] == True if self . params . get ( \"bold\" ): initializeBold = True # set up the bold model, if it didn't happen yet if initializeBold and not self . boldInitialized : self . initializeBold () def run ( self , inputs = None , chunkwise = False , chunksize = None , bold = False , append = False , append_outputs = None , continue_run = False , ): \"\"\" Main interfacing function to run a model. The model can be run in three different ways: 1) `model.run()` starts a new run. 2) `model.run(chunkwise=True)` runs the simulation in chunks of length `chunksize`. 3) `mode.run(continue_run=True)` continues the simulation of a previous run. :param inputs: list of inputs to the model, must have the same order as model.input_vars. Note: no sanity check is performed for performance reasons. Take care of the inputs yourself. :type inputs: list[np.ndarray|] :param chunkwise: simulate model chunkwise or in one single run, defaults to False :type chunkwise: bool, optional :param chunksize: size of the chunk to simulate in dt, if set will imply chunkwise=True, defaults to 2s :type chunksize: int, optional :param bold: simulate BOLD signal (only for chunkwise integration), defaults to False :type bold: bool, optional :param append: append the chunkwise outputs to the outputs attribute, defaults to False, defaults to False :type append: bool, optional :param continue_run: continue a simulation by using the initial values from a previous simulation :type continue_run: bool \"\"\" # TODO: legacy argument support if append_outputs is not None : append = append_outputs # if a previous run is not to be continued clear the model's state if continue_run is False : self . clearModelState () self . initializeRun ( initializeBold = bold ) # enable chunkwise if chunksize is set chunkwise = chunkwise if chunksize is None else True if chunkwise is False : self . integrate ( append_outputs = append , simulate_bold = bold ) if continue_run : self . setInitialValuesToLastState () else : if chunksize is None : chunksize = int ( 2000 / self . params [ \"dt\" ]) # check if model is safe for chunkwise integration # and whether sampling_dt is compatible with duration and chunksize self . checkChunkwise ( chunksize ) if bold and not self . boldInitialized : logging . warn ( f \" { self . name } : BOLD model not initialized, not simulating BOLD. Use `run(bold=True)`\" ) bold = False self . integrateChunkwise ( chunksize = chunksize , bold = bold , append_outputs = append ) # check if there was a problem with the simulated data self . checkOutputs () def checkOutputs ( self ): # check nans in output if np . isnan ( self . output ) . any (): logging . error ( \"nan in model output!\" ) else : EXPLOSION_THRESHOLD = 1e20 if ( self . output > EXPLOSION_THRESHOLD ) . any () > 0 : logging . error ( \"nan in model output!\" ) # check nans in BOLD if \"BOLD\" in self . outputs : if np . isnan ( self . outputs . BOLD . BOLD ) . any (): logging . error ( \"nan in BOLD output!\" ) def integrate ( self , append_outputs = False , simulate_bold = False ): \"\"\"Calls each models `integration` function and saves the state and the outputs of the model. :param append: append the chunkwise outputs to the outputs attribute, defaults to False, defaults to False :type append: bool, optional \"\"\" # run integration t , * variables = self . integration ( self . params ) self . storeOutputsAndStates ( t , variables , append = append_outputs ) # force bold if params['bold'] == True if self . params . get ( \"bold\" ): simulate_bold = True # bold simulation after integration if simulate_bold and self . boldInitialized : self . simulateBold ( t , variables , append = True ) def integrateChunkwise ( self , chunksize , bold = False , append_outputs = False ): \"\"\"Repeatedly calls the chunkwise integration for the whole duration of the simulation. If `bold==True`, the BOLD model is simulated after each chunk. :param chunksize: size of each chunk to simulate in units of dt :type chunksize: int :param bold: simulate BOLD model after each chunk, defaults to False :type bold: bool, optional :param append_outputs: append the chunkwise outputs to the outputs attribute, defaults to False :type append_outputs: bool, optional \"\"\" totalDuration = self . params [ \"duration\" ] dt = self . params [ \"dt\" ] # create a shallow copy of the parameters lastT = 0 while totalDuration - lastT >= dt - 1e-6 : # Determine the size of the next chunk # account for floating point errors remainingChunkSize = int ( round (( totalDuration - lastT ) / dt )) currentChunkSize = min ( chunksize , remainingChunkSize ) self . autochunk ( chunksize = currentChunkSize , append_outputs = append_outputs , bold = bold ) # we save the last simulated time step lastT += currentChunkSize * dt # or # lastT = self.state[\"t\"][-1] # set duration back to its original value self . params [ \"duration\" ] = totalDuration def clearModelState ( self ): \"\"\"Clears the model's state to create a fresh one\"\"\" self . state = dotdict ({}) self . outputs = dotdict ({}) # reinitialize bold model if self . params . get ( \"bold\" ): self . initializeBold () def storeOutputsAndStates ( self , t , variables , append = False ): \"\"\"Takes the simulated variables of the integration and stores it to the appropriate model output and state object. :param t: time vector :type t: list :param variables: variable from time integration :type variables: numpy.ndarray :param append: append output to existing output or overwrite, defaults to False :type append: bool, optional \"\"\" # save time array self . setOutput ( \"t\" , t , append = append , removeICs = True ) self . setStateVariables ( \"t\" , t ) # save outputs for svn , sv in zip ( self . state_vars , variables ): if svn in self . output_vars : self . setOutput ( svn , sv , append = append , removeICs = True ) self . setStateVariables ( svn , sv ) def setInitialValuesToLastState ( self ): \"\"\"Reads the last state of the model and sets the initial conditions to that state for continuing a simulation.\"\"\" for iv , sv in zip ( self . init_vars , self . state_vars ): # if state variables are one-dimensional (in space only) if ( self . state [ sv ] . ndim == 0 ) or ( self . state [ sv ] . ndim == 1 ): self . params [ iv ] = self . state [ sv ] # if they are space-time arrays else : # we set the next initial condition to the last state self . params [ iv ] = self . state [ sv ][:, - self . startindt :] def randomICs ( self , min = 0 , max = 1 ): \"\"\"Generates a new set of uniformly-distributed random initial conditions for the model. TODO: All parameters are drawn from the same distribution / range. Allow for independent ranges. :param min: Minium of uniform distribution :type min: float :param max: Maximum of uniform distribution :type max: float \"\"\" for iv in self . init_vars : if self . params [ iv ] . ndim == 1 : self . params [ iv ] = np . random . uniform ( min , max , ( self . params [ \"N\" ])) elif self . params [ iv ] . ndim == 2 : self . params [ iv ] = np . random . uniform ( min , max , ( self . params [ \"N\" ], 1 )) def setInputs ( self , inputs ): \"\"\"Take inputs from a list and store it in the appropriate model parameter for external input. TODO: This is not safe yet, checks should be implemented whether the model has inputs defined or not for example. :param inputs: list of inputs :type inputs: list[np.ndarray(), ...] \"\"\" for i , iv in enumerate ( self . input_vars ): self . params [ iv ] = inputs [ i ] . copy () def autochunk ( self , inputs = None , chunksize = 1 , append_outputs = False , bold = False ): \"\"\"Executes a single chunk of integration, either for a given duration or a single timestep `dt`. Gathers all inputs to the model and resets the initial conditions as a preparation for the next chunk. :param inputs: list of input values, ordered according to self.input_vars, defaults to None :type inputs: list[np.ndarray|], optional :param chunksize: length of a chunk to simulate in dt, defaults 1 :type chunksize: int, optional :param append_outputs: append the chunkwise outputs to the outputs attribute, defaults to False :type append_outputs: bool, optional \"\"\" # set the duration for this chunk self . params [ \"duration\" ] = chunksize * self . params [ \"dt\" ] # set inputs if inputs is not None : self . setInputs ( inputs ) # run integration self . integrate ( append_outputs = append_outputs , simulate_bold = bold ) # set initial conditions to last state for the next chunk self . setInitialValuesToLastState () def getMaxDelay ( self ): \"\"\"Computes the maximum delay of the model. This function should be overloaded if the model has internal delays (additional to delay between nodes defined by Dmat) such as the delay between an excitatory and inhibitory population within each brain area. If this function is not overloaded, the maximum delay is assumed to be defined from the global delay matrix `Dmat`. Note: Maxmimum delay is given in units of dt. :return: maxmimum delay of the model in units of dt :rtype: int \"\"\" dt = self . params . get ( \"dt\" ) Dmat = self . params . get ( \"lengthMat\" ) if Dmat is not None : # divide Dmat by signalV signalV = self . params . get ( \"signalV\" ) or 0 if signalV > 0 : Dmat = Dmat / signalV else : # if signalV is 0, eliminate delays Dmat = Dmat * 0.0 # only if Dmat and dt exist, a global max delay can be computed if Dmat is not None and dt is not None : Dmat_ndt = np . around ( Dmat / dt ) # delay matrix in multiples of dt max_global_delay = int ( np . amax ( Dmat_ndt )) else : max_global_delay = 0 return max_global_delay def setStateVariables ( self , name , data ): \"\"\"Saves the models current state variables. TODO: Cut state variables to length of self.maxDelay However, this could be time-memory tradeoff :param name: name of the state variable :type name: str :param data: value of the variable :type data: np.ndarray \"\"\" # old # self.state[name] = data.copy() # if the data is temporal, cut off initial values # NOTE: this shuold actually check for # if data.shape[1] > 1: # else: data.copy() # there coulb be (N, 1)-dimensional output, right now # it is requred to be of shape (N, ) if data . ndim == 2 : self . state [ name ] = data [:, - self . startindt :] . copy () else : self . state [ name ] = data . copy () def setOutput ( self , name , data , append = False , removeICs = False ): \"\"\"Adds an output to the model, typically a simulation result. :params name: Name of the output in dot.notation, a la \"outputgroup.output\" :type name: str :params data: Output data, can't be a dictionary! :type data: `numpy.ndarray` \"\"\" assert not isinstance ( data , dict ), \"Output data cannot be a dictionary.\" assert isinstance ( name , str ), \"Output name must be a string.\" assert isinstance ( data , np . ndarray ), \"Output must be a `numpy.ndarray`.\" # remove initial conditions from output if removeICs and name != \"t\" : if data . ndim == 1 : data = data [ self . startindt :] elif data . ndim == 2 : data = data [:, self . startindt :] else : raise ValueError ( f \"Don't know how to truncate data of shape { data . shape } .\" ) # subsample to sampling dt if data . ndim == 1 : data = data [:: self . sample_every ] elif data . ndim == 2 : data = data [:, :: self . sample_every ] else : raise ValueError ( f \"Don't know how to subsample data of shape { data . shape } .\" ) # if the output is a single name (not dot.separated) if \".\" not in name : # append data if append and name in self . outputs : # special treatment for time data: # increment the time by the last recorded duration if name == \"t\" : data += self . outputs [ name ][ - 1 ] self . outputs [ name ] = np . hstack (( self . outputs [ name ], data )) else : # save all data into output dict self . outputs [ name ] = data # set output as an attribute setattr ( self , name , self . outputs [ name ]) else : # build results dictionary and write into self.outputs # dot.notation iteration keys = name . split ( \".\" ) level = self . outputs # not copy, reference! for i , k in enumerate ( keys ): # if it's the last iteration, store data if i == len ( keys ) - 1 : # TODO: this needs to be append-aware like above # if append: # if k == \"t\": # data += level[k][-1] # level[k] = np.hstack((level[k], data)) # else: # level[k] = data level [ k ] = data # if key is in outputs, then go deeper elif k in level : level = level [ k ] setattr ( self , k , level ) # if it's a new key, create new nested dictionary, set attribute, then go deeper else : level [ k ] = dotdict ({}) setattr ( self , k , level [ k ]) level = level [ k ] def getOutput ( self , name ): \"\"\"Get an output of a given name (dot.semarated) :param name: A key, grouped outputs in the form group.subgroup.variable :type name: str :returns: Output data \"\"\" assert isinstance ( name , str ), \"Output name must be a string.\" keys = name . split ( \".\" ) lastOutput = self . outputs . copy () for i , k in enumerate ( keys ): assert k in lastOutput , f \"Key { k } not found in outputs.\" lastOutput = lastOutput [ k ] return lastOutput def __getitem__ ( self , key ): \"\"\"Index outputs with a dictionary-like key, e.g., `model['rates_exc']`.\"\"\" return self . getOutput ( key ) def getOutputs ( self , group = \"\" ): \"\"\"Get all outputs of an output group. Examples: `getOutputs(\"BOLD\")` or simply `getOutputs()` :param group: Group name, subgroups separated by dots. If left empty (default), all outputs of the root group are returned. :type group: str \"\"\" assert isinstance ( group , str ), \"Group name must be a string.\" def filterOutputsFromGroupDict ( groupDict ): \"\"\"Return a dictionary with the output data of a group disregarding all other nested dicts. :param groupDict: Dictionary of outputs (can include other groups) :type groupDict: dict \"\"\" assert isinstance ( groupDict , dict ), \"Not a dictionary.\" # make a deep copy of the dictionary returnDict = groupDict . copy () for key , value in groupDict . items (): if isinstance ( value , dict ): del returnDict [ key ] return returnDict # if a group deeper than the root is given, select the last node lastOutput = self . outputs . copy () if len ( group ) > 0 : keys = group . split ( \".\" ) for i , k in enumerate ( keys ): assert k in lastOutput , f \"Key { k } not found in outputs.\" lastOutput = lastOutput [ k ] assert isinstance ( lastOutput , dict ), f \"Key { k } does not refer to a group.\" # filter out all output *groups* that might be in this node and return only output data return filterOutputsFromGroupDict ( lastOutput ) @property def output ( self ): \"\"\"Returns value of default output as defined by `self.default_output`. Note that all outputs are saved in the attribute `self.outputs`. \"\"\" assert self . default_output is not None , \"Default output has not been set yet. Use `setDefaultOutput()`.\" return self . getOutput ( self . default_output ) def xr ( self , group = \"\" ): \"\"\"Converts a group of outputs to xarray. Output group needs to contain an element that starts with the letter \"t\" or it will not recognize any time axis. :param group: Output group name, example: \"BOLD\". Leave empty for top group. :type group: str \"\"\" assert isinstance ( group , str ), \"Group name must be a string.\" # take all outputs of one group: disregard all dictionaries because they are subgroups outputDict = self . getOutputs ( group ) # make sure that there is a time array timeDictKey = \"\" if \"t\" in outputDict : timeDictKey = \"t\" else : for k in outputDict : if k . startswith ( \"t\" ): timeDictKey = k logging . info ( f \"Assuming { k } to be the time axis.\" ) break assert len ( timeDictKey ) > 0 , f \"No time array found (starting with t) in output group { group } .\" t = outputDict [ timeDictKey ] . copy () del outputDict [ timeDictKey ] outputs = [] outputNames = [] for key , value in outputDict . items (): outputNames . append ( key ) outputs . append ( value ) nNodes = outputs [ 0 ] . shape [ 0 ] nodes = list ( range ( nNodes )) allOutputsStacked = np . stack ( outputs ) # What? Where? When? result = xr . DataArray ( allOutputsStacked , coords = [ outputNames , nodes , t ], dims = [ \"output\" , \"space\" , \"time\" ]) return result output property readonly Returns value of default output as defined by self.default_output . Note that all outputs are saved in the attribute self.outputs . __getitem__ ( self , key ) special Index outputs with a dictionary-like key, e.g., model['rates_exc'] . Source code in neurolib/models/model.py def __getitem__ ( self , key ): \"\"\"Index outputs with a dictionary-like key, e.g., `model['rates_exc']`.\"\"\" return self . getOutput ( key ) autochunk ( self , inputs = None , chunksize = 1 , append_outputs = False , bold = False ) Executes a single chunk of integration, either for a given duration or a single timestep dt . Gathers all inputs to the model and resets the initial conditions as a preparation for the next chunk. Parameters: Name Type Description Default inputs list[np.ndarray|], optional list of input values, ordered according to self.input_vars, defaults to None None chunksize int, optional length of a chunk to simulate in dt, defaults 1 1 append_outputs bool, optional append the chunkwise outputs to the outputs attribute, defaults to False False Source code in neurolib/models/model.py def autochunk ( self , inputs = None , chunksize = 1 , append_outputs = False , bold = False ): \"\"\"Executes a single chunk of integration, either for a given duration or a single timestep `dt`. Gathers all inputs to the model and resets the initial conditions as a preparation for the next chunk. :param inputs: list of input values, ordered according to self.input_vars, defaults to None :type inputs: list[np.ndarray|], optional :param chunksize: length of a chunk to simulate in dt, defaults 1 :type chunksize: int, optional :param append_outputs: append the chunkwise outputs to the outputs attribute, defaults to False :type append_outputs: bool, optional \"\"\" # set the duration for this chunk self . params [ \"duration\" ] = chunksize * self . params [ \"dt\" ] # set inputs if inputs is not None : self . setInputs ( inputs ) # run integration self . integrate ( append_outputs = append_outputs , simulate_bold = bold ) # set initial conditions to last state for the next chunk self . setInitialValuesToLastState () checkChunkwise ( self , chunksize ) Checks if the model fulfills requirements for chunkwise simulation. Checks whether the sampling rate for outputs fits to chunksize and duration. Throws errors if not. Source code in neurolib/models/model.py def checkChunkwise ( self , chunksize ): \"\"\"Checks if the model fulfills requirements for chunkwise simulation. Checks whether the sampling rate for outputs fits to chunksize and duration. Throws errors if not.\"\"\" assert self . state_vars is not None , \"State variable names not given.\" assert self . init_vars is not None , \"Initial value variable names not given.\" assert len ( self . state_vars ) == len ( self . init_vars ), \"State variables are not same length as initial values.\" # throw a warning if the user is nasty if int ( self . params [ \"duration\" ] / self . params [ \"dt\" ]) % chunksize != 0 : logging . warning ( f \"It is strongly advised to use a `chunksize` ( { chunksize } ) that is a divisor of `duration / dt` ( { int ( self . params [ 'duration' ] / self . params [ 'dt' ]) } ).\" ) # if `sampling_dt` is set, do some checks if self . params . get ( \"sampling_dt\" ) is not None : # sample_dt checks are required after setting chunksize assert ( chunksize * self . params [ \"dt\" ] >= self . params [ \"sampling_dt\" ] ), \"`chunksize * dt` must be >= `sampling_dt`\" # ugly floating point modulo hack: instead of float1%float2==0, we do # (float1/float2)%1==0 assert (( chunksize * self . params [ \"dt\" ]) / self . params [ \"sampling_dt\" ]) % 1 == 0 , ( f \"Chunksize { chunksize * self . params [ 'dt' ] } must be divisible by sampling dt \" f \" { self . params [ 'sampling_dt' ] } \" ) assert ( ( self . params [ \"duration\" ] % ( chunksize * self . params [ \"dt\" ])) / self . params [ \"sampling_dt\" ] ) % 1 == 0 , ( f \"Last chunk of size { self . params [ 'duration' ] % ( chunksize * self . params [ 'dt' ]) } must be divisible by sampling dt \" f \" { self . params [ 'sampling_dt' ] } \" ) clearModelState ( self ) Clears the model's state to create a fresh one Source code in neurolib/models/model.py def clearModelState ( self ): \"\"\"Clears the model's state to create a fresh one\"\"\" self . state = dotdict ({}) self . outputs = dotdict ({}) # reinitialize bold model if self . params . get ( \"bold\" ): self . initializeBold () getMaxDelay ( self ) Computes the maximum delay of the model. This function should be overloaded if the model has internal delays (additional to delay between nodes defined by Dmat) such as the delay between an excitatory and inhibitory population within each brain area. If this function is not overloaded, the maximum delay is assumed to be defined from the global delay matrix Dmat . Note: Maxmimum delay is given in units of dt. Returns: Type Description int maxmimum delay of the model in units of dt Source code in neurolib/models/model.py def getMaxDelay ( self ): \"\"\"Computes the maximum delay of the model. This function should be overloaded if the model has internal delays (additional to delay between nodes defined by Dmat) such as the delay between an excitatory and inhibitory population within each brain area. If this function is not overloaded, the maximum delay is assumed to be defined from the global delay matrix `Dmat`. Note: Maxmimum delay is given in units of dt. :return: maxmimum delay of the model in units of dt :rtype: int \"\"\" dt = self . params . get ( \"dt\" ) Dmat = self . params . get ( \"lengthMat\" ) if Dmat is not None : # divide Dmat by signalV signalV = self . params . get ( \"signalV\" ) or 0 if signalV > 0 : Dmat = Dmat / signalV else : # if signalV is 0, eliminate delays Dmat = Dmat * 0.0 # only if Dmat and dt exist, a global max delay can be computed if Dmat is not None and dt is not None : Dmat_ndt = np . around ( Dmat / dt ) # delay matrix in multiples of dt max_global_delay = int ( np . amax ( Dmat_ndt )) else : max_global_delay = 0 return max_global_delay getOutput ( self , name ) Get an output of a given name (dot.semarated) Parameters: Name Type Description Default name str A key, grouped outputs in the form group.subgroup.variable required Returns: Type Description Output data Source code in neurolib/models/model.py def getOutput ( self , name ): \"\"\"Get an output of a given name (dot.semarated) :param name: A key, grouped outputs in the form group.subgroup.variable :type name: str :returns: Output data \"\"\" assert isinstance ( name , str ), \"Output name must be a string.\" keys = name . split ( \".\" ) lastOutput = self . outputs . copy () for i , k in enumerate ( keys ): assert k in lastOutput , f \"Key { k } not found in outputs.\" lastOutput = lastOutput [ k ] return lastOutput getOutputs ( self , group = '' ) Get all outputs of an output group. Examples: getOutputs(\"BOLD\") or simply getOutputs() Parameters: Name Type Description Default group str Group name, subgroups separated by dots. If left empty (default), all outputs of the root group are returned. '' Source code in neurolib/models/model.py def getOutputs ( self , group = \"\" ): \"\"\"Get all outputs of an output group. Examples: `getOutputs(\"BOLD\")` or simply `getOutputs()` :param group: Group name, subgroups separated by dots. If left empty (default), all outputs of the root group are returned. :type group: str \"\"\" assert isinstance ( group , str ), \"Group name must be a string.\" def filterOutputsFromGroupDict ( groupDict ): \"\"\"Return a dictionary with the output data of a group disregarding all other nested dicts. :param groupDict: Dictionary of outputs (can include other groups) :type groupDict: dict \"\"\" assert isinstance ( groupDict , dict ), \"Not a dictionary.\" # make a deep copy of the dictionary returnDict = groupDict . copy () for key , value in groupDict . items (): if isinstance ( value , dict ): del returnDict [ key ] return returnDict # if a group deeper than the root is given, select the last node lastOutput = self . outputs . copy () if len ( group ) > 0 : keys = group . split ( \".\" ) for i , k in enumerate ( keys ): assert k in lastOutput , f \"Key { k } not found in outputs.\" lastOutput = lastOutput [ k ] assert isinstance ( lastOutput , dict ), f \"Key { k } does not refer to a group.\" # filter out all output *groups* that might be in this node and return only output data return filterOutputsFromGroupDict ( lastOutput ) initializeBold ( self ) Initialize BOLD model. Source code in neurolib/models/model.py def initializeBold ( self ): \"\"\"Initialize BOLD model.\"\"\" self . boldInitialized = False # function to transform model state before passing it to the bold model # Note: This can be used like the parameter \\epsilon in Friston2000 # (neural efficacy) by multiplying the input with a constant via # self.boldInputTransform = lambda x: x * epsilon if not hasattr ( self , \"boldInputTransform\" ): self . boldInputTransform = None self . boldModel = bold . BOLDModel ( self . params [ \"N\" ], self . params [ \"dt\" ]) self . boldInitialized = True initializeRun ( self , initializeBold = False ) Initialization before each run. Parameters: Name Type Description Default initializeBold bool initialize BOLD model False Source code in neurolib/models/model.py def initializeRun ( self , initializeBold = False ): \"\"\"Initialization before each run. :param initializeBold: initialize BOLD model :type initializeBold: bool \"\"\" # get the maxDelay of the system self . maxDelay = self . getMaxDelay () # length of the initial condition self . startindt = self . maxDelay + 1 # check dt / sampling_dt self . setSamplingDt () # force bold if params['bold'] == True if self . params . get ( \"bold\" ): initializeBold = True # set up the bold model, if it didn't happen yet if initializeBold and not self . boldInitialized : self . initializeBold () integrate ( self , append_outputs = False , simulate_bold = False ) Calls each models integration function and saves the state and the outputs of the model. Parameters: Name Type Description Default append bool, optional append the chunkwise outputs to the outputs attribute, defaults to False, defaults to False required Source code in neurolib/models/model.py def integrate ( self , append_outputs = False , simulate_bold = False ): \"\"\"Calls each models `integration` function and saves the state and the outputs of the model. :param append: append the chunkwise outputs to the outputs attribute, defaults to False, defaults to False :type append: bool, optional \"\"\" # run integration t , * variables = self . integration ( self . params ) self . storeOutputsAndStates ( t , variables , append = append_outputs ) # force bold if params['bold'] == True if self . params . get ( \"bold\" ): simulate_bold = True # bold simulation after integration if simulate_bold and self . boldInitialized : self . simulateBold ( t , variables , append = True ) integrateChunkwise ( self , chunksize , bold = False , append_outputs = False ) Repeatedly calls the chunkwise integration for the whole duration of the simulation. If bold==True , the BOLD model is simulated after each chunk. Parameters: Name Type Description Default chunksize int size of each chunk to simulate in units of dt required bold bool, optional simulate BOLD model after each chunk, defaults to False False append_outputs bool, optional append the chunkwise outputs to the outputs attribute, defaults to False False Source code in neurolib/models/model.py def integrateChunkwise ( self , chunksize , bold = False , append_outputs = False ): \"\"\"Repeatedly calls the chunkwise integration for the whole duration of the simulation. If `bold==True`, the BOLD model is simulated after each chunk. :param chunksize: size of each chunk to simulate in units of dt :type chunksize: int :param bold: simulate BOLD model after each chunk, defaults to False :type bold: bool, optional :param append_outputs: append the chunkwise outputs to the outputs attribute, defaults to False :type append_outputs: bool, optional \"\"\" totalDuration = self . params [ \"duration\" ] dt = self . params [ \"dt\" ] # create a shallow copy of the parameters lastT = 0 while totalDuration - lastT >= dt - 1e-6 : # Determine the size of the next chunk # account for floating point errors remainingChunkSize = int ( round (( totalDuration - lastT ) / dt )) currentChunkSize = min ( chunksize , remainingChunkSize ) self . autochunk ( chunksize = currentChunkSize , append_outputs = append_outputs , bold = bold ) # we save the last simulated time step lastT += currentChunkSize * dt # or # lastT = self.state[\"t\"][-1] # set duration back to its original value self . params [ \"duration\" ] = totalDuration randomICs ( self , min = 0 , max = 1 ) Generates a new set of uniformly-distributed random initial conditions for the model. TODO: All parameters are drawn from the same distribution / range. Allow for independent ranges. Parameters: Name Type Description Default min float Minium of uniform distribution 0 max float Maximum of uniform distribution 1 Source code in neurolib/models/model.py def randomICs ( self , min = 0 , max = 1 ): \"\"\"Generates a new set of uniformly-distributed random initial conditions for the model. TODO: All parameters are drawn from the same distribution / range. Allow for independent ranges. :param min: Minium of uniform distribution :type min: float :param max: Maximum of uniform distribution :type max: float \"\"\" for iv in self . init_vars : if self . params [ iv ] . ndim == 1 : self . params [ iv ] = np . random . uniform ( min , max , ( self . params [ \"N\" ])) elif self . params [ iv ] . ndim == 2 : self . params [ iv ] = np . random . uniform ( min , max , ( self . params [ \"N\" ], 1 )) run ( self , inputs = None , chunkwise = False , chunksize = None , bold = False , append = False , append_outputs = None , continue_run = False ) Main interfacing function to run a model. The model can be run in three different ways: 1) model.run() starts a new run. 2) model.run(chunkwise=True) runs the simulation in chunks of length chunksize . 3) mode.run(continue_run=True) continues the simulation of a previous run. Parameters: Name Type Description Default inputs list[np.ndarray|] list of inputs to the model, must have the same order as model.input_vars. Note: no sanity check is performed for performance reasons. Take care of the inputs yourself. None chunkwise bool, optional simulate model chunkwise or in one single run, defaults to False False chunksize int, optional size of the chunk to simulate in dt, if set will imply chunkwise=True, defaults to 2s None bold bool, optional simulate BOLD signal (only for chunkwise integration), defaults to False False append bool, optional append the chunkwise outputs to the outputs attribute, defaults to False, defaults to False False continue_run bool continue a simulation by using the initial values from a previous simulation False Source code in neurolib/models/model.py def run ( self , inputs = None , chunkwise = False , chunksize = None , bold = False , append = False , append_outputs = None , continue_run = False , ): \"\"\" Main interfacing function to run a model. The model can be run in three different ways: 1) `model.run()` starts a new run. 2) `model.run(chunkwise=True)` runs the simulation in chunks of length `chunksize`. 3) `mode.run(continue_run=True)` continues the simulation of a previous run. :param inputs: list of inputs to the model, must have the same order as model.input_vars. Note: no sanity check is performed for performance reasons. Take care of the inputs yourself. :type inputs: list[np.ndarray|] :param chunkwise: simulate model chunkwise or in one single run, defaults to False :type chunkwise: bool, optional :param chunksize: size of the chunk to simulate in dt, if set will imply chunkwise=True, defaults to 2s :type chunksize: int, optional :param bold: simulate BOLD signal (only for chunkwise integration), defaults to False :type bold: bool, optional :param append: append the chunkwise outputs to the outputs attribute, defaults to False, defaults to False :type append: bool, optional :param continue_run: continue a simulation by using the initial values from a previous simulation :type continue_run: bool \"\"\" # TODO: legacy argument support if append_outputs is not None : append = append_outputs # if a previous run is not to be continued clear the model's state if continue_run is False : self . clearModelState () self . initializeRun ( initializeBold = bold ) # enable chunkwise if chunksize is set chunkwise = chunkwise if chunksize is None else True if chunkwise is False : self . integrate ( append_outputs = append , simulate_bold = bold ) if continue_run : self . setInitialValuesToLastState () else : if chunksize is None : chunksize = int ( 2000 / self . params [ \"dt\" ]) # check if model is safe for chunkwise integration # and whether sampling_dt is compatible with duration and chunksize self . checkChunkwise ( chunksize ) if bold and not self . boldInitialized : logging . warn ( f \" { self . name } : BOLD model not initialized, not simulating BOLD. Use `run(bold=True)`\" ) bold = False self . integrateChunkwise ( chunksize = chunksize , bold = bold , append_outputs = append ) # check if there was a problem with the simulated data self . checkOutputs () setInitialValuesToLastState ( self ) Reads the last state of the model and sets the initial conditions to that state for continuing a simulation. Source code in neurolib/models/model.py def setInitialValuesToLastState ( self ): \"\"\"Reads the last state of the model and sets the initial conditions to that state for continuing a simulation.\"\"\" for iv , sv in zip ( self . init_vars , self . state_vars ): # if state variables are one-dimensional (in space only) if ( self . state [ sv ] . ndim == 0 ) or ( self . state [ sv ] . ndim == 1 ): self . params [ iv ] = self . state [ sv ] # if they are space-time arrays else : # we set the next initial condition to the last state self . params [ iv ] = self . state [ sv ][:, - self . startindt :] setInputs ( self , inputs ) Take inputs from a list and store it in the appropriate model parameter for external input. TODO: This is not safe yet, checks should be implemented whether the model has inputs defined or not for example. Parameters: Name Type Description Default inputs list[np.ndarray(), ...] list of inputs required Source code in neurolib/models/model.py def setInputs ( self , inputs ): \"\"\"Take inputs from a list and store it in the appropriate model parameter for external input. TODO: This is not safe yet, checks should be implemented whether the model has inputs defined or not for example. :param inputs: list of inputs :type inputs: list[np.ndarray(), ...] \"\"\" for i , iv in enumerate ( self . input_vars ): self . params [ iv ] = inputs [ i ] . copy () setOutput ( self , name , data , append = False , removeICs = False ) Adds an output to the model, typically a simulation result. Parameters: Name Type Description Default name str Name of the output in dot.notation, a la \"outputgroup.output\" required data `numpy.ndarray` Output data, can't be a dictionary! required Source code in neurolib/models/model.py def setOutput ( self , name , data , append = False , removeICs = False ): \"\"\"Adds an output to the model, typically a simulation result. :params name: Name of the output in dot.notation, a la \"outputgroup.output\" :type name: str :params data: Output data, can't be a dictionary! :type data: `numpy.ndarray` \"\"\" assert not isinstance ( data , dict ), \"Output data cannot be a dictionary.\" assert isinstance ( name , str ), \"Output name must be a string.\" assert isinstance ( data , np . ndarray ), \"Output must be a `numpy.ndarray`.\" # remove initial conditions from output if removeICs and name != \"t\" : if data . ndim == 1 : data = data [ self . startindt :] elif data . ndim == 2 : data = data [:, self . startindt :] else : raise ValueError ( f \"Don't know how to truncate data of shape { data . shape } .\" ) # subsample to sampling dt if data . ndim == 1 : data = data [:: self . sample_every ] elif data . ndim == 2 : data = data [:, :: self . sample_every ] else : raise ValueError ( f \"Don't know how to subsample data of shape { data . shape } .\" ) # if the output is a single name (not dot.separated) if \".\" not in name : # append data if append and name in self . outputs : # special treatment for time data: # increment the time by the last recorded duration if name == \"t\" : data += self . outputs [ name ][ - 1 ] self . outputs [ name ] = np . hstack (( self . outputs [ name ], data )) else : # save all data into output dict self . outputs [ name ] = data # set output as an attribute setattr ( self , name , self . outputs [ name ]) else : # build results dictionary and write into self.outputs # dot.notation iteration keys = name . split ( \".\" ) level = self . outputs # not copy, reference! for i , k in enumerate ( keys ): # if it's the last iteration, store data if i == len ( keys ) - 1 : # TODO: this needs to be append-aware like above # if append: # if k == \"t\": # data += level[k][-1] # level[k] = np.hstack((level[k], data)) # else: # level[k] = data level [ k ] = data # if key is in outputs, then go deeper elif k in level : level = level [ k ] setattr ( self , k , level ) # if it's a new key, create new nested dictionary, set attribute, then go deeper else : level [ k ] = dotdict ({}) setattr ( self , k , level [ k ]) level = level [ k ] setSamplingDt ( self ) Checks if sampling_dt is set correctly and sets self. sample_every 1) Check if sampling_dt is multiple of dt 2) Check if semplind_dt is greater than duration Source code in neurolib/models/model.py def setSamplingDt ( self ): \"\"\"Checks if sampling_dt is set correctly and sets self.`sample_every` 1) Check if sampling_dt is multiple of dt 2) Check if semplind_dt is greater than duration \"\"\" if self . params . get ( \"sampling_dt\" ) is None : self . sample_every = 1 elif self . params . get ( \"sampling_dt\" ) > 0 : assert self . params [ \"sampling_dt\" ] >= self . params [ \"dt\" ], \"`sampling_dt` needs to be >= `dt`\" assert ( self . params [ \"duration\" ] >= self . params [ \"sampling_dt\" ] ), \"`sampling_dt` needs to be lower than `duration`\" self . sample_every = int ( self . params [ \"sampling_dt\" ] / self . params [ \"dt\" ]) else : raise ValueError ( f \"Can't handle `sampling_dt`= { self . params . get ( 'sampling_dt' ) } \" ) setStateVariables ( self , name , data ) Saves the models current state variables. TODO: Cut state variables to length of self.maxDelay However, this could be time-memory tradeoff Parameters: Name Type Description Default name str name of the state variable required data np.ndarray value of the variable required Source code in neurolib/models/model.py def setStateVariables ( self , name , data ): \"\"\"Saves the models current state variables. TODO: Cut state variables to length of self.maxDelay However, this could be time-memory tradeoff :param name: name of the state variable :type name: str :param data: value of the variable :type data: np.ndarray \"\"\" # old # self.state[name] = data.copy() # if the data is temporal, cut off initial values # NOTE: this shuold actually check for # if data.shape[1] > 1: # else: data.copy() # there coulb be (N, 1)-dimensional output, right now # it is requred to be of shape (N, ) if data . ndim == 2 : self . state [ name ] = data [:, - self . startindt :] . copy () else : self . state [ name ] = data . copy () simulateBold ( self , t , variables , append = False ) Gets the default output of the model and simulates the BOLD model. Adds the simulated BOLD signal to outputs. Source code in neurolib/models/model.py def simulateBold ( self , t , variables , append = False ): \"\"\"Gets the default output of the model and simulates the BOLD model. Adds the simulated BOLD signal to outputs. \"\"\" if self . boldInitialized : # first we loop through all state variables for svn , sv in zip ( self . state_vars , variables ): # the default output is used as the input for the bold model if svn == self . default_output : bold_input = sv [:, self . startindt :] # logging.debug(f\"BOLD input `{svn}` of shape {bold_input.shape}\") if bold_input . shape [ 1 ] >= self . boldModel . samplingRate_NDt : # only if the length of the output has a zero mod to the sampling rate, # the downsampled output from the boldModel can correctly appended to previous data # so: we are lazy here and simply disable appending in that case ... if not bold_input . shape [ 1 ] % self . boldModel . samplingRate_NDt == 0 : append = False logging . warn ( f \"Output size { bold_input . shape [ 1 ] } is not a multiple of BOLD sampling length { self . boldModel . samplingRate_NDt } , will not append data.\" ) logging . debug ( f \"Simulating BOLD: boldModel.run(append= { append } )\" ) # transform bold input according to self.boldInputTransform if self . boldInputTransform : bold_input = self . boldInputTransform ( bold_input ) # simulate bold model self . boldModel . run ( bold_input , append = append ) t_BOLD = self . boldModel . t_BOLD BOLD = self . boldModel . BOLD self . setOutput ( \"BOLD.t_BOLD\" , t_BOLD ) self . setOutput ( \"BOLD.BOLD\" , BOLD ) else : logging . warn ( f \"Will not simulate BOLD if output { bold_input . shape [ 1 ] * self . params [ 'dt' ] } not at least of duration { self . boldModel . samplingRate_NDt * self . params [ 'dt' ] } \" ) else : logging . warn ( \"BOLD model not initialized, not simulating BOLD. Use `run(bold=True)`\" ) storeOutputsAndStates ( self , t , variables , append = False ) Takes the simulated variables of the integration and stores it to the appropriate model output and state object. Parameters: Name Type Description Default t list time vector required variables numpy.ndarray variable from time integration required append bool, optional append output to existing output or overwrite, defaults to False False Source code in neurolib/models/model.py def storeOutputsAndStates ( self , t , variables , append = False ): \"\"\"Takes the simulated variables of the integration and stores it to the appropriate model output and state object. :param t: time vector :type t: list :param variables: variable from time integration :type variables: numpy.ndarray :param append: append output to existing output or overwrite, defaults to False :type append: bool, optional \"\"\" # save time array self . setOutput ( \"t\" , t , append = append , removeICs = True ) self . setStateVariables ( \"t\" , t ) # save outputs for svn , sv in zip ( self . state_vars , variables ): if svn in self . output_vars : self . setOutput ( svn , sv , append = append , removeICs = True ) self . setStateVariables ( svn , sv ) xr ( self , group = '' ) Converts a group of outputs to xarray. Output group needs to contain an element that starts with the letter \"t\" or it will not recognize any time axis. Parameters: Name Type Description Default group str Output group name, example: \"BOLD\". Leave empty for top group. '' Source code in neurolib/models/model.py def xr ( self , group = \"\" ): \"\"\"Converts a group of outputs to xarray. Output group needs to contain an element that starts with the letter \"t\" or it will not recognize any time axis. :param group: Output group name, example: \"BOLD\". Leave empty for top group. :type group: str \"\"\" assert isinstance ( group , str ), \"Group name must be a string.\" # take all outputs of one group: disregard all dictionaries because they are subgroups outputDict = self . getOutputs ( group ) # make sure that there is a time array timeDictKey = \"\" if \"t\" in outputDict : timeDictKey = \"t\" else : for k in outputDict : if k . startswith ( \"t\" ): timeDictKey = k logging . info ( f \"Assuming { k } to be the time axis.\" ) break assert len ( timeDictKey ) > 0 , f \"No time array found (starting with t) in output group { group } .\" t = outputDict [ timeDictKey ] . copy () del outputDict [ timeDictKey ] outputs = [] outputNames = [] for key , value in outputDict . items (): outputNames . append ( key ) outputs . append ( value ) nNodes = outputs [ 0 ] . shape [ 0 ] nodes = list ( range ( nNodes )) allOutputsStacked = np . stack ( outputs ) # What? Where? When? result = xr . DataArray ( allOutputsStacked , coords = [ outputNames , nodes , t ], dims = [ \"output\" , \"space\" , \"time\" ]) return result","title":"Models"},{"location":"models/model/#models","text":"Models are the core of neurolib . The Model superclass will help you to load, simulate, and analyse models. It also makes it very easy to implement your own neural mass model (see Example 0.6 custom model ).","title":"Models"},{"location":"models/model/#loading-a-model","text":"To load a model, we need to import the submodule of a model and instantiate it. This example shows how to load a single node of the ALNModel . See Example 0 aln minimal on how to simulate a whole-brain network using this model. from neurolib.models.aln import ALNModel # Import the model model = ALNModel() # Create an instance model.run() # Run it","title":"Loading a model"},{"location":"models/model/#model-base-class-methods","text":"The Model base class runs models, manages their outputs, parameters and more. This class should serve as the base class for all implemented models. Source code in neurolib/models/model.py class Model : \"\"\"The Model base class runs models, manages their outputs, parameters and more. This class should serve as the base class for all implemented models. \"\"\" def __init__ ( self , integration , params ): if hasattr ( self , \"name\" ): if self . name is not None : assert isinstance ( self . name , str ), f \"Model name is not a string.\" else : self . name = \"Noname\" assert integration is not None , \"Model integration function not given.\" self . integration = integration assert isinstance ( params , dict ), \"Parameters must be a dictionary.\" self . params = dotdict ( params ) # assert self.state_vars not None: assert hasattr ( self , \"state_vars\" ), f \"Model { self . name } has no attribute `state_vars`, which should be alist of strings containing all variable names.\" assert np . all ([ type ( s ) is str for s in self . state_vars ]), \"All entries in state_vars must be strings.\" assert hasattr ( self , \"default_output\" ), f \"Model { self . name } needs to define a default output variable in `default_output`.\" assert isinstance ( self . default_output , str ), \"`default_output` must be a string.\" # if no output_vars is set, it will be replaced by state_vars if not hasattr ( self , \"output_vars\" ): self . output_vars = self . state_vars # create output and state dictionary self . outputs = dotdict ({}) self . state = dotdict ({}) self . maxDelay = None self . initializeRun () self . boldInitialized = False logging . info ( f \" { self . name } : Model initialized.\" ) def initializeBold ( self ): \"\"\"Initialize BOLD model.\"\"\" self . boldInitialized = False # function to transform model state before passing it to the bold model # Note: This can be used like the parameter \\epsilon in Friston2000 # (neural efficacy) by multiplying the input with a constant via # self.boldInputTransform = lambda x: x * epsilon if not hasattr ( self , \"boldInputTransform\" ): self . boldInputTransform = None self . boldModel = bold . BOLDModel ( self . params [ \"N\" ], self . params [ \"dt\" ]) self . boldInitialized = True # logging.info(f\"{self.name}: BOLD model initialized.\") def simulateBold ( self , t , variables , append = False ): \"\"\"Gets the default output of the model and simulates the BOLD model. Adds the simulated BOLD signal to outputs. \"\"\" if self . boldInitialized : # first we loop through all state variables for svn , sv in zip ( self . state_vars , variables ): # the default output is used as the input for the bold model if svn == self . default_output : bold_input = sv [:, self . startindt :] # logging.debug(f\"BOLD input `{svn}` of shape {bold_input.shape}\") if bold_input . shape [ 1 ] >= self . boldModel . samplingRate_NDt : # only if the length of the output has a zero mod to the sampling rate, # the downsampled output from the boldModel can correctly appended to previous data # so: we are lazy here and simply disable appending in that case ... if not bold_input . shape [ 1 ] % self . boldModel . samplingRate_NDt == 0 : append = False logging . warn ( f \"Output size { bold_input . shape [ 1 ] } is not a multiple of BOLD sampling length { self . boldModel . samplingRate_NDt } , will not append data.\" ) logging . debug ( f \"Simulating BOLD: boldModel.run(append= { append } )\" ) # transform bold input according to self.boldInputTransform if self . boldInputTransform : bold_input = self . boldInputTransform ( bold_input ) # simulate bold model self . boldModel . run ( bold_input , append = append ) t_BOLD = self . boldModel . t_BOLD BOLD = self . boldModel . BOLD self . setOutput ( \"BOLD.t_BOLD\" , t_BOLD ) self . setOutput ( \"BOLD.BOLD\" , BOLD ) else : logging . warn ( f \"Will not simulate BOLD if output { bold_input . shape [ 1 ] * self . params [ 'dt' ] } not at least of duration { self . boldModel . samplingRate_NDt * self . params [ 'dt' ] } \" ) else : logging . warn ( \"BOLD model not initialized, not simulating BOLD. Use `run(bold=True)`\" ) def checkChunkwise ( self , chunksize ): \"\"\"Checks if the model fulfills requirements for chunkwise simulation. Checks whether the sampling rate for outputs fits to chunksize and duration. Throws errors if not.\"\"\" assert self . state_vars is not None , \"State variable names not given.\" assert self . init_vars is not None , \"Initial value variable names not given.\" assert len ( self . state_vars ) == len ( self . init_vars ), \"State variables are not same length as initial values.\" # throw a warning if the user is nasty if int ( self . params [ \"duration\" ] / self . params [ \"dt\" ]) % chunksize != 0 : logging . warning ( f \"It is strongly advised to use a `chunksize` ( { chunksize } ) that is a divisor of `duration / dt` ( { int ( self . params [ 'duration' ] / self . params [ 'dt' ]) } ).\" ) # if `sampling_dt` is set, do some checks if self . params . get ( \"sampling_dt\" ) is not None : # sample_dt checks are required after setting chunksize assert ( chunksize * self . params [ \"dt\" ] >= self . params [ \"sampling_dt\" ] ), \"`chunksize * dt` must be >= `sampling_dt`\" # ugly floating point modulo hack: instead of float1%float2==0, we do # (float1/float2)%1==0 assert (( chunksize * self . params [ \"dt\" ]) / self . params [ \"sampling_dt\" ]) % 1 == 0 , ( f \"Chunksize { chunksize * self . params [ 'dt' ] } must be divisible by sampling dt \" f \" { self . params [ 'sampling_dt' ] } \" ) assert ( ( self . params [ \"duration\" ] % ( chunksize * self . params [ \"dt\" ])) / self . params [ \"sampling_dt\" ] ) % 1 == 0 , ( f \"Last chunk of size { self . params [ 'duration' ] % ( chunksize * self . params [ 'dt' ]) } must be divisible by sampling dt \" f \" { self . params [ 'sampling_dt' ] } \" ) def setSamplingDt ( self ): \"\"\"Checks if sampling_dt is set correctly and sets self.`sample_every` 1) Check if sampling_dt is multiple of dt 2) Check if semplind_dt is greater than duration \"\"\" if self . params . get ( \"sampling_dt\" ) is None : self . sample_every = 1 elif self . params . get ( \"sampling_dt\" ) > 0 : assert self . params [ \"sampling_dt\" ] >= self . params [ \"dt\" ], \"`sampling_dt` needs to be >= `dt`\" assert ( self . params [ \"duration\" ] >= self . params [ \"sampling_dt\" ] ), \"`sampling_dt` needs to be lower than `duration`\" self . sample_every = int ( self . params [ \"sampling_dt\" ] / self . params [ \"dt\" ]) else : raise ValueError ( f \"Can't handle `sampling_dt`= { self . params . get ( 'sampling_dt' ) } \" ) def initializeRun ( self , initializeBold = False ): \"\"\"Initialization before each run. :param initializeBold: initialize BOLD model :type initializeBold: bool \"\"\" # get the maxDelay of the system self . maxDelay = self . getMaxDelay () # length of the initial condition self . startindt = self . maxDelay + 1 # check dt / sampling_dt self . setSamplingDt () # force bold if params['bold'] == True if self . params . get ( \"bold\" ): initializeBold = True # set up the bold model, if it didn't happen yet if initializeBold and not self . boldInitialized : self . initializeBold () def run ( self , inputs = None , chunkwise = False , chunksize = None , bold = False , append = False , append_outputs = None , continue_run = False , ): \"\"\" Main interfacing function to run a model. The model can be run in three different ways: 1) `model.run()` starts a new run. 2) `model.run(chunkwise=True)` runs the simulation in chunks of length `chunksize`. 3) `mode.run(continue_run=True)` continues the simulation of a previous run. :param inputs: list of inputs to the model, must have the same order as model.input_vars. Note: no sanity check is performed for performance reasons. Take care of the inputs yourself. :type inputs: list[np.ndarray|] :param chunkwise: simulate model chunkwise or in one single run, defaults to False :type chunkwise: bool, optional :param chunksize: size of the chunk to simulate in dt, if set will imply chunkwise=True, defaults to 2s :type chunksize: int, optional :param bold: simulate BOLD signal (only for chunkwise integration), defaults to False :type bold: bool, optional :param append: append the chunkwise outputs to the outputs attribute, defaults to False, defaults to False :type append: bool, optional :param continue_run: continue a simulation by using the initial values from a previous simulation :type continue_run: bool \"\"\" # TODO: legacy argument support if append_outputs is not None : append = append_outputs # if a previous run is not to be continued clear the model's state if continue_run is False : self . clearModelState () self . initializeRun ( initializeBold = bold ) # enable chunkwise if chunksize is set chunkwise = chunkwise if chunksize is None else True if chunkwise is False : self . integrate ( append_outputs = append , simulate_bold = bold ) if continue_run : self . setInitialValuesToLastState () else : if chunksize is None : chunksize = int ( 2000 / self . params [ \"dt\" ]) # check if model is safe for chunkwise integration # and whether sampling_dt is compatible with duration and chunksize self . checkChunkwise ( chunksize ) if bold and not self . boldInitialized : logging . warn ( f \" { self . name } : BOLD model not initialized, not simulating BOLD. Use `run(bold=True)`\" ) bold = False self . integrateChunkwise ( chunksize = chunksize , bold = bold , append_outputs = append ) # check if there was a problem with the simulated data self . checkOutputs () def checkOutputs ( self ): # check nans in output if np . isnan ( self . output ) . any (): logging . error ( \"nan in model output!\" ) else : EXPLOSION_THRESHOLD = 1e20 if ( self . output > EXPLOSION_THRESHOLD ) . any () > 0 : logging . error ( \"nan in model output!\" ) # check nans in BOLD if \"BOLD\" in self . outputs : if np . isnan ( self . outputs . BOLD . BOLD ) . any (): logging . error ( \"nan in BOLD output!\" ) def integrate ( self , append_outputs = False , simulate_bold = False ): \"\"\"Calls each models `integration` function and saves the state and the outputs of the model. :param append: append the chunkwise outputs to the outputs attribute, defaults to False, defaults to False :type append: bool, optional \"\"\" # run integration t , * variables = self . integration ( self . params ) self . storeOutputsAndStates ( t , variables , append = append_outputs ) # force bold if params['bold'] == True if self . params . get ( \"bold\" ): simulate_bold = True # bold simulation after integration if simulate_bold and self . boldInitialized : self . simulateBold ( t , variables , append = True ) def integrateChunkwise ( self , chunksize , bold = False , append_outputs = False ): \"\"\"Repeatedly calls the chunkwise integration for the whole duration of the simulation. If `bold==True`, the BOLD model is simulated after each chunk. :param chunksize: size of each chunk to simulate in units of dt :type chunksize: int :param bold: simulate BOLD model after each chunk, defaults to False :type bold: bool, optional :param append_outputs: append the chunkwise outputs to the outputs attribute, defaults to False :type append_outputs: bool, optional \"\"\" totalDuration = self . params [ \"duration\" ] dt = self . params [ \"dt\" ] # create a shallow copy of the parameters lastT = 0 while totalDuration - lastT >= dt - 1e-6 : # Determine the size of the next chunk # account for floating point errors remainingChunkSize = int ( round (( totalDuration - lastT ) / dt )) currentChunkSize = min ( chunksize , remainingChunkSize ) self . autochunk ( chunksize = currentChunkSize , append_outputs = append_outputs , bold = bold ) # we save the last simulated time step lastT += currentChunkSize * dt # or # lastT = self.state[\"t\"][-1] # set duration back to its original value self . params [ \"duration\" ] = totalDuration def clearModelState ( self ): \"\"\"Clears the model's state to create a fresh one\"\"\" self . state = dotdict ({}) self . outputs = dotdict ({}) # reinitialize bold model if self . params . get ( \"bold\" ): self . initializeBold () def storeOutputsAndStates ( self , t , variables , append = False ): \"\"\"Takes the simulated variables of the integration and stores it to the appropriate model output and state object. :param t: time vector :type t: list :param variables: variable from time integration :type variables: numpy.ndarray :param append: append output to existing output or overwrite, defaults to False :type append: bool, optional \"\"\" # save time array self . setOutput ( \"t\" , t , append = append , removeICs = True ) self . setStateVariables ( \"t\" , t ) # save outputs for svn , sv in zip ( self . state_vars , variables ): if svn in self . output_vars : self . setOutput ( svn , sv , append = append , removeICs = True ) self . setStateVariables ( svn , sv ) def setInitialValuesToLastState ( self ): \"\"\"Reads the last state of the model and sets the initial conditions to that state for continuing a simulation.\"\"\" for iv , sv in zip ( self . init_vars , self . state_vars ): # if state variables are one-dimensional (in space only) if ( self . state [ sv ] . ndim == 0 ) or ( self . state [ sv ] . ndim == 1 ): self . params [ iv ] = self . state [ sv ] # if they are space-time arrays else : # we set the next initial condition to the last state self . params [ iv ] = self . state [ sv ][:, - self . startindt :] def randomICs ( self , min = 0 , max = 1 ): \"\"\"Generates a new set of uniformly-distributed random initial conditions for the model. TODO: All parameters are drawn from the same distribution / range. Allow for independent ranges. :param min: Minium of uniform distribution :type min: float :param max: Maximum of uniform distribution :type max: float \"\"\" for iv in self . init_vars : if self . params [ iv ] . ndim == 1 : self . params [ iv ] = np . random . uniform ( min , max , ( self . params [ \"N\" ])) elif self . params [ iv ] . ndim == 2 : self . params [ iv ] = np . random . uniform ( min , max , ( self . params [ \"N\" ], 1 )) def setInputs ( self , inputs ): \"\"\"Take inputs from a list and store it in the appropriate model parameter for external input. TODO: This is not safe yet, checks should be implemented whether the model has inputs defined or not for example. :param inputs: list of inputs :type inputs: list[np.ndarray(), ...] \"\"\" for i , iv in enumerate ( self . input_vars ): self . params [ iv ] = inputs [ i ] . copy () def autochunk ( self , inputs = None , chunksize = 1 , append_outputs = False , bold = False ): \"\"\"Executes a single chunk of integration, either for a given duration or a single timestep `dt`. Gathers all inputs to the model and resets the initial conditions as a preparation for the next chunk. :param inputs: list of input values, ordered according to self.input_vars, defaults to None :type inputs: list[np.ndarray|], optional :param chunksize: length of a chunk to simulate in dt, defaults 1 :type chunksize: int, optional :param append_outputs: append the chunkwise outputs to the outputs attribute, defaults to False :type append_outputs: bool, optional \"\"\" # set the duration for this chunk self . params [ \"duration\" ] = chunksize * self . params [ \"dt\" ] # set inputs if inputs is not None : self . setInputs ( inputs ) # run integration self . integrate ( append_outputs = append_outputs , simulate_bold = bold ) # set initial conditions to last state for the next chunk self . setInitialValuesToLastState () def getMaxDelay ( self ): \"\"\"Computes the maximum delay of the model. This function should be overloaded if the model has internal delays (additional to delay between nodes defined by Dmat) such as the delay between an excitatory and inhibitory population within each brain area. If this function is not overloaded, the maximum delay is assumed to be defined from the global delay matrix `Dmat`. Note: Maxmimum delay is given in units of dt. :return: maxmimum delay of the model in units of dt :rtype: int \"\"\" dt = self . params . get ( \"dt\" ) Dmat = self . params . get ( \"lengthMat\" ) if Dmat is not None : # divide Dmat by signalV signalV = self . params . get ( \"signalV\" ) or 0 if signalV > 0 : Dmat = Dmat / signalV else : # if signalV is 0, eliminate delays Dmat = Dmat * 0.0 # only if Dmat and dt exist, a global max delay can be computed if Dmat is not None and dt is not None : Dmat_ndt = np . around ( Dmat / dt ) # delay matrix in multiples of dt max_global_delay = int ( np . amax ( Dmat_ndt )) else : max_global_delay = 0 return max_global_delay def setStateVariables ( self , name , data ): \"\"\"Saves the models current state variables. TODO: Cut state variables to length of self.maxDelay However, this could be time-memory tradeoff :param name: name of the state variable :type name: str :param data: value of the variable :type data: np.ndarray \"\"\" # old # self.state[name] = data.copy() # if the data is temporal, cut off initial values # NOTE: this shuold actually check for # if data.shape[1] > 1: # else: data.copy() # there coulb be (N, 1)-dimensional output, right now # it is requred to be of shape (N, ) if data . ndim == 2 : self . state [ name ] = data [:, - self . startindt :] . copy () else : self . state [ name ] = data . copy () def setOutput ( self , name , data , append = False , removeICs = False ): \"\"\"Adds an output to the model, typically a simulation result. :params name: Name of the output in dot.notation, a la \"outputgroup.output\" :type name: str :params data: Output data, can't be a dictionary! :type data: `numpy.ndarray` \"\"\" assert not isinstance ( data , dict ), \"Output data cannot be a dictionary.\" assert isinstance ( name , str ), \"Output name must be a string.\" assert isinstance ( data , np . ndarray ), \"Output must be a `numpy.ndarray`.\" # remove initial conditions from output if removeICs and name != \"t\" : if data . ndim == 1 : data = data [ self . startindt :] elif data . ndim == 2 : data = data [:, self . startindt :] else : raise ValueError ( f \"Don't know how to truncate data of shape { data . shape } .\" ) # subsample to sampling dt if data . ndim == 1 : data = data [:: self . sample_every ] elif data . ndim == 2 : data = data [:, :: self . sample_every ] else : raise ValueError ( f \"Don't know how to subsample data of shape { data . shape } .\" ) # if the output is a single name (not dot.separated) if \".\" not in name : # append data if append and name in self . outputs : # special treatment for time data: # increment the time by the last recorded duration if name == \"t\" : data += self . outputs [ name ][ - 1 ] self . outputs [ name ] = np . hstack (( self . outputs [ name ], data )) else : # save all data into output dict self . outputs [ name ] = data # set output as an attribute setattr ( self , name , self . outputs [ name ]) else : # build results dictionary and write into self.outputs # dot.notation iteration keys = name . split ( \".\" ) level = self . outputs # not copy, reference! for i , k in enumerate ( keys ): # if it's the last iteration, store data if i == len ( keys ) - 1 : # TODO: this needs to be append-aware like above # if append: # if k == \"t\": # data += level[k][-1] # level[k] = np.hstack((level[k], data)) # else: # level[k] = data level [ k ] = data # if key is in outputs, then go deeper elif k in level : level = level [ k ] setattr ( self , k , level ) # if it's a new key, create new nested dictionary, set attribute, then go deeper else : level [ k ] = dotdict ({}) setattr ( self , k , level [ k ]) level = level [ k ] def getOutput ( self , name ): \"\"\"Get an output of a given name (dot.semarated) :param name: A key, grouped outputs in the form group.subgroup.variable :type name: str :returns: Output data \"\"\" assert isinstance ( name , str ), \"Output name must be a string.\" keys = name . split ( \".\" ) lastOutput = self . outputs . copy () for i , k in enumerate ( keys ): assert k in lastOutput , f \"Key { k } not found in outputs.\" lastOutput = lastOutput [ k ] return lastOutput def __getitem__ ( self , key ): \"\"\"Index outputs with a dictionary-like key, e.g., `model['rates_exc']`.\"\"\" return self . getOutput ( key ) def getOutputs ( self , group = \"\" ): \"\"\"Get all outputs of an output group. Examples: `getOutputs(\"BOLD\")` or simply `getOutputs()` :param group: Group name, subgroups separated by dots. If left empty (default), all outputs of the root group are returned. :type group: str \"\"\" assert isinstance ( group , str ), \"Group name must be a string.\" def filterOutputsFromGroupDict ( groupDict ): \"\"\"Return a dictionary with the output data of a group disregarding all other nested dicts. :param groupDict: Dictionary of outputs (can include other groups) :type groupDict: dict \"\"\" assert isinstance ( groupDict , dict ), \"Not a dictionary.\" # make a deep copy of the dictionary returnDict = groupDict . copy () for key , value in groupDict . items (): if isinstance ( value , dict ): del returnDict [ key ] return returnDict # if a group deeper than the root is given, select the last node lastOutput = self . outputs . copy () if len ( group ) > 0 : keys = group . split ( \".\" ) for i , k in enumerate ( keys ): assert k in lastOutput , f \"Key { k } not found in outputs.\" lastOutput = lastOutput [ k ] assert isinstance ( lastOutput , dict ), f \"Key { k } does not refer to a group.\" # filter out all output *groups* that might be in this node and return only output data return filterOutputsFromGroupDict ( lastOutput ) @property def output ( self ): \"\"\"Returns value of default output as defined by `self.default_output`. Note that all outputs are saved in the attribute `self.outputs`. \"\"\" assert self . default_output is not None , \"Default output has not been set yet. Use `setDefaultOutput()`.\" return self . getOutput ( self . default_output ) def xr ( self , group = \"\" ): \"\"\"Converts a group of outputs to xarray. Output group needs to contain an element that starts with the letter \"t\" or it will not recognize any time axis. :param group: Output group name, example: \"BOLD\". Leave empty for top group. :type group: str \"\"\" assert isinstance ( group , str ), \"Group name must be a string.\" # take all outputs of one group: disregard all dictionaries because they are subgroups outputDict = self . getOutputs ( group ) # make sure that there is a time array timeDictKey = \"\" if \"t\" in outputDict : timeDictKey = \"t\" else : for k in outputDict : if k . startswith ( \"t\" ): timeDictKey = k logging . info ( f \"Assuming { k } to be the time axis.\" ) break assert len ( timeDictKey ) > 0 , f \"No time array found (starting with t) in output group { group } .\" t = outputDict [ timeDictKey ] . copy () del outputDict [ timeDictKey ] outputs = [] outputNames = [] for key , value in outputDict . items (): outputNames . append ( key ) outputs . append ( value ) nNodes = outputs [ 0 ] . shape [ 0 ] nodes = list ( range ( nNodes )) allOutputsStacked = np . stack ( outputs ) # What? Where? When? result = xr . DataArray ( allOutputsStacked , coords = [ outputNames , nodes , t ], dims = [ \"output\" , \"space\" , \"time\" ]) return result","title":"Model base class methods"},{"location":"models/model/#neurolib.models.model.Model.output","text":"Returns value of default output as defined by self.default_output . Note that all outputs are saved in the attribute self.outputs .","title":"output"},{"location":"models/model/#neurolib.models.model.Model.__getitem__","text":"Index outputs with a dictionary-like key, e.g., model['rates_exc'] . Source code in neurolib/models/model.py def __getitem__ ( self , key ): \"\"\"Index outputs with a dictionary-like key, e.g., `model['rates_exc']`.\"\"\" return self . getOutput ( key )","title":"__getitem__()"},{"location":"models/model/#neurolib.models.model.Model.autochunk","text":"Executes a single chunk of integration, either for a given duration or a single timestep dt . Gathers all inputs to the model and resets the initial conditions as a preparation for the next chunk. Parameters: Name Type Description Default inputs list[np.ndarray|], optional list of input values, ordered according to self.input_vars, defaults to None None chunksize int, optional length of a chunk to simulate in dt, defaults 1 1 append_outputs bool, optional append the chunkwise outputs to the outputs attribute, defaults to False False Source code in neurolib/models/model.py def autochunk ( self , inputs = None , chunksize = 1 , append_outputs = False , bold = False ): \"\"\"Executes a single chunk of integration, either for a given duration or a single timestep `dt`. Gathers all inputs to the model and resets the initial conditions as a preparation for the next chunk. :param inputs: list of input values, ordered according to self.input_vars, defaults to None :type inputs: list[np.ndarray|], optional :param chunksize: length of a chunk to simulate in dt, defaults 1 :type chunksize: int, optional :param append_outputs: append the chunkwise outputs to the outputs attribute, defaults to False :type append_outputs: bool, optional \"\"\" # set the duration for this chunk self . params [ \"duration\" ] = chunksize * self . params [ \"dt\" ] # set inputs if inputs is not None : self . setInputs ( inputs ) # run integration self . integrate ( append_outputs = append_outputs , simulate_bold = bold ) # set initial conditions to last state for the next chunk self . setInitialValuesToLastState ()","title":"autochunk()"},{"location":"models/model/#neurolib.models.model.Model.checkChunkwise","text":"Checks if the model fulfills requirements for chunkwise simulation. Checks whether the sampling rate for outputs fits to chunksize and duration. Throws errors if not. Source code in neurolib/models/model.py def checkChunkwise ( self , chunksize ): \"\"\"Checks if the model fulfills requirements for chunkwise simulation. Checks whether the sampling rate for outputs fits to chunksize and duration. Throws errors if not.\"\"\" assert self . state_vars is not None , \"State variable names not given.\" assert self . init_vars is not None , \"Initial value variable names not given.\" assert len ( self . state_vars ) == len ( self . init_vars ), \"State variables are not same length as initial values.\" # throw a warning if the user is nasty if int ( self . params [ \"duration\" ] / self . params [ \"dt\" ]) % chunksize != 0 : logging . warning ( f \"It is strongly advised to use a `chunksize` ( { chunksize } ) that is a divisor of `duration / dt` ( { int ( self . params [ 'duration' ] / self . params [ 'dt' ]) } ).\" ) # if `sampling_dt` is set, do some checks if self . params . get ( \"sampling_dt\" ) is not None : # sample_dt checks are required after setting chunksize assert ( chunksize * self . params [ \"dt\" ] >= self . params [ \"sampling_dt\" ] ), \"`chunksize * dt` must be >= `sampling_dt`\" # ugly floating point modulo hack: instead of float1%float2==0, we do # (float1/float2)%1==0 assert (( chunksize * self . params [ \"dt\" ]) / self . params [ \"sampling_dt\" ]) % 1 == 0 , ( f \"Chunksize { chunksize * self . params [ 'dt' ] } must be divisible by sampling dt \" f \" { self . params [ 'sampling_dt' ] } \" ) assert ( ( self . params [ \"duration\" ] % ( chunksize * self . params [ \"dt\" ])) / self . params [ \"sampling_dt\" ] ) % 1 == 0 , ( f \"Last chunk of size { self . params [ 'duration' ] % ( chunksize * self . params [ 'dt' ]) } must be divisible by sampling dt \" f \" { self . params [ 'sampling_dt' ] } \" )","title":"checkChunkwise()"},{"location":"models/model/#neurolib.models.model.Model.clearModelState","text":"Clears the model's state to create a fresh one Source code in neurolib/models/model.py def clearModelState ( self ): \"\"\"Clears the model's state to create a fresh one\"\"\" self . state = dotdict ({}) self . outputs = dotdict ({}) # reinitialize bold model if self . params . get ( \"bold\" ): self . initializeBold ()","title":"clearModelState()"},{"location":"models/model/#neurolib.models.model.Model.getMaxDelay","text":"Computes the maximum delay of the model. This function should be overloaded if the model has internal delays (additional to delay between nodes defined by Dmat) such as the delay between an excitatory and inhibitory population within each brain area. If this function is not overloaded, the maximum delay is assumed to be defined from the global delay matrix Dmat . Note: Maxmimum delay is given in units of dt. Returns: Type Description int maxmimum delay of the model in units of dt Source code in neurolib/models/model.py def getMaxDelay ( self ): \"\"\"Computes the maximum delay of the model. This function should be overloaded if the model has internal delays (additional to delay between nodes defined by Dmat) such as the delay between an excitatory and inhibitory population within each brain area. If this function is not overloaded, the maximum delay is assumed to be defined from the global delay matrix `Dmat`. Note: Maxmimum delay is given in units of dt. :return: maxmimum delay of the model in units of dt :rtype: int \"\"\" dt = self . params . get ( \"dt\" ) Dmat = self . params . get ( \"lengthMat\" ) if Dmat is not None : # divide Dmat by signalV signalV = self . params . get ( \"signalV\" ) or 0 if signalV > 0 : Dmat = Dmat / signalV else : # if signalV is 0, eliminate delays Dmat = Dmat * 0.0 # only if Dmat and dt exist, a global max delay can be computed if Dmat is not None and dt is not None : Dmat_ndt = np . around ( Dmat / dt ) # delay matrix in multiples of dt max_global_delay = int ( np . amax ( Dmat_ndt )) else : max_global_delay = 0 return max_global_delay","title":"getMaxDelay()"},{"location":"models/model/#neurolib.models.model.Model.getOutput","text":"Get an output of a given name (dot.semarated) Parameters: Name Type Description Default name str A key, grouped outputs in the form group.subgroup.variable required Returns: Type Description Output data Source code in neurolib/models/model.py def getOutput ( self , name ): \"\"\"Get an output of a given name (dot.semarated) :param name: A key, grouped outputs in the form group.subgroup.variable :type name: str :returns: Output data \"\"\" assert isinstance ( name , str ), \"Output name must be a string.\" keys = name . split ( \".\" ) lastOutput = self . outputs . copy () for i , k in enumerate ( keys ): assert k in lastOutput , f \"Key { k } not found in outputs.\" lastOutput = lastOutput [ k ] return lastOutput","title":"getOutput()"},{"location":"models/model/#neurolib.models.model.Model.getOutputs","text":"Get all outputs of an output group. Examples: getOutputs(\"BOLD\") or simply getOutputs() Parameters: Name Type Description Default group str Group name, subgroups separated by dots. If left empty (default), all outputs of the root group are returned. '' Source code in neurolib/models/model.py def getOutputs ( self , group = \"\" ): \"\"\"Get all outputs of an output group. Examples: `getOutputs(\"BOLD\")` or simply `getOutputs()` :param group: Group name, subgroups separated by dots. If left empty (default), all outputs of the root group are returned. :type group: str \"\"\" assert isinstance ( group , str ), \"Group name must be a string.\" def filterOutputsFromGroupDict ( groupDict ): \"\"\"Return a dictionary with the output data of a group disregarding all other nested dicts. :param groupDict: Dictionary of outputs (can include other groups) :type groupDict: dict \"\"\" assert isinstance ( groupDict , dict ), \"Not a dictionary.\" # make a deep copy of the dictionary returnDict = groupDict . copy () for key , value in groupDict . items (): if isinstance ( value , dict ): del returnDict [ key ] return returnDict # if a group deeper than the root is given, select the last node lastOutput = self . outputs . copy () if len ( group ) > 0 : keys = group . split ( \".\" ) for i , k in enumerate ( keys ): assert k in lastOutput , f \"Key { k } not found in outputs.\" lastOutput = lastOutput [ k ] assert isinstance ( lastOutput , dict ), f \"Key { k } does not refer to a group.\" # filter out all output *groups* that might be in this node and return only output data return filterOutputsFromGroupDict ( lastOutput )","title":"getOutputs()"},{"location":"models/model/#neurolib.models.model.Model.initializeBold","text":"Initialize BOLD model. Source code in neurolib/models/model.py def initializeBold ( self ): \"\"\"Initialize BOLD model.\"\"\" self . boldInitialized = False # function to transform model state before passing it to the bold model # Note: This can be used like the parameter \\epsilon in Friston2000 # (neural efficacy) by multiplying the input with a constant via # self.boldInputTransform = lambda x: x * epsilon if not hasattr ( self , \"boldInputTransform\" ): self . boldInputTransform = None self . boldModel = bold . BOLDModel ( self . params [ \"N\" ], self . params [ \"dt\" ]) self . boldInitialized = True","title":"initializeBold()"},{"location":"models/model/#neurolib.models.model.Model.initializeRun","text":"Initialization before each run. Parameters: Name Type Description Default initializeBold bool initialize BOLD model False Source code in neurolib/models/model.py def initializeRun ( self , initializeBold = False ): \"\"\"Initialization before each run. :param initializeBold: initialize BOLD model :type initializeBold: bool \"\"\" # get the maxDelay of the system self . maxDelay = self . getMaxDelay () # length of the initial condition self . startindt = self . maxDelay + 1 # check dt / sampling_dt self . setSamplingDt () # force bold if params['bold'] == True if self . params . get ( \"bold\" ): initializeBold = True # set up the bold model, if it didn't happen yet if initializeBold and not self . boldInitialized : self . initializeBold ()","title":"initializeRun()"},{"location":"models/model/#neurolib.models.model.Model.integrate","text":"Calls each models integration function and saves the state and the outputs of the model. Parameters: Name Type Description Default append bool, optional append the chunkwise outputs to the outputs attribute, defaults to False, defaults to False required Source code in neurolib/models/model.py def integrate ( self , append_outputs = False , simulate_bold = False ): \"\"\"Calls each models `integration` function and saves the state and the outputs of the model. :param append: append the chunkwise outputs to the outputs attribute, defaults to False, defaults to False :type append: bool, optional \"\"\" # run integration t , * variables = self . integration ( self . params ) self . storeOutputsAndStates ( t , variables , append = append_outputs ) # force bold if params['bold'] == True if self . params . get ( \"bold\" ): simulate_bold = True # bold simulation after integration if simulate_bold and self . boldInitialized : self . simulateBold ( t , variables , append = True )","title":"integrate()"},{"location":"models/model/#neurolib.models.model.Model.integrateChunkwise","text":"Repeatedly calls the chunkwise integration for the whole duration of the simulation. If bold==True , the BOLD model is simulated after each chunk. Parameters: Name Type Description Default chunksize int size of each chunk to simulate in units of dt required bold bool, optional simulate BOLD model after each chunk, defaults to False False append_outputs bool, optional append the chunkwise outputs to the outputs attribute, defaults to False False Source code in neurolib/models/model.py def integrateChunkwise ( self , chunksize , bold = False , append_outputs = False ): \"\"\"Repeatedly calls the chunkwise integration for the whole duration of the simulation. If `bold==True`, the BOLD model is simulated after each chunk. :param chunksize: size of each chunk to simulate in units of dt :type chunksize: int :param bold: simulate BOLD model after each chunk, defaults to False :type bold: bool, optional :param append_outputs: append the chunkwise outputs to the outputs attribute, defaults to False :type append_outputs: bool, optional \"\"\" totalDuration = self . params [ \"duration\" ] dt = self . params [ \"dt\" ] # create a shallow copy of the parameters lastT = 0 while totalDuration - lastT >= dt - 1e-6 : # Determine the size of the next chunk # account for floating point errors remainingChunkSize = int ( round (( totalDuration - lastT ) / dt )) currentChunkSize = min ( chunksize , remainingChunkSize ) self . autochunk ( chunksize = currentChunkSize , append_outputs = append_outputs , bold = bold ) # we save the last simulated time step lastT += currentChunkSize * dt # or # lastT = self.state[\"t\"][-1] # set duration back to its original value self . params [ \"duration\" ] = totalDuration","title":"integrateChunkwise()"},{"location":"models/model/#neurolib.models.model.Model.randomICs","text":"Generates a new set of uniformly-distributed random initial conditions for the model. TODO: All parameters are drawn from the same distribution / range. Allow for independent ranges. Parameters: Name Type Description Default min float Minium of uniform distribution 0 max float Maximum of uniform distribution 1 Source code in neurolib/models/model.py def randomICs ( self , min = 0 , max = 1 ): \"\"\"Generates a new set of uniformly-distributed random initial conditions for the model. TODO: All parameters are drawn from the same distribution / range. Allow for independent ranges. :param min: Minium of uniform distribution :type min: float :param max: Maximum of uniform distribution :type max: float \"\"\" for iv in self . init_vars : if self . params [ iv ] . ndim == 1 : self . params [ iv ] = np . random . uniform ( min , max , ( self . params [ \"N\" ])) elif self . params [ iv ] . ndim == 2 : self . params [ iv ] = np . random . uniform ( min , max , ( self . params [ \"N\" ], 1 ))","title":"randomICs()"},{"location":"models/model/#neurolib.models.model.Model.run","text":"Main interfacing function to run a model. The model can be run in three different ways: 1) model.run() starts a new run. 2) model.run(chunkwise=True) runs the simulation in chunks of length chunksize . 3) mode.run(continue_run=True) continues the simulation of a previous run. Parameters: Name Type Description Default inputs list[np.ndarray|] list of inputs to the model, must have the same order as model.input_vars. Note: no sanity check is performed for performance reasons. Take care of the inputs yourself. None chunkwise bool, optional simulate model chunkwise or in one single run, defaults to False False chunksize int, optional size of the chunk to simulate in dt, if set will imply chunkwise=True, defaults to 2s None bold bool, optional simulate BOLD signal (only for chunkwise integration), defaults to False False append bool, optional append the chunkwise outputs to the outputs attribute, defaults to False, defaults to False False continue_run bool continue a simulation by using the initial values from a previous simulation False Source code in neurolib/models/model.py def run ( self , inputs = None , chunkwise = False , chunksize = None , bold = False , append = False , append_outputs = None , continue_run = False , ): \"\"\" Main interfacing function to run a model. The model can be run in three different ways: 1) `model.run()` starts a new run. 2) `model.run(chunkwise=True)` runs the simulation in chunks of length `chunksize`. 3) `mode.run(continue_run=True)` continues the simulation of a previous run. :param inputs: list of inputs to the model, must have the same order as model.input_vars. Note: no sanity check is performed for performance reasons. Take care of the inputs yourself. :type inputs: list[np.ndarray|] :param chunkwise: simulate model chunkwise or in one single run, defaults to False :type chunkwise: bool, optional :param chunksize: size of the chunk to simulate in dt, if set will imply chunkwise=True, defaults to 2s :type chunksize: int, optional :param bold: simulate BOLD signal (only for chunkwise integration), defaults to False :type bold: bool, optional :param append: append the chunkwise outputs to the outputs attribute, defaults to False, defaults to False :type append: bool, optional :param continue_run: continue a simulation by using the initial values from a previous simulation :type continue_run: bool \"\"\" # TODO: legacy argument support if append_outputs is not None : append = append_outputs # if a previous run is not to be continued clear the model's state if continue_run is False : self . clearModelState () self . initializeRun ( initializeBold = bold ) # enable chunkwise if chunksize is set chunkwise = chunkwise if chunksize is None else True if chunkwise is False : self . integrate ( append_outputs = append , simulate_bold = bold ) if continue_run : self . setInitialValuesToLastState () else : if chunksize is None : chunksize = int ( 2000 / self . params [ \"dt\" ]) # check if model is safe for chunkwise integration # and whether sampling_dt is compatible with duration and chunksize self . checkChunkwise ( chunksize ) if bold and not self . boldInitialized : logging . warn ( f \" { self . name } : BOLD model not initialized, not simulating BOLD. Use `run(bold=True)`\" ) bold = False self . integrateChunkwise ( chunksize = chunksize , bold = bold , append_outputs = append ) # check if there was a problem with the simulated data self . checkOutputs ()","title":"run()"},{"location":"models/model/#neurolib.models.model.Model.setInitialValuesToLastState","text":"Reads the last state of the model and sets the initial conditions to that state for continuing a simulation. Source code in neurolib/models/model.py def setInitialValuesToLastState ( self ): \"\"\"Reads the last state of the model and sets the initial conditions to that state for continuing a simulation.\"\"\" for iv , sv in zip ( self . init_vars , self . state_vars ): # if state variables are one-dimensional (in space only) if ( self . state [ sv ] . ndim == 0 ) or ( self . state [ sv ] . ndim == 1 ): self . params [ iv ] = self . state [ sv ] # if they are space-time arrays else : # we set the next initial condition to the last state self . params [ iv ] = self . state [ sv ][:, - self . startindt :]","title":"setInitialValuesToLastState()"},{"location":"models/model/#neurolib.models.model.Model.setInputs","text":"Take inputs from a list and store it in the appropriate model parameter for external input. TODO: This is not safe yet, checks should be implemented whether the model has inputs defined or not for example. Parameters: Name Type Description Default inputs list[np.ndarray(), ...] list of inputs required Source code in neurolib/models/model.py def setInputs ( self , inputs ): \"\"\"Take inputs from a list and store it in the appropriate model parameter for external input. TODO: This is not safe yet, checks should be implemented whether the model has inputs defined or not for example. :param inputs: list of inputs :type inputs: list[np.ndarray(), ...] \"\"\" for i , iv in enumerate ( self . input_vars ): self . params [ iv ] = inputs [ i ] . copy ()","title":"setInputs()"},{"location":"models/model/#neurolib.models.model.Model.setOutput","text":"Adds an output to the model, typically a simulation result. Parameters: Name Type Description Default name str Name of the output in dot.notation, a la \"outputgroup.output\" required data `numpy.ndarray` Output data, can't be a dictionary! required Source code in neurolib/models/model.py def setOutput ( self , name , data , append = False , removeICs = False ): \"\"\"Adds an output to the model, typically a simulation result. :params name: Name of the output in dot.notation, a la \"outputgroup.output\" :type name: str :params data: Output data, can't be a dictionary! :type data: `numpy.ndarray` \"\"\" assert not isinstance ( data , dict ), \"Output data cannot be a dictionary.\" assert isinstance ( name , str ), \"Output name must be a string.\" assert isinstance ( data , np . ndarray ), \"Output must be a `numpy.ndarray`.\" # remove initial conditions from output if removeICs and name != \"t\" : if data . ndim == 1 : data = data [ self . startindt :] elif data . ndim == 2 : data = data [:, self . startindt :] else : raise ValueError ( f \"Don't know how to truncate data of shape { data . shape } .\" ) # subsample to sampling dt if data . ndim == 1 : data = data [:: self . sample_every ] elif data . ndim == 2 : data = data [:, :: self . sample_every ] else : raise ValueError ( f \"Don't know how to subsample data of shape { data . shape } .\" ) # if the output is a single name (not dot.separated) if \".\" not in name : # append data if append and name in self . outputs : # special treatment for time data: # increment the time by the last recorded duration if name == \"t\" : data += self . outputs [ name ][ - 1 ] self . outputs [ name ] = np . hstack (( self . outputs [ name ], data )) else : # save all data into output dict self . outputs [ name ] = data # set output as an attribute setattr ( self , name , self . outputs [ name ]) else : # build results dictionary and write into self.outputs # dot.notation iteration keys = name . split ( \".\" ) level = self . outputs # not copy, reference! for i , k in enumerate ( keys ): # if it's the last iteration, store data if i == len ( keys ) - 1 : # TODO: this needs to be append-aware like above # if append: # if k == \"t\": # data += level[k][-1] # level[k] = np.hstack((level[k], data)) # else: # level[k] = data level [ k ] = data # if key is in outputs, then go deeper elif k in level : level = level [ k ] setattr ( self , k , level ) # if it's a new key, create new nested dictionary, set attribute, then go deeper else : level [ k ] = dotdict ({}) setattr ( self , k , level [ k ]) level = level [ k ]","title":"setOutput()"},{"location":"models/model/#neurolib.models.model.Model.setSamplingDt","text":"Checks if sampling_dt is set correctly and sets self. sample_every 1) Check if sampling_dt is multiple of dt 2) Check if semplind_dt is greater than duration Source code in neurolib/models/model.py def setSamplingDt ( self ): \"\"\"Checks if sampling_dt is set correctly and sets self.`sample_every` 1) Check if sampling_dt is multiple of dt 2) Check if semplind_dt is greater than duration \"\"\" if self . params . get ( \"sampling_dt\" ) is None : self . sample_every = 1 elif self . params . get ( \"sampling_dt\" ) > 0 : assert self . params [ \"sampling_dt\" ] >= self . params [ \"dt\" ], \"`sampling_dt` needs to be >= `dt`\" assert ( self . params [ \"duration\" ] >= self . params [ \"sampling_dt\" ] ), \"`sampling_dt` needs to be lower than `duration`\" self . sample_every = int ( self . params [ \"sampling_dt\" ] / self . params [ \"dt\" ]) else : raise ValueError ( f \"Can't handle `sampling_dt`= { self . params . get ( 'sampling_dt' ) } \" )","title":"setSamplingDt()"},{"location":"models/model/#neurolib.models.model.Model.setStateVariables","text":"Saves the models current state variables. TODO: Cut state variables to length of self.maxDelay However, this could be time-memory tradeoff Parameters: Name Type Description Default name str name of the state variable required data np.ndarray value of the variable required Source code in neurolib/models/model.py def setStateVariables ( self , name , data ): \"\"\"Saves the models current state variables. TODO: Cut state variables to length of self.maxDelay However, this could be time-memory tradeoff :param name: name of the state variable :type name: str :param data: value of the variable :type data: np.ndarray \"\"\" # old # self.state[name] = data.copy() # if the data is temporal, cut off initial values # NOTE: this shuold actually check for # if data.shape[1] > 1: # else: data.copy() # there coulb be (N, 1)-dimensional output, right now # it is requred to be of shape (N, ) if data . ndim == 2 : self . state [ name ] = data [:, - self . startindt :] . copy () else : self . state [ name ] = data . copy ()","title":"setStateVariables()"},{"location":"models/model/#neurolib.models.model.Model.simulateBold","text":"Gets the default output of the model and simulates the BOLD model. Adds the simulated BOLD signal to outputs. Source code in neurolib/models/model.py def simulateBold ( self , t , variables , append = False ): \"\"\"Gets the default output of the model and simulates the BOLD model. Adds the simulated BOLD signal to outputs. \"\"\" if self . boldInitialized : # first we loop through all state variables for svn , sv in zip ( self . state_vars , variables ): # the default output is used as the input for the bold model if svn == self . default_output : bold_input = sv [:, self . startindt :] # logging.debug(f\"BOLD input `{svn}` of shape {bold_input.shape}\") if bold_input . shape [ 1 ] >= self . boldModel . samplingRate_NDt : # only if the length of the output has a zero mod to the sampling rate, # the downsampled output from the boldModel can correctly appended to previous data # so: we are lazy here and simply disable appending in that case ... if not bold_input . shape [ 1 ] % self . boldModel . samplingRate_NDt == 0 : append = False logging . warn ( f \"Output size { bold_input . shape [ 1 ] } is not a multiple of BOLD sampling length { self . boldModel . samplingRate_NDt } , will not append data.\" ) logging . debug ( f \"Simulating BOLD: boldModel.run(append= { append } )\" ) # transform bold input according to self.boldInputTransform if self . boldInputTransform : bold_input = self . boldInputTransform ( bold_input ) # simulate bold model self . boldModel . run ( bold_input , append = append ) t_BOLD = self . boldModel . t_BOLD BOLD = self . boldModel . BOLD self . setOutput ( \"BOLD.t_BOLD\" , t_BOLD ) self . setOutput ( \"BOLD.BOLD\" , BOLD ) else : logging . warn ( f \"Will not simulate BOLD if output { bold_input . shape [ 1 ] * self . params [ 'dt' ] } not at least of duration { self . boldModel . samplingRate_NDt * self . params [ 'dt' ] } \" ) else : logging . warn ( \"BOLD model not initialized, not simulating BOLD. Use `run(bold=True)`\" )","title":"simulateBold()"},{"location":"models/model/#neurolib.models.model.Model.storeOutputsAndStates","text":"Takes the simulated variables of the integration and stores it to the appropriate model output and state object. Parameters: Name Type Description Default t list time vector required variables numpy.ndarray variable from time integration required append bool, optional append output to existing output or overwrite, defaults to False False Source code in neurolib/models/model.py def storeOutputsAndStates ( self , t , variables , append = False ): \"\"\"Takes the simulated variables of the integration and stores it to the appropriate model output and state object. :param t: time vector :type t: list :param variables: variable from time integration :type variables: numpy.ndarray :param append: append output to existing output or overwrite, defaults to False :type append: bool, optional \"\"\" # save time array self . setOutput ( \"t\" , t , append = append , removeICs = True ) self . setStateVariables ( \"t\" , t ) # save outputs for svn , sv in zip ( self . state_vars , variables ): if svn in self . output_vars : self . setOutput ( svn , sv , append = append , removeICs = True ) self . setStateVariables ( svn , sv )","title":"storeOutputsAndStates()"},{"location":"models/model/#neurolib.models.model.Model.xr","text":"Converts a group of outputs to xarray. Output group needs to contain an element that starts with the letter \"t\" or it will not recognize any time axis. Parameters: Name Type Description Default group str Output group name, example: \"BOLD\". Leave empty for top group. '' Source code in neurolib/models/model.py def xr ( self , group = \"\" ): \"\"\"Converts a group of outputs to xarray. Output group needs to contain an element that starts with the letter \"t\" or it will not recognize any time axis. :param group: Output group name, example: \"BOLD\". Leave empty for top group. :type group: str \"\"\" assert isinstance ( group , str ), \"Group name must be a string.\" # take all outputs of one group: disregard all dictionaries because they are subgroups outputDict = self . getOutputs ( group ) # make sure that there is a time array timeDictKey = \"\" if \"t\" in outputDict : timeDictKey = \"t\" else : for k in outputDict : if k . startswith ( \"t\" ): timeDictKey = k logging . info ( f \"Assuming { k } to be the time axis.\" ) break assert len ( timeDictKey ) > 0 , f \"No time array found (starting with t) in output group { group } .\" t = outputDict [ timeDictKey ] . copy () del outputDict [ timeDictKey ] outputs = [] outputNames = [] for key , value in outputDict . items (): outputNames . append ( key ) outputs . append ( value ) nNodes = outputs [ 0 ] . shape [ 0 ] nodes = list ( range ( nNodes )) allOutputsStacked = np . stack ( outputs ) # What? Where? When? result = xr . DataArray ( allOutputsStacked , coords = [ outputNames , nodes , t ], dims = [ \"output\" , \"space\" , \"time\" ]) return result","title":"xr()"},{"location":"models/parameters/","text":"Parameters Model parameters in neurolib are stored as a dictionary-like object params as one of a model's attributes. Changing parameters is straightforward: from neurolib.models.aln import ALNModel # Import the model model = ALNModel () # Create an instance model . params [ 'duration' ] = 10 * 1000 # in ms model . run () # Run it Parameters are dotdict objects that can also be accessed using the more simple syntax model.params.parameter_name = 123 (see Collections ). Default parameters The default parameters of a model are stored in the loadDefaultParams.py within each model's directory. This function is called by the model.py file upon initialisation and returns all necessary parameters of the model. Below is an example function that prepares the structural connectivity matrices Cmat and Dmat , all parameters of the model, and its initial values. def loadDefaultParams ( Cmat = None , Dmat = None , seed = None ): \"\"\"Load default parameters for a model :param Cmat: Structural connectivity matrix (adjacency matrix) of coupling strengths, will be normalized to 1. If not given, then a single node simulation will be assumed, defaults to None :type Cmat: numpy.ndarray, optional :param Dmat: Fiber length matrix, will be used for computing the delay matrix together with the signal transmission speed parameter `signalV`, defaults to None :type Dmat: numpy.ndarray, optional :param seed: Seed for the random number generator, defaults to None :type seed: int, optional :return: A dictionary with the default parameters of the model :rtype: dict \"\"\" params = dotdict ({}) ### runtime parameters params . dt = 0.1 # ms 0.1ms is reasonable params . duration = 2000 # Simulation duration (ms) np . random . seed ( seed ) # seed for RNG of noise and ICs # set seed to 0 if None, pypet will complain otherwise params . seed = seed or 0 # make sure that seed=0 remains None if seed == 0 : seed = None # ------------------------------------------------------------------------ # global whole-brain network parameters # ------------------------------------------------------------------------ # the coupling parameter determines how nodes are coupled. # \"diffusive\" for diffusive coupling, \"additive\" for additive coupling params . coupling = \"diffusive\" params . signalV = 20.0 params . K_gl = 0.6 # global coupling strength if Cmat is None : params . N = 1 params . Cmat = np . zeros (( 1 , 1 )) params . lengthMat = np . zeros (( 1 , 1 )) else : params . Cmat = Cmat . copy () # coupling matrix np . fill_diagonal ( params . Cmat , 0 ) # no self connections params . N = len ( params . Cmat ) # number of nodes params . lengthMat = Dmat # ------------------------------------------------------------------------ # local node parameters # ------------------------------------------------------------------------ # external input parameters: params . tau_ou = 5.0 # ms Timescale of the Ornstein-Uhlenbeck noise process params . sigma_ou = 0.0 # mV/ms/sqrt(ms) noise intensity params . x_ou_mean = 0.0 # mV/ms (OU process) [0-5] params . y_ou_mean = 0.0 # mV/ms (OU process) [0-5] # neural mass model parameters params . a = 0.25 # Hopf bifurcation parameter params . w = 0.2 # Oscillator frequency, 32 Hz at w = 0.2 # ------------------------------------------------------------------------ # initial values of the state variables params . xs_init = 0.5 * np . random . uniform ( - 1 , 1 , ( params . N , 1 )) params . ys_init = 0.5 * np . random . uniform ( - 1 , 1 , ( params . N , 1 )) # Ornstein-Uhlenbeck noise state variables params . x_ou = np . zeros (( params . N ,)) params . y_ou = np . zeros (( params . N ,)) # values of the external inputs params . x_ext = np . zeros (( params . N ,)) params . y_ext = np . zeros (( params . N ,)) return params","title":"Parameters"},{"location":"models/parameters/#parameters","text":"Model parameters in neurolib are stored as a dictionary-like object params as one of a model's attributes. Changing parameters is straightforward: from neurolib.models.aln import ALNModel # Import the model model = ALNModel () # Create an instance model . params [ 'duration' ] = 10 * 1000 # in ms model . run () # Run it Parameters are dotdict objects that can also be accessed using the more simple syntax model.params.parameter_name = 123 (see Collections ).","title":"Parameters"},{"location":"models/parameters/#default-parameters","text":"The default parameters of a model are stored in the loadDefaultParams.py within each model's directory. This function is called by the model.py file upon initialisation and returns all necessary parameters of the model. Below is an example function that prepares the structural connectivity matrices Cmat and Dmat , all parameters of the model, and its initial values. def loadDefaultParams ( Cmat = None , Dmat = None , seed = None ): \"\"\"Load default parameters for a model :param Cmat: Structural connectivity matrix (adjacency matrix) of coupling strengths, will be normalized to 1. If not given, then a single node simulation will be assumed, defaults to None :type Cmat: numpy.ndarray, optional :param Dmat: Fiber length matrix, will be used for computing the delay matrix together with the signal transmission speed parameter `signalV`, defaults to None :type Dmat: numpy.ndarray, optional :param seed: Seed for the random number generator, defaults to None :type seed: int, optional :return: A dictionary with the default parameters of the model :rtype: dict \"\"\" params = dotdict ({}) ### runtime parameters params . dt = 0.1 # ms 0.1ms is reasonable params . duration = 2000 # Simulation duration (ms) np . random . seed ( seed ) # seed for RNG of noise and ICs # set seed to 0 if None, pypet will complain otherwise params . seed = seed or 0 # make sure that seed=0 remains None if seed == 0 : seed = None # ------------------------------------------------------------------------ # global whole-brain network parameters # ------------------------------------------------------------------------ # the coupling parameter determines how nodes are coupled. # \"diffusive\" for diffusive coupling, \"additive\" for additive coupling params . coupling = \"diffusive\" params . signalV = 20.0 params . K_gl = 0.6 # global coupling strength if Cmat is None : params . N = 1 params . Cmat = np . zeros (( 1 , 1 )) params . lengthMat = np . zeros (( 1 , 1 )) else : params . Cmat = Cmat . copy () # coupling matrix np . fill_diagonal ( params . Cmat , 0 ) # no self connections params . N = len ( params . Cmat ) # number of nodes params . lengthMat = Dmat # ------------------------------------------------------------------------ # local node parameters # ------------------------------------------------------------------------ # external input parameters: params . tau_ou = 5.0 # ms Timescale of the Ornstein-Uhlenbeck noise process params . sigma_ou = 0.0 # mV/ms/sqrt(ms) noise intensity params . x_ou_mean = 0.0 # mV/ms (OU process) [0-5] params . y_ou_mean = 0.0 # mV/ms (OU process) [0-5] # neural mass model parameters params . a = 0.25 # Hopf bifurcation parameter params . w = 0.2 # Oscillator frequency, 32 Hz at w = 0.2 # ------------------------------------------------------------------------ # initial values of the state variables params . xs_init = 0.5 * np . random . uniform ( - 1 , 1 , ( params . N , 1 )) params . ys_init = 0.5 * np . random . uniform ( - 1 , 1 , ( params . N , 1 )) # Ornstein-Uhlenbeck noise state variables params . x_ou = np . zeros (( params . N ,)) params . y_ou = np . zeros (( params . N ,)) # values of the external inputs params . x_ext = np . zeros (( params . N ,)) params . y_ext = np . zeros (( params . N ,)) return params","title":"Default parameters"},{"location":"optimization/evolution/","text":"Evolution Evolutionary parameter optimization. This class helps you to optimize any function or model using an evolutionary algorithm. It uses the package deap and supports its builtin mating and selection functions as well as custom ones. Source code in neurolib/optimize/evolution/evolution.py class Evolution : \"\"\"Evolutionary parameter optimization. This class helps you to optimize any function or model using an evolutionary algorithm. It uses the package `deap` and supports its builtin mating and selection functions as well as custom ones. \"\"\" def __init__ ( self , evalFunction , parameterSpace , weightList = None , model = None , filename = \"evolution.hdf\" , ncores = None , POP_INIT_SIZE = 100 , POP_SIZE = 20 , NGEN = 10 , algorithm = \"adaptive\" , matingOperator = None , MATE_P = None , mutationOperator = None , MUTATE_P = None , selectionOperator = None , SELECT_P = None , parentSelectionOperator = None , PARENT_SELECT_P = None , individualGenerator = None , IND_GENERATOR_P = None , ): \"\"\"Initialize evolutionary optimization. :param evalFunction: Evaluation function of a run that provides a fitness vector and simulation outputs :type evalFunction: function :param parameterSpace: Parameter space to run evolution in. :type parameterSpace: `neurolib.utils.parameterSpace.ParameterSpace` :param weightList: List of floats that defines the dimensionality of the fitness vector returned from evalFunction and the weights of each component for multiobjective optimization (positive = maximize, negative = minimize). If not given, then a single positive weight will be used, defaults to None :type weightList: list[float], optional :param model: Model to simulate, defaults to None :type model: `neurolib.models.model.Model`, optional :param filename: HDF file to store all results in, defaults to \"evolution.hdf\" :type filename: str, optional :param ncores: Number of cores to simulate on (max cores default), defaults to None :type ncores: int, optional :param POP_INIT_SIZE: Size of first population to initialize evolution with (random, uniformly distributed), defaults to 100 :type POP_INIT_SIZE: int, optional :param POP_SIZE: Size of the population during evolution, defaults to 20 :type POP_SIZE: int, optional :param NGEN: Numbers of generations to evaluate, defaults to 10 :type NGEN: int, optional :param matingOperator: Custom mating operator, defaults to deap.tools.cxBlend :type matingOperator: deap operator, optional :param MATE_P: Mating operator keyword arguments (for the default crossover operator cxBlend, this defaults `alpha` = 0.5) :type MATE_P: dict, optional :param mutationOperator: Custom mutation operator, defaults to du.gaussianAdaptiveMutation_nStepSizes :type mutationOperator: deap operator, optional :param MUTATE_P: Mutation operator keyword arguments :type MUTATE_P: dict, optional :param selectionOperator: Custom selection operator, defaults to du.selBest_multiObj :type selectionOperator: deap operator, optional :param SELECT_P: Selection operator keyword arguments :type SELECT_P: dict, optional :param parentSelectionOperator: Operator for parent selection, defaults to du.selRank :param PARENT_SELECT_P: Parent selection operator keyword arguments (for the default operator selRank, this defaults to `s` = 1.5 in Eiben&Smith p.81) :type PARENT_SELECT_P: dict, optional :param individualGenerator: Function to generate initial individuals, defaults to du.randomParametersAdaptive \"\"\" if weightList is None : logging . info ( \"weightList not set, assuming single fitness value to be maximized.\" ) weightList = [ 1.0 ] trajectoryName = \"results\" + datetime . datetime . now () . strftime ( \"-%Y-%m- %d -%HH-%MM-%SS\" ) logging . info ( f \"Trajectory Name: { trajectoryName } \" ) self . HDF_FILE = os . path . join ( paths . HDF_DIR , filename ) trajectoryFileName = self . HDF_FILE logging . info ( \"Storing data to: {} \" . format ( trajectoryFileName )) logging . info ( \"Trajectory Name: {} \" . format ( trajectoryName )) if ncores is None : ncores = multiprocessing . cpu_count () logging . info ( \"Number of cores: {} \" . format ( ncores )) # initialize pypet environment # env = pp.Environment(trajectory=trajectoryName, filename=trajectoryFileName) env = pp . Environment ( trajectory = trajectoryName , filename = trajectoryFileName , use_pool = False , multiproc = True , ncores = ncores , complevel = 9 , log_config = paths . PYPET_LOGGING_CONFIG , ) # Get the trajectory from the environment traj = env . traj # Sanity check if everything went ok assert ( trajectoryName == traj . v_name ), f \"Pypet trajectory has a different name than trajectoryName { trajectoryName } \" # trajectoryName = traj.v_name self . model = model self . evalFunction = evalFunction self . weightList = weightList self . NGEN = NGEN assert POP_SIZE % 2 == 0 , \"Please chose an even number for POP_SIZE!\" self . POP_SIZE = POP_SIZE assert POP_INIT_SIZE % 2 == 0 , \"Please chose an even number for POP_INIT_SIZE!\" self . POP_INIT_SIZE = POP_INIT_SIZE self . ncores = ncores # comment string for storing info self . comments = \"no comments\" self . traj = env . traj self . env = env self . trajectoryName = trajectoryName self . trajectoryFileName = trajectoryFileName self . _initialPopulationSimulated = False # -------- settings self . verbose = False self . verbose_plotting = True self . plotColor = \"C0\" # -------- simulation self . parameterSpace = parameterSpace self . ParametersInterval = self . parameterSpace . named_tuple_constructor self . paramInterval = self . parameterSpace . named_tuple self . toolbox = deap . base . Toolbox () # -------- algorithms if algorithm == \"adaptive\" : logging . info ( f \"Evolution: Using algorithm: { algorithm } \" ) self . matingOperator = tools . cxBlend self . MATE_P = { \"alpha\" : 0.5 } or MATE_P self . mutationOperator = du . gaussianAdaptiveMutation_nStepSizes self . selectionOperator = du . selBest_multiObj self . parentSelectionOperator = du . selRank self . PARENT_SELECT_P = { \"s\" : 1.5 } or PARENT_SELECT_P self . individualGenerator = du . randomParametersAdaptive elif algorithm == \"nsga2\" : logging . info ( f \"Evolution: Using algorithm: { algorithm } \" ) self . matingOperator = tools . cxSimulatedBinaryBounded self . MATE_P = { \"low\" : self . parameterSpace . lowerBound , \"up\" : self . parameterSpace . upperBound , \"eta\" : 20.0 , } or MATE_P self . mutationOperator = tools . mutPolynomialBounded self . MUTATE_P = { \"low\" : self . parameterSpace . lowerBound , \"up\" : self . parameterSpace . upperBound , \"eta\" : 20.0 , \"indpb\" : 1.0 / len ( self . weightList ), } or MUTATE_P self . selectionOperator = tools . selNSGA2 self . parentSelectionOperator = tools . selTournamentDCD self . individualGenerator = du . randomParameters else : raise ValueError ( \"Evolution: algorithm must be one of the following: ['adaptive', 'nsga2']\" ) # if the operators are set manually, then overwrite them self . matingOperator = self . matingOperator if hasattr ( self , \"matingOperator\" ) else matingOperator self . mutationOperator = self . mutationOperator if hasattr ( self , \"mutationOperator\" ) else mutationOperator self . selectionOperator = self . selectionOperator if hasattr ( self , \"selectionOperator\" ) else selectionOperator self . parentSelectionOperator = ( self . parentSelectionOperator if hasattr ( self , \"parentSelectionOperator\" ) else parentSelectionOperator ) self . individualGenerator = ( self . individualGenerator if hasattr ( self , \"individualGenerator\" ) else individualGenerator ) # let's also make sure that the parameters are set correctly self . MATE_P = self . MATE_P if hasattr ( self , \"MATE_P\" ) else {} self . PARENT_SELECT_P = self . PARENT_SELECT_P if hasattr ( self , \"PARENT_SELECT_P\" ) else {} self . MUTATE_P = self . MUTATE_P if hasattr ( self , \"MUTATE_P\" ) else {} self . SELECT_P = self . SELECT_P if hasattr ( self , \"SELECT_P\" ) else {} self . _initDEAP ( self . toolbox , self . env , self . paramInterval , self . evalFunction , weightList = self . weightList , matingOperator = self . matingOperator , mutationOperator = self . mutationOperator , selectionOperator = self . selectionOperator , parentSelectionOperator = self . parentSelectionOperator , individualGenerator = self . individualGenerator , ) # set up pypet trajectory self . _initPypetTrajectory ( self . traj , self . paramInterval , self . POP_SIZE , self . NGEN , self . model , ) # population history: dict of all valid individuals per generation self . history = {} # initialize population self . evaluationCounter = 0 self . last_id = 0 def run ( self , verbose = False , verbose_plotting = True ): \"\"\"Run the evolution or continue previous evolution. If evolution was not initialized first using `runInitial()`, this will be done. :param verbose: Print and plot state of evolution during run, defaults to False :type verbose: bool, optional \"\"\" self . verbose = verbose self . verbose_plotting = verbose_plotting if not self . _initialPopulationSimulated : self . runInitial () self . runEvolution () def getIndividualFromTraj ( self , traj ): \"\"\"Get individual from pypet trajectory :param traj: Pypet trajectory :type traj: `pypet.trajectory.Trajectory` :return: Individual (`DEAP` type) :rtype: `deap.creator.Individual` \"\"\" # either pass an individual or a pypet trajectory with the attribute individual if type ( traj ) . __name__ == \"Individual\" : individual = traj else : individual = traj . individual ind_id = traj . id individual = [ p for p in self . pop if p . id == ind_id ] if len ( individual ) > 0 : individual = individual [ 0 ] return individual def getModelFromTraj ( self , traj ): \"\"\"Return the appropriate model with parameters for this individual :params traj: Pypet trajectory with individual (traj.individual) or directly a deap.Individual :returns model: Model with the parameters of this individual. :param traj: Pypet trajectory with individual (traj.individual) or directly a deap.Individual :type traj: `pypet.trajectory.Trajectory` :return: Model with the parameters of this individual. :rtype: `neurolib.models.model.Model` \"\"\" model = self . model # resolve star notation - MultiModel individual_params = self . individualToDict ( self . getIndividualFromTraj ( traj )) if self . parameterSpace . star : individual_params = unwrap_star_dotdict ( individual_params , self . model , replaced_dict = BACKWARD_REPLACE ) model . params . update ( individual_params ) return model def getIndividualFromHistory ( self , id ): \"\"\"Searches the entire evolution history for an individual with a specific id and returns it. :param id: Individual id :type id: int :return: Individual (`DEAP` type) :rtype: `deap.creator.Individual` \"\"\" for key , value in self . history . items (): for p in value : if p . id == id : return p logging . warning ( f \"No individual with id= { id } found. Returning `None`\" ) return None def individualToDict ( self , individual ): \"\"\"Convert an individual to a parameter dictionary. :param individual: Individual (`DEAP` type) :type individual: `deap.creator.Individual` :return: Parameter dictionary of this individual :rtype: dict \"\"\" return self . ParametersInterval ( * ( individual [: len ( self . paramInterval )])) . _asdict () . copy () def _initPypetTrajectory ( self , traj , paramInterval , POP_SIZE , NGEN , model ): \"\"\"Initializes pypet trajectory and store all simulation parameters for later analysis. :param traj: Pypet trajectory (must be already initialized!) :type traj: `pypet.trajectory.Trajectory` :param paramInterval: Parameter space, from ParameterSpace class :type paramInterval: parameterSpace.named_tuple :param POP_SIZE: Population size :type POP_SIZE: int :param MATE_P: Crossover parameter :type MATE_P: float :param NGEN: Number of generations :type NGEN: int :param model: Model to store the default parameters of :type model: `neurolib.models.model.Model` \"\"\" # Initialize pypet trajectory and add all simulation parameters traj . f_add_parameter ( \"popsize\" , POP_SIZE , comment = \"Population size\" ) # traj . f_add_parameter ( \"NGEN\" , NGEN , comment = \"Number of generations\" ) # Placeholders for individuals and results that are about to be explored traj . f_add_parameter ( \"generation\" , 0 , comment = \"Current generation\" ) traj . f_add_result ( \"scores\" , [], comment = \"Score of all individuals for each generation\" ) traj . f_add_result_group ( \"evolution\" , comment = \"Contains results for each generation\" ) traj . f_add_result_group ( \"outputs\" , comment = \"Contains simulation results\" ) # TODO: save evolution parameters and operators as well, MATE_P, MUTATE_P, etc.. # if a model was given, save its parameters # NOTE: Convert model.params to dict() since it is a dotdict() and pypet doesn't like that if model is not None : params_dict = dict ( model . params ) # replace all None with zeros, pypet doesn't like None for key , value in params_dict . items (): if value is None : params_dict [ key ] = \"None\" traj . f_add_result ( \"params\" , params_dict , comment = \"Default parameters\" ) # todo: initialize this after individuals have been defined! traj . f_add_parameter ( \"id\" , 0 , comment = \"Index of individual\" ) traj . f_add_parameter ( \"ind_len\" , 20 , comment = \"Length of individual\" ) traj . f_add_derived_parameter ( \"individual\" , [ 0 for x in range ( traj . ind_len )], \"An indivudal of the population\" , ) def _initDEAP ( self , toolbox , pypetEnvironment , paramInterval , evalFunction , weightList , matingOperator , mutationOperator , selectionOperator , parentSelectionOperator , individualGenerator , ): \"\"\"Initializes DEAP and registers all methods to the deap.toolbox :param toolbox: Deap toolbox :type toolbox: deap.base.Toolbox :param pypetEnvironment: Pypet environment (must be initialized first!) :type pypetEnvironment: [type] :param paramInterval: Parameter space, from ParameterSpace class :type paramInterval: parameterSpace.named_tuple :param evalFunction: Evaluation function :type evalFunction: function :param weightList: List of weiths for multiobjective optimization :type weightList: list[float] :param matingOperator: Mating function (crossover) :type matingOperator: function :param selectionOperator: Parent selection function :type selectionOperator: function :param individualGenerator: Function that generates individuals \"\"\" # ------------- register everything in deap deap . creator . create ( \"FitnessMulti\" , deap . base . Fitness , weights = tuple ( weightList )) deap . creator . create ( \"Individual\" , list , fitness = deap . creator . FitnessMulti ) # initially, each individual has randomized genes # need to create a lambda funciton because du.generateRandomParams wants an argument but # toolbox.register cannot pass an argument to it. toolbox . register ( \"individual\" , deap . tools . initIterate , deap . creator . Individual , lambda : individualGenerator ( paramInterval ), ) logging . info ( f \"Evolution: Individual generation: { individualGenerator } \" ) toolbox . register ( \"population\" , deap . tools . initRepeat , list , toolbox . individual ) toolbox . register ( \"map\" , pypetEnvironment . run ) toolbox . register ( \"run_map\" , pypetEnvironment . run_map ) def _worker ( arg , fn ): \"\"\" Wrapper to get original exception from inner, `fn`, function. \"\"\" try : return fn ( arg ) except Exception as e : logging . exception ( e ) raise toolbox . register ( \"evaluate\" , partial ( _worker , fn = evalFunction )) # Operator registering toolbox . register ( \"mate\" , matingOperator ) logging . info ( f \"Evolution: Mating operator: { matingOperator } \" ) toolbox . register ( \"mutate\" , mutationOperator ) logging . info ( f \"Evolution: Mutation operator: { mutationOperator } \" ) toolbox . register ( \"selBest\" , du . selBest_multiObj ) toolbox . register ( \"selectParents\" , parentSelectionOperator ) logging . info ( f \"Evolution: Parent selection: { parentSelectionOperator } \" ) toolbox . register ( \"select\" , selectionOperator ) logging . info ( f \"Evolution: Selection operator: { selectionOperator } \" ) def _evalPopulationUsingPypet ( self , traj , toolbox , pop , gIdx ): \"\"\"Evaluate the fitness of the popoulation of the current generation using pypet :param traj: Pypet trajectory :type traj: `pypet.trajectory.Trajectory` :param toolbox: `deap` toolbox :type toolbox: deap.base.Toolbox :param pop: Population :type pop: list :param gIdx: Index of the current generation :type gIdx: int :return: Evaluated population with fitnesses :rtype: list \"\"\" # Add as many explored runs as individuals that need to be evaluated. # Furthermore, add the individuals as explored parameters. # We need to convert them to lists or write our own custom IndividualParameter ;-) # Note the second argument to `cartesian_product`: # This is for only having the cartesian product # between ``generation x (ind_idx AND individual)``, so that every individual has just one # unique index within a generation. # this function is necessary for the NSGA-2 algorithms because # some operators return np.float64 instead of float and pypet # does not like individuals with mixed types... sigh. def _cleanIndividual ( ind ): return [ float ( i ) for i in ind ] traj . f_expand ( pp . cartesian_product ( { \"generation\" : [ gIdx ], \"id\" : [ x . id for x in pop ], \"individual\" : [ list ( _cleanIndividual ( x )) for x in pop ], }, [( \"id\" , \"individual\" ), \"generation\" ], ) ) # the current generation # unique id of each individual # increment the evaluationCounter self . evaluationCounter += len ( pop ) # run simulations for one generation evolutionResult = toolbox . map ( toolbox . evaluate ) # This error can have different reasons but is most likely # due to multiprocessing problems. One possibility is that your evaluation # function is not pickleable or that it returns an object that is not pickleable. assert len ( evolutionResult ) > 0 , \"No results returned from simulations.\" for idx , result in enumerate ( evolutionResult ): runIndex , packedReturnFromEvalFunction = result # packedReturnFromEvalFunction is the return from the evaluation function # it has length two, the first is the fitness, second is the model output assert ( len ( packedReturnFromEvalFunction ) == 2 ), \"Evaluation function must return tuple with shape (fitness, output_data)\" fitnessesResult , returnedOutputs = packedReturnFromEvalFunction # store simulation outputs pop [ idx ] . outputs = returnedOutputs # store fitness values pop [ idx ] . fitness . values = fitnessesResult # compute score pop [ idx ] . fitness . score = np . ma . masked_invalid ( pop [ idx ] . fitness . wvalues ) . sum () / ( len ( pop [ idx ] . fitness . wvalues ) ) return pop def getValidPopulation ( self , pop = None ): \"\"\"Returns a list of the valid population. :params pop: Population to check, defaults to self.pop :type pop: deap population :return: List of valid population :rtype: list \"\"\" pop = pop or self . pop return [ p for p in pop if np . isfinite ( p . fitness . values ) . all ()] def getInvalidPopulation ( self , pop = None ): \"\"\"Returns a list of the invalid population. :params pop: Population to check, defaults to self.pop :type pop: deap population :return: List of invalid population :rtype: list \"\"\" pop = pop or self . pop return [ p for p in pop if not np . isfinite ( p . fitness . values ) . all ()] def _tagPopulation ( self , pop ): \"\"\"Take a fresh population and add id's and attributes such as parameters that we can use later :param pop: Fresh population :type pop: list :return: Population with tags :rtype: list \"\"\" for i , ind in enumerate ( pop ): assert not hasattr ( ind , \"id\" ), \"Individual has an id already, will not overwrite it!\" ind . id = self . last_id ind . gIdx = self . gIdx ind . simulation_stored = False ind_dict = self . individualToDict ( ind ) for key , value in ind_dict . items (): # set the parameters as attributes for easy access setattr ( ind , key , value ) ind . params = ind_dict # increment id counter self . last_id += 1 return pop def runInitial ( self ): \"\"\"Run the first round of evolution with the initial population of size `POP_INIT_SIZE` and select the best `POP_SIZE` for the following evolution. This needs to be run before `runEvolution()` \"\"\" self . _t_start_initial_population = datetime . datetime . now () # Create the initial population self . pop = self . toolbox . population ( n = self . POP_INIT_SIZE ) ### Evaluate the initial population logging . info ( \"Evaluating initial population of size %i ...\" % len ( self . pop )) self . gIdx = 0 # set generation index self . pop = self . _tagPopulation ( self . pop ) # evaluate self . pop = self . _evalPopulationUsingPypet ( self . traj , self . toolbox , self . pop , self . gIdx ) if self . verbose : eu . printParamDist ( self . pop , self . paramInterval , self . gIdx ) # save all simulation data to pypet self . pop = eu . saveToPypet ( self . traj , self . pop , self . gIdx ) # reduce initial population to popsize self . pop = self . toolbox . select ( self . pop , k = self . traj . popsize , ** self . SELECT_P ) self . _initialPopulationSimulated = True # populate history for tracking self . history [ self . gIdx ] = self . pop # self.getValidPopulation(self.pop) self . _t_end_initial_population = datetime . datetime . now () def runEvolution ( self ): \"\"\"Run the evolutionary optimization process for `NGEN` generations.\"\"\" # Start evolution logging . info ( \"Start of evolution\" ) self . _t_start_evolution = datetime . datetime . now () for self . gIdx in range ( self . gIdx + 1 , self . gIdx + self . traj . NGEN ): # ------- Weed out the invalid individuals and replace them by random new individuals -------- # validpop = self . getValidPopulation ( self . pop ) # replace invalid individuals invalidpop = self . getInvalidPopulation ( self . pop ) logging . info ( \"Replacing {} invalid individuals.\" . format ( len ( invalidpop ))) newpop = self . toolbox . population ( n = len ( invalidpop )) newpop = self . _tagPopulation ( newpop ) # ------- Create the next generation by crossover and mutation -------- # ### Select parents using rank selection and clone them ### offspring = list ( map ( self . toolbox . clone , self . toolbox . selectParents ( self . pop , self . POP_SIZE , ** self . PARENT_SELECT_P ), ) ) ##### cross-over #### for i in range ( 1 , len ( offspring ), 2 ): offspring [ i - 1 ], offspring [ i ] = self . toolbox . mate ( offspring [ i - 1 ], offspring [ i ], ** self . MATE_P ) # delete fitness inherited from parents del offspring [ i - 1 ] . fitness . values , offspring [ i ] . fitness . values del offspring [ i - 1 ] . fitness . wvalues , offspring [ i ] . fitness . wvalues # assign parent IDs to new offspring offspring [ i - 1 ] . parentIds = offspring [ i - 1 ] . id , offspring [ i ] . id offspring [ i ] . parentIds = offspring [ i - 1 ] . id , offspring [ i ] . id # delete id originally set from parents, needs to be deleted here! # will be set later in _tagPopulation() del offspring [ i - 1 ] . id , offspring [ i ] . id ##### Mutation #### # Apply mutation du . mutateUntilValid ( offspring , self . paramInterval , self . toolbox , MUTATE_P = self . MUTATE_P ) offspring = self . _tagPopulation ( offspring ) # ------- Evaluate next generation -------- # self . pop = offspring + newpop self . _evalPopulationUsingPypet ( self . traj , self . toolbox , offspring + newpop , self . gIdx ) # log individuals self . history [ self . gIdx ] = validpop + offspring + newpop # self.getValidPopulation(self.pop) # ------- Select surviving population -------- # # select next generation self . pop = self . toolbox . select ( validpop + offspring + newpop , k = self . traj . popsize , ** self . SELECT_P ) # ------- END OF ROUND ------- # save all simulation data to pypet self . pop = eu . saveToPypet ( self . traj , self . pop , self . gIdx ) # select best individual for logging self . best_ind = self . toolbox . selBest ( self . pop , 1 )[ 0 ] # text log next_print = print if self . verbose else logging . info next_print ( \"----------- Generation %i -----------\" % self . gIdx ) next_print ( \"Best individual is {} \" . format ( self . best_ind )) next_print ( \"Score: {} \" . format ( self . best_ind . fitness . score )) next_print ( \"Fitness: {} \" . format ( self . best_ind . fitness . values )) next_print ( \"--- Population statistics ---\" ) # verbose output if self . verbose : self . info ( plot = self . verbose_plotting , info = True ) logging . info ( \"--- End of evolution ---\" ) logging . info ( \"Best individual is %s , %s \" % ( self . best_ind , self . best_ind . fitness . values )) logging . info ( \"--- End of evolution ---\" ) self . traj . f_store () # We switched off automatic storing, so we need to store manually self . _t_end_evolution = datetime . datetime . now () self . _buildEvolutionTree () def _buildEvolutionTree ( self ): \"\"\"Builds a genealogy tree that is networkx compatible. Plot the tree using: import matplotlib.pyplot as plt import networkx as nx from networkx.drawing.nx_pydot import graphviz_layout G = nx.DiGraph(evolution.tree) G = G.reverse() # Make the graph top-down pos = graphviz_layout(G, prog='dot') plt.figure(figsize=(8, 8)) nx.draw(G, pos, node_size=50, alpha=0.5, node_color=list(evolution.genx.values()), with_labels=False) plt.show() \"\"\" self . tree = dict () self . id_genx = dict () self . id_score = dict () for gen , pop in self . history . items (): for p in pop : self . tree [ p . id ] = p . parentIds if hasattr ( p , \"parentIds\" ) else () self . id_genx [ p . id ] = p . gIdx self . id_score [ p . id ] = p . fitness . score def info ( self , plot = True , bestN = 5 , info = True , reverse = False ): \"\"\"Print and plot information about the evolution and the current population :param plot: plot a plot using `matplotlib`, defaults to True :type plot: bool, optional :param bestN: Print summary of `bestN` best individuals, defaults to 5 :type bestN: int, optional :param info: Print information about the evolution environment :type info: bool, optional \"\"\" if info : eu . printEvolutionInfo ( self ) validPop = self . getValidPopulation ( self . pop ) scores = self . getScores () # Text output print ( \"--- Info summary ---\" ) print ( \"Valid: {} \" . format ( len ( validPop ))) print ( \"Mean score (weighted fitness): {:.2} \" . format ( np . mean ( scores ))) eu . printParamDist ( self . pop , self . paramInterval , self . gIdx ) print ( \"--------------------\" ) print ( f \"Best { bestN } individuals:\" ) eu . printIndividuals ( self . toolbox . selBest ( self . pop , bestN ), self . paramInterval ) print ( \"--------------------\" ) # Plotting evolutionary progress if plot : # hack: during the evolution we need to use reverse=True # after the evolution (with evolution.info()), we need False try : self . plotProgress ( reverse = reverse ) except : logging . warning ( \"Could not plot progress, is this a previously saved simulation?\" ) eu . plotPopulation ( self , plotScattermatrix = True , save_plots = self . trajectoryName , color = self . plotColor , ) def plotProgress ( self , reverse = False ): \"\"\"Plots progress of fitnesses of current evolution run\"\"\" eu . plotProgress ( self , reverse = reverse ) def saveEvolution ( self , fname = None ): \"\"\"Save evolution to file using dill. :param fname: Filename, defaults to a path in ./data/ :type fname: str, optional \"\"\" import dill fname = fname or os . path . join ( \"data/\" , \"evolution-\" + self . trajectoryName + \".dill\" ) dill . dump ( self , open ( fname , \"wb\" )) logging . info ( f \"Saving evolution to { fname } \" ) def loadEvolution ( self , fname ): \"\"\"Load evolution from previously saved simulations. Example usage: ``` evaluateSimulation = lambda x: x # the function can be omitted, that's why we define a lambda here pars = ParameterSpace(['a', 'b'], # should be same as previously saved evolution [[0.0, 4.0], [0.0, 5.0]]) evolution = Evolution(evaluateSimulation, pars, weightList = [1.0]) evolution = evolution.loadEvolution(\"data/evolution-results-2020-05-15-00H-24M-48S.dill\") ``` :param fname: Filename, defaults to a path in ./data/ :type fname: str :return: Evolution :rtype: self \"\"\" import dill evolution = dill . load ( open ( fname , \"rb\" )) # parameter space is not saved correctly in dill, don't know why # that is why we recreate it using the values of # the parameter space in the dill pars = ParameterSpace ( evolution . parameterSpace . parameterNames , evolution . parameterSpace . parameterValues , ) evolution . parameterSpace = pars evolution . paramInterval = evolution . parameterSpace . named_tuple evolution . ParametersInterval = evolution . parameterSpace . named_tuple_constructor return evolution def _outputToDf ( self , pop , df ): \"\"\"Loads outputs dictionary from evolution from the .outputs attribute and writes data into a dataframe. :param pop: Population of which to get outputs from. :type pop: list :param df: Dataframe to which outputs are written :type df: pandas.core.frame.DataFrame :return: Dataframe with outputs :rtype: pandas.core.frame.DataFrame \"\"\" # defines which variable types will be saved in the results dataframe SUPPORTED_TYPES = ( float , int , np . ndarray , list ) SCALAR_TYPES = ( float , int ) ARRAY_TYPES = ( np . ndarray , list ) assert len ( pop ) == len ( df ), \"Dataframe and population do not have same length.\" nan_value = np . nan # load outputs into dataframe for i , p in enumerate ( pop ): if hasattr ( p , \"outputs\" ): for key , value in p . outputs . items (): # only save floats, ints and arrays if isinstance ( value , SUPPORTED_TYPES ): # save 1-dim arrays if isinstance ( value , ARRAY_TYPES ): # to save a numpy array, convert column to object type if key not in df : df [ key ] = None df [ key ] = df [ key ] . astype ( object ) df . at [ i , key ] = value elif isinstance ( value , SCALAR_TYPES ): # save numbers df . loc [ i , key ] = value else : df . loc [ i , key ] = nan_value return df def _dropDuplicatesFromDf ( self , df ): \"\"\"Drops duplicates from dfEvolution dataframe. Tries vanilla drop_duplicates, which fails if the Dataframe contains data objects like numpy.arrays. Tries to drop via key \"id\" if it fails. :param df: Input dataframe with duplicates to drop :type df: pandas.core.frame.DataFrame :return: Dataframe without duplicates :rtype: pandas.core.frame.DataFrame \"\"\" try : df = df . drop_duplicates () except : logging . info ( 'Failed to drop_duplicates() without column name. Trying by column \"id\".' ) try : df = df . drop_duplicates ( subset = \"id\" ) except : logging . warning ( \"Failed to drop_duplicates from dataframe.\" ) return df def dfPop ( self , outputs = False ): \"\"\"Returns a `pandas` DataFrame of the current generation's population parameters. This object can be further used to easily analyse the population. :return: Pandas DataFrame with all individuals and their parameters :rtype: `pandas.core.frame.DataFrame` \"\"\" # add the current population to the dataframe validPop = self . getValidPopulation ( self . pop ) indIds = [ p . id for p in validPop ] popArray = np . array ([ p [ 0 : len ( self . paramInterval . _fields )] for p in validPop ]) . T dfPop = pd . DataFrame ( popArray , index = self . parameterSpace . parameterNames ) . T # add more information to the dataframe scores = self . getScores () dfPop [ \"score\" ] = scores dfPop [ \"id\" ] = indIds dfPop [ \"gen\" ] = [ p . gIdx for p in validPop ] if outputs : dfPop = self . _outputToDf ( validPop , dfPop ) # add fitness columns # NOTE: when loading an evolution with dill using loadingEvolution # MultiFitness values dissappear and only one is left. # See dfEvolution() for a solution using wvalues n_fitnesses = len ( validPop [ 0 ] . fitness . values ) for i in range ( n_fitnesses ): for ip , p in enumerate ( validPop ): column_name = \"f\" + str ( i ) dfPop . loc [ ip , column_name ] = p . fitness . values [ i ] return dfPop def dfEvolution ( self , outputs = False ): \"\"\"Returns a `pandas` DataFrame with the individuals of the the whole evolution. This method can be usef after loading an evolution from disk using loadEvolution() :return: Pandas DataFrame with all individuals and their parameters :rtype: `pandas.core.frame.DataFrame` \"\"\" parameters = self . parameterSpace . parameterNames allIndividuals = [ p for gen , pop in self . history . items () for p in pop ] popArray = np . array ([ p [ 0 : len ( self . paramInterval . _fields )] for p in allIndividuals ]) . T dfEvolution = pd . DataFrame ( popArray , index = parameters ) . T # add more information to the dataframe scores = [ float ( p . fitness . score ) for p in allIndividuals ] indIds = [ p . id for p in allIndividuals ] dfEvolution [ \"score\" ] = scores dfEvolution [ \"id\" ] = indIds dfEvolution [ \"gen\" ] = [ p . gIdx for p in allIndividuals ] if outputs : dfEvolution = self . _outputToDf ( allIndividuals , dfEvolution ) # add fitness columns # NOTE: have to do this with wvalues and divide by weights later, why? # Because after loading the evolution with dill, somehow multiple fitnesses # dissappear and only the first one is left. However, wvalues still has all # fitnesses, and we have acces to weightList, so this hack kind of helps n_fitnesses = len ( self . pop [ 0 ] . fitness . wvalues ) for i in range ( n_fitnesses ): for ip , p in enumerate ( allIndividuals ): dfEvolution . loc [ ip , f \"f { i } \" ] = p . fitness . wvalues [ i ] / self . weightList [ i ] # the history keeps all individuals of all generations # there can be duplicates (in elitism for example), which we filter # out for the dataframe dfEvolution = self . _dropDuplicatesFromDf ( dfEvolution ) dfEvolution = dfEvolution . reset_index ( drop = True ) return dfEvolution def loadResults ( self , filename = None , trajectoryName = None ): \"\"\"Load results from a hdf file of a previous evolution and store the pypet trajectory in `self.traj` :param filename: hdf filename of the previous run, defaults to None :type filename: str, optional :param trajectoryName: Name of the trajectory in the hdf file to load. If not given, the last one will be loaded, defaults to None :type trajectoryName: str, optional \"\"\" if filename == None : filename = self . HDF_FILE self . traj = pu . loadPypetTrajectory ( filename , trajectoryName ) def getScores ( self ): \"\"\"Returns the scores of the current valid population\"\"\" validPop = self . getValidPopulation ( self . pop ) return np . array ([ pop . fitness . score for pop in validPop ]) def getScoresDuringEvolution ( self , traj = None , drop_first = True , reverse = False ): \"\"\"Get the scores of each generation's population. :param traj: Pypet trajectory. If not given, the current trajectory is used, defaults to None :type traj: `pypet.trajectory.Trajectory`, optional :param drop_first: Drop the first (initial) generation. This can be usefull because it can have a different size (`POP_INIT_SIZE`) than the succeeding populations (`POP_SIZE`) which can make data handling tricky, defaults to True :type drop_first: bool, optional :param reverse: Reverse the order of each generation. This is a necessary workaraound because loading from the an hdf file returns the generations in a reversed order compared to loading each generation from the pypet trajectory in memory, defaults to False :type reverse: bool, optional :return: Tuple of list of all generations and an array of the scores of all individuals :rtype: tuple[list, numpy.ndarray] \"\"\" if traj == None : traj = self . traj generation_names = list ( traj . results . evolution . f_to_dict ( nested = True ) . keys ()) if reverse : generation_names = generation_names [:: - 1 ] if drop_first and \"gen_000000\" in generation_names : generation_names . remove ( \"gen_000000\" ) npop = len ( traj . results . evolution [ generation_names [ 0 ]] . scores ) gens = [] all_scores = np . empty (( len ( generation_names ), npop )) for i , r in enumerate ( generation_names ): gens . append ( i ) scores = traj . results . evolution [ r ] . scores all_scores [ i ] = scores if drop_first : gens = np . add ( gens , 1 ) return gens , all_scores __init__ ( self , evalFunction , parameterSpace , weightList = None , model = None , filename = 'evolution.hdf' , ncores = None , POP_INIT_SIZE = 100 , POP_SIZE = 20 , NGEN = 10 , algorithm = 'adaptive' , matingOperator = None , MATE_P = None , mutationOperator = None , MUTATE_P = None , selectionOperator = None , SELECT_P = None , parentSelectionOperator = None , PARENT_SELECT_P = None , individualGenerator = None , IND_GENERATOR_P = None ) special Initialize evolutionary optimization. Parameters: Name Type Description Default evalFunction function Evaluation function of a run that provides a fitness vector and simulation outputs required parameterSpace `neurolib.utils.parameterSpace.ParameterSpace` Parameter space to run evolution in. required weightList list[float], optional List of floats that defines the dimensionality of the fitness vector returned from evalFunction and the weights of each component for multiobjective optimization (positive = maximize, negative = minimize). If not given, then a single positive weight will be used, defaults to None None model `neurolib.models.model.Model`, optional Model to simulate, defaults to None None filename str, optional HDF file to store all results in, defaults to \"evolution.hdf\" 'evolution.hdf' ncores int, optional Number of cores to simulate on (max cores default), defaults to None None POP_INIT_SIZE int, optional Size of first population to initialize evolution with (random, uniformly distributed), defaults to 100 100 POP_SIZE int, optional Size of the population during evolution, defaults to 20 20 NGEN int, optional Numbers of generations to evaluate, defaults to 10 10 matingOperator Union[deap operat,, optional] Custom mating operator, defaults to deap.tools.cxBlend None MATE_P dict, optional Mating operator keyword arguments (for the default crossover operator cxBlend, this defaults alpha = 0.5) None mutationOperator Union[deap operat,, optional] Custom mutation operator, defaults to du.gaussianAdaptiveMutation_nStepSizes None MUTATE_P dict, optional Mutation operator keyword arguments None selectionOperator Union[deap operat,, optional] Custom selection operator, defaults to du.selBest_multiObj None SELECT_P dict, optional Selection operator keyword arguments None parentSelectionOperator Operator for parent selection, defaults to du.selRank None PARENT_SELECT_P dict, optional Parent selection operator keyword arguments (for the default operator selRank, this defaults to s = 1.5 in Eiben&Smith p.81) None individualGenerator Function to generate initial individuals, defaults to du.randomParametersAdaptive None Source code in neurolib/optimize/evolution/evolution.py def __init__ ( self , evalFunction , parameterSpace , weightList = None , model = None , filename = \"evolution.hdf\" , ncores = None , POP_INIT_SIZE = 100 , POP_SIZE = 20 , NGEN = 10 , algorithm = \"adaptive\" , matingOperator = None , MATE_P = None , mutationOperator = None , MUTATE_P = None , selectionOperator = None , SELECT_P = None , parentSelectionOperator = None , PARENT_SELECT_P = None , individualGenerator = None , IND_GENERATOR_P = None , ): \"\"\"Initialize evolutionary optimization. :param evalFunction: Evaluation function of a run that provides a fitness vector and simulation outputs :type evalFunction: function :param parameterSpace: Parameter space to run evolution in. :type parameterSpace: `neurolib.utils.parameterSpace.ParameterSpace` :param weightList: List of floats that defines the dimensionality of the fitness vector returned from evalFunction and the weights of each component for multiobjective optimization (positive = maximize, negative = minimize). If not given, then a single positive weight will be used, defaults to None :type weightList: list[float], optional :param model: Model to simulate, defaults to None :type model: `neurolib.models.model.Model`, optional :param filename: HDF file to store all results in, defaults to \"evolution.hdf\" :type filename: str, optional :param ncores: Number of cores to simulate on (max cores default), defaults to None :type ncores: int, optional :param POP_INIT_SIZE: Size of first population to initialize evolution with (random, uniformly distributed), defaults to 100 :type POP_INIT_SIZE: int, optional :param POP_SIZE: Size of the population during evolution, defaults to 20 :type POP_SIZE: int, optional :param NGEN: Numbers of generations to evaluate, defaults to 10 :type NGEN: int, optional :param matingOperator: Custom mating operator, defaults to deap.tools.cxBlend :type matingOperator: deap operator, optional :param MATE_P: Mating operator keyword arguments (for the default crossover operator cxBlend, this defaults `alpha` = 0.5) :type MATE_P: dict, optional :param mutationOperator: Custom mutation operator, defaults to du.gaussianAdaptiveMutation_nStepSizes :type mutationOperator: deap operator, optional :param MUTATE_P: Mutation operator keyword arguments :type MUTATE_P: dict, optional :param selectionOperator: Custom selection operator, defaults to du.selBest_multiObj :type selectionOperator: deap operator, optional :param SELECT_P: Selection operator keyword arguments :type SELECT_P: dict, optional :param parentSelectionOperator: Operator for parent selection, defaults to du.selRank :param PARENT_SELECT_P: Parent selection operator keyword arguments (for the default operator selRank, this defaults to `s` = 1.5 in Eiben&Smith p.81) :type PARENT_SELECT_P: dict, optional :param individualGenerator: Function to generate initial individuals, defaults to du.randomParametersAdaptive \"\"\" if weightList is None : logging . info ( \"weightList not set, assuming single fitness value to be maximized.\" ) weightList = [ 1.0 ] trajectoryName = \"results\" + datetime . datetime . now () . strftime ( \"-%Y-%m- %d -%HH-%MM-%SS\" ) logging . info ( f \"Trajectory Name: { trajectoryName } \" ) self . HDF_FILE = os . path . join ( paths . HDF_DIR , filename ) trajectoryFileName = self . HDF_FILE logging . info ( \"Storing data to: {} \" . format ( trajectoryFileName )) logging . info ( \"Trajectory Name: {} \" . format ( trajectoryName )) if ncores is None : ncores = multiprocessing . cpu_count () logging . info ( \"Number of cores: {} \" . format ( ncores )) # initialize pypet environment # env = pp.Environment(trajectory=trajectoryName, filename=trajectoryFileName) env = pp . Environment ( trajectory = trajectoryName , filename = trajectoryFileName , use_pool = False , multiproc = True , ncores = ncores , complevel = 9 , log_config = paths . PYPET_LOGGING_CONFIG , ) # Get the trajectory from the environment traj = env . traj # Sanity check if everything went ok assert ( trajectoryName == traj . v_name ), f \"Pypet trajectory has a different name than trajectoryName { trajectoryName } \" # trajectoryName = traj.v_name self . model = model self . evalFunction = evalFunction self . weightList = weightList self . NGEN = NGEN assert POP_SIZE % 2 == 0 , \"Please chose an even number for POP_SIZE!\" self . POP_SIZE = POP_SIZE assert POP_INIT_SIZE % 2 == 0 , \"Please chose an even number for POP_INIT_SIZE!\" self . POP_INIT_SIZE = POP_INIT_SIZE self . ncores = ncores # comment string for storing info self . comments = \"no comments\" self . traj = env . traj self . env = env self . trajectoryName = trajectoryName self . trajectoryFileName = trajectoryFileName self . _initialPopulationSimulated = False # -------- settings self . verbose = False self . verbose_plotting = True self . plotColor = \"C0\" # -------- simulation self . parameterSpace = parameterSpace self . ParametersInterval = self . parameterSpace . named_tuple_constructor self . paramInterval = self . parameterSpace . named_tuple self . toolbox = deap . base . Toolbox () # -------- algorithms if algorithm == \"adaptive\" : logging . info ( f \"Evolution: Using algorithm: { algorithm } \" ) self . matingOperator = tools . cxBlend self . MATE_P = { \"alpha\" : 0.5 } or MATE_P self . mutationOperator = du . gaussianAdaptiveMutation_nStepSizes self . selectionOperator = du . selBest_multiObj self . parentSelectionOperator = du . selRank self . PARENT_SELECT_P = { \"s\" : 1.5 } or PARENT_SELECT_P self . individualGenerator = du . randomParametersAdaptive elif algorithm == \"nsga2\" : logging . info ( f \"Evolution: Using algorithm: { algorithm } \" ) self . matingOperator = tools . cxSimulatedBinaryBounded self . MATE_P = { \"low\" : self . parameterSpace . lowerBound , \"up\" : self . parameterSpace . upperBound , \"eta\" : 20.0 , } or MATE_P self . mutationOperator = tools . mutPolynomialBounded self . MUTATE_P = { \"low\" : self . parameterSpace . lowerBound , \"up\" : self . parameterSpace . upperBound , \"eta\" : 20.0 , \"indpb\" : 1.0 / len ( self . weightList ), } or MUTATE_P self . selectionOperator = tools . selNSGA2 self . parentSelectionOperator = tools . selTournamentDCD self . individualGenerator = du . randomParameters else : raise ValueError ( \"Evolution: algorithm must be one of the following: ['adaptive', 'nsga2']\" ) # if the operators are set manually, then overwrite them self . matingOperator = self . matingOperator if hasattr ( self , \"matingOperator\" ) else matingOperator self . mutationOperator = self . mutationOperator if hasattr ( self , \"mutationOperator\" ) else mutationOperator self . selectionOperator = self . selectionOperator if hasattr ( self , \"selectionOperator\" ) else selectionOperator self . parentSelectionOperator = ( self . parentSelectionOperator if hasattr ( self , \"parentSelectionOperator\" ) else parentSelectionOperator ) self . individualGenerator = ( self . individualGenerator if hasattr ( self , \"individualGenerator\" ) else individualGenerator ) # let's also make sure that the parameters are set correctly self . MATE_P = self . MATE_P if hasattr ( self , \"MATE_P\" ) else {} self . PARENT_SELECT_P = self . PARENT_SELECT_P if hasattr ( self , \"PARENT_SELECT_P\" ) else {} self . MUTATE_P = self . MUTATE_P if hasattr ( self , \"MUTATE_P\" ) else {} self . SELECT_P = self . SELECT_P if hasattr ( self , \"SELECT_P\" ) else {} self . _initDEAP ( self . toolbox , self . env , self . paramInterval , self . evalFunction , weightList = self . weightList , matingOperator = self . matingOperator , mutationOperator = self . mutationOperator , selectionOperator = self . selectionOperator , parentSelectionOperator = self . parentSelectionOperator , individualGenerator = self . individualGenerator , ) # set up pypet trajectory self . _initPypetTrajectory ( self . traj , self . paramInterval , self . POP_SIZE , self . NGEN , self . model , ) # population history: dict of all valid individuals per generation self . history = {} # initialize population self . evaluationCounter = 0 self . last_id = 0 dfEvolution ( self , outputs = False ) Returns a pandas DataFrame with the individuals of the the whole evolution. This method can be usef after loading an evolution from disk using loadEvolution() Returns: Type Description Union[`pandas.c,e.frame.DataFrame`] Pandas DataFrame with all individuals and their parameters Source code in neurolib/optimize/evolution/evolution.py def dfEvolution ( self , outputs = False ): \"\"\"Returns a `pandas` DataFrame with the individuals of the the whole evolution. This method can be usef after loading an evolution from disk using loadEvolution() :return: Pandas DataFrame with all individuals and their parameters :rtype: `pandas.core.frame.DataFrame` \"\"\" parameters = self . parameterSpace . parameterNames allIndividuals = [ p for gen , pop in self . history . items () for p in pop ] popArray = np . array ([ p [ 0 : len ( self . paramInterval . _fields )] for p in allIndividuals ]) . T dfEvolution = pd . DataFrame ( popArray , index = parameters ) . T # add more information to the dataframe scores = [ float ( p . fitness . score ) for p in allIndividuals ] indIds = [ p . id for p in allIndividuals ] dfEvolution [ \"score\" ] = scores dfEvolution [ \"id\" ] = indIds dfEvolution [ \"gen\" ] = [ p . gIdx for p in allIndividuals ] if outputs : dfEvolution = self . _outputToDf ( allIndividuals , dfEvolution ) # add fitness columns # NOTE: have to do this with wvalues and divide by weights later, why? # Because after loading the evolution with dill, somehow multiple fitnesses # dissappear and only the first one is left. However, wvalues still has all # fitnesses, and we have acces to weightList, so this hack kind of helps n_fitnesses = len ( self . pop [ 0 ] . fitness . wvalues ) for i in range ( n_fitnesses ): for ip , p in enumerate ( allIndividuals ): dfEvolution . loc [ ip , f \"f { i } \" ] = p . fitness . wvalues [ i ] / self . weightList [ i ] # the history keeps all individuals of all generations # there can be duplicates (in elitism for example), which we filter # out for the dataframe dfEvolution = self . _dropDuplicatesFromDf ( dfEvolution ) dfEvolution = dfEvolution . reset_index ( drop = True ) return dfEvolution dfPop ( self , outputs = False ) Returns a pandas DataFrame of the current generation's population parameters. This object can be further used to easily analyse the population. Returns: Type Description Union[`pandas.c,e.frame.DataFrame`] Pandas DataFrame with all individuals and their parameters Source code in neurolib/optimize/evolution/evolution.py def dfPop ( self , outputs = False ): \"\"\"Returns a `pandas` DataFrame of the current generation's population parameters. This object can be further used to easily analyse the population. :return: Pandas DataFrame with all individuals and their parameters :rtype: `pandas.core.frame.DataFrame` \"\"\" # add the current population to the dataframe validPop = self . getValidPopulation ( self . pop ) indIds = [ p . id for p in validPop ] popArray = np . array ([ p [ 0 : len ( self . paramInterval . _fields )] for p in validPop ]) . T dfPop = pd . DataFrame ( popArray , index = self . parameterSpace . parameterNames ) . T # add more information to the dataframe scores = self . getScores () dfPop [ \"score\" ] = scores dfPop [ \"id\" ] = indIds dfPop [ \"gen\" ] = [ p . gIdx for p in validPop ] if outputs : dfPop = self . _outputToDf ( validPop , dfPop ) # add fitness columns # NOTE: when loading an evolution with dill using loadingEvolution # MultiFitness values dissappear and only one is left. # See dfEvolution() for a solution using wvalues n_fitnesses = len ( validPop [ 0 ] . fitness . values ) for i in range ( n_fitnesses ): for ip , p in enumerate ( validPop ): column_name = \"f\" + str ( i ) dfPop . loc [ ip , column_name ] = p . fitness . values [ i ] return dfPop getIndividualFromHistory ( self , id ) Searches the entire evolution history for an individual with a specific id and returns it. Parameters: Name Type Description Default id int Individual id required Returns: Type Description Union[`deap.creat,.Individual`] Individual ( DEAP type) Source code in neurolib/optimize/evolution/evolution.py def getIndividualFromHistory ( self , id ): \"\"\"Searches the entire evolution history for an individual with a specific id and returns it. :param id: Individual id :type id: int :return: Individual (`DEAP` type) :rtype: `deap.creator.Individual` \"\"\" for key , value in self . history . items (): for p in value : if p . id == id : return p logging . warning ( f \"No individual with id= { id } found. Returning `None`\" ) return None getIndividualFromTraj ( self , traj ) Get individual from pypet trajectory Parameters: Name Type Description Default traj Union[`pypet.traject,y.Traject,y`] Pypet trajectory required Returns: Type Description Union[`deap.creat,.Individual`] Individual ( DEAP type) Source code in neurolib/optimize/evolution/evolution.py def getIndividualFromTraj ( self , traj ): \"\"\"Get individual from pypet trajectory :param traj: Pypet trajectory :type traj: `pypet.trajectory.Trajectory` :return: Individual (`DEAP` type) :rtype: `deap.creator.Individual` \"\"\" # either pass an individual or a pypet trajectory with the attribute individual if type ( traj ) . __name__ == \"Individual\" : individual = traj else : individual = traj . individual ind_id = traj . id individual = [ p for p in self . pop if p . id == ind_id ] if len ( individual ) > 0 : individual = individual [ 0 ] return individual getInvalidPopulation ( self , pop = None ) Returns a list of the invalid population. Parameters: Name Type Description Default pop deap population Population to check, defaults to self.pop None Returns: Type Description list List of invalid population Source code in neurolib/optimize/evolution/evolution.py def getInvalidPopulation ( self , pop = None ): \"\"\"Returns a list of the invalid population. :params pop: Population to check, defaults to self.pop :type pop: deap population :return: List of invalid population :rtype: list \"\"\" pop = pop or self . pop return [ p for p in pop if not np . isfinite ( p . fitness . values ) . all ()] getModelFromTraj ( self , traj ) Return the appropriate model with parameters for this individual Parameters: Name Type Description Default traj Union[`pypet.traject,y.Traject,y`] Pypet trajectory with individual (traj.individual) or directly a deap.Individual required Returns: Type Description `neurolib.models.model.Model` Model with the parameters of this individual. Source code in neurolib/optimize/evolution/evolution.py def getModelFromTraj ( self , traj ): \"\"\"Return the appropriate model with parameters for this individual :params traj: Pypet trajectory with individual (traj.individual) or directly a deap.Individual :returns model: Model with the parameters of this individual. :param traj: Pypet trajectory with individual (traj.individual) or directly a deap.Individual :type traj: `pypet.trajectory.Trajectory` :return: Model with the parameters of this individual. :rtype: `neurolib.models.model.Model` \"\"\" model = self . model # resolve star notation - MultiModel individual_params = self . individualToDict ( self . getIndividualFromTraj ( traj )) if self . parameterSpace . star : individual_params = unwrap_star_dotdict ( individual_params , self . model , replaced_dict = BACKWARD_REPLACE ) model . params . update ( individual_params ) return model getScores ( self ) Returns the scores of the current valid population Source code in neurolib/optimize/evolution/evolution.py def getScores ( self ): \"\"\"Returns the scores of the current valid population\"\"\" validPop = self . getValidPopulation ( self . pop ) return np . array ([ pop . fitness . score for pop in validPop ]) getScoresDuringEvolution ( self , traj = None , drop_first = True , reverse = False ) Get the scores of each generation's population. Parameters: Name Type Description Default traj Union[`pypet.traject,y.Traject,y`, optional] Pypet trajectory. If not given, the current trajectory is used, defaults to None None drop_first bool, optional Drop the first (initial) generation. This can be usefull because it can have a different size ( POP_INIT_SIZE ) than the succeeding populations ( POP_SIZE ) which can make data handling tricky, defaults to True True reverse bool, optional Reverse the order of each generation. This is a necessary workaraound because loading from the an hdf file returns the generations in a reversed order compared to loading each generation from the pypet trajectory in memory, defaults to False False Returns: Type Description tuple[list, numpy.ndarray] Tuple of list of all generations and an array of the scores of all individuals Source code in neurolib/optimize/evolution/evolution.py def getScoresDuringEvolution ( self , traj = None , drop_first = True , reverse = False ): \"\"\"Get the scores of each generation's population. :param traj: Pypet trajectory. If not given, the current trajectory is used, defaults to None :type traj: `pypet.trajectory.Trajectory`, optional :param drop_first: Drop the first (initial) generation. This can be usefull because it can have a different size (`POP_INIT_SIZE`) than the succeeding populations (`POP_SIZE`) which can make data handling tricky, defaults to True :type drop_first: bool, optional :param reverse: Reverse the order of each generation. This is a necessary workaraound because loading from the an hdf file returns the generations in a reversed order compared to loading each generation from the pypet trajectory in memory, defaults to False :type reverse: bool, optional :return: Tuple of list of all generations and an array of the scores of all individuals :rtype: tuple[list, numpy.ndarray] \"\"\" if traj == None : traj = self . traj generation_names = list ( traj . results . evolution . f_to_dict ( nested = True ) . keys ()) if reverse : generation_names = generation_names [:: - 1 ] if drop_first and \"gen_000000\" in generation_names : generation_names . remove ( \"gen_000000\" ) npop = len ( traj . results . evolution [ generation_names [ 0 ]] . scores ) gens = [] all_scores = np . empty (( len ( generation_names ), npop )) for i , r in enumerate ( generation_names ): gens . append ( i ) scores = traj . results . evolution [ r ] . scores all_scores [ i ] = scores if drop_first : gens = np . add ( gens , 1 ) return gens , all_scores getValidPopulation ( self , pop = None ) Returns a list of the valid population. Parameters: Name Type Description Default pop deap population Population to check, defaults to self.pop None Returns: Type Description list List of valid population Source code in neurolib/optimize/evolution/evolution.py def getValidPopulation ( self , pop = None ): \"\"\"Returns a list of the valid population. :params pop: Population to check, defaults to self.pop :type pop: deap population :return: List of valid population :rtype: list \"\"\" pop = pop or self . pop return [ p for p in pop if np . isfinite ( p . fitness . values ) . all ()] individualToDict ( self , individual ) Convert an individual to a parameter dictionary. Parameters: Name Type Description Default individual Union[`deap.creat,.Individual`] Individual ( DEAP type) required Returns: Type Description dict Parameter dictionary of this individual Source code in neurolib/optimize/evolution/evolution.py def individualToDict ( self , individual ): \"\"\"Convert an individual to a parameter dictionary. :param individual: Individual (`DEAP` type) :type individual: `deap.creator.Individual` :return: Parameter dictionary of this individual :rtype: dict \"\"\" return self . ParametersInterval ( * ( individual [: len ( self . paramInterval )])) . _asdict () . copy () info ( self , plot = True , bestN = 5 , info = True , reverse = False ) Print and plot information about the evolution and the current population Parameters: Name Type Description Default plot bool, optional plot a plot using matplotlib , defaults to True True bestN int, optional Print summary of bestN best individuals, defaults to 5 5 info bool, optional Print information about the evolution environment True Source code in neurolib/optimize/evolution/evolution.py def info ( self , plot = True , bestN = 5 , info = True , reverse = False ): \"\"\"Print and plot information about the evolution and the current population :param plot: plot a plot using `matplotlib`, defaults to True :type plot: bool, optional :param bestN: Print summary of `bestN` best individuals, defaults to 5 :type bestN: int, optional :param info: Print information about the evolution environment :type info: bool, optional \"\"\" if info : eu . printEvolutionInfo ( self ) validPop = self . getValidPopulation ( self . pop ) scores = self . getScores () # Text output print ( \"--- Info summary ---\" ) print ( \"Valid: {} \" . format ( len ( validPop ))) print ( \"Mean score (weighted fitness): {:.2} \" . format ( np . mean ( scores ))) eu . printParamDist ( self . pop , self . paramInterval , self . gIdx ) print ( \"--------------------\" ) print ( f \"Best { bestN } individuals:\" ) eu . printIndividuals ( self . toolbox . selBest ( self . pop , bestN ), self . paramInterval ) print ( \"--------------------\" ) # Plotting evolutionary progress if plot : # hack: during the evolution we need to use reverse=True # after the evolution (with evolution.info()), we need False try : self . plotProgress ( reverse = reverse ) except : logging . warning ( \"Could not plot progress, is this a previously saved simulation?\" ) eu . plotPopulation ( self , plotScattermatrix = True , save_plots = self . trajectoryName , color = self . plotColor , ) loadEvolution ( self , fname ) Load evolution from previously saved simulations. Example usage: evaluateSimulation = lambda x: x # the function can be omitted, that's why we define a lambda here pars = ParameterSpace(['a', 'b'], # should be same as previously saved evolution [[0.0, 4.0], [0.0, 5.0]]) evolution = Evolution(evaluateSimulation, pars, weightList = [1.0]) evolution = evolution.loadEvolution(\"data/evolution-results-2020-05-15-00H-24M-48S.dill\") Parameters: Name Type Description Default fname str Filename, defaults to a path in ./data/ required Returns: Type Description self Evolution Source code in neurolib/optimize/evolution/evolution.py def loadEvolution ( self , fname ): \"\"\"Load evolution from previously saved simulations. Example usage: ``` evaluateSimulation = lambda x: x # the function can be omitted, that's why we define a lambda here pars = ParameterSpace(['a', 'b'], # should be same as previously saved evolution [[0.0, 4.0], [0.0, 5.0]]) evolution = Evolution(evaluateSimulation, pars, weightList = [1.0]) evolution = evolution.loadEvolution(\"data/evolution-results-2020-05-15-00H-24M-48S.dill\") ``` :param fname: Filename, defaults to a path in ./data/ :type fname: str :return: Evolution :rtype: self \"\"\" import dill evolution = dill . load ( open ( fname , \"rb\" )) # parameter space is not saved correctly in dill, don't know why # that is why we recreate it using the values of # the parameter space in the dill pars = ParameterSpace ( evolution . parameterSpace . parameterNames , evolution . parameterSpace . parameterValues , ) evolution . parameterSpace = pars evolution . paramInterval = evolution . parameterSpace . named_tuple evolution . ParametersInterval = evolution . parameterSpace . named_tuple_constructor return evolution loadResults ( self , filename = None , trajectoryName = None ) Load results from a hdf file of a previous evolution and store the pypet trajectory in self.traj Parameters: Name Type Description Default filename str, optional hdf filename of the previous run, defaults to None None trajectoryName str, optional Name of the trajectory in the hdf file to load. If not given, the last one will be loaded, defaults to None None Source code in neurolib/optimize/evolution/evolution.py def loadResults ( self , filename = None , trajectoryName = None ): \"\"\"Load results from a hdf file of a previous evolution and store the pypet trajectory in `self.traj` :param filename: hdf filename of the previous run, defaults to None :type filename: str, optional :param trajectoryName: Name of the trajectory in the hdf file to load. If not given, the last one will be loaded, defaults to None :type trajectoryName: str, optional \"\"\" if filename == None : filename = self . HDF_FILE self . traj = pu . loadPypetTrajectory ( filename , trajectoryName ) plotProgress ( self , reverse = False ) Plots progress of fitnesses of current evolution run Source code in neurolib/optimize/evolution/evolution.py def plotProgress ( self , reverse = False ): \"\"\"Plots progress of fitnesses of current evolution run\"\"\" eu . plotProgress ( self , reverse = reverse ) run ( self , verbose = False , verbose_plotting = True ) Run the evolution or continue previous evolution. If evolution was not initialized first using runInitial() , this will be done. Parameters: Name Type Description Default verbose bool, optional Print and plot state of evolution during run, defaults to False False Source code in neurolib/optimize/evolution/evolution.py def run ( self , verbose = False , verbose_plotting = True ): \"\"\"Run the evolution or continue previous evolution. If evolution was not initialized first using `runInitial()`, this will be done. :param verbose: Print and plot state of evolution during run, defaults to False :type verbose: bool, optional \"\"\" self . verbose = verbose self . verbose_plotting = verbose_plotting if not self . _initialPopulationSimulated : self . runInitial () self . runEvolution () runEvolution ( self ) Run the evolutionary optimization process for NGEN generations. Source code in neurolib/optimize/evolution/evolution.py def runEvolution ( self ): \"\"\"Run the evolutionary optimization process for `NGEN` generations.\"\"\" # Start evolution logging . info ( \"Start of evolution\" ) self . _t_start_evolution = datetime . datetime . now () for self . gIdx in range ( self . gIdx + 1 , self . gIdx + self . traj . NGEN ): # ------- Weed out the invalid individuals and replace them by random new individuals -------- # validpop = self . getValidPopulation ( self . pop ) # replace invalid individuals invalidpop = self . getInvalidPopulation ( self . pop ) logging . info ( \"Replacing {} invalid individuals.\" . format ( len ( invalidpop ))) newpop = self . toolbox . population ( n = len ( invalidpop )) newpop = self . _tagPopulation ( newpop ) # ------- Create the next generation by crossover and mutation -------- # ### Select parents using rank selection and clone them ### offspring = list ( map ( self . toolbox . clone , self . toolbox . selectParents ( self . pop , self . POP_SIZE , ** self . PARENT_SELECT_P ), ) ) ##### cross-over #### for i in range ( 1 , len ( offspring ), 2 ): offspring [ i - 1 ], offspring [ i ] = self . toolbox . mate ( offspring [ i - 1 ], offspring [ i ], ** self . MATE_P ) # delete fitness inherited from parents del offspring [ i - 1 ] . fitness . values , offspring [ i ] . fitness . values del offspring [ i - 1 ] . fitness . wvalues , offspring [ i ] . fitness . wvalues # assign parent IDs to new offspring offspring [ i - 1 ] . parentIds = offspring [ i - 1 ] . id , offspring [ i ] . id offspring [ i ] . parentIds = offspring [ i - 1 ] . id , offspring [ i ] . id # delete id originally set from parents, needs to be deleted here! # will be set later in _tagPopulation() del offspring [ i - 1 ] . id , offspring [ i ] . id ##### Mutation #### # Apply mutation du . mutateUntilValid ( offspring , self . paramInterval , self . toolbox , MUTATE_P = self . MUTATE_P ) offspring = self . _tagPopulation ( offspring ) # ------- Evaluate next generation -------- # self . pop = offspring + newpop self . _evalPopulationUsingPypet ( self . traj , self . toolbox , offspring + newpop , self . gIdx ) # log individuals self . history [ self . gIdx ] = validpop + offspring + newpop # self.getValidPopulation(self.pop) # ------- Select surviving population -------- # # select next generation self . pop = self . toolbox . select ( validpop + offspring + newpop , k = self . traj . popsize , ** self . SELECT_P ) # ------- END OF ROUND ------- # save all simulation data to pypet self . pop = eu . saveToPypet ( self . traj , self . pop , self . gIdx ) # select best individual for logging self . best_ind = self . toolbox . selBest ( self . pop , 1 )[ 0 ] # text log next_print = print if self . verbose else logging . info next_print ( \"----------- Generation %i -----------\" % self . gIdx ) next_print ( \"Best individual is {} \" . format ( self . best_ind )) next_print ( \"Score: {} \" . format ( self . best_ind . fitness . score )) next_print ( \"Fitness: {} \" . format ( self . best_ind . fitness . values )) next_print ( \"--- Population statistics ---\" ) # verbose output if self . verbose : self . info ( plot = self . verbose_plotting , info = True ) logging . info ( \"--- End of evolution ---\" ) logging . info ( \"Best individual is %s , %s \" % ( self . best_ind , self . best_ind . fitness . values )) logging . info ( \"--- End of evolution ---\" ) self . traj . f_store () # We switched off automatic storing, so we need to store manually self . _t_end_evolution = datetime . datetime . now () self . _buildEvolutionTree () runInitial ( self ) Run the first round of evolution with the initial population of size POP_INIT_SIZE and select the best POP_SIZE for the following evolution. This needs to be run before runEvolution() Source code in neurolib/optimize/evolution/evolution.py def runInitial ( self ): \"\"\"Run the first round of evolution with the initial population of size `POP_INIT_SIZE` and select the best `POP_SIZE` for the following evolution. This needs to be run before `runEvolution()` \"\"\" self . _t_start_initial_population = datetime . datetime . now () # Create the initial population self . pop = self . toolbox . population ( n = self . POP_INIT_SIZE ) ### Evaluate the initial population logging . info ( \"Evaluating initial population of size %i ...\" % len ( self . pop )) self . gIdx = 0 # set generation index self . pop = self . _tagPopulation ( self . pop ) # evaluate self . pop = self . _evalPopulationUsingPypet ( self . traj , self . toolbox , self . pop , self . gIdx ) if self . verbose : eu . printParamDist ( self . pop , self . paramInterval , self . gIdx ) # save all simulation data to pypet self . pop = eu . saveToPypet ( self . traj , self . pop , self . gIdx ) # reduce initial population to popsize self . pop = self . toolbox . select ( self . pop , k = self . traj . popsize , ** self . SELECT_P ) self . _initialPopulationSimulated = True # populate history for tracking self . history [ self . gIdx ] = self . pop # self.getValidPopulation(self.pop) self . _t_end_initial_population = datetime . datetime . now () saveEvolution ( self , fname = None ) Save evolution to file using dill. Parameters: Name Type Description Default fname str, optional Filename, defaults to a path in ./data/ None Source code in neurolib/optimize/evolution/evolution.py def saveEvolution ( self , fname = None ): \"\"\"Save evolution to file using dill. :param fname: Filename, defaults to a path in ./data/ :type fname: str, optional \"\"\" import dill fname = fname or os . path . join ( \"data/\" , \"evolution-\" + self . trajectoryName + \".dill\" ) dill . dump ( self , open ( fname , \"wb\" )) logging . info ( f \"Saving evolution to { fname } \" )","title":"Evolution"},{"location":"optimization/evolution/#evolution","text":"Evolutionary parameter optimization. This class helps you to optimize any function or model using an evolutionary algorithm. It uses the package deap and supports its builtin mating and selection functions as well as custom ones. Source code in neurolib/optimize/evolution/evolution.py class Evolution : \"\"\"Evolutionary parameter optimization. This class helps you to optimize any function or model using an evolutionary algorithm. It uses the package `deap` and supports its builtin mating and selection functions as well as custom ones. \"\"\" def __init__ ( self , evalFunction , parameterSpace , weightList = None , model = None , filename = \"evolution.hdf\" , ncores = None , POP_INIT_SIZE = 100 , POP_SIZE = 20 , NGEN = 10 , algorithm = \"adaptive\" , matingOperator = None , MATE_P = None , mutationOperator = None , MUTATE_P = None , selectionOperator = None , SELECT_P = None , parentSelectionOperator = None , PARENT_SELECT_P = None , individualGenerator = None , IND_GENERATOR_P = None , ): \"\"\"Initialize evolutionary optimization. :param evalFunction: Evaluation function of a run that provides a fitness vector and simulation outputs :type evalFunction: function :param parameterSpace: Parameter space to run evolution in. :type parameterSpace: `neurolib.utils.parameterSpace.ParameterSpace` :param weightList: List of floats that defines the dimensionality of the fitness vector returned from evalFunction and the weights of each component for multiobjective optimization (positive = maximize, negative = minimize). If not given, then a single positive weight will be used, defaults to None :type weightList: list[float], optional :param model: Model to simulate, defaults to None :type model: `neurolib.models.model.Model`, optional :param filename: HDF file to store all results in, defaults to \"evolution.hdf\" :type filename: str, optional :param ncores: Number of cores to simulate on (max cores default), defaults to None :type ncores: int, optional :param POP_INIT_SIZE: Size of first population to initialize evolution with (random, uniformly distributed), defaults to 100 :type POP_INIT_SIZE: int, optional :param POP_SIZE: Size of the population during evolution, defaults to 20 :type POP_SIZE: int, optional :param NGEN: Numbers of generations to evaluate, defaults to 10 :type NGEN: int, optional :param matingOperator: Custom mating operator, defaults to deap.tools.cxBlend :type matingOperator: deap operator, optional :param MATE_P: Mating operator keyword arguments (for the default crossover operator cxBlend, this defaults `alpha` = 0.5) :type MATE_P: dict, optional :param mutationOperator: Custom mutation operator, defaults to du.gaussianAdaptiveMutation_nStepSizes :type mutationOperator: deap operator, optional :param MUTATE_P: Mutation operator keyword arguments :type MUTATE_P: dict, optional :param selectionOperator: Custom selection operator, defaults to du.selBest_multiObj :type selectionOperator: deap operator, optional :param SELECT_P: Selection operator keyword arguments :type SELECT_P: dict, optional :param parentSelectionOperator: Operator for parent selection, defaults to du.selRank :param PARENT_SELECT_P: Parent selection operator keyword arguments (for the default operator selRank, this defaults to `s` = 1.5 in Eiben&Smith p.81) :type PARENT_SELECT_P: dict, optional :param individualGenerator: Function to generate initial individuals, defaults to du.randomParametersAdaptive \"\"\" if weightList is None : logging . info ( \"weightList not set, assuming single fitness value to be maximized.\" ) weightList = [ 1.0 ] trajectoryName = \"results\" + datetime . datetime . now () . strftime ( \"-%Y-%m- %d -%HH-%MM-%SS\" ) logging . info ( f \"Trajectory Name: { trajectoryName } \" ) self . HDF_FILE = os . path . join ( paths . HDF_DIR , filename ) trajectoryFileName = self . HDF_FILE logging . info ( \"Storing data to: {} \" . format ( trajectoryFileName )) logging . info ( \"Trajectory Name: {} \" . format ( trajectoryName )) if ncores is None : ncores = multiprocessing . cpu_count () logging . info ( \"Number of cores: {} \" . format ( ncores )) # initialize pypet environment # env = pp.Environment(trajectory=trajectoryName, filename=trajectoryFileName) env = pp . Environment ( trajectory = trajectoryName , filename = trajectoryFileName , use_pool = False , multiproc = True , ncores = ncores , complevel = 9 , log_config = paths . PYPET_LOGGING_CONFIG , ) # Get the trajectory from the environment traj = env . traj # Sanity check if everything went ok assert ( trajectoryName == traj . v_name ), f \"Pypet trajectory has a different name than trajectoryName { trajectoryName } \" # trajectoryName = traj.v_name self . model = model self . evalFunction = evalFunction self . weightList = weightList self . NGEN = NGEN assert POP_SIZE % 2 == 0 , \"Please chose an even number for POP_SIZE!\" self . POP_SIZE = POP_SIZE assert POP_INIT_SIZE % 2 == 0 , \"Please chose an even number for POP_INIT_SIZE!\" self . POP_INIT_SIZE = POP_INIT_SIZE self . ncores = ncores # comment string for storing info self . comments = \"no comments\" self . traj = env . traj self . env = env self . trajectoryName = trajectoryName self . trajectoryFileName = trajectoryFileName self . _initialPopulationSimulated = False # -------- settings self . verbose = False self . verbose_plotting = True self . plotColor = \"C0\" # -------- simulation self . parameterSpace = parameterSpace self . ParametersInterval = self . parameterSpace . named_tuple_constructor self . paramInterval = self . parameterSpace . named_tuple self . toolbox = deap . base . Toolbox () # -------- algorithms if algorithm == \"adaptive\" : logging . info ( f \"Evolution: Using algorithm: { algorithm } \" ) self . matingOperator = tools . cxBlend self . MATE_P = { \"alpha\" : 0.5 } or MATE_P self . mutationOperator = du . gaussianAdaptiveMutation_nStepSizes self . selectionOperator = du . selBest_multiObj self . parentSelectionOperator = du . selRank self . PARENT_SELECT_P = { \"s\" : 1.5 } or PARENT_SELECT_P self . individualGenerator = du . randomParametersAdaptive elif algorithm == \"nsga2\" : logging . info ( f \"Evolution: Using algorithm: { algorithm } \" ) self . matingOperator = tools . cxSimulatedBinaryBounded self . MATE_P = { \"low\" : self . parameterSpace . lowerBound , \"up\" : self . parameterSpace . upperBound , \"eta\" : 20.0 , } or MATE_P self . mutationOperator = tools . mutPolynomialBounded self . MUTATE_P = { \"low\" : self . parameterSpace . lowerBound , \"up\" : self . parameterSpace . upperBound , \"eta\" : 20.0 , \"indpb\" : 1.0 / len ( self . weightList ), } or MUTATE_P self . selectionOperator = tools . selNSGA2 self . parentSelectionOperator = tools . selTournamentDCD self . individualGenerator = du . randomParameters else : raise ValueError ( \"Evolution: algorithm must be one of the following: ['adaptive', 'nsga2']\" ) # if the operators are set manually, then overwrite them self . matingOperator = self . matingOperator if hasattr ( self , \"matingOperator\" ) else matingOperator self . mutationOperator = self . mutationOperator if hasattr ( self , \"mutationOperator\" ) else mutationOperator self . selectionOperator = self . selectionOperator if hasattr ( self , \"selectionOperator\" ) else selectionOperator self . parentSelectionOperator = ( self . parentSelectionOperator if hasattr ( self , \"parentSelectionOperator\" ) else parentSelectionOperator ) self . individualGenerator = ( self . individualGenerator if hasattr ( self , \"individualGenerator\" ) else individualGenerator ) # let's also make sure that the parameters are set correctly self . MATE_P = self . MATE_P if hasattr ( self , \"MATE_P\" ) else {} self . PARENT_SELECT_P = self . PARENT_SELECT_P if hasattr ( self , \"PARENT_SELECT_P\" ) else {} self . MUTATE_P = self . MUTATE_P if hasattr ( self , \"MUTATE_P\" ) else {} self . SELECT_P = self . SELECT_P if hasattr ( self , \"SELECT_P\" ) else {} self . _initDEAP ( self . toolbox , self . env , self . paramInterval , self . evalFunction , weightList = self . weightList , matingOperator = self . matingOperator , mutationOperator = self . mutationOperator , selectionOperator = self . selectionOperator , parentSelectionOperator = self . parentSelectionOperator , individualGenerator = self . individualGenerator , ) # set up pypet trajectory self . _initPypetTrajectory ( self . traj , self . paramInterval , self . POP_SIZE , self . NGEN , self . model , ) # population history: dict of all valid individuals per generation self . history = {} # initialize population self . evaluationCounter = 0 self . last_id = 0 def run ( self , verbose = False , verbose_plotting = True ): \"\"\"Run the evolution or continue previous evolution. If evolution was not initialized first using `runInitial()`, this will be done. :param verbose: Print and plot state of evolution during run, defaults to False :type verbose: bool, optional \"\"\" self . verbose = verbose self . verbose_plotting = verbose_plotting if not self . _initialPopulationSimulated : self . runInitial () self . runEvolution () def getIndividualFromTraj ( self , traj ): \"\"\"Get individual from pypet trajectory :param traj: Pypet trajectory :type traj: `pypet.trajectory.Trajectory` :return: Individual (`DEAP` type) :rtype: `deap.creator.Individual` \"\"\" # either pass an individual or a pypet trajectory with the attribute individual if type ( traj ) . __name__ == \"Individual\" : individual = traj else : individual = traj . individual ind_id = traj . id individual = [ p for p in self . pop if p . id == ind_id ] if len ( individual ) > 0 : individual = individual [ 0 ] return individual def getModelFromTraj ( self , traj ): \"\"\"Return the appropriate model with parameters for this individual :params traj: Pypet trajectory with individual (traj.individual) or directly a deap.Individual :returns model: Model with the parameters of this individual. :param traj: Pypet trajectory with individual (traj.individual) or directly a deap.Individual :type traj: `pypet.trajectory.Trajectory` :return: Model with the parameters of this individual. :rtype: `neurolib.models.model.Model` \"\"\" model = self . model # resolve star notation - MultiModel individual_params = self . individualToDict ( self . getIndividualFromTraj ( traj )) if self . parameterSpace . star : individual_params = unwrap_star_dotdict ( individual_params , self . model , replaced_dict = BACKWARD_REPLACE ) model . params . update ( individual_params ) return model def getIndividualFromHistory ( self , id ): \"\"\"Searches the entire evolution history for an individual with a specific id and returns it. :param id: Individual id :type id: int :return: Individual (`DEAP` type) :rtype: `deap.creator.Individual` \"\"\" for key , value in self . history . items (): for p in value : if p . id == id : return p logging . warning ( f \"No individual with id= { id } found. Returning `None`\" ) return None def individualToDict ( self , individual ): \"\"\"Convert an individual to a parameter dictionary. :param individual: Individual (`DEAP` type) :type individual: `deap.creator.Individual` :return: Parameter dictionary of this individual :rtype: dict \"\"\" return self . ParametersInterval ( * ( individual [: len ( self . paramInterval )])) . _asdict () . copy () def _initPypetTrajectory ( self , traj , paramInterval , POP_SIZE , NGEN , model ): \"\"\"Initializes pypet trajectory and store all simulation parameters for later analysis. :param traj: Pypet trajectory (must be already initialized!) :type traj: `pypet.trajectory.Trajectory` :param paramInterval: Parameter space, from ParameterSpace class :type paramInterval: parameterSpace.named_tuple :param POP_SIZE: Population size :type POP_SIZE: int :param MATE_P: Crossover parameter :type MATE_P: float :param NGEN: Number of generations :type NGEN: int :param model: Model to store the default parameters of :type model: `neurolib.models.model.Model` \"\"\" # Initialize pypet trajectory and add all simulation parameters traj . f_add_parameter ( \"popsize\" , POP_SIZE , comment = \"Population size\" ) # traj . f_add_parameter ( \"NGEN\" , NGEN , comment = \"Number of generations\" ) # Placeholders for individuals and results that are about to be explored traj . f_add_parameter ( \"generation\" , 0 , comment = \"Current generation\" ) traj . f_add_result ( \"scores\" , [], comment = \"Score of all individuals for each generation\" ) traj . f_add_result_group ( \"evolution\" , comment = \"Contains results for each generation\" ) traj . f_add_result_group ( \"outputs\" , comment = \"Contains simulation results\" ) # TODO: save evolution parameters and operators as well, MATE_P, MUTATE_P, etc.. # if a model was given, save its parameters # NOTE: Convert model.params to dict() since it is a dotdict() and pypet doesn't like that if model is not None : params_dict = dict ( model . params ) # replace all None with zeros, pypet doesn't like None for key , value in params_dict . items (): if value is None : params_dict [ key ] = \"None\" traj . f_add_result ( \"params\" , params_dict , comment = \"Default parameters\" ) # todo: initialize this after individuals have been defined! traj . f_add_parameter ( \"id\" , 0 , comment = \"Index of individual\" ) traj . f_add_parameter ( \"ind_len\" , 20 , comment = \"Length of individual\" ) traj . f_add_derived_parameter ( \"individual\" , [ 0 for x in range ( traj . ind_len )], \"An indivudal of the population\" , ) def _initDEAP ( self , toolbox , pypetEnvironment , paramInterval , evalFunction , weightList , matingOperator , mutationOperator , selectionOperator , parentSelectionOperator , individualGenerator , ): \"\"\"Initializes DEAP and registers all methods to the deap.toolbox :param toolbox: Deap toolbox :type toolbox: deap.base.Toolbox :param pypetEnvironment: Pypet environment (must be initialized first!) :type pypetEnvironment: [type] :param paramInterval: Parameter space, from ParameterSpace class :type paramInterval: parameterSpace.named_tuple :param evalFunction: Evaluation function :type evalFunction: function :param weightList: List of weiths for multiobjective optimization :type weightList: list[float] :param matingOperator: Mating function (crossover) :type matingOperator: function :param selectionOperator: Parent selection function :type selectionOperator: function :param individualGenerator: Function that generates individuals \"\"\" # ------------- register everything in deap deap . creator . create ( \"FitnessMulti\" , deap . base . Fitness , weights = tuple ( weightList )) deap . creator . create ( \"Individual\" , list , fitness = deap . creator . FitnessMulti ) # initially, each individual has randomized genes # need to create a lambda funciton because du.generateRandomParams wants an argument but # toolbox.register cannot pass an argument to it. toolbox . register ( \"individual\" , deap . tools . initIterate , deap . creator . Individual , lambda : individualGenerator ( paramInterval ), ) logging . info ( f \"Evolution: Individual generation: { individualGenerator } \" ) toolbox . register ( \"population\" , deap . tools . initRepeat , list , toolbox . individual ) toolbox . register ( \"map\" , pypetEnvironment . run ) toolbox . register ( \"run_map\" , pypetEnvironment . run_map ) def _worker ( arg , fn ): \"\"\" Wrapper to get original exception from inner, `fn`, function. \"\"\" try : return fn ( arg ) except Exception as e : logging . exception ( e ) raise toolbox . register ( \"evaluate\" , partial ( _worker , fn = evalFunction )) # Operator registering toolbox . register ( \"mate\" , matingOperator ) logging . info ( f \"Evolution: Mating operator: { matingOperator } \" ) toolbox . register ( \"mutate\" , mutationOperator ) logging . info ( f \"Evolution: Mutation operator: { mutationOperator } \" ) toolbox . register ( \"selBest\" , du . selBest_multiObj ) toolbox . register ( \"selectParents\" , parentSelectionOperator ) logging . info ( f \"Evolution: Parent selection: { parentSelectionOperator } \" ) toolbox . register ( \"select\" , selectionOperator ) logging . info ( f \"Evolution: Selection operator: { selectionOperator } \" ) def _evalPopulationUsingPypet ( self , traj , toolbox , pop , gIdx ): \"\"\"Evaluate the fitness of the popoulation of the current generation using pypet :param traj: Pypet trajectory :type traj: `pypet.trajectory.Trajectory` :param toolbox: `deap` toolbox :type toolbox: deap.base.Toolbox :param pop: Population :type pop: list :param gIdx: Index of the current generation :type gIdx: int :return: Evaluated population with fitnesses :rtype: list \"\"\" # Add as many explored runs as individuals that need to be evaluated. # Furthermore, add the individuals as explored parameters. # We need to convert them to lists or write our own custom IndividualParameter ;-) # Note the second argument to `cartesian_product`: # This is for only having the cartesian product # between ``generation x (ind_idx AND individual)``, so that every individual has just one # unique index within a generation. # this function is necessary for the NSGA-2 algorithms because # some operators return np.float64 instead of float and pypet # does not like individuals with mixed types... sigh. def _cleanIndividual ( ind ): return [ float ( i ) for i in ind ] traj . f_expand ( pp . cartesian_product ( { \"generation\" : [ gIdx ], \"id\" : [ x . id for x in pop ], \"individual\" : [ list ( _cleanIndividual ( x )) for x in pop ], }, [( \"id\" , \"individual\" ), \"generation\" ], ) ) # the current generation # unique id of each individual # increment the evaluationCounter self . evaluationCounter += len ( pop ) # run simulations for one generation evolutionResult = toolbox . map ( toolbox . evaluate ) # This error can have different reasons but is most likely # due to multiprocessing problems. One possibility is that your evaluation # function is not pickleable or that it returns an object that is not pickleable. assert len ( evolutionResult ) > 0 , \"No results returned from simulations.\" for idx , result in enumerate ( evolutionResult ): runIndex , packedReturnFromEvalFunction = result # packedReturnFromEvalFunction is the return from the evaluation function # it has length two, the first is the fitness, second is the model output assert ( len ( packedReturnFromEvalFunction ) == 2 ), \"Evaluation function must return tuple with shape (fitness, output_data)\" fitnessesResult , returnedOutputs = packedReturnFromEvalFunction # store simulation outputs pop [ idx ] . outputs = returnedOutputs # store fitness values pop [ idx ] . fitness . values = fitnessesResult # compute score pop [ idx ] . fitness . score = np . ma . masked_invalid ( pop [ idx ] . fitness . wvalues ) . sum () / ( len ( pop [ idx ] . fitness . wvalues ) ) return pop def getValidPopulation ( self , pop = None ): \"\"\"Returns a list of the valid population. :params pop: Population to check, defaults to self.pop :type pop: deap population :return: List of valid population :rtype: list \"\"\" pop = pop or self . pop return [ p for p in pop if np . isfinite ( p . fitness . values ) . all ()] def getInvalidPopulation ( self , pop = None ): \"\"\"Returns a list of the invalid population. :params pop: Population to check, defaults to self.pop :type pop: deap population :return: List of invalid population :rtype: list \"\"\" pop = pop or self . pop return [ p for p in pop if not np . isfinite ( p . fitness . values ) . all ()] def _tagPopulation ( self , pop ): \"\"\"Take a fresh population and add id's and attributes such as parameters that we can use later :param pop: Fresh population :type pop: list :return: Population with tags :rtype: list \"\"\" for i , ind in enumerate ( pop ): assert not hasattr ( ind , \"id\" ), \"Individual has an id already, will not overwrite it!\" ind . id = self . last_id ind . gIdx = self . gIdx ind . simulation_stored = False ind_dict = self . individualToDict ( ind ) for key , value in ind_dict . items (): # set the parameters as attributes for easy access setattr ( ind , key , value ) ind . params = ind_dict # increment id counter self . last_id += 1 return pop def runInitial ( self ): \"\"\"Run the first round of evolution with the initial population of size `POP_INIT_SIZE` and select the best `POP_SIZE` for the following evolution. This needs to be run before `runEvolution()` \"\"\" self . _t_start_initial_population = datetime . datetime . now () # Create the initial population self . pop = self . toolbox . population ( n = self . POP_INIT_SIZE ) ### Evaluate the initial population logging . info ( \"Evaluating initial population of size %i ...\" % len ( self . pop )) self . gIdx = 0 # set generation index self . pop = self . _tagPopulation ( self . pop ) # evaluate self . pop = self . _evalPopulationUsingPypet ( self . traj , self . toolbox , self . pop , self . gIdx ) if self . verbose : eu . printParamDist ( self . pop , self . paramInterval , self . gIdx ) # save all simulation data to pypet self . pop = eu . saveToPypet ( self . traj , self . pop , self . gIdx ) # reduce initial population to popsize self . pop = self . toolbox . select ( self . pop , k = self . traj . popsize , ** self . SELECT_P ) self . _initialPopulationSimulated = True # populate history for tracking self . history [ self . gIdx ] = self . pop # self.getValidPopulation(self.pop) self . _t_end_initial_population = datetime . datetime . now () def runEvolution ( self ): \"\"\"Run the evolutionary optimization process for `NGEN` generations.\"\"\" # Start evolution logging . info ( \"Start of evolution\" ) self . _t_start_evolution = datetime . datetime . now () for self . gIdx in range ( self . gIdx + 1 , self . gIdx + self . traj . NGEN ): # ------- Weed out the invalid individuals and replace them by random new individuals -------- # validpop = self . getValidPopulation ( self . pop ) # replace invalid individuals invalidpop = self . getInvalidPopulation ( self . pop ) logging . info ( \"Replacing {} invalid individuals.\" . format ( len ( invalidpop ))) newpop = self . toolbox . population ( n = len ( invalidpop )) newpop = self . _tagPopulation ( newpop ) # ------- Create the next generation by crossover and mutation -------- # ### Select parents using rank selection and clone them ### offspring = list ( map ( self . toolbox . clone , self . toolbox . selectParents ( self . pop , self . POP_SIZE , ** self . PARENT_SELECT_P ), ) ) ##### cross-over #### for i in range ( 1 , len ( offspring ), 2 ): offspring [ i - 1 ], offspring [ i ] = self . toolbox . mate ( offspring [ i - 1 ], offspring [ i ], ** self . MATE_P ) # delete fitness inherited from parents del offspring [ i - 1 ] . fitness . values , offspring [ i ] . fitness . values del offspring [ i - 1 ] . fitness . wvalues , offspring [ i ] . fitness . wvalues # assign parent IDs to new offspring offspring [ i - 1 ] . parentIds = offspring [ i - 1 ] . id , offspring [ i ] . id offspring [ i ] . parentIds = offspring [ i - 1 ] . id , offspring [ i ] . id # delete id originally set from parents, needs to be deleted here! # will be set later in _tagPopulation() del offspring [ i - 1 ] . id , offspring [ i ] . id ##### Mutation #### # Apply mutation du . mutateUntilValid ( offspring , self . paramInterval , self . toolbox , MUTATE_P = self . MUTATE_P ) offspring = self . _tagPopulation ( offspring ) # ------- Evaluate next generation -------- # self . pop = offspring + newpop self . _evalPopulationUsingPypet ( self . traj , self . toolbox , offspring + newpop , self . gIdx ) # log individuals self . history [ self . gIdx ] = validpop + offspring + newpop # self.getValidPopulation(self.pop) # ------- Select surviving population -------- # # select next generation self . pop = self . toolbox . select ( validpop + offspring + newpop , k = self . traj . popsize , ** self . SELECT_P ) # ------- END OF ROUND ------- # save all simulation data to pypet self . pop = eu . saveToPypet ( self . traj , self . pop , self . gIdx ) # select best individual for logging self . best_ind = self . toolbox . selBest ( self . pop , 1 )[ 0 ] # text log next_print = print if self . verbose else logging . info next_print ( \"----------- Generation %i -----------\" % self . gIdx ) next_print ( \"Best individual is {} \" . format ( self . best_ind )) next_print ( \"Score: {} \" . format ( self . best_ind . fitness . score )) next_print ( \"Fitness: {} \" . format ( self . best_ind . fitness . values )) next_print ( \"--- Population statistics ---\" ) # verbose output if self . verbose : self . info ( plot = self . verbose_plotting , info = True ) logging . info ( \"--- End of evolution ---\" ) logging . info ( \"Best individual is %s , %s \" % ( self . best_ind , self . best_ind . fitness . values )) logging . info ( \"--- End of evolution ---\" ) self . traj . f_store () # We switched off automatic storing, so we need to store manually self . _t_end_evolution = datetime . datetime . now () self . _buildEvolutionTree () def _buildEvolutionTree ( self ): \"\"\"Builds a genealogy tree that is networkx compatible. Plot the tree using: import matplotlib.pyplot as plt import networkx as nx from networkx.drawing.nx_pydot import graphviz_layout G = nx.DiGraph(evolution.tree) G = G.reverse() # Make the graph top-down pos = graphviz_layout(G, prog='dot') plt.figure(figsize=(8, 8)) nx.draw(G, pos, node_size=50, alpha=0.5, node_color=list(evolution.genx.values()), with_labels=False) plt.show() \"\"\" self . tree = dict () self . id_genx = dict () self . id_score = dict () for gen , pop in self . history . items (): for p in pop : self . tree [ p . id ] = p . parentIds if hasattr ( p , \"parentIds\" ) else () self . id_genx [ p . id ] = p . gIdx self . id_score [ p . id ] = p . fitness . score def info ( self , plot = True , bestN = 5 , info = True , reverse = False ): \"\"\"Print and plot information about the evolution and the current population :param plot: plot a plot using `matplotlib`, defaults to True :type plot: bool, optional :param bestN: Print summary of `bestN` best individuals, defaults to 5 :type bestN: int, optional :param info: Print information about the evolution environment :type info: bool, optional \"\"\" if info : eu . printEvolutionInfo ( self ) validPop = self . getValidPopulation ( self . pop ) scores = self . getScores () # Text output print ( \"--- Info summary ---\" ) print ( \"Valid: {} \" . format ( len ( validPop ))) print ( \"Mean score (weighted fitness): {:.2} \" . format ( np . mean ( scores ))) eu . printParamDist ( self . pop , self . paramInterval , self . gIdx ) print ( \"--------------------\" ) print ( f \"Best { bestN } individuals:\" ) eu . printIndividuals ( self . toolbox . selBest ( self . pop , bestN ), self . paramInterval ) print ( \"--------------------\" ) # Plotting evolutionary progress if plot : # hack: during the evolution we need to use reverse=True # after the evolution (with evolution.info()), we need False try : self . plotProgress ( reverse = reverse ) except : logging . warning ( \"Could not plot progress, is this a previously saved simulation?\" ) eu . plotPopulation ( self , plotScattermatrix = True , save_plots = self . trajectoryName , color = self . plotColor , ) def plotProgress ( self , reverse = False ): \"\"\"Plots progress of fitnesses of current evolution run\"\"\" eu . plotProgress ( self , reverse = reverse ) def saveEvolution ( self , fname = None ): \"\"\"Save evolution to file using dill. :param fname: Filename, defaults to a path in ./data/ :type fname: str, optional \"\"\" import dill fname = fname or os . path . join ( \"data/\" , \"evolution-\" + self . trajectoryName + \".dill\" ) dill . dump ( self , open ( fname , \"wb\" )) logging . info ( f \"Saving evolution to { fname } \" ) def loadEvolution ( self , fname ): \"\"\"Load evolution from previously saved simulations. Example usage: ``` evaluateSimulation = lambda x: x # the function can be omitted, that's why we define a lambda here pars = ParameterSpace(['a', 'b'], # should be same as previously saved evolution [[0.0, 4.0], [0.0, 5.0]]) evolution = Evolution(evaluateSimulation, pars, weightList = [1.0]) evolution = evolution.loadEvolution(\"data/evolution-results-2020-05-15-00H-24M-48S.dill\") ``` :param fname: Filename, defaults to a path in ./data/ :type fname: str :return: Evolution :rtype: self \"\"\" import dill evolution = dill . load ( open ( fname , \"rb\" )) # parameter space is not saved correctly in dill, don't know why # that is why we recreate it using the values of # the parameter space in the dill pars = ParameterSpace ( evolution . parameterSpace . parameterNames , evolution . parameterSpace . parameterValues , ) evolution . parameterSpace = pars evolution . paramInterval = evolution . parameterSpace . named_tuple evolution . ParametersInterval = evolution . parameterSpace . named_tuple_constructor return evolution def _outputToDf ( self , pop , df ): \"\"\"Loads outputs dictionary from evolution from the .outputs attribute and writes data into a dataframe. :param pop: Population of which to get outputs from. :type pop: list :param df: Dataframe to which outputs are written :type df: pandas.core.frame.DataFrame :return: Dataframe with outputs :rtype: pandas.core.frame.DataFrame \"\"\" # defines which variable types will be saved in the results dataframe SUPPORTED_TYPES = ( float , int , np . ndarray , list ) SCALAR_TYPES = ( float , int ) ARRAY_TYPES = ( np . ndarray , list ) assert len ( pop ) == len ( df ), \"Dataframe and population do not have same length.\" nan_value = np . nan # load outputs into dataframe for i , p in enumerate ( pop ): if hasattr ( p , \"outputs\" ): for key , value in p . outputs . items (): # only save floats, ints and arrays if isinstance ( value , SUPPORTED_TYPES ): # save 1-dim arrays if isinstance ( value , ARRAY_TYPES ): # to save a numpy array, convert column to object type if key not in df : df [ key ] = None df [ key ] = df [ key ] . astype ( object ) df . at [ i , key ] = value elif isinstance ( value , SCALAR_TYPES ): # save numbers df . loc [ i , key ] = value else : df . loc [ i , key ] = nan_value return df def _dropDuplicatesFromDf ( self , df ): \"\"\"Drops duplicates from dfEvolution dataframe. Tries vanilla drop_duplicates, which fails if the Dataframe contains data objects like numpy.arrays. Tries to drop via key \"id\" if it fails. :param df: Input dataframe with duplicates to drop :type df: pandas.core.frame.DataFrame :return: Dataframe without duplicates :rtype: pandas.core.frame.DataFrame \"\"\" try : df = df . drop_duplicates () except : logging . info ( 'Failed to drop_duplicates() without column name. Trying by column \"id\".' ) try : df = df . drop_duplicates ( subset = \"id\" ) except : logging . warning ( \"Failed to drop_duplicates from dataframe.\" ) return df def dfPop ( self , outputs = False ): \"\"\"Returns a `pandas` DataFrame of the current generation's population parameters. This object can be further used to easily analyse the population. :return: Pandas DataFrame with all individuals and their parameters :rtype: `pandas.core.frame.DataFrame` \"\"\" # add the current population to the dataframe validPop = self . getValidPopulation ( self . pop ) indIds = [ p . id for p in validPop ] popArray = np . array ([ p [ 0 : len ( self . paramInterval . _fields )] for p in validPop ]) . T dfPop = pd . DataFrame ( popArray , index = self . parameterSpace . parameterNames ) . T # add more information to the dataframe scores = self . getScores () dfPop [ \"score\" ] = scores dfPop [ \"id\" ] = indIds dfPop [ \"gen\" ] = [ p . gIdx for p in validPop ] if outputs : dfPop = self . _outputToDf ( validPop , dfPop ) # add fitness columns # NOTE: when loading an evolution with dill using loadingEvolution # MultiFitness values dissappear and only one is left. # See dfEvolution() for a solution using wvalues n_fitnesses = len ( validPop [ 0 ] . fitness . values ) for i in range ( n_fitnesses ): for ip , p in enumerate ( validPop ): column_name = \"f\" + str ( i ) dfPop . loc [ ip , column_name ] = p . fitness . values [ i ] return dfPop def dfEvolution ( self , outputs = False ): \"\"\"Returns a `pandas` DataFrame with the individuals of the the whole evolution. This method can be usef after loading an evolution from disk using loadEvolution() :return: Pandas DataFrame with all individuals and their parameters :rtype: `pandas.core.frame.DataFrame` \"\"\" parameters = self . parameterSpace . parameterNames allIndividuals = [ p for gen , pop in self . history . items () for p in pop ] popArray = np . array ([ p [ 0 : len ( self . paramInterval . _fields )] for p in allIndividuals ]) . T dfEvolution = pd . DataFrame ( popArray , index = parameters ) . T # add more information to the dataframe scores = [ float ( p . fitness . score ) for p in allIndividuals ] indIds = [ p . id for p in allIndividuals ] dfEvolution [ \"score\" ] = scores dfEvolution [ \"id\" ] = indIds dfEvolution [ \"gen\" ] = [ p . gIdx for p in allIndividuals ] if outputs : dfEvolution = self . _outputToDf ( allIndividuals , dfEvolution ) # add fitness columns # NOTE: have to do this with wvalues and divide by weights later, why? # Because after loading the evolution with dill, somehow multiple fitnesses # dissappear and only the first one is left. However, wvalues still has all # fitnesses, and we have acces to weightList, so this hack kind of helps n_fitnesses = len ( self . pop [ 0 ] . fitness . wvalues ) for i in range ( n_fitnesses ): for ip , p in enumerate ( allIndividuals ): dfEvolution . loc [ ip , f \"f { i } \" ] = p . fitness . wvalues [ i ] / self . weightList [ i ] # the history keeps all individuals of all generations # there can be duplicates (in elitism for example), which we filter # out for the dataframe dfEvolution = self . _dropDuplicatesFromDf ( dfEvolution ) dfEvolution = dfEvolution . reset_index ( drop = True ) return dfEvolution def loadResults ( self , filename = None , trajectoryName = None ): \"\"\"Load results from a hdf file of a previous evolution and store the pypet trajectory in `self.traj` :param filename: hdf filename of the previous run, defaults to None :type filename: str, optional :param trajectoryName: Name of the trajectory in the hdf file to load. If not given, the last one will be loaded, defaults to None :type trajectoryName: str, optional \"\"\" if filename == None : filename = self . HDF_FILE self . traj = pu . loadPypetTrajectory ( filename , trajectoryName ) def getScores ( self ): \"\"\"Returns the scores of the current valid population\"\"\" validPop = self . getValidPopulation ( self . pop ) return np . array ([ pop . fitness . score for pop in validPop ]) def getScoresDuringEvolution ( self , traj = None , drop_first = True , reverse = False ): \"\"\"Get the scores of each generation's population. :param traj: Pypet trajectory. If not given, the current trajectory is used, defaults to None :type traj: `pypet.trajectory.Trajectory`, optional :param drop_first: Drop the first (initial) generation. This can be usefull because it can have a different size (`POP_INIT_SIZE`) than the succeeding populations (`POP_SIZE`) which can make data handling tricky, defaults to True :type drop_first: bool, optional :param reverse: Reverse the order of each generation. This is a necessary workaraound because loading from the an hdf file returns the generations in a reversed order compared to loading each generation from the pypet trajectory in memory, defaults to False :type reverse: bool, optional :return: Tuple of list of all generations and an array of the scores of all individuals :rtype: tuple[list, numpy.ndarray] \"\"\" if traj == None : traj = self . traj generation_names = list ( traj . results . evolution . f_to_dict ( nested = True ) . keys ()) if reverse : generation_names = generation_names [:: - 1 ] if drop_first and \"gen_000000\" in generation_names : generation_names . remove ( \"gen_000000\" ) npop = len ( traj . results . evolution [ generation_names [ 0 ]] . scores ) gens = [] all_scores = np . empty (( len ( generation_names ), npop )) for i , r in enumerate ( generation_names ): gens . append ( i ) scores = traj . results . evolution [ r ] . scores all_scores [ i ] = scores if drop_first : gens = np . add ( gens , 1 ) return gens , all_scores","title":"Evolution"},{"location":"optimization/evolution/#neurolib.optimize.evolution.evolution.Evolution.__init__","text":"Initialize evolutionary optimization. Parameters: Name Type Description Default evalFunction function Evaluation function of a run that provides a fitness vector and simulation outputs required parameterSpace `neurolib.utils.parameterSpace.ParameterSpace` Parameter space to run evolution in. required weightList list[float], optional List of floats that defines the dimensionality of the fitness vector returned from evalFunction and the weights of each component for multiobjective optimization (positive = maximize, negative = minimize). If not given, then a single positive weight will be used, defaults to None None model `neurolib.models.model.Model`, optional Model to simulate, defaults to None None filename str, optional HDF file to store all results in, defaults to \"evolution.hdf\" 'evolution.hdf' ncores int, optional Number of cores to simulate on (max cores default), defaults to None None POP_INIT_SIZE int, optional Size of first population to initialize evolution with (random, uniformly distributed), defaults to 100 100 POP_SIZE int, optional Size of the population during evolution, defaults to 20 20 NGEN int, optional Numbers of generations to evaluate, defaults to 10 10 matingOperator Union[deap operat,, optional] Custom mating operator, defaults to deap.tools.cxBlend None MATE_P dict, optional Mating operator keyword arguments (for the default crossover operator cxBlend, this defaults alpha = 0.5) None mutationOperator Union[deap operat,, optional] Custom mutation operator, defaults to du.gaussianAdaptiveMutation_nStepSizes None MUTATE_P dict, optional Mutation operator keyword arguments None selectionOperator Union[deap operat,, optional] Custom selection operator, defaults to du.selBest_multiObj None SELECT_P dict, optional Selection operator keyword arguments None parentSelectionOperator Operator for parent selection, defaults to du.selRank None PARENT_SELECT_P dict, optional Parent selection operator keyword arguments (for the default operator selRank, this defaults to s = 1.5 in Eiben&Smith p.81) None individualGenerator Function to generate initial individuals, defaults to du.randomParametersAdaptive None Source code in neurolib/optimize/evolution/evolution.py def __init__ ( self , evalFunction , parameterSpace , weightList = None , model = None , filename = \"evolution.hdf\" , ncores = None , POP_INIT_SIZE = 100 , POP_SIZE = 20 , NGEN = 10 , algorithm = \"adaptive\" , matingOperator = None , MATE_P = None , mutationOperator = None , MUTATE_P = None , selectionOperator = None , SELECT_P = None , parentSelectionOperator = None , PARENT_SELECT_P = None , individualGenerator = None , IND_GENERATOR_P = None , ): \"\"\"Initialize evolutionary optimization. :param evalFunction: Evaluation function of a run that provides a fitness vector and simulation outputs :type evalFunction: function :param parameterSpace: Parameter space to run evolution in. :type parameterSpace: `neurolib.utils.parameterSpace.ParameterSpace` :param weightList: List of floats that defines the dimensionality of the fitness vector returned from evalFunction and the weights of each component for multiobjective optimization (positive = maximize, negative = minimize). If not given, then a single positive weight will be used, defaults to None :type weightList: list[float], optional :param model: Model to simulate, defaults to None :type model: `neurolib.models.model.Model`, optional :param filename: HDF file to store all results in, defaults to \"evolution.hdf\" :type filename: str, optional :param ncores: Number of cores to simulate on (max cores default), defaults to None :type ncores: int, optional :param POP_INIT_SIZE: Size of first population to initialize evolution with (random, uniformly distributed), defaults to 100 :type POP_INIT_SIZE: int, optional :param POP_SIZE: Size of the population during evolution, defaults to 20 :type POP_SIZE: int, optional :param NGEN: Numbers of generations to evaluate, defaults to 10 :type NGEN: int, optional :param matingOperator: Custom mating operator, defaults to deap.tools.cxBlend :type matingOperator: deap operator, optional :param MATE_P: Mating operator keyword arguments (for the default crossover operator cxBlend, this defaults `alpha` = 0.5) :type MATE_P: dict, optional :param mutationOperator: Custom mutation operator, defaults to du.gaussianAdaptiveMutation_nStepSizes :type mutationOperator: deap operator, optional :param MUTATE_P: Mutation operator keyword arguments :type MUTATE_P: dict, optional :param selectionOperator: Custom selection operator, defaults to du.selBest_multiObj :type selectionOperator: deap operator, optional :param SELECT_P: Selection operator keyword arguments :type SELECT_P: dict, optional :param parentSelectionOperator: Operator for parent selection, defaults to du.selRank :param PARENT_SELECT_P: Parent selection operator keyword arguments (for the default operator selRank, this defaults to `s` = 1.5 in Eiben&Smith p.81) :type PARENT_SELECT_P: dict, optional :param individualGenerator: Function to generate initial individuals, defaults to du.randomParametersAdaptive \"\"\" if weightList is None : logging . info ( \"weightList not set, assuming single fitness value to be maximized.\" ) weightList = [ 1.0 ] trajectoryName = \"results\" + datetime . datetime . now () . strftime ( \"-%Y-%m- %d -%HH-%MM-%SS\" ) logging . info ( f \"Trajectory Name: { trajectoryName } \" ) self . HDF_FILE = os . path . join ( paths . HDF_DIR , filename ) trajectoryFileName = self . HDF_FILE logging . info ( \"Storing data to: {} \" . format ( trajectoryFileName )) logging . info ( \"Trajectory Name: {} \" . format ( trajectoryName )) if ncores is None : ncores = multiprocessing . cpu_count () logging . info ( \"Number of cores: {} \" . format ( ncores )) # initialize pypet environment # env = pp.Environment(trajectory=trajectoryName, filename=trajectoryFileName) env = pp . Environment ( trajectory = trajectoryName , filename = trajectoryFileName , use_pool = False , multiproc = True , ncores = ncores , complevel = 9 , log_config = paths . PYPET_LOGGING_CONFIG , ) # Get the trajectory from the environment traj = env . traj # Sanity check if everything went ok assert ( trajectoryName == traj . v_name ), f \"Pypet trajectory has a different name than trajectoryName { trajectoryName } \" # trajectoryName = traj.v_name self . model = model self . evalFunction = evalFunction self . weightList = weightList self . NGEN = NGEN assert POP_SIZE % 2 == 0 , \"Please chose an even number for POP_SIZE!\" self . POP_SIZE = POP_SIZE assert POP_INIT_SIZE % 2 == 0 , \"Please chose an even number for POP_INIT_SIZE!\" self . POP_INIT_SIZE = POP_INIT_SIZE self . ncores = ncores # comment string for storing info self . comments = \"no comments\" self . traj = env . traj self . env = env self . trajectoryName = trajectoryName self . trajectoryFileName = trajectoryFileName self . _initialPopulationSimulated = False # -------- settings self . verbose = False self . verbose_plotting = True self . plotColor = \"C0\" # -------- simulation self . parameterSpace = parameterSpace self . ParametersInterval = self . parameterSpace . named_tuple_constructor self . paramInterval = self . parameterSpace . named_tuple self . toolbox = deap . base . Toolbox () # -------- algorithms if algorithm == \"adaptive\" : logging . info ( f \"Evolution: Using algorithm: { algorithm } \" ) self . matingOperator = tools . cxBlend self . MATE_P = { \"alpha\" : 0.5 } or MATE_P self . mutationOperator = du . gaussianAdaptiveMutation_nStepSizes self . selectionOperator = du . selBest_multiObj self . parentSelectionOperator = du . selRank self . PARENT_SELECT_P = { \"s\" : 1.5 } or PARENT_SELECT_P self . individualGenerator = du . randomParametersAdaptive elif algorithm == \"nsga2\" : logging . info ( f \"Evolution: Using algorithm: { algorithm } \" ) self . matingOperator = tools . cxSimulatedBinaryBounded self . MATE_P = { \"low\" : self . parameterSpace . lowerBound , \"up\" : self . parameterSpace . upperBound , \"eta\" : 20.0 , } or MATE_P self . mutationOperator = tools . mutPolynomialBounded self . MUTATE_P = { \"low\" : self . parameterSpace . lowerBound , \"up\" : self . parameterSpace . upperBound , \"eta\" : 20.0 , \"indpb\" : 1.0 / len ( self . weightList ), } or MUTATE_P self . selectionOperator = tools . selNSGA2 self . parentSelectionOperator = tools . selTournamentDCD self . individualGenerator = du . randomParameters else : raise ValueError ( \"Evolution: algorithm must be one of the following: ['adaptive', 'nsga2']\" ) # if the operators are set manually, then overwrite them self . matingOperator = self . matingOperator if hasattr ( self , \"matingOperator\" ) else matingOperator self . mutationOperator = self . mutationOperator if hasattr ( self , \"mutationOperator\" ) else mutationOperator self . selectionOperator = self . selectionOperator if hasattr ( self , \"selectionOperator\" ) else selectionOperator self . parentSelectionOperator = ( self . parentSelectionOperator if hasattr ( self , \"parentSelectionOperator\" ) else parentSelectionOperator ) self . individualGenerator = ( self . individualGenerator if hasattr ( self , \"individualGenerator\" ) else individualGenerator ) # let's also make sure that the parameters are set correctly self . MATE_P = self . MATE_P if hasattr ( self , \"MATE_P\" ) else {} self . PARENT_SELECT_P = self . PARENT_SELECT_P if hasattr ( self , \"PARENT_SELECT_P\" ) else {} self . MUTATE_P = self . MUTATE_P if hasattr ( self , \"MUTATE_P\" ) else {} self . SELECT_P = self . SELECT_P if hasattr ( self , \"SELECT_P\" ) else {} self . _initDEAP ( self . toolbox , self . env , self . paramInterval , self . evalFunction , weightList = self . weightList , matingOperator = self . matingOperator , mutationOperator = self . mutationOperator , selectionOperator = self . selectionOperator , parentSelectionOperator = self . parentSelectionOperator , individualGenerator = self . individualGenerator , ) # set up pypet trajectory self . _initPypetTrajectory ( self . traj , self . paramInterval , self . POP_SIZE , self . NGEN , self . model , ) # population history: dict of all valid individuals per generation self . history = {} # initialize population self . evaluationCounter = 0 self . last_id = 0","title":"__init__()"},{"location":"optimization/evolution/#neurolib.optimize.evolution.evolution.Evolution.dfEvolution","text":"Returns a pandas DataFrame with the individuals of the the whole evolution. This method can be usef after loading an evolution from disk using loadEvolution() Returns: Type Description Union[`pandas.c,e.frame.DataFrame`] Pandas DataFrame with all individuals and their parameters Source code in neurolib/optimize/evolution/evolution.py def dfEvolution ( self , outputs = False ): \"\"\"Returns a `pandas` DataFrame with the individuals of the the whole evolution. This method can be usef after loading an evolution from disk using loadEvolution() :return: Pandas DataFrame with all individuals and their parameters :rtype: `pandas.core.frame.DataFrame` \"\"\" parameters = self . parameterSpace . parameterNames allIndividuals = [ p for gen , pop in self . history . items () for p in pop ] popArray = np . array ([ p [ 0 : len ( self . paramInterval . _fields )] for p in allIndividuals ]) . T dfEvolution = pd . DataFrame ( popArray , index = parameters ) . T # add more information to the dataframe scores = [ float ( p . fitness . score ) for p in allIndividuals ] indIds = [ p . id for p in allIndividuals ] dfEvolution [ \"score\" ] = scores dfEvolution [ \"id\" ] = indIds dfEvolution [ \"gen\" ] = [ p . gIdx for p in allIndividuals ] if outputs : dfEvolution = self . _outputToDf ( allIndividuals , dfEvolution ) # add fitness columns # NOTE: have to do this with wvalues and divide by weights later, why? # Because after loading the evolution with dill, somehow multiple fitnesses # dissappear and only the first one is left. However, wvalues still has all # fitnesses, and we have acces to weightList, so this hack kind of helps n_fitnesses = len ( self . pop [ 0 ] . fitness . wvalues ) for i in range ( n_fitnesses ): for ip , p in enumerate ( allIndividuals ): dfEvolution . loc [ ip , f \"f { i } \" ] = p . fitness . wvalues [ i ] / self . weightList [ i ] # the history keeps all individuals of all generations # there can be duplicates (in elitism for example), which we filter # out for the dataframe dfEvolution = self . _dropDuplicatesFromDf ( dfEvolution ) dfEvolution = dfEvolution . reset_index ( drop = True ) return dfEvolution","title":"dfEvolution()"},{"location":"optimization/evolution/#neurolib.optimize.evolution.evolution.Evolution.dfPop","text":"Returns a pandas DataFrame of the current generation's population parameters. This object can be further used to easily analyse the population. Returns: Type Description Union[`pandas.c,e.frame.DataFrame`] Pandas DataFrame with all individuals and their parameters Source code in neurolib/optimize/evolution/evolution.py def dfPop ( self , outputs = False ): \"\"\"Returns a `pandas` DataFrame of the current generation's population parameters. This object can be further used to easily analyse the population. :return: Pandas DataFrame with all individuals and their parameters :rtype: `pandas.core.frame.DataFrame` \"\"\" # add the current population to the dataframe validPop = self . getValidPopulation ( self . pop ) indIds = [ p . id for p in validPop ] popArray = np . array ([ p [ 0 : len ( self . paramInterval . _fields )] for p in validPop ]) . T dfPop = pd . DataFrame ( popArray , index = self . parameterSpace . parameterNames ) . T # add more information to the dataframe scores = self . getScores () dfPop [ \"score\" ] = scores dfPop [ \"id\" ] = indIds dfPop [ \"gen\" ] = [ p . gIdx for p in validPop ] if outputs : dfPop = self . _outputToDf ( validPop , dfPop ) # add fitness columns # NOTE: when loading an evolution with dill using loadingEvolution # MultiFitness values dissappear and only one is left. # See dfEvolution() for a solution using wvalues n_fitnesses = len ( validPop [ 0 ] . fitness . values ) for i in range ( n_fitnesses ): for ip , p in enumerate ( validPop ): column_name = \"f\" + str ( i ) dfPop . loc [ ip , column_name ] = p . fitness . values [ i ] return dfPop","title":"dfPop()"},{"location":"optimization/evolution/#neurolib.optimize.evolution.evolution.Evolution.getIndividualFromHistory","text":"Searches the entire evolution history for an individual with a specific id and returns it. Parameters: Name Type Description Default id int Individual id required Returns: Type Description Union[`deap.creat,.Individual`] Individual ( DEAP type) Source code in neurolib/optimize/evolution/evolution.py def getIndividualFromHistory ( self , id ): \"\"\"Searches the entire evolution history for an individual with a specific id and returns it. :param id: Individual id :type id: int :return: Individual (`DEAP` type) :rtype: `deap.creator.Individual` \"\"\" for key , value in self . history . items (): for p in value : if p . id == id : return p logging . warning ( f \"No individual with id= { id } found. Returning `None`\" ) return None","title":"getIndividualFromHistory()"},{"location":"optimization/evolution/#neurolib.optimize.evolution.evolution.Evolution.getIndividualFromTraj","text":"Get individual from pypet trajectory Parameters: Name Type Description Default traj Union[`pypet.traject,y.Traject,y`] Pypet trajectory required Returns: Type Description Union[`deap.creat,.Individual`] Individual ( DEAP type) Source code in neurolib/optimize/evolution/evolution.py def getIndividualFromTraj ( self , traj ): \"\"\"Get individual from pypet trajectory :param traj: Pypet trajectory :type traj: `pypet.trajectory.Trajectory` :return: Individual (`DEAP` type) :rtype: `deap.creator.Individual` \"\"\" # either pass an individual or a pypet trajectory with the attribute individual if type ( traj ) . __name__ == \"Individual\" : individual = traj else : individual = traj . individual ind_id = traj . id individual = [ p for p in self . pop if p . id == ind_id ] if len ( individual ) > 0 : individual = individual [ 0 ] return individual","title":"getIndividualFromTraj()"},{"location":"optimization/evolution/#neurolib.optimize.evolution.evolution.Evolution.getInvalidPopulation","text":"Returns a list of the invalid population. Parameters: Name Type Description Default pop deap population Population to check, defaults to self.pop None Returns: Type Description list List of invalid population Source code in neurolib/optimize/evolution/evolution.py def getInvalidPopulation ( self , pop = None ): \"\"\"Returns a list of the invalid population. :params pop: Population to check, defaults to self.pop :type pop: deap population :return: List of invalid population :rtype: list \"\"\" pop = pop or self . pop return [ p for p in pop if not np . isfinite ( p . fitness . values ) . all ()]","title":"getInvalidPopulation()"},{"location":"optimization/evolution/#neurolib.optimize.evolution.evolution.Evolution.getModelFromTraj","text":"Return the appropriate model with parameters for this individual Parameters: Name Type Description Default traj Union[`pypet.traject,y.Traject,y`] Pypet trajectory with individual (traj.individual) or directly a deap.Individual required Returns: Type Description `neurolib.models.model.Model` Model with the parameters of this individual. Source code in neurolib/optimize/evolution/evolution.py def getModelFromTraj ( self , traj ): \"\"\"Return the appropriate model with parameters for this individual :params traj: Pypet trajectory with individual (traj.individual) or directly a deap.Individual :returns model: Model with the parameters of this individual. :param traj: Pypet trajectory with individual (traj.individual) or directly a deap.Individual :type traj: `pypet.trajectory.Trajectory` :return: Model with the parameters of this individual. :rtype: `neurolib.models.model.Model` \"\"\" model = self . model # resolve star notation - MultiModel individual_params = self . individualToDict ( self . getIndividualFromTraj ( traj )) if self . parameterSpace . star : individual_params = unwrap_star_dotdict ( individual_params , self . model , replaced_dict = BACKWARD_REPLACE ) model . params . update ( individual_params ) return model","title":"getModelFromTraj()"},{"location":"optimization/evolution/#neurolib.optimize.evolution.evolution.Evolution.getScores","text":"Returns the scores of the current valid population Source code in neurolib/optimize/evolution/evolution.py def getScores ( self ): \"\"\"Returns the scores of the current valid population\"\"\" validPop = self . getValidPopulation ( self . pop ) return np . array ([ pop . fitness . score for pop in validPop ])","title":"getScores()"},{"location":"optimization/evolution/#neurolib.optimize.evolution.evolution.Evolution.getScoresDuringEvolution","text":"Get the scores of each generation's population. Parameters: Name Type Description Default traj Union[`pypet.traject,y.Traject,y`, optional] Pypet trajectory. If not given, the current trajectory is used, defaults to None None drop_first bool, optional Drop the first (initial) generation. This can be usefull because it can have a different size ( POP_INIT_SIZE ) than the succeeding populations ( POP_SIZE ) which can make data handling tricky, defaults to True True reverse bool, optional Reverse the order of each generation. This is a necessary workaraound because loading from the an hdf file returns the generations in a reversed order compared to loading each generation from the pypet trajectory in memory, defaults to False False Returns: Type Description tuple[list, numpy.ndarray] Tuple of list of all generations and an array of the scores of all individuals Source code in neurolib/optimize/evolution/evolution.py def getScoresDuringEvolution ( self , traj = None , drop_first = True , reverse = False ): \"\"\"Get the scores of each generation's population. :param traj: Pypet trajectory. If not given, the current trajectory is used, defaults to None :type traj: `pypet.trajectory.Trajectory`, optional :param drop_first: Drop the first (initial) generation. This can be usefull because it can have a different size (`POP_INIT_SIZE`) than the succeeding populations (`POP_SIZE`) which can make data handling tricky, defaults to True :type drop_first: bool, optional :param reverse: Reverse the order of each generation. This is a necessary workaraound because loading from the an hdf file returns the generations in a reversed order compared to loading each generation from the pypet trajectory in memory, defaults to False :type reverse: bool, optional :return: Tuple of list of all generations and an array of the scores of all individuals :rtype: tuple[list, numpy.ndarray] \"\"\" if traj == None : traj = self . traj generation_names = list ( traj . results . evolution . f_to_dict ( nested = True ) . keys ()) if reverse : generation_names = generation_names [:: - 1 ] if drop_first and \"gen_000000\" in generation_names : generation_names . remove ( \"gen_000000\" ) npop = len ( traj . results . evolution [ generation_names [ 0 ]] . scores ) gens = [] all_scores = np . empty (( len ( generation_names ), npop )) for i , r in enumerate ( generation_names ): gens . append ( i ) scores = traj . results . evolution [ r ] . scores all_scores [ i ] = scores if drop_first : gens = np . add ( gens , 1 ) return gens , all_scores","title":"getScoresDuringEvolution()"},{"location":"optimization/evolution/#neurolib.optimize.evolution.evolution.Evolution.getValidPopulation","text":"Returns a list of the valid population. Parameters: Name Type Description Default pop deap population Population to check, defaults to self.pop None Returns: Type Description list List of valid population Source code in neurolib/optimize/evolution/evolution.py def getValidPopulation ( self , pop = None ): \"\"\"Returns a list of the valid population. :params pop: Population to check, defaults to self.pop :type pop: deap population :return: List of valid population :rtype: list \"\"\" pop = pop or self . pop return [ p for p in pop if np . isfinite ( p . fitness . values ) . all ()]","title":"getValidPopulation()"},{"location":"optimization/evolution/#neurolib.optimize.evolution.evolution.Evolution.individualToDict","text":"Convert an individual to a parameter dictionary. Parameters: Name Type Description Default individual Union[`deap.creat,.Individual`] Individual ( DEAP type) required Returns: Type Description dict Parameter dictionary of this individual Source code in neurolib/optimize/evolution/evolution.py def individualToDict ( self , individual ): \"\"\"Convert an individual to a parameter dictionary. :param individual: Individual (`DEAP` type) :type individual: `deap.creator.Individual` :return: Parameter dictionary of this individual :rtype: dict \"\"\" return self . ParametersInterval ( * ( individual [: len ( self . paramInterval )])) . _asdict () . copy ()","title":"individualToDict()"},{"location":"optimization/evolution/#neurolib.optimize.evolution.evolution.Evolution.info","text":"Print and plot information about the evolution and the current population Parameters: Name Type Description Default plot bool, optional plot a plot using matplotlib , defaults to True True bestN int, optional Print summary of bestN best individuals, defaults to 5 5 info bool, optional Print information about the evolution environment True Source code in neurolib/optimize/evolution/evolution.py def info ( self , plot = True , bestN = 5 , info = True , reverse = False ): \"\"\"Print and plot information about the evolution and the current population :param plot: plot a plot using `matplotlib`, defaults to True :type plot: bool, optional :param bestN: Print summary of `bestN` best individuals, defaults to 5 :type bestN: int, optional :param info: Print information about the evolution environment :type info: bool, optional \"\"\" if info : eu . printEvolutionInfo ( self ) validPop = self . getValidPopulation ( self . pop ) scores = self . getScores () # Text output print ( \"--- Info summary ---\" ) print ( \"Valid: {} \" . format ( len ( validPop ))) print ( \"Mean score (weighted fitness): {:.2} \" . format ( np . mean ( scores ))) eu . printParamDist ( self . pop , self . paramInterval , self . gIdx ) print ( \"--------------------\" ) print ( f \"Best { bestN } individuals:\" ) eu . printIndividuals ( self . toolbox . selBest ( self . pop , bestN ), self . paramInterval ) print ( \"--------------------\" ) # Plotting evolutionary progress if plot : # hack: during the evolution we need to use reverse=True # after the evolution (with evolution.info()), we need False try : self . plotProgress ( reverse = reverse ) except : logging . warning ( \"Could not plot progress, is this a previously saved simulation?\" ) eu . plotPopulation ( self , plotScattermatrix = True , save_plots = self . trajectoryName , color = self . plotColor , )","title":"info()"},{"location":"optimization/evolution/#neurolib.optimize.evolution.evolution.Evolution.loadEvolution","text":"Load evolution from previously saved simulations. Example usage: evaluateSimulation = lambda x: x # the function can be omitted, that's why we define a lambda here pars = ParameterSpace(['a', 'b'], # should be same as previously saved evolution [[0.0, 4.0], [0.0, 5.0]]) evolution = Evolution(evaluateSimulation, pars, weightList = [1.0]) evolution = evolution.loadEvolution(\"data/evolution-results-2020-05-15-00H-24M-48S.dill\") Parameters: Name Type Description Default fname str Filename, defaults to a path in ./data/ required Returns: Type Description self Evolution Source code in neurolib/optimize/evolution/evolution.py def loadEvolution ( self , fname ): \"\"\"Load evolution from previously saved simulations. Example usage: ``` evaluateSimulation = lambda x: x # the function can be omitted, that's why we define a lambda here pars = ParameterSpace(['a', 'b'], # should be same as previously saved evolution [[0.0, 4.0], [0.0, 5.0]]) evolution = Evolution(evaluateSimulation, pars, weightList = [1.0]) evolution = evolution.loadEvolution(\"data/evolution-results-2020-05-15-00H-24M-48S.dill\") ``` :param fname: Filename, defaults to a path in ./data/ :type fname: str :return: Evolution :rtype: self \"\"\" import dill evolution = dill . load ( open ( fname , \"rb\" )) # parameter space is not saved correctly in dill, don't know why # that is why we recreate it using the values of # the parameter space in the dill pars = ParameterSpace ( evolution . parameterSpace . parameterNames , evolution . parameterSpace . parameterValues , ) evolution . parameterSpace = pars evolution . paramInterval = evolution . parameterSpace . named_tuple evolution . ParametersInterval = evolution . parameterSpace . named_tuple_constructor return evolution","title":"loadEvolution()"},{"location":"optimization/evolution/#neurolib.optimize.evolution.evolution.Evolution.loadResults","text":"Load results from a hdf file of a previous evolution and store the pypet trajectory in self.traj Parameters: Name Type Description Default filename str, optional hdf filename of the previous run, defaults to None None trajectoryName str, optional Name of the trajectory in the hdf file to load. If not given, the last one will be loaded, defaults to None None Source code in neurolib/optimize/evolution/evolution.py def loadResults ( self , filename = None , trajectoryName = None ): \"\"\"Load results from a hdf file of a previous evolution and store the pypet trajectory in `self.traj` :param filename: hdf filename of the previous run, defaults to None :type filename: str, optional :param trajectoryName: Name of the trajectory in the hdf file to load. If not given, the last one will be loaded, defaults to None :type trajectoryName: str, optional \"\"\" if filename == None : filename = self . HDF_FILE self . traj = pu . loadPypetTrajectory ( filename , trajectoryName )","title":"loadResults()"},{"location":"optimization/evolution/#neurolib.optimize.evolution.evolution.Evolution.plotProgress","text":"Plots progress of fitnesses of current evolution run Source code in neurolib/optimize/evolution/evolution.py def plotProgress ( self , reverse = False ): \"\"\"Plots progress of fitnesses of current evolution run\"\"\" eu . plotProgress ( self , reverse = reverse )","title":"plotProgress()"},{"location":"optimization/evolution/#neurolib.optimize.evolution.evolution.Evolution.run","text":"Run the evolution or continue previous evolution. If evolution was not initialized first using runInitial() , this will be done. Parameters: Name Type Description Default verbose bool, optional Print and plot state of evolution during run, defaults to False False Source code in neurolib/optimize/evolution/evolution.py def run ( self , verbose = False , verbose_plotting = True ): \"\"\"Run the evolution or continue previous evolution. If evolution was not initialized first using `runInitial()`, this will be done. :param verbose: Print and plot state of evolution during run, defaults to False :type verbose: bool, optional \"\"\" self . verbose = verbose self . verbose_plotting = verbose_plotting if not self . _initialPopulationSimulated : self . runInitial () self . runEvolution ()","title":"run()"},{"location":"optimization/evolution/#neurolib.optimize.evolution.evolution.Evolution.runEvolution","text":"Run the evolutionary optimization process for NGEN generations. Source code in neurolib/optimize/evolution/evolution.py def runEvolution ( self ): \"\"\"Run the evolutionary optimization process for `NGEN` generations.\"\"\" # Start evolution logging . info ( \"Start of evolution\" ) self . _t_start_evolution = datetime . datetime . now () for self . gIdx in range ( self . gIdx + 1 , self . gIdx + self . traj . NGEN ): # ------- Weed out the invalid individuals and replace them by random new individuals -------- # validpop = self . getValidPopulation ( self . pop ) # replace invalid individuals invalidpop = self . getInvalidPopulation ( self . pop ) logging . info ( \"Replacing {} invalid individuals.\" . format ( len ( invalidpop ))) newpop = self . toolbox . population ( n = len ( invalidpop )) newpop = self . _tagPopulation ( newpop ) # ------- Create the next generation by crossover and mutation -------- # ### Select parents using rank selection and clone them ### offspring = list ( map ( self . toolbox . clone , self . toolbox . selectParents ( self . pop , self . POP_SIZE , ** self . PARENT_SELECT_P ), ) ) ##### cross-over #### for i in range ( 1 , len ( offspring ), 2 ): offspring [ i - 1 ], offspring [ i ] = self . toolbox . mate ( offspring [ i - 1 ], offspring [ i ], ** self . MATE_P ) # delete fitness inherited from parents del offspring [ i - 1 ] . fitness . values , offspring [ i ] . fitness . values del offspring [ i - 1 ] . fitness . wvalues , offspring [ i ] . fitness . wvalues # assign parent IDs to new offspring offspring [ i - 1 ] . parentIds = offspring [ i - 1 ] . id , offspring [ i ] . id offspring [ i ] . parentIds = offspring [ i - 1 ] . id , offspring [ i ] . id # delete id originally set from parents, needs to be deleted here! # will be set later in _tagPopulation() del offspring [ i - 1 ] . id , offspring [ i ] . id ##### Mutation #### # Apply mutation du . mutateUntilValid ( offspring , self . paramInterval , self . toolbox , MUTATE_P = self . MUTATE_P ) offspring = self . _tagPopulation ( offspring ) # ------- Evaluate next generation -------- # self . pop = offspring + newpop self . _evalPopulationUsingPypet ( self . traj , self . toolbox , offspring + newpop , self . gIdx ) # log individuals self . history [ self . gIdx ] = validpop + offspring + newpop # self.getValidPopulation(self.pop) # ------- Select surviving population -------- # # select next generation self . pop = self . toolbox . select ( validpop + offspring + newpop , k = self . traj . popsize , ** self . SELECT_P ) # ------- END OF ROUND ------- # save all simulation data to pypet self . pop = eu . saveToPypet ( self . traj , self . pop , self . gIdx ) # select best individual for logging self . best_ind = self . toolbox . selBest ( self . pop , 1 )[ 0 ] # text log next_print = print if self . verbose else logging . info next_print ( \"----------- Generation %i -----------\" % self . gIdx ) next_print ( \"Best individual is {} \" . format ( self . best_ind )) next_print ( \"Score: {} \" . format ( self . best_ind . fitness . score )) next_print ( \"Fitness: {} \" . format ( self . best_ind . fitness . values )) next_print ( \"--- Population statistics ---\" ) # verbose output if self . verbose : self . info ( plot = self . verbose_plotting , info = True ) logging . info ( \"--- End of evolution ---\" ) logging . info ( \"Best individual is %s , %s \" % ( self . best_ind , self . best_ind . fitness . values )) logging . info ( \"--- End of evolution ---\" ) self . traj . f_store () # We switched off automatic storing, so we need to store manually self . _t_end_evolution = datetime . datetime . now () self . _buildEvolutionTree ()","title":"runEvolution()"},{"location":"optimization/evolution/#neurolib.optimize.evolution.evolution.Evolution.runInitial","text":"Run the first round of evolution with the initial population of size POP_INIT_SIZE and select the best POP_SIZE for the following evolution. This needs to be run before runEvolution() Source code in neurolib/optimize/evolution/evolution.py def runInitial ( self ): \"\"\"Run the first round of evolution with the initial population of size `POP_INIT_SIZE` and select the best `POP_SIZE` for the following evolution. This needs to be run before `runEvolution()` \"\"\" self . _t_start_initial_population = datetime . datetime . now () # Create the initial population self . pop = self . toolbox . population ( n = self . POP_INIT_SIZE ) ### Evaluate the initial population logging . info ( \"Evaluating initial population of size %i ...\" % len ( self . pop )) self . gIdx = 0 # set generation index self . pop = self . _tagPopulation ( self . pop ) # evaluate self . pop = self . _evalPopulationUsingPypet ( self . traj , self . toolbox , self . pop , self . gIdx ) if self . verbose : eu . printParamDist ( self . pop , self . paramInterval , self . gIdx ) # save all simulation data to pypet self . pop = eu . saveToPypet ( self . traj , self . pop , self . gIdx ) # reduce initial population to popsize self . pop = self . toolbox . select ( self . pop , k = self . traj . popsize , ** self . SELECT_P ) self . _initialPopulationSimulated = True # populate history for tracking self . history [ self . gIdx ] = self . pop # self.getValidPopulation(self.pop) self . _t_end_initial_population = datetime . datetime . now ()","title":"runInitial()"},{"location":"optimization/evolution/#neurolib.optimize.evolution.evolution.Evolution.saveEvolution","text":"Save evolution to file using dill. Parameters: Name Type Description Default fname str, optional Filename, defaults to a path in ./data/ None Source code in neurolib/optimize/evolution/evolution.py def saveEvolution ( self , fname = None ): \"\"\"Save evolution to file using dill. :param fname: Filename, defaults to a path in ./data/ :type fname: str, optional \"\"\" import dill fname = fname or os . path . join ( \"data/\" , \"evolution-\" + self . trajectoryName + \".dill\" ) dill . dump ( self , open ( fname , \"wb\" )) logging . info ( f \"Saving evolution to { fname } \" )","title":"saveEvolution()"},{"location":"utils/dataset/","text":"Dataset This class is for loading empirical Datasets. Datasets are stored as matrices and can include functional (e.g. fMRI) and structural (e.g. DTI) data. Format Empirical datasets are stored in the neurolib/data/datasets directory. In each dataset, subject-wise functional and structural data is stored as MATLAB .mat matrices that can be opened in Python using SciPy's loadmat function. Structural data are \\(N \\times N\\) , and functional time series are \\(N \\times t\\) matrices, \\(N\\) being the number of brain regions and \\(t\\) the number of time steps. Example datasets are included in neurolib and custom datasets can be added by placing them in the dataset directory. Structural DTI data To simulate a whole-brain network model, first we need to load the structural connectivity matrices from a DTI data set. The matrices are usually a result of processing DTI data and performing fiber tractography using software like FSL or DSIStudio . The handling of the datasets is done by the Dataset class, and the attributes in the following refer to its instances. Upon initialization, the subject-wise data set is loaded from disk. For all examples in this paper, we use freely available data from the ConnectomeDB of the Human Connectome Project (HCP). For a given parcellation of the brain into \\(N\\) brain regions, these matrices are the \\(N \\times N\\) adjacency matrix self.Cmat , i.e. the structural connectivity matrix, which determines the coupling strengths between brain areas, and the fiber length matrix Dmat which determines the signal transmission delays. The two example datasets currently included in neurolib use the the 80 cortical regions of the AAL2 atlas to define the brain areas and are sorted in a LRLR-ordering. Connectivity matrix normalization The elements of the structural connectivity matrix Cmat are typically the number of reconstructed fibers from DTI tractography. Since the number of fibers depends on the method and the parameters of the (probabilistic or deterministic) tractography, they need to be normalized using one of the three implemented methods. The first method max is to simply divide the entries of Cmat by the largest entry, such that the the largest entry becomes 1. The second method waytotal divides the entries of each column of Cmat by the number fiber tracts generated from the respective brain region during probabilistic tractography in FSL, which is contained in the waytotal.txt file. The third method nvoxel divides the entries of each column of Cmat by the size, e.g., the number of voxels of the corresponding brain area. The last two methods yield an asymmetric connectivity matrix, while the first one keeps Cmat symmetric. All normalization steps are done on the subject-wise matrices Cmats and Dmats . In a final step, all matrices can also be averaged across all subjects to yield one Cmat and Dmat per dataset. Functional MRI data Subject-wise fMRI time series must be in a \\((N \\times t)\\) -dimensional format, where \\(N\\) is the number of brain regions and \\(t\\) the length of the time series. Each region-wise time series represents the BOLD activity averaged across all voxels of that region, which can be also obtained from software like FSL. Functional connectivity (FC) captures the spatial correlation structure of the BOLD time series averaged across the entire time of the recording. FC matrices are accessible via the attribute FCs and are generated by computing the Pearson correlation of the time series between all regions, yielding a \\(N \\times N\\) matrix for each subject. To capture the temporal fluctuations of time-dependent FC(t), which are lost when averaging across the entire recording time, functional connectivity dynamics matrices ( FCDs ) are computed as the element-wise Pearson correlation of time-dependent FC(t) matrices in a moving window across the BOLD time series of a chosen window length of, for example, 1 min. This yields a \\(t_{FCD} \\times t_{FCD}\\) FCD matrix for each subject, with \\(t_{FCD}\\) being the number of steps the window was moved. Source code in neurolib/utils/loadData.py class Dataset : \"\"\" This class is for loading empirical Datasets. Datasets are stored as matrices and can include functional (e.g. fMRI) and structural (e.g. DTI) data. ## Format Empirical datasets are stored in the `neurolib/data/datasets` directory. In each dataset, subject-wise functional and structural data is stored as MATLAB `.mat` matrices that can be opened in Python using SciPy's `loadmat` function. Structural data are $N \\\\times N$, and functional time series are $N \\\\times t$ matrices, $N$ being the number of brain regions and $t$ the number of time steps. Example datasets are included in `neurolib` and custom datasets can be added by placing them in the dataset directory. ## Structural DTI data To simulate a whole-brain network model, first we need to load the structural connectivity matrices from a DTI data set. The matrices are usually a result of processing DTI data and performing fiber tractography using software like *FSL* or *DSIStudio*. The handling of the datasets is done by the `Dataset` class, and the attributes in the following refer to its instances. Upon initialization, the subject-wise data set is loaded from disk. For all examples in this paper, we use freely available data from the ConnectomeDB of the Human Connectome Project (HCP). For a given parcellation of the brain into $N$ brain regions, these matrices are the $N \\\\times N$ adjacency matrix `self.Cmat`, i.e. the structural connectivity matrix, which determines the coupling strengths between brain areas, and the fiber length matrix `Dmat` which determines the signal transmission delays. The two example datasets currently included in `neurolib` use the the 80 cortical regions of the AAL2 atlas to define the brain areas and are sorted in a LRLR-ordering. ## Connectivity matrix normalization The elements of the structural connectivity matrix `Cmat` are typically the number of reconstructed fibers from DTI tractography. Since the number of fibers depends on the method and the parameters of the (probabilistic or deterministic) tractography, they need to be normalized using one of the three implemented methods. The first method `max` is to simply divide the entries of `Cmat` by the largest entry, such that the the largest entry becomes 1. The second method `waytotal` divides the entries of each column of `Cmat` by the number fiber tracts generated from the respective brain region during probabilistic tractography in FSL, which is contained in the `waytotal.txt` file. The third method `nvoxel` divides the entries of each column of `Cmat` by the size, e.g., the number of voxels of the corresponding brain area. The last two methods yield an asymmetric connectivity matrix, while the first one keeps `Cmat` symmetric. All normalization steps are done on the subject-wise matrices `Cmats` and `Dmats`. In a final step, all matrices can also be averaged across all subjects to yield one `Cmat` and `Dmat` per dataset. ## Functional MRI data Subject-wise fMRI time series must be in a $(N \\\\times t)$-dimensional format, where $N$ is the number of brain regions and $t$ the length of the time series. Each region-wise time series represents the BOLD activity averaged across all voxels of that region, which can be also obtained from software like FSL. Functional connectivity (FC) captures the spatial correlation structure of the BOLD time series averaged across the entire time of the recording. FC matrices are accessible via the attribute `FCs` and are generated by computing the Pearson correlation of the time series between all regions, yielding a $N \\\\times N$ matrix for each subject. To capture the temporal fluctuations of time-dependent FC(t), which are lost when averaging across the entire recording time, functional connectivity dynamics matrices (`FCDs`) are computed as the element-wise Pearson correlation of time-dependent FC(t) matrices in a moving window across the BOLD time series of a chosen window length of, for example, 1 min. This yields a $t_{FCD} \\\\times t_{FCD}$ FCD matrix for each subject, with $t_{FCD}$ being the number of steps the window was moved. \"\"\" def __init__ ( self , datasetName = None , normalizeCmats = \"max\" , fcd = False , subcortical = False ): \"\"\" Load the empirical data sets that are provided with `neurolib`. Right now, datasets work on a per-subject base. A dataset must be located in the `neurolib/data/datasets/` directory. Each subject's dataset must be in the `subjects` subdirectory of that folder. In each subject folder there is a directory called `functional` for time series data and `structural` the structural connectivity data. See `loadData.loadSubjectFiles()` for more details on which files are being loaded. The structural connectivity data (accessible using the attribute loadData.Cmat), can be normalized using the `normalizeCmats` flag. This defaults to \"max\" which normalizes the Cmat by its maxmimum. Other options are `waytotal` or `nvoxel`, which normalizes the Cmat by dividing every row of the matrix by the waytotal or nvoxel files that are provided in the datasets. Info: the waytotal.txt and the nvoxel.txt are files extracted from the tractography of DTI data using `probtrackX` from the `fsl` pipeline. Individual subject data is provided with the class attributes: self.BOLDs: BOLD timeseries of each individual self.FCs: Functional connectivity of BOLD timeseries Mean data is provided with the class attributes: self.Cmat: Structural connectivity matrix (for coupling strenghts between areas) self.Dmat: Fiber length matrix (for delays) self.BOLDs: BOLD timeseries of each area self.FCs: Functional connectiviy matrices of each BOLD timeseries :param datasetName: Name of the dataset to load :type datasetName: str :param normalizeCmats: Normalization method for the structural connectivity matrix. normalizationMethods = [\"max\", \"waytotal\", \"nvoxel\"] :type normalizeCmats: str :param fcd: Compute FCD matrices of BOLD data, defaults to False :type fcd: bool :param subcortical: Include subcortical areas from the atlas or not, defaults to False :type subcortical: bool \"\"\" self . has_subjects = None if datasetName : self . loadDataset ( datasetName , normalizeCmats = normalizeCmats , fcd = fcd , subcortical = subcortical ) def loadDataset ( self , datasetName , normalizeCmats = \"max\" , fcd = False , subcortical = False ): \"\"\"Load data into accessible class attributes. :param datasetName: Name of the dataset (must be in `datasets` directory) :type datasetName: str :param normalizeCmats: Normalization method for Cmats, defaults to \"max\" :type normalizeCmats: str, optional :raises NotImplementedError: If unknown normalization method is used \"\"\" # the base directory of the dataset dsBaseDirectory = os . path . join ( os . path . dirname ( __file__ ), \"..\" , \"data\" , \"datasets\" , datasetName ) assert os . path . exists ( dsBaseDirectory ), f \"Dataset { datasetName } not found in { dsBaseDirectory } .\" self . dsBaseDirectory = dsBaseDirectory self . data = dotdict ({}) # load all available subject data from disk to memory logging . info ( f \"Loading dataset { datasetName } from { self . dsBaseDirectory } .\" ) self . _loadSubjectFiles ( self . dsBaseDirectory , subcortical = subcortical ) assert len ( self . data ) > 0 , \"No data loaded.\" assert self . has_subjects self . Cmats = self . _normalizeCmats ( self . getDataPerSubject ( \"cm\" ), method = normalizeCmats ) self . Dmats = self . getDataPerSubject ( \"len\" ) # take the average of all self . Cmat = np . mean ( self . Cmats , axis = 0 ) self . Dmat = self . getDataPerSubject ( \"len\" , apply = \"all\" , apply_function = np . mean , apply_function_kwargs = { \"axis\" : 0 }, ) self . BOLDs = self . getDataPerSubject ( \"bold\" ) self . FCs = self . getDataPerSubject ( \"bold\" , apply_function = func . fc ) if fcd : self . computeFCD () logging . info ( f \"Dataset { datasetName } loaded.\" ) def computeFCD ( self ): logging . info ( \"Computing FCD matrices ...\" ) self . FCDs = self . getDataPerSubject ( \"bold\" , apply_function = func . fcd , apply_function_kwargs = { \"stepsize\" : 10 }) def getDataPerSubject ( self , name , apply = \"single\" , apply_function = None , apply_function_kwargs = {}, normalizeCmats = \"max\" , ): \"\"\"Load data of a certain kind for all users of the current dataset :param name: Name of data type, i.e. \"bold\" or \"cm\" :type name: str :param apply: Apply function per subject (\"single\") or on all subjects (\"all\"), defaults to \"single\" :type apply: str, optional :param apply_function: Apply function on data, defaults to None :type apply_function: function, optional :param apply_function_kwargs: Keyword arguments of fuction, defaults to {} :type apply_function_kwargs: dict, optional :return: Subjectwise data, after function apply :rtype: list[np.ndarray] \"\"\" values = [] for subject , value in self . data [ \"subjects\" ] . items (): assert name in value , f \"Data type { name } not found in dataset of subject { subject } .\" val = value [ name ] if apply_function and apply == \"single\" : val = apply_function ( val , ** apply_function_kwargs ) values . append ( val ) if apply_function and apply == \"all\" : values = apply_function ( values , ** apply_function_kwargs ) return values def _normalizeCmats ( self , Cmats , method = \"max\" , FSL_SAMPLES_PER_VOXEL = 5000 ): # normalize per subject data normalizationMethods = [ None , \"max\" , \"waytotal\" , \"nvoxel\" ] if method not in normalizationMethods : raise NotImplementedError ( f '\" { method } \" is not a known normalization method. Use one of these: { normalizationMethods } ' ) if method == \"max\" : Cmats = [ cm / np . max ( cm ) for cm in Cmats ] elif method == \"waytotal\" : self . waytotal = self . getDataPerSubject ( \"waytotal\" ) Cmats = [ cm / wt for cm , wt in zip ( Cmats , self . waytotal )] elif method == \"nvoxel\" : self . nvoxel = self . getDataPerSubject ( \"nvoxel\" ) Cmats = [ cm / ( nv [:, 0 ] * FSL_SAMPLES_PER_VOXEL ) for cm , nv in zip ( Cmats , self . nvoxel )] return Cmats def _loadSubjectFiles ( self , dsBaseDirectory , subcortical = False ): \"\"\"Dirty subject-wise file loader. Depends on the exact naming of all files as provided in the `neurolib/data/datasets` directory. Uses `glob.glob()` to find all files based on hardcoded file name matching. Can filter out subcortical regions from the AAL2 atlas. Info: Dirty implementation that assumes a lot of things about the dataset and filenames. :param dsBaseDirectory: Base directory of the dataset :type dsBaseDirectory: str :param subcortical: Filter subcortical regions from files defined by the AAL2 atlas, defaults to False :type subcortical: bool, optional \"\"\" # check if there are subject files in the dataset if os . path . exists ( os . path . join ( dsBaseDirectory , \"subjects\" )): self . has_subjects = True self . data [ \"subjects\" ] = {} # data type paths, glob strings, dirty BOLD_paths_glob = os . path . join ( dsBaseDirectory , \"subjects\" , \"*\" , \"functional\" , \"*rsfMRI*.mat\" ) CM_paths_glob = os . path . join ( dsBaseDirectory , \"subjects\" , \"*\" , \"structural\" , \"DTI_CM*.mat\" ) LEN_paths_glob = os . path . join ( dsBaseDirectory , \"subjects\" , \"*\" , \"structural\" , \"DTI_LEN*.mat\" ) WAY_paths_glob = os . path . join ( dsBaseDirectory , \"subjects\" , \"*\" , \"structural\" , \"waytotal*.txt\" ) NVOXEL_paths_glob = os . path . join ( dsBaseDirectory , \"subjects\" , \"*\" , \"structural\" , \"nvoxel*.txt\" ) _ftypes = { \"bold\" : BOLD_paths_glob , \"cm\" : CM_paths_glob , \"len\" : LEN_paths_glob , \"waytotal\" : WAY_paths_glob , \"nvoxel\" : NVOXEL_paths_glob , } for _name , _glob in _ftypes . items (): fnames = glob . glob ( _glob ) # if there is none of this data type if len ( fnames ) == 0 : continue for f in fnames : # dirty subject = f . split ( os . path . sep )[ - 3 ] # create subject in dict if not present yet if not subject in self . data [ \"subjects\" ]: self . data [ \"subjects\" ][ subject ] = {} # if the data for this type is not already loaded if _name not in self . data [ \"subjects\" ][ subject ]: # bold, cm and len matrixes are provided as .mat files if _name in [ \"bold\" , \"cm\" , \"len\" ]: filter_subcotrical_axis = \"both\" if _name == \"bold\" : key = \"tc\" filter_subcotrical_axis = 0 elif _name == \"cm\" : key = \"sc\" elif _name == \"len\" : key = \"len\" # load the data data = self . loadMatrix ( f , key = key ) if not subcortical : data = filterSubcortical ( data , axis = filter_subcotrical_axis ) self . data [ \"subjects\" ][ subject ][ _name ] = data # waytotal and nvoxel files are .txt files elif _name in [ \"waytotal\" , \"nvoxel\" ]: data = np . loadtxt ( f ) if not subcortical : data = filterSubcortical ( data , axis = 0 ) self . data [ \"subjects\" ][ subject ][ _name ] = data def loadMatrix ( self , matFileName , key = \"\" , verbose = False ): \"\"\"Function to furiously load .mat files with scipy.io.loadmat. Info: More formats are supported but commented out in the code. :param matFileName: Filename of matrix to load :type matFileName: str :param key: .mat file key in which data is stored (example: \"sc\") :type key: str :return: Loaded matrix :rtype: numpy.ndarray \"\"\" if verbose : print ( f \"Loading { matFileName } \" ) matrix = scipy . io . loadmat ( matFileName ) if verbose : print ( \" \\t Loading using scipy.io.loadmat...\" ) print ( f \"Keys: { list ( matrix . keys ()) } \" ) if key != \"\" and key in list ( matrix . keys ()): matrix = matrix [ key ] if verbose : print ( f ' \\t Loaded key \" { key } \"' ) elif type ( matrix ) is dict : raise ValueError ( f \"Object is still a dict. Here are the keys: { matrix . keys () } \" ) return matrix return 0 __init__ ( self , datasetName = None , normalizeCmats = 'max' , fcd = False , subcortical = False ) special Load the empirical data sets that are provided with neurolib . Right now, datasets work on a per-subject base. A dataset must be located in the neurolib/data/datasets/ directory. Each subject's dataset must be in the subjects subdirectory of that folder. In each subject folder there is a directory called functional for time series data and structural the structural connectivity data. See loadData.loadSubjectFiles() for more details on which files are being loaded. The structural connectivity data (accessible using the attribute loadData.Cmat), can be normalized using the normalizeCmats flag. This defaults to \"max\" which normalizes the Cmat by its maxmimum. Other options are waytotal or nvoxel , which normalizes the Cmat by dividing every row of the matrix by the waytotal or nvoxel files that are provided in the datasets. Info: the waytotal.txt and the nvoxel.txt are files extracted from the tractography of DTI data using probtrackX from the fsl pipeline. Individual subject data is provided with the class attributes: self.BOLDs: BOLD timeseries of each individual self.FCs: Functional connectivity of BOLD timeseries Mean data is provided with the class attributes: self.Cmat: Structural connectivity matrix (for coupling strenghts between areas) self.Dmat: Fiber length matrix (for delays) self.BOLDs: BOLD timeseries of each area self.FCs: Functional connectiviy matrices of each BOLD timeseries Parameters: Name Type Description Default datasetName str Name of the dataset to load None normalizeCmats str Normalization method for the structural connectivity matrix. normalizationMethods = [\"max\", \"waytotal\", \"nvoxel\"] 'max' fcd bool Compute FCD matrices of BOLD data, defaults to False False subcortical bool Include subcortical areas from the atlas or not, defaults to False False Source code in neurolib/utils/loadData.py def __init__ ( self , datasetName = None , normalizeCmats = \"max\" , fcd = False , subcortical = False ): \"\"\" Load the empirical data sets that are provided with `neurolib`. Right now, datasets work on a per-subject base. A dataset must be located in the `neurolib/data/datasets/` directory. Each subject's dataset must be in the `subjects` subdirectory of that folder. In each subject folder there is a directory called `functional` for time series data and `structural` the structural connectivity data. See `loadData.loadSubjectFiles()` for more details on which files are being loaded. The structural connectivity data (accessible using the attribute loadData.Cmat), can be normalized using the `normalizeCmats` flag. This defaults to \"max\" which normalizes the Cmat by its maxmimum. Other options are `waytotal` or `nvoxel`, which normalizes the Cmat by dividing every row of the matrix by the waytotal or nvoxel files that are provided in the datasets. Info: the waytotal.txt and the nvoxel.txt are files extracted from the tractography of DTI data using `probtrackX` from the `fsl` pipeline. Individual subject data is provided with the class attributes: self.BOLDs: BOLD timeseries of each individual self.FCs: Functional connectivity of BOLD timeseries Mean data is provided with the class attributes: self.Cmat: Structural connectivity matrix (for coupling strenghts between areas) self.Dmat: Fiber length matrix (for delays) self.BOLDs: BOLD timeseries of each area self.FCs: Functional connectiviy matrices of each BOLD timeseries :param datasetName: Name of the dataset to load :type datasetName: str :param normalizeCmats: Normalization method for the structural connectivity matrix. normalizationMethods = [\"max\", \"waytotal\", \"nvoxel\"] :type normalizeCmats: str :param fcd: Compute FCD matrices of BOLD data, defaults to False :type fcd: bool :param subcortical: Include subcortical areas from the atlas or not, defaults to False :type subcortical: bool \"\"\" self . has_subjects = None if datasetName : self . loadDataset ( datasetName , normalizeCmats = normalizeCmats , fcd = fcd , subcortical = subcortical ) getDataPerSubject ( self , name , apply = 'single' , apply_function = None , apply_function_kwargs = {}, normalizeCmats = 'max' ) Load data of a certain kind for all users of the current dataset Parameters: Name Type Description Default name str Name of data type, i.e. \"bold\" or \"cm\" required apply str, optional Apply function per subject (\"single\") or on all subjects (\"all\"), defaults to \"single\" 'single' apply_function function, optional Apply function on data, defaults to None None apply_function_kwargs dict, optional Keyword arguments of fuction, defaults to {} {} Returns: Type Description list[np.ndarray] Subjectwise data, after function apply Source code in neurolib/utils/loadData.py def getDataPerSubject ( self , name , apply = \"single\" , apply_function = None , apply_function_kwargs = {}, normalizeCmats = \"max\" , ): \"\"\"Load data of a certain kind for all users of the current dataset :param name: Name of data type, i.e. \"bold\" or \"cm\" :type name: str :param apply: Apply function per subject (\"single\") or on all subjects (\"all\"), defaults to \"single\" :type apply: str, optional :param apply_function: Apply function on data, defaults to None :type apply_function: function, optional :param apply_function_kwargs: Keyword arguments of fuction, defaults to {} :type apply_function_kwargs: dict, optional :return: Subjectwise data, after function apply :rtype: list[np.ndarray] \"\"\" values = [] for subject , value in self . data [ \"subjects\" ] . items (): assert name in value , f \"Data type { name } not found in dataset of subject { subject } .\" val = value [ name ] if apply_function and apply == \"single\" : val = apply_function ( val , ** apply_function_kwargs ) values . append ( val ) if apply_function and apply == \"all\" : values = apply_function ( values , ** apply_function_kwargs ) return values loadDataset ( self , datasetName , normalizeCmats = 'max' , fcd = False , subcortical = False ) Load data into accessible class attributes. Parameters: Name Type Description Default datasetName str Name of the dataset (must be in datasets directory) required normalizeCmats str, optional Normalization method for Cmats, defaults to \"max\" 'max' Exceptions: Type Description NotImplementedError If unknown normalization method is used Source code in neurolib/utils/loadData.py def loadDataset ( self , datasetName , normalizeCmats = \"max\" , fcd = False , subcortical = False ): \"\"\"Load data into accessible class attributes. :param datasetName: Name of the dataset (must be in `datasets` directory) :type datasetName: str :param normalizeCmats: Normalization method for Cmats, defaults to \"max\" :type normalizeCmats: str, optional :raises NotImplementedError: If unknown normalization method is used \"\"\" # the base directory of the dataset dsBaseDirectory = os . path . join ( os . path . dirname ( __file__ ), \"..\" , \"data\" , \"datasets\" , datasetName ) assert os . path . exists ( dsBaseDirectory ), f \"Dataset { datasetName } not found in { dsBaseDirectory } .\" self . dsBaseDirectory = dsBaseDirectory self . data = dotdict ({}) # load all available subject data from disk to memory logging . info ( f \"Loading dataset { datasetName } from { self . dsBaseDirectory } .\" ) self . _loadSubjectFiles ( self . dsBaseDirectory , subcortical = subcortical ) assert len ( self . data ) > 0 , \"No data loaded.\" assert self . has_subjects self . Cmats = self . _normalizeCmats ( self . getDataPerSubject ( \"cm\" ), method = normalizeCmats ) self . Dmats = self . getDataPerSubject ( \"len\" ) # take the average of all self . Cmat = np . mean ( self . Cmats , axis = 0 ) self . Dmat = self . getDataPerSubject ( \"len\" , apply = \"all\" , apply_function = np . mean , apply_function_kwargs = { \"axis\" : 0 }, ) self . BOLDs = self . getDataPerSubject ( \"bold\" ) self . FCs = self . getDataPerSubject ( \"bold\" , apply_function = func . fc ) if fcd : self . computeFCD () logging . info ( f \"Dataset { datasetName } loaded.\" ) loadMatrix ( self , matFileName , key = '' , verbose = False ) Function to furiously load .mat files with scipy.io.loadmat. Info: More formats are supported but commented out in the code. Parameters: Name Type Description Default matFileName str Filename of matrix to load required key str .mat file key in which data is stored (example: \"sc\") '' Returns: Type Description numpy.ndarray Loaded matrix Source code in neurolib/utils/loadData.py def loadMatrix ( self , matFileName , key = \"\" , verbose = False ): \"\"\"Function to furiously load .mat files with scipy.io.loadmat. Info: More formats are supported but commented out in the code. :param matFileName: Filename of matrix to load :type matFileName: str :param key: .mat file key in which data is stored (example: \"sc\") :type key: str :return: Loaded matrix :rtype: numpy.ndarray \"\"\" if verbose : print ( f \"Loading { matFileName } \" ) matrix = scipy . io . loadmat ( matFileName ) if verbose : print ( \" \\t Loading using scipy.io.loadmat...\" ) print ( f \"Keys: { list ( matrix . keys ()) } \" ) if key != \"\" and key in list ( matrix . keys ()): matrix = matrix [ key ] if verbose : print ( f ' \\t Loaded key \" { key } \"' ) elif type ( matrix ) is dict : raise ValueError ( f \"Object is still a dict. Here are the keys: { matrix . keys () } \" ) return matrix return 0","title":"Dataset"},{"location":"utils/dataset/#dataset","text":"This class is for loading empirical Datasets. Datasets are stored as matrices and can include functional (e.g. fMRI) and structural (e.g. DTI) data.","title":"Dataset"},{"location":"utils/dataset/#neurolib.utils.loadData.Dataset--format","text":"Empirical datasets are stored in the neurolib/data/datasets directory. In each dataset, subject-wise functional and structural data is stored as MATLAB .mat matrices that can be opened in Python using SciPy's loadmat function. Structural data are \\(N \\times N\\) , and functional time series are \\(N \\times t\\) matrices, \\(N\\) being the number of brain regions and \\(t\\) the number of time steps. Example datasets are included in neurolib and custom datasets can be added by placing them in the dataset directory.","title":"Format"},{"location":"utils/dataset/#neurolib.utils.loadData.Dataset--structural-dti-data","text":"To simulate a whole-brain network model, first we need to load the structural connectivity matrices from a DTI data set. The matrices are usually a result of processing DTI data and performing fiber tractography using software like FSL or DSIStudio . The handling of the datasets is done by the Dataset class, and the attributes in the following refer to its instances. Upon initialization, the subject-wise data set is loaded from disk. For all examples in this paper, we use freely available data from the ConnectomeDB of the Human Connectome Project (HCP). For a given parcellation of the brain into \\(N\\) brain regions, these matrices are the \\(N \\times N\\) adjacency matrix self.Cmat , i.e. the structural connectivity matrix, which determines the coupling strengths between brain areas, and the fiber length matrix Dmat which determines the signal transmission delays. The two example datasets currently included in neurolib use the the 80 cortical regions of the AAL2 atlas to define the brain areas and are sorted in a LRLR-ordering.","title":"Structural DTI data"},{"location":"utils/dataset/#neurolib.utils.loadData.Dataset--connectivity-matrix-normalization","text":"The elements of the structural connectivity matrix Cmat are typically the number of reconstructed fibers from DTI tractography. Since the number of fibers depends on the method and the parameters of the (probabilistic or deterministic) tractography, they need to be normalized using one of the three implemented methods. The first method max is to simply divide the entries of Cmat by the largest entry, such that the the largest entry becomes 1. The second method waytotal divides the entries of each column of Cmat by the number fiber tracts generated from the respective brain region during probabilistic tractography in FSL, which is contained in the waytotal.txt file. The third method nvoxel divides the entries of each column of Cmat by the size, e.g., the number of voxels of the corresponding brain area. The last two methods yield an asymmetric connectivity matrix, while the first one keeps Cmat symmetric. All normalization steps are done on the subject-wise matrices Cmats and Dmats . In a final step, all matrices can also be averaged across all subjects to yield one Cmat and Dmat per dataset.","title":"Connectivity matrix normalization"},{"location":"utils/dataset/#neurolib.utils.loadData.Dataset--functional-mri-data","text":"Subject-wise fMRI time series must be in a \\((N \\times t)\\) -dimensional format, where \\(N\\) is the number of brain regions and \\(t\\) the length of the time series. Each region-wise time series represents the BOLD activity averaged across all voxels of that region, which can be also obtained from software like FSL. Functional connectivity (FC) captures the spatial correlation structure of the BOLD time series averaged across the entire time of the recording. FC matrices are accessible via the attribute FCs and are generated by computing the Pearson correlation of the time series between all regions, yielding a \\(N \\times N\\) matrix for each subject. To capture the temporal fluctuations of time-dependent FC(t), which are lost when averaging across the entire recording time, functional connectivity dynamics matrices ( FCDs ) are computed as the element-wise Pearson correlation of time-dependent FC(t) matrices in a moving window across the BOLD time series of a chosen window length of, for example, 1 min. This yields a \\(t_{FCD} \\times t_{FCD}\\) FCD matrix for each subject, with \\(t_{FCD}\\) being the number of steps the window was moved. Source code in neurolib/utils/loadData.py class Dataset : \"\"\" This class is for loading empirical Datasets. Datasets are stored as matrices and can include functional (e.g. fMRI) and structural (e.g. DTI) data. ## Format Empirical datasets are stored in the `neurolib/data/datasets` directory. In each dataset, subject-wise functional and structural data is stored as MATLAB `.mat` matrices that can be opened in Python using SciPy's `loadmat` function. Structural data are $N \\\\times N$, and functional time series are $N \\\\times t$ matrices, $N$ being the number of brain regions and $t$ the number of time steps. Example datasets are included in `neurolib` and custom datasets can be added by placing them in the dataset directory. ## Structural DTI data To simulate a whole-brain network model, first we need to load the structural connectivity matrices from a DTI data set. The matrices are usually a result of processing DTI data and performing fiber tractography using software like *FSL* or *DSIStudio*. The handling of the datasets is done by the `Dataset` class, and the attributes in the following refer to its instances. Upon initialization, the subject-wise data set is loaded from disk. For all examples in this paper, we use freely available data from the ConnectomeDB of the Human Connectome Project (HCP). For a given parcellation of the brain into $N$ brain regions, these matrices are the $N \\\\times N$ adjacency matrix `self.Cmat`, i.e. the structural connectivity matrix, which determines the coupling strengths between brain areas, and the fiber length matrix `Dmat` which determines the signal transmission delays. The two example datasets currently included in `neurolib` use the the 80 cortical regions of the AAL2 atlas to define the brain areas and are sorted in a LRLR-ordering. ## Connectivity matrix normalization The elements of the structural connectivity matrix `Cmat` are typically the number of reconstructed fibers from DTI tractography. Since the number of fibers depends on the method and the parameters of the (probabilistic or deterministic) tractography, they need to be normalized using one of the three implemented methods. The first method `max` is to simply divide the entries of `Cmat` by the largest entry, such that the the largest entry becomes 1. The second method `waytotal` divides the entries of each column of `Cmat` by the number fiber tracts generated from the respective brain region during probabilistic tractography in FSL, which is contained in the `waytotal.txt` file. The third method `nvoxel` divides the entries of each column of `Cmat` by the size, e.g., the number of voxels of the corresponding brain area. The last two methods yield an asymmetric connectivity matrix, while the first one keeps `Cmat` symmetric. All normalization steps are done on the subject-wise matrices `Cmats` and `Dmats`. In a final step, all matrices can also be averaged across all subjects to yield one `Cmat` and `Dmat` per dataset. ## Functional MRI data Subject-wise fMRI time series must be in a $(N \\\\times t)$-dimensional format, where $N$ is the number of brain regions and $t$ the length of the time series. Each region-wise time series represents the BOLD activity averaged across all voxels of that region, which can be also obtained from software like FSL. Functional connectivity (FC) captures the spatial correlation structure of the BOLD time series averaged across the entire time of the recording. FC matrices are accessible via the attribute `FCs` and are generated by computing the Pearson correlation of the time series between all regions, yielding a $N \\\\times N$ matrix for each subject. To capture the temporal fluctuations of time-dependent FC(t), which are lost when averaging across the entire recording time, functional connectivity dynamics matrices (`FCDs`) are computed as the element-wise Pearson correlation of time-dependent FC(t) matrices in a moving window across the BOLD time series of a chosen window length of, for example, 1 min. This yields a $t_{FCD} \\\\times t_{FCD}$ FCD matrix for each subject, with $t_{FCD}$ being the number of steps the window was moved. \"\"\" def __init__ ( self , datasetName = None , normalizeCmats = \"max\" , fcd = False , subcortical = False ): \"\"\" Load the empirical data sets that are provided with `neurolib`. Right now, datasets work on a per-subject base. A dataset must be located in the `neurolib/data/datasets/` directory. Each subject's dataset must be in the `subjects` subdirectory of that folder. In each subject folder there is a directory called `functional` for time series data and `structural` the structural connectivity data. See `loadData.loadSubjectFiles()` for more details on which files are being loaded. The structural connectivity data (accessible using the attribute loadData.Cmat), can be normalized using the `normalizeCmats` flag. This defaults to \"max\" which normalizes the Cmat by its maxmimum. Other options are `waytotal` or `nvoxel`, which normalizes the Cmat by dividing every row of the matrix by the waytotal or nvoxel files that are provided in the datasets. Info: the waytotal.txt and the nvoxel.txt are files extracted from the tractography of DTI data using `probtrackX` from the `fsl` pipeline. Individual subject data is provided with the class attributes: self.BOLDs: BOLD timeseries of each individual self.FCs: Functional connectivity of BOLD timeseries Mean data is provided with the class attributes: self.Cmat: Structural connectivity matrix (for coupling strenghts between areas) self.Dmat: Fiber length matrix (for delays) self.BOLDs: BOLD timeseries of each area self.FCs: Functional connectiviy matrices of each BOLD timeseries :param datasetName: Name of the dataset to load :type datasetName: str :param normalizeCmats: Normalization method for the structural connectivity matrix. normalizationMethods = [\"max\", \"waytotal\", \"nvoxel\"] :type normalizeCmats: str :param fcd: Compute FCD matrices of BOLD data, defaults to False :type fcd: bool :param subcortical: Include subcortical areas from the atlas or not, defaults to False :type subcortical: bool \"\"\" self . has_subjects = None if datasetName : self . loadDataset ( datasetName , normalizeCmats = normalizeCmats , fcd = fcd , subcortical = subcortical ) def loadDataset ( self , datasetName , normalizeCmats = \"max\" , fcd = False , subcortical = False ): \"\"\"Load data into accessible class attributes. :param datasetName: Name of the dataset (must be in `datasets` directory) :type datasetName: str :param normalizeCmats: Normalization method for Cmats, defaults to \"max\" :type normalizeCmats: str, optional :raises NotImplementedError: If unknown normalization method is used \"\"\" # the base directory of the dataset dsBaseDirectory = os . path . join ( os . path . dirname ( __file__ ), \"..\" , \"data\" , \"datasets\" , datasetName ) assert os . path . exists ( dsBaseDirectory ), f \"Dataset { datasetName } not found in { dsBaseDirectory } .\" self . dsBaseDirectory = dsBaseDirectory self . data = dotdict ({}) # load all available subject data from disk to memory logging . info ( f \"Loading dataset { datasetName } from { self . dsBaseDirectory } .\" ) self . _loadSubjectFiles ( self . dsBaseDirectory , subcortical = subcortical ) assert len ( self . data ) > 0 , \"No data loaded.\" assert self . has_subjects self . Cmats = self . _normalizeCmats ( self . getDataPerSubject ( \"cm\" ), method = normalizeCmats ) self . Dmats = self . getDataPerSubject ( \"len\" ) # take the average of all self . Cmat = np . mean ( self . Cmats , axis = 0 ) self . Dmat = self . getDataPerSubject ( \"len\" , apply = \"all\" , apply_function = np . mean , apply_function_kwargs = { \"axis\" : 0 }, ) self . BOLDs = self . getDataPerSubject ( \"bold\" ) self . FCs = self . getDataPerSubject ( \"bold\" , apply_function = func . fc ) if fcd : self . computeFCD () logging . info ( f \"Dataset { datasetName } loaded.\" ) def computeFCD ( self ): logging . info ( \"Computing FCD matrices ...\" ) self . FCDs = self . getDataPerSubject ( \"bold\" , apply_function = func . fcd , apply_function_kwargs = { \"stepsize\" : 10 }) def getDataPerSubject ( self , name , apply = \"single\" , apply_function = None , apply_function_kwargs = {}, normalizeCmats = \"max\" , ): \"\"\"Load data of a certain kind for all users of the current dataset :param name: Name of data type, i.e. \"bold\" or \"cm\" :type name: str :param apply: Apply function per subject (\"single\") or on all subjects (\"all\"), defaults to \"single\" :type apply: str, optional :param apply_function: Apply function on data, defaults to None :type apply_function: function, optional :param apply_function_kwargs: Keyword arguments of fuction, defaults to {} :type apply_function_kwargs: dict, optional :return: Subjectwise data, after function apply :rtype: list[np.ndarray] \"\"\" values = [] for subject , value in self . data [ \"subjects\" ] . items (): assert name in value , f \"Data type { name } not found in dataset of subject { subject } .\" val = value [ name ] if apply_function and apply == \"single\" : val = apply_function ( val , ** apply_function_kwargs ) values . append ( val ) if apply_function and apply == \"all\" : values = apply_function ( values , ** apply_function_kwargs ) return values def _normalizeCmats ( self , Cmats , method = \"max\" , FSL_SAMPLES_PER_VOXEL = 5000 ): # normalize per subject data normalizationMethods = [ None , \"max\" , \"waytotal\" , \"nvoxel\" ] if method not in normalizationMethods : raise NotImplementedError ( f '\" { method } \" is not a known normalization method. Use one of these: { normalizationMethods } ' ) if method == \"max\" : Cmats = [ cm / np . max ( cm ) for cm in Cmats ] elif method == \"waytotal\" : self . waytotal = self . getDataPerSubject ( \"waytotal\" ) Cmats = [ cm / wt for cm , wt in zip ( Cmats , self . waytotal )] elif method == \"nvoxel\" : self . nvoxel = self . getDataPerSubject ( \"nvoxel\" ) Cmats = [ cm / ( nv [:, 0 ] * FSL_SAMPLES_PER_VOXEL ) for cm , nv in zip ( Cmats , self . nvoxel )] return Cmats def _loadSubjectFiles ( self , dsBaseDirectory , subcortical = False ): \"\"\"Dirty subject-wise file loader. Depends on the exact naming of all files as provided in the `neurolib/data/datasets` directory. Uses `glob.glob()` to find all files based on hardcoded file name matching. Can filter out subcortical regions from the AAL2 atlas. Info: Dirty implementation that assumes a lot of things about the dataset and filenames. :param dsBaseDirectory: Base directory of the dataset :type dsBaseDirectory: str :param subcortical: Filter subcortical regions from files defined by the AAL2 atlas, defaults to False :type subcortical: bool, optional \"\"\" # check if there are subject files in the dataset if os . path . exists ( os . path . join ( dsBaseDirectory , \"subjects\" )): self . has_subjects = True self . data [ \"subjects\" ] = {} # data type paths, glob strings, dirty BOLD_paths_glob = os . path . join ( dsBaseDirectory , \"subjects\" , \"*\" , \"functional\" , \"*rsfMRI*.mat\" ) CM_paths_glob = os . path . join ( dsBaseDirectory , \"subjects\" , \"*\" , \"structural\" , \"DTI_CM*.mat\" ) LEN_paths_glob = os . path . join ( dsBaseDirectory , \"subjects\" , \"*\" , \"structural\" , \"DTI_LEN*.mat\" ) WAY_paths_glob = os . path . join ( dsBaseDirectory , \"subjects\" , \"*\" , \"structural\" , \"waytotal*.txt\" ) NVOXEL_paths_glob = os . path . join ( dsBaseDirectory , \"subjects\" , \"*\" , \"structural\" , \"nvoxel*.txt\" ) _ftypes = { \"bold\" : BOLD_paths_glob , \"cm\" : CM_paths_glob , \"len\" : LEN_paths_glob , \"waytotal\" : WAY_paths_glob , \"nvoxel\" : NVOXEL_paths_glob , } for _name , _glob in _ftypes . items (): fnames = glob . glob ( _glob ) # if there is none of this data type if len ( fnames ) == 0 : continue for f in fnames : # dirty subject = f . split ( os . path . sep )[ - 3 ] # create subject in dict if not present yet if not subject in self . data [ \"subjects\" ]: self . data [ \"subjects\" ][ subject ] = {} # if the data for this type is not already loaded if _name not in self . data [ \"subjects\" ][ subject ]: # bold, cm and len matrixes are provided as .mat files if _name in [ \"bold\" , \"cm\" , \"len\" ]: filter_subcotrical_axis = \"both\" if _name == \"bold\" : key = \"tc\" filter_subcotrical_axis = 0 elif _name == \"cm\" : key = \"sc\" elif _name == \"len\" : key = \"len\" # load the data data = self . loadMatrix ( f , key = key ) if not subcortical : data = filterSubcortical ( data , axis = filter_subcotrical_axis ) self . data [ \"subjects\" ][ subject ][ _name ] = data # waytotal and nvoxel files are .txt files elif _name in [ \"waytotal\" , \"nvoxel\" ]: data = np . loadtxt ( f ) if not subcortical : data = filterSubcortical ( data , axis = 0 ) self . data [ \"subjects\" ][ subject ][ _name ] = data def loadMatrix ( self , matFileName , key = \"\" , verbose = False ): \"\"\"Function to furiously load .mat files with scipy.io.loadmat. Info: More formats are supported but commented out in the code. :param matFileName: Filename of matrix to load :type matFileName: str :param key: .mat file key in which data is stored (example: \"sc\") :type key: str :return: Loaded matrix :rtype: numpy.ndarray \"\"\" if verbose : print ( f \"Loading { matFileName } \" ) matrix = scipy . io . loadmat ( matFileName ) if verbose : print ( \" \\t Loading using scipy.io.loadmat...\" ) print ( f \"Keys: { list ( matrix . keys ()) } \" ) if key != \"\" and key in list ( matrix . keys ()): matrix = matrix [ key ] if verbose : print ( f ' \\t Loaded key \" { key } \"' ) elif type ( matrix ) is dict : raise ValueError ( f \"Object is still a dict. Here are the keys: { matrix . keys () } \" ) return matrix return 0","title":"Functional MRI data"},{"location":"utils/dataset/#neurolib.utils.loadData.Dataset.__init__","text":"Load the empirical data sets that are provided with neurolib . Right now, datasets work on a per-subject base. A dataset must be located in the neurolib/data/datasets/ directory. Each subject's dataset must be in the subjects subdirectory of that folder. In each subject folder there is a directory called functional for time series data and structural the structural connectivity data. See loadData.loadSubjectFiles() for more details on which files are being loaded. The structural connectivity data (accessible using the attribute loadData.Cmat), can be normalized using the normalizeCmats flag. This defaults to \"max\" which normalizes the Cmat by its maxmimum. Other options are waytotal or nvoxel , which normalizes the Cmat by dividing every row of the matrix by the waytotal or nvoxel files that are provided in the datasets. Info: the waytotal.txt and the nvoxel.txt are files extracted from the tractography of DTI data using probtrackX from the fsl pipeline. Individual subject data is provided with the class attributes: self.BOLDs: BOLD timeseries of each individual self.FCs: Functional connectivity of BOLD timeseries Mean data is provided with the class attributes: self.Cmat: Structural connectivity matrix (for coupling strenghts between areas) self.Dmat: Fiber length matrix (for delays) self.BOLDs: BOLD timeseries of each area self.FCs: Functional connectiviy matrices of each BOLD timeseries Parameters: Name Type Description Default datasetName str Name of the dataset to load None normalizeCmats str Normalization method for the structural connectivity matrix. normalizationMethods = [\"max\", \"waytotal\", \"nvoxel\"] 'max' fcd bool Compute FCD matrices of BOLD data, defaults to False False subcortical bool Include subcortical areas from the atlas or not, defaults to False False Source code in neurolib/utils/loadData.py def __init__ ( self , datasetName = None , normalizeCmats = \"max\" , fcd = False , subcortical = False ): \"\"\" Load the empirical data sets that are provided with `neurolib`. Right now, datasets work on a per-subject base. A dataset must be located in the `neurolib/data/datasets/` directory. Each subject's dataset must be in the `subjects` subdirectory of that folder. In each subject folder there is a directory called `functional` for time series data and `structural` the structural connectivity data. See `loadData.loadSubjectFiles()` for more details on which files are being loaded. The structural connectivity data (accessible using the attribute loadData.Cmat), can be normalized using the `normalizeCmats` flag. This defaults to \"max\" which normalizes the Cmat by its maxmimum. Other options are `waytotal` or `nvoxel`, which normalizes the Cmat by dividing every row of the matrix by the waytotal or nvoxel files that are provided in the datasets. Info: the waytotal.txt and the nvoxel.txt are files extracted from the tractography of DTI data using `probtrackX` from the `fsl` pipeline. Individual subject data is provided with the class attributes: self.BOLDs: BOLD timeseries of each individual self.FCs: Functional connectivity of BOLD timeseries Mean data is provided with the class attributes: self.Cmat: Structural connectivity matrix (for coupling strenghts between areas) self.Dmat: Fiber length matrix (for delays) self.BOLDs: BOLD timeseries of each area self.FCs: Functional connectiviy matrices of each BOLD timeseries :param datasetName: Name of the dataset to load :type datasetName: str :param normalizeCmats: Normalization method for the structural connectivity matrix. normalizationMethods = [\"max\", \"waytotal\", \"nvoxel\"] :type normalizeCmats: str :param fcd: Compute FCD matrices of BOLD data, defaults to False :type fcd: bool :param subcortical: Include subcortical areas from the atlas or not, defaults to False :type subcortical: bool \"\"\" self . has_subjects = None if datasetName : self . loadDataset ( datasetName , normalizeCmats = normalizeCmats , fcd = fcd , subcortical = subcortical )","title":"__init__()"},{"location":"utils/dataset/#neurolib.utils.loadData.Dataset.getDataPerSubject","text":"Load data of a certain kind for all users of the current dataset Parameters: Name Type Description Default name str Name of data type, i.e. \"bold\" or \"cm\" required apply str, optional Apply function per subject (\"single\") or on all subjects (\"all\"), defaults to \"single\" 'single' apply_function function, optional Apply function on data, defaults to None None apply_function_kwargs dict, optional Keyword arguments of fuction, defaults to {} {} Returns: Type Description list[np.ndarray] Subjectwise data, after function apply Source code in neurolib/utils/loadData.py def getDataPerSubject ( self , name , apply = \"single\" , apply_function = None , apply_function_kwargs = {}, normalizeCmats = \"max\" , ): \"\"\"Load data of a certain kind for all users of the current dataset :param name: Name of data type, i.e. \"bold\" or \"cm\" :type name: str :param apply: Apply function per subject (\"single\") or on all subjects (\"all\"), defaults to \"single\" :type apply: str, optional :param apply_function: Apply function on data, defaults to None :type apply_function: function, optional :param apply_function_kwargs: Keyword arguments of fuction, defaults to {} :type apply_function_kwargs: dict, optional :return: Subjectwise data, after function apply :rtype: list[np.ndarray] \"\"\" values = [] for subject , value in self . data [ \"subjects\" ] . items (): assert name in value , f \"Data type { name } not found in dataset of subject { subject } .\" val = value [ name ] if apply_function and apply == \"single\" : val = apply_function ( val , ** apply_function_kwargs ) values . append ( val ) if apply_function and apply == \"all\" : values = apply_function ( values , ** apply_function_kwargs ) return values","title":"getDataPerSubject()"},{"location":"utils/dataset/#neurolib.utils.loadData.Dataset.loadDataset","text":"Load data into accessible class attributes. Parameters: Name Type Description Default datasetName str Name of the dataset (must be in datasets directory) required normalizeCmats str, optional Normalization method for Cmats, defaults to \"max\" 'max' Exceptions: Type Description NotImplementedError If unknown normalization method is used Source code in neurolib/utils/loadData.py def loadDataset ( self , datasetName , normalizeCmats = \"max\" , fcd = False , subcortical = False ): \"\"\"Load data into accessible class attributes. :param datasetName: Name of the dataset (must be in `datasets` directory) :type datasetName: str :param normalizeCmats: Normalization method for Cmats, defaults to \"max\" :type normalizeCmats: str, optional :raises NotImplementedError: If unknown normalization method is used \"\"\" # the base directory of the dataset dsBaseDirectory = os . path . join ( os . path . dirname ( __file__ ), \"..\" , \"data\" , \"datasets\" , datasetName ) assert os . path . exists ( dsBaseDirectory ), f \"Dataset { datasetName } not found in { dsBaseDirectory } .\" self . dsBaseDirectory = dsBaseDirectory self . data = dotdict ({}) # load all available subject data from disk to memory logging . info ( f \"Loading dataset { datasetName } from { self . dsBaseDirectory } .\" ) self . _loadSubjectFiles ( self . dsBaseDirectory , subcortical = subcortical ) assert len ( self . data ) > 0 , \"No data loaded.\" assert self . has_subjects self . Cmats = self . _normalizeCmats ( self . getDataPerSubject ( \"cm\" ), method = normalizeCmats ) self . Dmats = self . getDataPerSubject ( \"len\" ) # take the average of all self . Cmat = np . mean ( self . Cmats , axis = 0 ) self . Dmat = self . getDataPerSubject ( \"len\" , apply = \"all\" , apply_function = np . mean , apply_function_kwargs = { \"axis\" : 0 }, ) self . BOLDs = self . getDataPerSubject ( \"bold\" ) self . FCs = self . getDataPerSubject ( \"bold\" , apply_function = func . fc ) if fcd : self . computeFCD () logging . info ( f \"Dataset { datasetName } loaded.\" )","title":"loadDataset()"},{"location":"utils/dataset/#neurolib.utils.loadData.Dataset.loadMatrix","text":"Function to furiously load .mat files with scipy.io.loadmat. Info: More formats are supported but commented out in the code. Parameters: Name Type Description Default matFileName str Filename of matrix to load required key str .mat file key in which data is stored (example: \"sc\") '' Returns: Type Description numpy.ndarray Loaded matrix Source code in neurolib/utils/loadData.py def loadMatrix ( self , matFileName , key = \"\" , verbose = False ): \"\"\"Function to furiously load .mat files with scipy.io.loadmat. Info: More formats are supported but commented out in the code. :param matFileName: Filename of matrix to load :type matFileName: str :param key: .mat file key in which data is stored (example: \"sc\") :type key: str :return: Loaded matrix :rtype: numpy.ndarray \"\"\" if verbose : print ( f \"Loading { matFileName } \" ) matrix = scipy . io . loadmat ( matFileName ) if verbose : print ( \" \\t Loading using scipy.io.loadmat...\" ) print ( f \"Keys: { list ( matrix . keys ()) } \" ) if key != \"\" and key in list ( matrix . keys ()): matrix = matrix [ key ] if verbose : print ( f ' \\t Loaded key \" { key } \"' ) elif type ( matrix ) is dict : raise ValueError ( f \"Object is still a dict. Here are the keys: { matrix . keys () } \" ) return matrix return 0","title":"loadMatrix()"},{"location":"utils/functions/","text":"Functions fc ( ts ) Functional connectivity matrix of timeseries multidimensional ts (Nxt). Pearson correlation (from np.corrcoef() is used). Parameters: Name Type Description Default ts numpy.ndarray Nxt timeseries required Returns: Type Description numpy.ndarray N x N functional connectivity matrix Source code in neurolib/utils/functions.py def fc ( ts ): \"\"\"Functional connectivity matrix of timeseries multidimensional `ts` (Nxt). Pearson correlation (from `np.corrcoef()` is used). :param ts: Nxt timeseries :type ts: numpy.ndarray :return: N x N functional connectivity matrix :rtype: numpy.ndarray \"\"\" fc = np . corrcoef ( ts ) fc = np . nan_to_num ( fc ) # remove NaNs return fc fcd ( ts , windowsize = 30 , stepsize = 5 ) Computes FCD (functional connectivity dynamics) matrix, as described in Deco's whole-brain model papers. Default paramters are suited for computing FCS matrices of BOLD timeseries: A windowsize of 30 at the BOLD sampling rate of 0.5 Hz equals 60s and stepsize = 5 equals 10s. Parameters: Name Type Description Default ts numpy.ndarray Nxt timeseries required windowsize int, optional Size of each rolling window in timesteps, defaults to 30 30 stepsize int, optional Stepsize between each rolling window, defaults to 5 5 Returns: Type Description numpy.ndarray T x T FCD matrix Source code in neurolib/utils/functions.py def fcd ( ts , windowsize = 30 , stepsize = 5 ): \"\"\"Computes FCD (functional connectivity dynamics) matrix, as described in Deco's whole-brain model papers. Default paramters are suited for computing FCS matrices of BOLD timeseries: A windowsize of 30 at the BOLD sampling rate of 0.5 Hz equals 60s and stepsize = 5 equals 10s. :param ts: Nxt timeseries :type ts: numpy.ndarray :param windowsize: Size of each rolling window in timesteps, defaults to 30 :type windowsize: int, optional :param stepsize: Stepsize between each rolling window, defaults to 5 :type stepsize: int, optional :return: T x T FCD matrix :rtype: numpy.ndarray \"\"\" t_window_width = int ( windowsize ) # int(windowsize * 30) # x minutes stepsize = stepsize # ts.shape[1]/N corrFCs = [] try : counter = range ( 0 , ts . shape [ 1 ] - t_window_width , stepsize ) for t in counter : ts_slice = ts [:, t : t + t_window_width ] corrFCs . append ( np . corrcoef ( ts_slice )) FCd = np . empty ([ len ( corrFCs ), len ( corrFCs )]) f1i = 0 for f1 in corrFCs : f2i = 0 for f2 in corrFCs : FCd [ f1i , f2i ] = np . corrcoef ( f1 . reshape (( 1 , f1 . size )), f2 . reshape (( 1 , f2 . size )))[ 0 , 1 ] f2i += 1 f1i += 1 return FCd except : return 0 getMeanPowerSpectrum ( activities , dt , maxfr = 70 , spectrum_windowsize = 1.0 , normalize = False ) Returns the mean power spectrum of multiple timeseries. Parameters: Name Type Description Default activities np.ndarray N-dimensional timeseries required dt float Simulation time step required maxfr int, optional Maximum frequency in Hz to cutoff from return, defaults to 70 70 spectrum_windowsize float, optional Length of the window used in Welch's method (in seconds), defaults to 1.0 1.0 normalize bool, optional Maximum power is normalized to 1 if True, defaults to False False Returns: Type Description [np.ndarray, np.ndarray] Frquencies and the power of each frequency Source code in neurolib/utils/functions.py def getMeanPowerSpectrum ( activities , dt , maxfr = 70 , spectrum_windowsize = 1.0 , normalize = False ): \"\"\"Returns the mean power spectrum of multiple timeseries. :param activities: N-dimensional timeseries :type activities: np.ndarray :param dt: Simulation time step :type dt: float :param maxfr: Maximum frequency in Hz to cutoff from return, defaults to 70 :type maxfr: int, optional :param spectrum_windowsize: Length of the window used in Welch's method (in seconds), defaults to 1.0 :type spectrum_windowsize: float, optional :param normalize: Maximum power is normalized to 1 if True, defaults to False :type normalize: bool, optional :return: Frquencies and the power of each frequency :rtype: [np.ndarray, np.ndarray] \"\"\" powers = np . zeros ( getPowerSpectrum ( activities [ 0 ], dt , maxfr , spectrum_windowsize )[ 0 ] . shape ) ps = [] for rate in activities : f , Pxx_spec = getPowerSpectrum ( rate , dt , maxfr , spectrum_windowsize ) ps . append ( Pxx_spec ) powers += Pxx_spec powers /= len ( ps ) if normalize : powers /= np . max ( powers ) return f , powers getPowerSpectrum ( activity , dt , maxfr = 70 , spectrum_windowsize = 1.0 , normalize = False ) Returns a power spectrum using Welch's method. Parameters: Name Type Description Default activity np.ndarray One-dimensional timeseries required dt float Simulation time step required maxfr int, optional Maximum frequency in Hz to cutoff from return, defaults to 70 70 spectrum_windowsize float, optional Length of the window used in Welch's method (in seconds), defaults to 1.0 1.0 normalize bool, optional Maximum power is normalized to 1 if True, defaults to False False Returns: Type Description [np.ndarray, np.ndarray] Frquencies and the power of each frequency Source code in neurolib/utils/functions.py def getPowerSpectrum ( activity , dt , maxfr = 70 , spectrum_windowsize = 1.0 , normalize = False ): \"\"\"Returns a power spectrum using Welch's method. :param activity: One-dimensional timeseries :type activity: np.ndarray :param dt: Simulation time step :type dt: float :param maxfr: Maximum frequency in Hz to cutoff from return, defaults to 70 :type maxfr: int, optional :param spectrum_windowsize: Length of the window used in Welch's method (in seconds), defaults to 1.0 :type spectrum_windowsize: float, optional :param normalize: Maximum power is normalized to 1 if True, defaults to False :type normalize: bool, optional :return: Frquencies and the power of each frequency :rtype: [np.ndarray, np.ndarray] \"\"\" # convert to one-dimensional array if it is an (1xn)-D array if activity . shape [ 0 ] == 1 and activity . shape [ 1 ] > 1 : activity = activity [ 0 ] assert len ( activity . shape ) == 1 , \"activity is not one-dimensional!\" f , Pxx_spec = scipy . signal . welch ( activity , 1000 / dt , window = \"hanning\" , nperseg = int ( spectrum_windowsize * 1000 / dt ), scaling = \"spectrum\" , ) f = f [ f < maxfr ] Pxx_spec = Pxx_spec [ 0 : len ( f )] if normalize : Pxx_spec /= np . max ( Pxx_spec ) return f , Pxx_spec kuramoto ( traces , smoothing = 0.0 , distance = 10 , prominence = 5 ) Computes the Kuramoto order parameter of a timeseries which is a measure for synchrony. Can smooth timeseries if there is noise. Peaks are then detected using a peakfinder. From these peaks a phase is derived and then the amount of phase synchrony (the Kuramoto order parameter) is computed. Parameters: Name Type Description Default traces numpy.ndarray Multidimensional timeseries array required smoothing float, optional Gaussian smoothing strength 0.0 distance int, optional minimum distance between peaks in samples 10 prominence int, optional vertical distance between the peak and its lowest contour line 5 Returns: Type Description numpy.ndarray Timeseries of Kuramoto order paramter Source code in neurolib/utils/functions.py def kuramoto ( traces , smoothing = 0.0 , distance = 10 , prominence = 5 ): \"\"\" Computes the Kuramoto order parameter of a timeseries which is a measure for synchrony. Can smooth timeseries if there is noise. Peaks are then detected using a peakfinder. From these peaks a phase is derived and then the amount of phase synchrony (the Kuramoto order parameter) is computed. :param traces: Multidimensional timeseries array :type traces: numpy.ndarray :param smoothing: Gaussian smoothing strength :type smoothing: float, optional :param distance: minimum distance between peaks in samples :type distance: int, optional :param prominence: vertical distance between the peak and its lowest contour line :type prominence: int, optional :return: Timeseries of Kuramoto order paramter :rtype: numpy.ndarray \"\"\" @numba . njit def _estimate_phase ( maximalist , n_times ): lastMax = 0 phases = np . empty (( n_times ), dtype = np . float64 ) n = 0 for m in maximalist : for t in range ( lastMax , m ): # compute instantaneous phase phi = 2 * np . pi * float ( t - lastMax ) / float ( m - lastMax ) phases [ n ] = phi n += 1 lastMax = m phases [ - 1 ] = 2 * np . pi return phases @numba . njit def _estimate_r ( ntraces , times , phases ): kuramoto = np . empty (( times ), dtype = np . float64 ) for t in range ( times ): R = 1 j * 0 for n in range ( ntraces ): R += np . exp ( 1 j * phases [ n , t ]) R /= ntraces kuramoto [ t ] = np . absolute ( R ) return kuramoto nTraces , nTimes = traces . shape phases = np . empty_like ( traces ) for n in range ( nTraces ): a = traces [ n ] # find peaks if smoothing > 0 : # smooth data a = scipy . ndimage . filters . gaussian_filter ( traces [ n ], smoothing ) maximalist = scipy . signal . find_peaks ( a , distance = distance , prominence = prominence )[ 0 ] maximalist = np . append ( maximalist , len ( traces [ n ]) - 1 ) . astype ( int ) if len ( maximalist ) > 1 : phases [ n , :] = _estimate_phase ( maximalist , nTimes ) else : logging . warning ( \"Kuramoto: No peaks found, returning 0.\" ) return 0 # determine kuramoto order paramter kuramoto = _estimate_r ( nTraces , nTimes , phases ) return kuramoto matrix_correlation ( M1 , M2 ) Pearson correlation of the lower triagonal of two matrices. The triangular matrix is offset by k = 1 in order to ignore the diagonal line Parameters: Name Type Description Default M1 numpy.ndarray First matrix required M2 numpy.ndarray Second matrix required Returns: Type Description float Correlation coefficient Source code in neurolib/utils/functions.py def matrix_correlation ( M1 , M2 ): \"\"\"Pearson correlation of the lower triagonal of two matrices. The triangular matrix is offset by k = 1 in order to ignore the diagonal line :param M1: First matrix :type M1: numpy.ndarray :param M2: Second matrix :type M2: numpy.ndarray :return: Correlation coefficient :rtype: float \"\"\" cc = np . corrcoef ( M1 [ np . triu_indices_from ( M1 , k = 1 )], M2 [ np . triu_indices_from ( M2 , k = 1 )])[ 0 , 1 ] return cc matrix_kolmogorov ( m1 , m2 ) Computes the Kolmogorov distance between the distributions of lower-triangular entries of two matrices See: https://en.wikipedia.org/wiki/Kolmogorov%E2%80%93Smirnov_test#Two-sample_Kolmogorov%E2%80%93Smirnov_test Parameters: Name Type Description Default m1 np.ndarray matrix 1 required m2 np.ndarray matrix 2 required Returns: Type Description float 2-sample KS statistics Source code in neurolib/utils/functions.py def matrix_kolmogorov ( m1 , m2 ): \"\"\"Computes the Kolmogorov distance between the distributions of lower-triangular entries of two matrices See: https://en.wikipedia.org/wiki/Kolmogorov%E2%80%93Smirnov_test#Two-sample_Kolmogorov%E2%80%93Smirnov_test :param m1: matrix 1 :type m1: np.ndarray :param m2: matrix 2 :type m2: np.ndarray :return: 2-sample KS statistics :rtype: float \"\"\" # get the values of the lower triangle triu_ind1 = np . triu_indices ( m1 . shape [ 0 ], k = 1 ) m1_vals = m1 [ triu_ind1 ] triu_ind2 = np . triu_indices ( m2 . shape [ 0 ], k = 1 ) m2_vals = m2 [ triu_ind2 ] # return the distance, omit p-value return scipy . stats . ks_2samp ( m1_vals , m2_vals )[ 0 ] ts_kolmogorov ( ts1 , ts2 , ** fcd_kwargs ) Computes kolmogorov distance between two timeseries. This is done by first computing two FCD matrices (one for each timeseries) and then measuring the Kolmogorov distance of the upper triangle of these matrices. Parameters: Name Type Description Default ts1 np.ndarray Timeseries 1 required ts2 np.ndarray Timeseries 2 required Returns: Type Description float 2-sample KS statistics Source code in neurolib/utils/functions.py def ts_kolmogorov ( ts1 , ts2 , ** fcd_kwargs ): \"\"\"Computes kolmogorov distance between two timeseries. This is done by first computing two FCD matrices (one for each timeseries) and then measuring the Kolmogorov distance of the upper triangle of these matrices. :param ts1: Timeseries 1 :type ts1: np.ndarray :param ts2: Timeseries 2 :type ts2: np.ndarray :return: 2-sample KS statistics :rtype: float \"\"\" fcd1 = fcd ( ts1 , ** fcd_kwargs ) fcd2 = fcd ( ts2 , ** fcd_kwargs ) return matrix_kolmogorov ( fcd1 , fcd2 ) weighted_correlation ( x , y , w ) Weighted Pearson correlation of two series. Parameters: Name Type Description Default x list, np.array Timeseries 1 required y list, np.array Timeseries 2, must have same length as x required w list, np.array Weight vector, must have same length as x and y required Returns: Type Description float Weighted correlation coefficient Source code in neurolib/utils/functions.py def weighted_correlation ( x , y , w ): \"\"\"Weighted Pearson correlation of two series. :param x: Timeseries 1 :type x: list, np.array :param y: Timeseries 2, must have same length as x :type y: list, np.array :param w: Weight vector, must have same length as x and y :type w: list, np.array :return: Weighted correlation coefficient :rtype: float \"\"\" def weighted_mean ( x , w ): \"\"\"Weighted Mean\"\"\" return np . sum ( x * w ) / np . sum ( w ) def weighted_cov ( x , y , w ): \"\"\"Weighted Covariance\"\"\" return np . sum ( w * ( x - weighted_mean ( x , w )) * ( y - weighted_mean ( y , w ))) / np . sum ( w ) return weighted_cov ( x , y , w ) / np . sqrt ( weighted_cov ( x , x , w ) * weighted_cov ( y , y , w ))","title":"Functions"},{"location":"utils/functions/#functions","text":"","title":"Functions"},{"location":"utils/functions/#neurolib.utils.functions.fc","text":"Functional connectivity matrix of timeseries multidimensional ts (Nxt). Pearson correlation (from np.corrcoef() is used). Parameters: Name Type Description Default ts numpy.ndarray Nxt timeseries required Returns: Type Description numpy.ndarray N x N functional connectivity matrix Source code in neurolib/utils/functions.py def fc ( ts ): \"\"\"Functional connectivity matrix of timeseries multidimensional `ts` (Nxt). Pearson correlation (from `np.corrcoef()` is used). :param ts: Nxt timeseries :type ts: numpy.ndarray :return: N x N functional connectivity matrix :rtype: numpy.ndarray \"\"\" fc = np . corrcoef ( ts ) fc = np . nan_to_num ( fc ) # remove NaNs return fc","title":"fc()"},{"location":"utils/functions/#neurolib.utils.functions.fcd","text":"Computes FCD (functional connectivity dynamics) matrix, as described in Deco's whole-brain model papers. Default paramters are suited for computing FCS matrices of BOLD timeseries: A windowsize of 30 at the BOLD sampling rate of 0.5 Hz equals 60s and stepsize = 5 equals 10s. Parameters: Name Type Description Default ts numpy.ndarray Nxt timeseries required windowsize int, optional Size of each rolling window in timesteps, defaults to 30 30 stepsize int, optional Stepsize between each rolling window, defaults to 5 5 Returns: Type Description numpy.ndarray T x T FCD matrix Source code in neurolib/utils/functions.py def fcd ( ts , windowsize = 30 , stepsize = 5 ): \"\"\"Computes FCD (functional connectivity dynamics) matrix, as described in Deco's whole-brain model papers. Default paramters are suited for computing FCS matrices of BOLD timeseries: A windowsize of 30 at the BOLD sampling rate of 0.5 Hz equals 60s and stepsize = 5 equals 10s. :param ts: Nxt timeseries :type ts: numpy.ndarray :param windowsize: Size of each rolling window in timesteps, defaults to 30 :type windowsize: int, optional :param stepsize: Stepsize between each rolling window, defaults to 5 :type stepsize: int, optional :return: T x T FCD matrix :rtype: numpy.ndarray \"\"\" t_window_width = int ( windowsize ) # int(windowsize * 30) # x minutes stepsize = stepsize # ts.shape[1]/N corrFCs = [] try : counter = range ( 0 , ts . shape [ 1 ] - t_window_width , stepsize ) for t in counter : ts_slice = ts [:, t : t + t_window_width ] corrFCs . append ( np . corrcoef ( ts_slice )) FCd = np . empty ([ len ( corrFCs ), len ( corrFCs )]) f1i = 0 for f1 in corrFCs : f2i = 0 for f2 in corrFCs : FCd [ f1i , f2i ] = np . corrcoef ( f1 . reshape (( 1 , f1 . size )), f2 . reshape (( 1 , f2 . size )))[ 0 , 1 ] f2i += 1 f1i += 1 return FCd except : return 0","title":"fcd()"},{"location":"utils/functions/#neurolib.utils.functions.getMeanPowerSpectrum","text":"Returns the mean power spectrum of multiple timeseries. Parameters: Name Type Description Default activities np.ndarray N-dimensional timeseries required dt float Simulation time step required maxfr int, optional Maximum frequency in Hz to cutoff from return, defaults to 70 70 spectrum_windowsize float, optional Length of the window used in Welch's method (in seconds), defaults to 1.0 1.0 normalize bool, optional Maximum power is normalized to 1 if True, defaults to False False Returns: Type Description [np.ndarray, np.ndarray] Frquencies and the power of each frequency Source code in neurolib/utils/functions.py def getMeanPowerSpectrum ( activities , dt , maxfr = 70 , spectrum_windowsize = 1.0 , normalize = False ): \"\"\"Returns the mean power spectrum of multiple timeseries. :param activities: N-dimensional timeseries :type activities: np.ndarray :param dt: Simulation time step :type dt: float :param maxfr: Maximum frequency in Hz to cutoff from return, defaults to 70 :type maxfr: int, optional :param spectrum_windowsize: Length of the window used in Welch's method (in seconds), defaults to 1.0 :type spectrum_windowsize: float, optional :param normalize: Maximum power is normalized to 1 if True, defaults to False :type normalize: bool, optional :return: Frquencies and the power of each frequency :rtype: [np.ndarray, np.ndarray] \"\"\" powers = np . zeros ( getPowerSpectrum ( activities [ 0 ], dt , maxfr , spectrum_windowsize )[ 0 ] . shape ) ps = [] for rate in activities : f , Pxx_spec = getPowerSpectrum ( rate , dt , maxfr , spectrum_windowsize ) ps . append ( Pxx_spec ) powers += Pxx_spec powers /= len ( ps ) if normalize : powers /= np . max ( powers ) return f , powers","title":"getMeanPowerSpectrum()"},{"location":"utils/functions/#neurolib.utils.functions.getPowerSpectrum","text":"Returns a power spectrum using Welch's method. Parameters: Name Type Description Default activity np.ndarray One-dimensional timeseries required dt float Simulation time step required maxfr int, optional Maximum frequency in Hz to cutoff from return, defaults to 70 70 spectrum_windowsize float, optional Length of the window used in Welch's method (in seconds), defaults to 1.0 1.0 normalize bool, optional Maximum power is normalized to 1 if True, defaults to False False Returns: Type Description [np.ndarray, np.ndarray] Frquencies and the power of each frequency Source code in neurolib/utils/functions.py def getPowerSpectrum ( activity , dt , maxfr = 70 , spectrum_windowsize = 1.0 , normalize = False ): \"\"\"Returns a power spectrum using Welch's method. :param activity: One-dimensional timeseries :type activity: np.ndarray :param dt: Simulation time step :type dt: float :param maxfr: Maximum frequency in Hz to cutoff from return, defaults to 70 :type maxfr: int, optional :param spectrum_windowsize: Length of the window used in Welch's method (in seconds), defaults to 1.0 :type spectrum_windowsize: float, optional :param normalize: Maximum power is normalized to 1 if True, defaults to False :type normalize: bool, optional :return: Frquencies and the power of each frequency :rtype: [np.ndarray, np.ndarray] \"\"\" # convert to one-dimensional array if it is an (1xn)-D array if activity . shape [ 0 ] == 1 and activity . shape [ 1 ] > 1 : activity = activity [ 0 ] assert len ( activity . shape ) == 1 , \"activity is not one-dimensional!\" f , Pxx_spec = scipy . signal . welch ( activity , 1000 / dt , window = \"hanning\" , nperseg = int ( spectrum_windowsize * 1000 / dt ), scaling = \"spectrum\" , ) f = f [ f < maxfr ] Pxx_spec = Pxx_spec [ 0 : len ( f )] if normalize : Pxx_spec /= np . max ( Pxx_spec ) return f , Pxx_spec","title":"getPowerSpectrum()"},{"location":"utils/functions/#neurolib.utils.functions.kuramoto","text":"Computes the Kuramoto order parameter of a timeseries which is a measure for synchrony. Can smooth timeseries if there is noise. Peaks are then detected using a peakfinder. From these peaks a phase is derived and then the amount of phase synchrony (the Kuramoto order parameter) is computed. Parameters: Name Type Description Default traces numpy.ndarray Multidimensional timeseries array required smoothing float, optional Gaussian smoothing strength 0.0 distance int, optional minimum distance between peaks in samples 10 prominence int, optional vertical distance between the peak and its lowest contour line 5 Returns: Type Description numpy.ndarray Timeseries of Kuramoto order paramter Source code in neurolib/utils/functions.py def kuramoto ( traces , smoothing = 0.0 , distance = 10 , prominence = 5 ): \"\"\" Computes the Kuramoto order parameter of a timeseries which is a measure for synchrony. Can smooth timeseries if there is noise. Peaks are then detected using a peakfinder. From these peaks a phase is derived and then the amount of phase synchrony (the Kuramoto order parameter) is computed. :param traces: Multidimensional timeseries array :type traces: numpy.ndarray :param smoothing: Gaussian smoothing strength :type smoothing: float, optional :param distance: minimum distance between peaks in samples :type distance: int, optional :param prominence: vertical distance between the peak and its lowest contour line :type prominence: int, optional :return: Timeseries of Kuramoto order paramter :rtype: numpy.ndarray \"\"\" @numba . njit def _estimate_phase ( maximalist , n_times ): lastMax = 0 phases = np . empty (( n_times ), dtype = np . float64 ) n = 0 for m in maximalist : for t in range ( lastMax , m ): # compute instantaneous phase phi = 2 * np . pi * float ( t - lastMax ) / float ( m - lastMax ) phases [ n ] = phi n += 1 lastMax = m phases [ - 1 ] = 2 * np . pi return phases @numba . njit def _estimate_r ( ntraces , times , phases ): kuramoto = np . empty (( times ), dtype = np . float64 ) for t in range ( times ): R = 1 j * 0 for n in range ( ntraces ): R += np . exp ( 1 j * phases [ n , t ]) R /= ntraces kuramoto [ t ] = np . absolute ( R ) return kuramoto nTraces , nTimes = traces . shape phases = np . empty_like ( traces ) for n in range ( nTraces ): a = traces [ n ] # find peaks if smoothing > 0 : # smooth data a = scipy . ndimage . filters . gaussian_filter ( traces [ n ], smoothing ) maximalist = scipy . signal . find_peaks ( a , distance = distance , prominence = prominence )[ 0 ] maximalist = np . append ( maximalist , len ( traces [ n ]) - 1 ) . astype ( int ) if len ( maximalist ) > 1 : phases [ n , :] = _estimate_phase ( maximalist , nTimes ) else : logging . warning ( \"Kuramoto: No peaks found, returning 0.\" ) return 0 # determine kuramoto order paramter kuramoto = _estimate_r ( nTraces , nTimes , phases ) return kuramoto","title":"kuramoto()"},{"location":"utils/functions/#neurolib.utils.functions.matrix_correlation","text":"Pearson correlation of the lower triagonal of two matrices. The triangular matrix is offset by k = 1 in order to ignore the diagonal line Parameters: Name Type Description Default M1 numpy.ndarray First matrix required M2 numpy.ndarray Second matrix required Returns: Type Description float Correlation coefficient Source code in neurolib/utils/functions.py def matrix_correlation ( M1 , M2 ): \"\"\"Pearson correlation of the lower triagonal of two matrices. The triangular matrix is offset by k = 1 in order to ignore the diagonal line :param M1: First matrix :type M1: numpy.ndarray :param M2: Second matrix :type M2: numpy.ndarray :return: Correlation coefficient :rtype: float \"\"\" cc = np . corrcoef ( M1 [ np . triu_indices_from ( M1 , k = 1 )], M2 [ np . triu_indices_from ( M2 , k = 1 )])[ 0 , 1 ] return cc","title":"matrix_correlation()"},{"location":"utils/functions/#neurolib.utils.functions.matrix_kolmogorov","text":"Computes the Kolmogorov distance between the distributions of lower-triangular entries of two matrices See: https://en.wikipedia.org/wiki/Kolmogorov%E2%80%93Smirnov_test#Two-sample_Kolmogorov%E2%80%93Smirnov_test Parameters: Name Type Description Default m1 np.ndarray matrix 1 required m2 np.ndarray matrix 2 required Returns: Type Description float 2-sample KS statistics Source code in neurolib/utils/functions.py def matrix_kolmogorov ( m1 , m2 ): \"\"\"Computes the Kolmogorov distance between the distributions of lower-triangular entries of two matrices See: https://en.wikipedia.org/wiki/Kolmogorov%E2%80%93Smirnov_test#Two-sample_Kolmogorov%E2%80%93Smirnov_test :param m1: matrix 1 :type m1: np.ndarray :param m2: matrix 2 :type m2: np.ndarray :return: 2-sample KS statistics :rtype: float \"\"\" # get the values of the lower triangle triu_ind1 = np . triu_indices ( m1 . shape [ 0 ], k = 1 ) m1_vals = m1 [ triu_ind1 ] triu_ind2 = np . triu_indices ( m2 . shape [ 0 ], k = 1 ) m2_vals = m2 [ triu_ind2 ] # return the distance, omit p-value return scipy . stats . ks_2samp ( m1_vals , m2_vals )[ 0 ]","title":"matrix_kolmogorov()"},{"location":"utils/functions/#neurolib.utils.functions.ts_kolmogorov","text":"Computes kolmogorov distance between two timeseries. This is done by first computing two FCD matrices (one for each timeseries) and then measuring the Kolmogorov distance of the upper triangle of these matrices. Parameters: Name Type Description Default ts1 np.ndarray Timeseries 1 required ts2 np.ndarray Timeseries 2 required Returns: Type Description float 2-sample KS statistics Source code in neurolib/utils/functions.py def ts_kolmogorov ( ts1 , ts2 , ** fcd_kwargs ): \"\"\"Computes kolmogorov distance between two timeseries. This is done by first computing two FCD matrices (one for each timeseries) and then measuring the Kolmogorov distance of the upper triangle of these matrices. :param ts1: Timeseries 1 :type ts1: np.ndarray :param ts2: Timeseries 2 :type ts2: np.ndarray :return: 2-sample KS statistics :rtype: float \"\"\" fcd1 = fcd ( ts1 , ** fcd_kwargs ) fcd2 = fcd ( ts2 , ** fcd_kwargs ) return matrix_kolmogorov ( fcd1 , fcd2 )","title":"ts_kolmogorov()"},{"location":"utils/functions/#neurolib.utils.functions.weighted_correlation","text":"Weighted Pearson correlation of two series. Parameters: Name Type Description Default x list, np.array Timeseries 1 required y list, np.array Timeseries 2, must have same length as x required w list, np.array Weight vector, must have same length as x and y required Returns: Type Description float Weighted correlation coefficient Source code in neurolib/utils/functions.py def weighted_correlation ( x , y , w ): \"\"\"Weighted Pearson correlation of two series. :param x: Timeseries 1 :type x: list, np.array :param y: Timeseries 2, must have same length as x :type y: list, np.array :param w: Weight vector, must have same length as x and y :type w: list, np.array :return: Weighted correlation coefficient :rtype: float \"\"\" def weighted_mean ( x , w ): \"\"\"Weighted Mean\"\"\" return np . sum ( x * w ) / np . sum ( w ) def weighted_cov ( x , y , w ): \"\"\"Weighted Covariance\"\"\" return np . sum ( w * ( x - weighted_mean ( x , w )) * ( y - weighted_mean ( y , w ))) / np . sum ( w ) return weighted_cov ( x , y , w ) / np . sqrt ( weighted_cov ( x , x , w ) * weighted_cov ( y , y , w ))","title":"weighted_correlation()"},{"location":"utils/parameterspace/","text":"ParameterSpace Parameter space Source code in neurolib/utils/parameterSpace.py class ParameterSpace : \"\"\" Parameter space \"\"\" def __init__ ( self , parameters , parameterValues = None , kind = None , allow_star_notation = False ): \"\"\" Initialize parameter space. Parameter space can be initialized in two ways: Either a `parameters` is a dictionary of the form `{\"parName1\" : [0, 1, 2], \"parName2\" : [3, 4]}`, or `parameters` is a list of names and `parameterValues` are values of each parameter. :param parameters: parameter dictionary or list of names of parameters e.g. `['x', 'y']` :type parameters: `dict, list[str, str]` :param parameterValues: list of parameter values (must be floats) e.g. `[[x_min, x_max], [y_min, y_max], ...]` :type parameterValues: `list[list[float, float]]` :param kind: string describing the kind of parameter space: - `point`: a single point in parameter space - `bound`: a bound in parameter space, i.e. two values per parameter - `grid`: a cartesian product over parameters - `sequence`: a sequence of univariate parameter changes - only one will change at the time, other parameters will stay as default - `explicit`: explicitely define a parameter space, i.e lists of all parameters have to have the same length - None: parameterSpace tries to auto-detect the correct kind :type kind: str :param allow_star_notation: whether to allow star notation in parameter names - MultiModel :type allow_star_notation: bool \"\"\" assert kind in SUPPORTED_KINDS self . kind = kind self . parameters = parameters self . star = allow_star_notation # in case a parameter dictionary was given if parameterValues is None : assert isinstance ( parameters , dict ), \"Parameters must be a dict, if no values are given in `parameterValues`\" processedParameters = self . _processParameterDict ( parameters ) else : # check if all names are strings assert np . all ([ isinstance ( pn , str ) for pn in parameters ]), \"Parameter names must all be strings.\" # check if all parameter values are lists assert np . all ([ isinstance ( pv , ( list , tuple )) for pv in parameterValues ]), \"Parameter values must be a list.\" parameters = self . _parameterListsToDict ( parameters , parameterValues ) processedParameters = self . _processParameterDict ( parameters ) self . parameters = processedParameters self . parameterNames = list ( self . parameters . keys ()) self . parameterValues = list ( self . parameters . values ()) # let's create a named tuple of the parameters # Note: evolution.py implementation relies on named tuples self . named_tuple_constructor = namedtuple ( \"ParameterSpace\" , sanitize_dot_dict ( parameters )) self . named_tuple = self . named_tuple_constructor ( * self . parameterValues ) # set attributes of this class to make it accessible for i , p in enumerate ( self . parameters ): setattr ( self , p , self . parameterValues [ i ]) def __str__ ( self ): \"\"\"Print the named_tuple object\"\"\" return str ( self . parameters ) def __getitem__ ( self , key ): return self . parameters [ key ] def __setitem__ ( self , key , value ): self . parameters [ key ] = value self . _processParameterDict ( self . parameters ) def dict ( self ): \"\"\"Returns the parameter space as a dicitonary of lists. :rtype: dict \"\"\" return self . parameters def get_parametrization ( self ): assert self . kind is not None if self . kind in [ \"point\" , \"bound\" , \"explicit\" ]: # check same length it = iter ( self . parameters . values ()) length = len ( next ( it )) assert all ( len ( l ) == length for l in it ) # just return as dict return self . parameters elif self . kind == \"grid\" : # cartesian product return pypet . cartesian_product ( self . parameters ) elif self . kind == \"sequence\" : # return as sequence return self . _inflate_to_sequence ( self . parameters ) @staticmethod def _inflate_to_sequence ( param_dict ): \"\"\" Inflate dict of parameters to a sequence of same length, using None as placeholder when a particular parameter should not change. {\"a\": [1, 2], \"b\": [3, 4, 5]} -> {\"a\": [1, 2, None, None, None], \"b\": [None, None, 3, 4, 5]} \"\"\" return { k : [ None ] * sum ([ len ( tmp ) for tmp in list ( param_dict . values ())[: i ]]) + v + [ None ] * sum ([ len ( tmp ) for tmp in list ( param_dict . values ())[ i + 1 :]]) for i , ( k , v ) in enumerate ( param_dict . items ()) } def getRandom ( self , safe = False ): \"\"\"This function returns a random single parameter from the whole space in the form of { \"par1\" : 1, \"par2\" : 2}. This function is used by neurolib/optimize/exploarion.py to add parameters of the space to pypet (for initialization) :param safe: Return a \"safe\" parameter or the original. Safe refers to returning python floats, not, for example numpy.float64 (necessary for pypet). ;type safe: bool \"\"\" randomPar = {} if safe : for key , value in self . parameters . items (): random_value = np . random . choice ( value ) if isinstance ( random_value , np . float64 ): random_value = float ( random_value ) elif isinstance ( random_value , np . int64 ): random_value = int ( random_value ) randomPar [ key ] = random_value else : for key , value in self . parameters . items (): randomPar [ key ] = np . random . choice ( value ) return randomPar @property def lowerBound ( self ): \"\"\"Returns lower bound of all parameters as a list\"\"\" return [ np . min ( p ) for p in self . parameterValues ] @property def upperBound ( self ): \"\"\"Returns upper bound of all parameters as a list\"\"\" return [ np . max ( p ) for p in self . parameterValues ] @property def ndims ( self ): \"\"\"Number of dimensions (parameters)\"\"\" return len ( self . parameters ) @staticmethod def _validate_single_bound ( single_bound ): \"\"\" Validate single bound. :param single_bound: single coordinate bound to validate :type single_bound: list|tuple \"\"\" assert isinstance ( single_bound , ( list , tuple ) ), \"An error occured while validating the ParameterSpace of kind 'bound': Pass parameter bounds as a list or tuple!\" assert ( len ( single_bound ) == 2 ), \"An error occured while validating the ParameterSpace of kind 'bound': Only two bounds (min and max) are allowed\" assert ( single_bound [ 1 ] > single_bound [ 0 ] ), \"An error occured while validating the ParameterSpace of kind 'bound': Minimum parameter value can't be larger than the maximum!\" def _validate_param_bounds ( self , param_bounds ): \"\"\" Validate param bounds. :param param_bounds: parameter bounds to validate :type param_bounds: list|None \"\"\" assert param_bounds is not None assert isinstance ( param_bounds , ( list , tuple )) # check every single parameter bound for single_bound in param_bounds : self . _validate_single_bound ( single_bound ) def _processParameterDict ( self , parameters ): \"\"\"Processes all parameters and do checks. Determine the kind of the parameter space. :param parameters: parameter dictionary :type param: dict :retun: processed parameter dictionary :rtype: dict \"\"\" # convert all parameter arrays into lists for key , value in parameters . items (): if isinstance ( value , np . ndarray ): assert len ( value . shape ) == 1 , f \"Parameter { key } is not one-dimensional.\" value = value . tolist () parameters [ key ] = value # auto detect the parameter kind if self . kind is None : for key , value in parameters . items (): # auto detect what kind of space we have # kind = \"point\" is a single point in parameter space, one value only # kind = \"bound\" is a bounded parameter space with 2 values: min and max # kind = \"grid\" is a grid space with as many values on each axis as wished parameterLengths = [ len ( value ) for key , value in parameters . items ()] # if all parameters have the same length if parameterLengths . count ( parameterLengths [ 0 ]) == len ( parameterLengths ): if parameterLengths [ 0 ] == 1 : self . kind = \"point\" elif parameterLengths [ 0 ] == 2 : self . kind = \"bound\" else : self . kind = \"grid\" # do some kind-specific tests if self . kind == \"bound\" : # check the boundaries self . _validate_param_bounds ( list ( parameters . values ())) # set all parameters as attributes for easy access for key , value in parameters . items (): setattr ( self , key , value ) return parameters def _parameterListsToDict ( self , keys , values ): parameters = {} assert len ( keys ) == len ( values ), \"Names and values of parameters are not same length.\" for key , value in zip ( keys , values ): parameters [ key ] = value return parameters lowerBound property readonly Returns lower bound of all parameters as a list ndims property readonly Number of dimensions (parameters) upperBound property readonly Returns upper bound of all parameters as a list __init__ ( self , parameters , parameterValues = None , kind = None , allow_star_notation = False ) special Initialize parameter space. Parameter space can be initialized in two ways: Either a parameters is a dictionary of the form {\"parName1\" : [0, 1, 2], \"parName2\" : [3, 4]} , or parameters is a list of names and parameterValues are values of each parameter. Parameters: Name Type Description Default parameters `dict, list[str, str]` parameter dictionary or list of names of parameters e.g. ['x', 'y'] required parameterValues `list[list[float, float]]` list of parameter values (must be floats) e.g. [[x_min, x_max], [y_min, y_max], ...] None kind str string describing the kind of parameter space: - point : a single point in parameter space - bound : a bound in parameter space, i.e. two values per parameter - grid : a cartesian product over parameters - sequence : a sequence of univariate parameter changes - only one will change at the time, other parameters will stay as default - explicit : explicitely define a parameter space, i.e lists of all parameters have to have the same length - None: parameterSpace tries to auto-detect the correct kind None allow_star_notation bool whether to allow star notation in parameter names - MultiModel False Source code in neurolib/utils/parameterSpace.py def __init__ ( self , parameters , parameterValues = None , kind = None , allow_star_notation = False ): \"\"\" Initialize parameter space. Parameter space can be initialized in two ways: Either a `parameters` is a dictionary of the form `{\"parName1\" : [0, 1, 2], \"parName2\" : [3, 4]}`, or `parameters` is a list of names and `parameterValues` are values of each parameter. :param parameters: parameter dictionary or list of names of parameters e.g. `['x', 'y']` :type parameters: `dict, list[str, str]` :param parameterValues: list of parameter values (must be floats) e.g. `[[x_min, x_max], [y_min, y_max], ...]` :type parameterValues: `list[list[float, float]]` :param kind: string describing the kind of parameter space: - `point`: a single point in parameter space - `bound`: a bound in parameter space, i.e. two values per parameter - `grid`: a cartesian product over parameters - `sequence`: a sequence of univariate parameter changes - only one will change at the time, other parameters will stay as default - `explicit`: explicitely define a parameter space, i.e lists of all parameters have to have the same length - None: parameterSpace tries to auto-detect the correct kind :type kind: str :param allow_star_notation: whether to allow star notation in parameter names - MultiModel :type allow_star_notation: bool \"\"\" assert kind in SUPPORTED_KINDS self . kind = kind self . parameters = parameters self . star = allow_star_notation # in case a parameter dictionary was given if parameterValues is None : assert isinstance ( parameters , dict ), \"Parameters must be a dict, if no values are given in `parameterValues`\" processedParameters = self . _processParameterDict ( parameters ) else : # check if all names are strings assert np . all ([ isinstance ( pn , str ) for pn in parameters ]), \"Parameter names must all be strings.\" # check if all parameter values are lists assert np . all ([ isinstance ( pv , ( list , tuple )) for pv in parameterValues ]), \"Parameter values must be a list.\" parameters = self . _parameterListsToDict ( parameters , parameterValues ) processedParameters = self . _processParameterDict ( parameters ) self . parameters = processedParameters self . parameterNames = list ( self . parameters . keys ()) self . parameterValues = list ( self . parameters . values ()) # let's create a named tuple of the parameters # Note: evolution.py implementation relies on named tuples self . named_tuple_constructor = namedtuple ( \"ParameterSpace\" , sanitize_dot_dict ( parameters )) self . named_tuple = self . named_tuple_constructor ( * self . parameterValues ) # set attributes of this class to make it accessible for i , p in enumerate ( self . parameters ): setattr ( self , p , self . parameterValues [ i ]) __str__ ( self ) special Print the named_tuple object Source code in neurolib/utils/parameterSpace.py def __str__ ( self ): \"\"\"Print the named_tuple object\"\"\" return str ( self . parameters ) dict ( self ) Returns the parameter space as a dicitonary of lists. Source code in neurolib/utils/parameterSpace.py def dict ( self ): \"\"\"Returns the parameter space as a dicitonary of lists. :rtype: dict \"\"\" return self . parameters getRandom ( self , safe = False ) This function returns a random single parameter from the whole space in the form of { \"par1\" : 1, \"par2\" : 2}. This function is used by neurolib/optimize/exploarion.py to add parameters of the space to pypet (for initialization) Parameters: Name Type Description Default safe Return a \"safe\" parameter or the original. Safe refers to returning python floats, not, for example numpy.float64 (necessary for pypet). ;type safe: bool False Source code in neurolib/utils/parameterSpace.py def getRandom ( self , safe = False ): \"\"\"This function returns a random single parameter from the whole space in the form of { \"par1\" : 1, \"par2\" : 2}. This function is used by neurolib/optimize/exploarion.py to add parameters of the space to pypet (for initialization) :param safe: Return a \"safe\" parameter or the original. Safe refers to returning python floats, not, for example numpy.float64 (necessary for pypet). ;type safe: bool \"\"\" randomPar = {} if safe : for key , value in self . parameters . items (): random_value = np . random . choice ( value ) if isinstance ( random_value , np . float64 ): random_value = float ( random_value ) elif isinstance ( random_value , np . int64 ): random_value = int ( random_value ) randomPar [ key ] = random_value else : for key , value in self . parameters . items (): randomPar [ key ] = np . random . choice ( value ) return randomPar","title":"ParameterSpace"},{"location":"utils/parameterspace/#parameterspace","text":"Parameter space Source code in neurolib/utils/parameterSpace.py class ParameterSpace : \"\"\" Parameter space \"\"\" def __init__ ( self , parameters , parameterValues = None , kind = None , allow_star_notation = False ): \"\"\" Initialize parameter space. Parameter space can be initialized in two ways: Either a `parameters` is a dictionary of the form `{\"parName1\" : [0, 1, 2], \"parName2\" : [3, 4]}`, or `parameters` is a list of names and `parameterValues` are values of each parameter. :param parameters: parameter dictionary or list of names of parameters e.g. `['x', 'y']` :type parameters: `dict, list[str, str]` :param parameterValues: list of parameter values (must be floats) e.g. `[[x_min, x_max], [y_min, y_max], ...]` :type parameterValues: `list[list[float, float]]` :param kind: string describing the kind of parameter space: - `point`: a single point in parameter space - `bound`: a bound in parameter space, i.e. two values per parameter - `grid`: a cartesian product over parameters - `sequence`: a sequence of univariate parameter changes - only one will change at the time, other parameters will stay as default - `explicit`: explicitely define a parameter space, i.e lists of all parameters have to have the same length - None: parameterSpace tries to auto-detect the correct kind :type kind: str :param allow_star_notation: whether to allow star notation in parameter names - MultiModel :type allow_star_notation: bool \"\"\" assert kind in SUPPORTED_KINDS self . kind = kind self . parameters = parameters self . star = allow_star_notation # in case a parameter dictionary was given if parameterValues is None : assert isinstance ( parameters , dict ), \"Parameters must be a dict, if no values are given in `parameterValues`\" processedParameters = self . _processParameterDict ( parameters ) else : # check if all names are strings assert np . all ([ isinstance ( pn , str ) for pn in parameters ]), \"Parameter names must all be strings.\" # check if all parameter values are lists assert np . all ([ isinstance ( pv , ( list , tuple )) for pv in parameterValues ]), \"Parameter values must be a list.\" parameters = self . _parameterListsToDict ( parameters , parameterValues ) processedParameters = self . _processParameterDict ( parameters ) self . parameters = processedParameters self . parameterNames = list ( self . parameters . keys ()) self . parameterValues = list ( self . parameters . values ()) # let's create a named tuple of the parameters # Note: evolution.py implementation relies on named tuples self . named_tuple_constructor = namedtuple ( \"ParameterSpace\" , sanitize_dot_dict ( parameters )) self . named_tuple = self . named_tuple_constructor ( * self . parameterValues ) # set attributes of this class to make it accessible for i , p in enumerate ( self . parameters ): setattr ( self , p , self . parameterValues [ i ]) def __str__ ( self ): \"\"\"Print the named_tuple object\"\"\" return str ( self . parameters ) def __getitem__ ( self , key ): return self . parameters [ key ] def __setitem__ ( self , key , value ): self . parameters [ key ] = value self . _processParameterDict ( self . parameters ) def dict ( self ): \"\"\"Returns the parameter space as a dicitonary of lists. :rtype: dict \"\"\" return self . parameters def get_parametrization ( self ): assert self . kind is not None if self . kind in [ \"point\" , \"bound\" , \"explicit\" ]: # check same length it = iter ( self . parameters . values ()) length = len ( next ( it )) assert all ( len ( l ) == length for l in it ) # just return as dict return self . parameters elif self . kind == \"grid\" : # cartesian product return pypet . cartesian_product ( self . parameters ) elif self . kind == \"sequence\" : # return as sequence return self . _inflate_to_sequence ( self . parameters ) @staticmethod def _inflate_to_sequence ( param_dict ): \"\"\" Inflate dict of parameters to a sequence of same length, using None as placeholder when a particular parameter should not change. {\"a\": [1, 2], \"b\": [3, 4, 5]} -> {\"a\": [1, 2, None, None, None], \"b\": [None, None, 3, 4, 5]} \"\"\" return { k : [ None ] * sum ([ len ( tmp ) for tmp in list ( param_dict . values ())[: i ]]) + v + [ None ] * sum ([ len ( tmp ) for tmp in list ( param_dict . values ())[ i + 1 :]]) for i , ( k , v ) in enumerate ( param_dict . items ()) } def getRandom ( self , safe = False ): \"\"\"This function returns a random single parameter from the whole space in the form of { \"par1\" : 1, \"par2\" : 2}. This function is used by neurolib/optimize/exploarion.py to add parameters of the space to pypet (for initialization) :param safe: Return a \"safe\" parameter or the original. Safe refers to returning python floats, not, for example numpy.float64 (necessary for pypet). ;type safe: bool \"\"\" randomPar = {} if safe : for key , value in self . parameters . items (): random_value = np . random . choice ( value ) if isinstance ( random_value , np . float64 ): random_value = float ( random_value ) elif isinstance ( random_value , np . int64 ): random_value = int ( random_value ) randomPar [ key ] = random_value else : for key , value in self . parameters . items (): randomPar [ key ] = np . random . choice ( value ) return randomPar @property def lowerBound ( self ): \"\"\"Returns lower bound of all parameters as a list\"\"\" return [ np . min ( p ) for p in self . parameterValues ] @property def upperBound ( self ): \"\"\"Returns upper bound of all parameters as a list\"\"\" return [ np . max ( p ) for p in self . parameterValues ] @property def ndims ( self ): \"\"\"Number of dimensions (parameters)\"\"\" return len ( self . parameters ) @staticmethod def _validate_single_bound ( single_bound ): \"\"\" Validate single bound. :param single_bound: single coordinate bound to validate :type single_bound: list|tuple \"\"\" assert isinstance ( single_bound , ( list , tuple ) ), \"An error occured while validating the ParameterSpace of kind 'bound': Pass parameter bounds as a list or tuple!\" assert ( len ( single_bound ) == 2 ), \"An error occured while validating the ParameterSpace of kind 'bound': Only two bounds (min and max) are allowed\" assert ( single_bound [ 1 ] > single_bound [ 0 ] ), \"An error occured while validating the ParameterSpace of kind 'bound': Minimum parameter value can't be larger than the maximum!\" def _validate_param_bounds ( self , param_bounds ): \"\"\" Validate param bounds. :param param_bounds: parameter bounds to validate :type param_bounds: list|None \"\"\" assert param_bounds is not None assert isinstance ( param_bounds , ( list , tuple )) # check every single parameter bound for single_bound in param_bounds : self . _validate_single_bound ( single_bound ) def _processParameterDict ( self , parameters ): \"\"\"Processes all parameters and do checks. Determine the kind of the parameter space. :param parameters: parameter dictionary :type param: dict :retun: processed parameter dictionary :rtype: dict \"\"\" # convert all parameter arrays into lists for key , value in parameters . items (): if isinstance ( value , np . ndarray ): assert len ( value . shape ) == 1 , f \"Parameter { key } is not one-dimensional.\" value = value . tolist () parameters [ key ] = value # auto detect the parameter kind if self . kind is None : for key , value in parameters . items (): # auto detect what kind of space we have # kind = \"point\" is a single point in parameter space, one value only # kind = \"bound\" is a bounded parameter space with 2 values: min and max # kind = \"grid\" is a grid space with as many values on each axis as wished parameterLengths = [ len ( value ) for key , value in parameters . items ()] # if all parameters have the same length if parameterLengths . count ( parameterLengths [ 0 ]) == len ( parameterLengths ): if parameterLengths [ 0 ] == 1 : self . kind = \"point\" elif parameterLengths [ 0 ] == 2 : self . kind = \"bound\" else : self . kind = \"grid\" # do some kind-specific tests if self . kind == \"bound\" : # check the boundaries self . _validate_param_bounds ( list ( parameters . values ())) # set all parameters as attributes for easy access for key , value in parameters . items (): setattr ( self , key , value ) return parameters def _parameterListsToDict ( self , keys , values ): parameters = {} assert len ( keys ) == len ( values ), \"Names and values of parameters are not same length.\" for key , value in zip ( keys , values ): parameters [ key ] = value return parameters","title":"ParameterSpace"},{"location":"utils/parameterspace/#neurolib.utils.parameterSpace.ParameterSpace.lowerBound","text":"Returns lower bound of all parameters as a list","title":"lowerBound"},{"location":"utils/parameterspace/#neurolib.utils.parameterSpace.ParameterSpace.ndims","text":"Number of dimensions (parameters)","title":"ndims"},{"location":"utils/parameterspace/#neurolib.utils.parameterSpace.ParameterSpace.upperBound","text":"Returns upper bound of all parameters as a list","title":"upperBound"},{"location":"utils/parameterspace/#neurolib.utils.parameterSpace.ParameterSpace.__init__","text":"Initialize parameter space. Parameter space can be initialized in two ways: Either a parameters is a dictionary of the form {\"parName1\" : [0, 1, 2], \"parName2\" : [3, 4]} , or parameters is a list of names and parameterValues are values of each parameter. Parameters: Name Type Description Default parameters `dict, list[str, str]` parameter dictionary or list of names of parameters e.g. ['x', 'y'] required parameterValues `list[list[float, float]]` list of parameter values (must be floats) e.g. [[x_min, x_max], [y_min, y_max], ...] None kind str string describing the kind of parameter space: - point : a single point in parameter space - bound : a bound in parameter space, i.e. two values per parameter - grid : a cartesian product over parameters - sequence : a sequence of univariate parameter changes - only one will change at the time, other parameters will stay as default - explicit : explicitely define a parameter space, i.e lists of all parameters have to have the same length - None: parameterSpace tries to auto-detect the correct kind None allow_star_notation bool whether to allow star notation in parameter names - MultiModel False Source code in neurolib/utils/parameterSpace.py def __init__ ( self , parameters , parameterValues = None , kind = None , allow_star_notation = False ): \"\"\" Initialize parameter space. Parameter space can be initialized in two ways: Either a `parameters` is a dictionary of the form `{\"parName1\" : [0, 1, 2], \"parName2\" : [3, 4]}`, or `parameters` is a list of names and `parameterValues` are values of each parameter. :param parameters: parameter dictionary or list of names of parameters e.g. `['x', 'y']` :type parameters: `dict, list[str, str]` :param parameterValues: list of parameter values (must be floats) e.g. `[[x_min, x_max], [y_min, y_max], ...]` :type parameterValues: `list[list[float, float]]` :param kind: string describing the kind of parameter space: - `point`: a single point in parameter space - `bound`: a bound in parameter space, i.e. two values per parameter - `grid`: a cartesian product over parameters - `sequence`: a sequence of univariate parameter changes - only one will change at the time, other parameters will stay as default - `explicit`: explicitely define a parameter space, i.e lists of all parameters have to have the same length - None: parameterSpace tries to auto-detect the correct kind :type kind: str :param allow_star_notation: whether to allow star notation in parameter names - MultiModel :type allow_star_notation: bool \"\"\" assert kind in SUPPORTED_KINDS self . kind = kind self . parameters = parameters self . star = allow_star_notation # in case a parameter dictionary was given if parameterValues is None : assert isinstance ( parameters , dict ), \"Parameters must be a dict, if no values are given in `parameterValues`\" processedParameters = self . _processParameterDict ( parameters ) else : # check if all names are strings assert np . all ([ isinstance ( pn , str ) for pn in parameters ]), \"Parameter names must all be strings.\" # check if all parameter values are lists assert np . all ([ isinstance ( pv , ( list , tuple )) for pv in parameterValues ]), \"Parameter values must be a list.\" parameters = self . _parameterListsToDict ( parameters , parameterValues ) processedParameters = self . _processParameterDict ( parameters ) self . parameters = processedParameters self . parameterNames = list ( self . parameters . keys ()) self . parameterValues = list ( self . parameters . values ()) # let's create a named tuple of the parameters # Note: evolution.py implementation relies on named tuples self . named_tuple_constructor = namedtuple ( \"ParameterSpace\" , sanitize_dot_dict ( parameters )) self . named_tuple = self . named_tuple_constructor ( * self . parameterValues ) # set attributes of this class to make it accessible for i , p in enumerate ( self . parameters ): setattr ( self , p , self . parameterValues [ i ])","title":"__init__()"},{"location":"utils/parameterspace/#neurolib.utils.parameterSpace.ParameterSpace.__str__","text":"Print the named_tuple object Source code in neurolib/utils/parameterSpace.py def __str__ ( self ): \"\"\"Print the named_tuple object\"\"\" return str ( self . parameters )","title":"__str__()"},{"location":"utils/parameterspace/#neurolib.utils.parameterSpace.ParameterSpace.dict","text":"Returns the parameter space as a dicitonary of lists. Source code in neurolib/utils/parameterSpace.py def dict ( self ): \"\"\"Returns the parameter space as a dicitonary of lists. :rtype: dict \"\"\" return self . parameters","title":"dict()"},{"location":"utils/parameterspace/#neurolib.utils.parameterSpace.ParameterSpace.getRandom","text":"This function returns a random single parameter from the whole space in the form of { \"par1\" : 1, \"par2\" : 2}. This function is used by neurolib/optimize/exploarion.py to add parameters of the space to pypet (for initialization) Parameters: Name Type Description Default safe Return a \"safe\" parameter or the original. Safe refers to returning python floats, not, for example numpy.float64 (necessary for pypet). ;type safe: bool False Source code in neurolib/utils/parameterSpace.py def getRandom ( self , safe = False ): \"\"\"This function returns a random single parameter from the whole space in the form of { \"par1\" : 1, \"par2\" : 2}. This function is used by neurolib/optimize/exploarion.py to add parameters of the space to pypet (for initialization) :param safe: Return a \"safe\" parameter or the original. Safe refers to returning python floats, not, for example numpy.float64 (necessary for pypet). ;type safe: bool \"\"\" randomPar = {} if safe : for key , value in self . parameters . items (): random_value = np . random . choice ( value ) if isinstance ( random_value , np . float64 ): random_value = float ( random_value ) elif isinstance ( random_value , np . int64 ): random_value = int ( random_value ) randomPar [ key ] = random_value else : for key , value in self . parameters . items (): randomPar [ key ] = np . random . choice ( value ) return randomPar","title":"getRandom()"},{"location":"utils/signal/","text":"Signal Source code in neurolib/utils/signal.py class Signal : name = \"\" label = \"\" signal_type = \"\" unit = \"\" description = \"\" _copy_attributes = [ \"name\" , \"label\" , \"signal_type\" , \"unit\" , \"description\" , \"process_steps\" , ] PROCESS_STEPS_KEY = \"process_steps\" @classmethod def from_model_output ( cls , model , group = \"\" , time_in_ms = True ): \"\"\" Initial Signal from modelling output. \"\"\" assert isinstance ( model , Model ) return cls ( model . xr ( group = group ), time_in_ms = time_in_ms ) @classmethod def from_file ( cls , filename ): \"\"\" Load signal from saved file. :param filename: filename for the Signal :type filename: str \"\"\" if not filename . endswith ( NC_EXT ): filename += NC_EXT # load NC file xarray = xr . load_dataarray ( filename ) # init class signal = cls ( xarray ) # if nc file has attributes, copy them to signal class if xarray . attrs : process_steps = [] for k , v in xarray . attrs . items (): if cls . PROCESS_STEPS_KEY in k : idx = int ( k [ len ( cls . PROCESS_STEPS_KEY ) + 1 :]) process_steps . insert ( idx , v ) else : setattr ( signal , k , v ) else : logging . warning ( \"No metadata found, setting empty...\" ) process_steps = [ f \"raw { signal . signal_type } signal: { signal . start_time } --\" f \" { signal . end_time } s\" ] setattr ( signal , cls . PROCESS_STEPS_KEY , process_steps ) return signal def __init__ ( self , data , time_in_ms = False ): \"\"\" :param data: data for the signal, assumes time dimension with time in seconds :type data: xr.DataArray :param time_in_ms: whether time dimension is in ms :type time_in_ms: bool \"\"\" assert isinstance ( data , xr . DataArray ) data = deepcopy ( data ) assert \"time\" in data . dims , \"DataArray must have time axis\" if time_in_ms : data [ \"time\" ] = data [ \"time\" ] / 1000.0 data [ \"time\" ] = np . around ( data [ \"time\" ], 6 ) self . data = data # assert time dimension is last self . data = self . data . transpose ( * ( self . dims_not_time + [ \"time\" ])) # compute dt and sampling frequency self . dt = np . around ( np . diff ( data . time ) . mean (), 6 ) self . sampling_frequency = 1.0 / self . dt self . process_steps = [ f \"raw { self . signal_type } signal: { self . start_time } -- { self . end_time } s\" ] def __str__ ( self ): \"\"\" String representation. \"\"\" return ( f \" { self . name } representing { self . signal_type } signal with unit of \" f \" { self . unit } with user-provided description: ` { self . description } `\" f \". Shape of the signal is { self . shape } with dimensions \" f \" { self . data . dims } . Signal starts at { self . start_time } and ends at \" f \" { self . end_time } .\" ) def __repr__ ( self ): \"\"\" Representation. \"\"\" return self . __str__ () def __eq__ ( self , other ): \"\"\" Comparison operator. :param other: other `Signal` to compare with :type other: `Signal` :return: whether two `Signals` are the same :rtype: bool \"\"\" assert isinstance ( other , Signal ) # assert data are the same try : xr . testing . assert_allclose ( self . data , other . data ) eq = True except AssertionError : eq = False # check attributes, but if not equal, only warn the user for attr in self . _copy_attributes : if getattr ( self , attr ) != getattr ( other , attr ): logging . warning ( f \"` { attr } ` not equal between signals.\" ) return eq def __getitem__ ( self , pos ): \"\"\" Get item selects in output dimension. \"\"\" add_steps = [ f \"select ` { pos } ` output\" ] return self . __constructor__ ( self . data . sel ( output = pos )) . __finalize__ ( self , add_steps ) def __finalize__ ( self , other , add_steps = None ): \"\"\" Copy attributes from other to self. Used when constructing class instance with different data, but same metadata. :param other: other instance of `Signal` :type other: `Signal` :param add_steps: add steps to preprocessing :type add_steps: list|None \"\"\" assert isinstance ( other , Signal ) for attr in self . _copy_attributes : setattr ( self , attr , deepcopy ( getattr ( other , attr ))) if add_steps is not None : self . process_steps += add_steps return self @property def __constructor__ ( self ): \"\"\" Return constructor, so that each child class would initiate a new instance of the correct class, i.e. first in the method resolution order. \"\"\" return self . __class__ . mro ()[ 0 ] def _write_attrs_to_xr ( self ): \"\"\" Copy attributes to xarray before saving. \"\"\" # write attributes to xarray for attr in self . _copy_attributes : value = getattr ( self , attr ) # if list need to unwrap if isinstance ( value , ( list , tuple )): for idx , val in enumerate ( value ): self . data . attrs [ f \" { attr } _ { idx } \" ] = val else : self . data . attrs [ attr ] = deepcopy ( value ) def save ( self , filename ): \"\"\" Save signal. :param filename: filename to save, currently saves to netCDF file, which is natively supported by xarray :type filename: str \"\"\" self . _write_attrs_to_xr () if not filename . endswith ( NC_EXT ): filename += NC_EXT self . data . to_netcdf ( filename ) def iterate ( self , return_as = \"signal\" ): \"\"\" Return iterator over columns, so univariate measures can be computed per column. Loops over tuples as (variable name, timeseries). :param return_as: how to return columns: `xr` as xr.DataArray, `signal` as instance of NeuroSignal with the same attributes as the mother signal :type return_as: str \"\"\" try : stacked = self . data . stack ({ \"all\" : self . dims_not_time }) except ValueError : logging . warning ( \"No dimensions along which to stack...\" ) stacked = self . data . expand_dims ( \"all\" ) if return_as == \"xr\" : yield from stacked . groupby ( \"all\" ) elif return_as == \"signal\" : for name_coords , column in stacked . groupby ( \"all\" ): if not isinstance ( name_coords , ( list , tuple )): name_coords = [ name_coords ] name_dict = { k : v for k , v in zip ( self . dims_not_time , name_coords )} yield name_dict , self . __constructor__ ( column ) . __finalize__ ( self , [ f \"select { column . name } \" ]) else : raise ValueError ( f \"Data type not understood: { return_as } \" ) def sel ( self , sel_args , inplace = True ): \"\"\" Subselect part of signal using xarray's `sel`, i.e. selecting by actual physical index, hence time in seconds. :param sel_args: arguments you'd give to xr.sel(), i.e. slice of times you want to select, in seconds as a len=2 list or tuple :type sel_args: tuple|list :param inplace: whether to do the operation in place or return :type inplace: bool \"\"\" assert len ( sel_args ) == 2 , \"Must provide 2 arguments\" selected = self . data . sel ( time = slice ( sel_args [ 0 ], sel_args [ 1 ])) add_steps = [ f \"select { sel_args [ 0 ] or 'x' } : { sel_args [ 1 ] or 'x' } s\" ] if inplace : self . data = selected self . process_steps += add_steps else : return self . __constructor__ ( selected ) . __finalize__ ( self , add_steps ) def isel ( self , isel_args , inplace = True ): \"\"\" Subselect part of signal using xarray's `isel`, i.e. selecting by index, hence integers. :param loc_args: arguments you'd give to xr.isel(), i.e. slice of indices you want to select, in seconds as a len=2 list or tuple :type loc_args: tuple|list :param inplace: whether to do the operation in place or return :type inplace: bool \"\"\" assert len ( isel_args ) == 2 , \"Must provide 2 arguments\" selected = self . data . isel ( time = slice ( isel_args [ 0 ], isel_args [ 1 ])) start = isel_args [ 0 ] * self . dt if isel_args [ 0 ] is not None else \"x\" end = isel_args [ 1 ] * self . dt if isel_args [ 1 ] is not None else \"x\" add_steps = [ f \"select { start } : { end } s\" ] if inplace : self . data = selected self . process_steps += add_steps else : return self . __constructor__ ( selected ) . __finalize__ ( self , add_steps ) def rolling ( self , roll_over , function = np . mean , dropnans = True , inplace = True ): \"\"\" Return rolling reduction over signal's time dimension. The window is centered around the midpoint. :param roll_over: window to use, in seconds :type roll_over: float :param function: function to use for reduction :type function: callable :param dropnans: whether to drop NaNs - will shorten time dimension, or not :type dropnans: bool :param inplace: whether to do the operation in place or return :type inplace: bool \"\"\" assert callable ( function ) rolling = self . data . rolling ( time = int ( roll_over * self . sampling_frequency ), center = True ) . reduce ( function ) add_steps = [ f \"rolling { function . __name__ } over { roll_over } s\" ] if dropnans : rolling = rolling . dropna ( \"time\" ) add_steps [ 0 ] += \"; drop NaNs\" if inplace : self . data = rolling self . process_steps += add_steps else : return self . __constructor__ ( rolling ) . __finalize__ ( self , add_steps ) def sliding_window ( self , length , step = 1 , window_function = \"boxcar\" , lengths_in_seconds = False ): \"\"\" Return iterator over sliding windows with windowing function applied. Each window has length `length` and each is translated by `step` steps. For no windowing function use \"boxcar\". If the last window would have the same length as other, it is omitted, i.e. last window does not have to end with the final timeseries point! :param length: length of the window, can be index or time in seconds, see `lengths_in_seconds` :type length: int|float :param step: how much to translate window in the temporal sense, can be index or time in seconds, see `lengths_in_seconds` :type step: int|float :param window_function: windowing function to use, this is passed to `get_window()`; see `scipy.signal.windows.get_window` documentation :type window_function: str|tuple|float :param lengths_in_seconds: if True, `length` and `step` are interpreted in seconds, if False they are indices :type lengths_in_seconds: bool :yield: generator with windowed Signals \"\"\" if lengths_in_seconds : length = int ( length / self . dt ) step = int ( step / self . dt ) assert ( length < self . data . time . shape [ 0 ] ), f \"Length must be smaller than time span of the timeseries: { self . data . time . shape [ 0 ] } \" assert step <= length , \"Step cannot be larger than length, some part of timeseries would be omitted!\" current_idx = 0 add_steps = f \" { str ( window_function ) } window: \" windowing_function = get_window ( window_function , Nx = length ) while current_idx <= ( self . data . time . shape [ 0 ] - length ): yield self . __constructor__ ( self . data . isel ( time = slice ( current_idx , current_idx + length )) * windowing_function ) . __finalize__ ( self , [ add_steps + f \" { current_idx } : { current_idx + length } \" ]) current_idx += step @property def shape ( self ): \"\"\" Return shape of the data. Time axis is the first one. \"\"\" return self . data . shape @property def dims_not_time ( self ): \"\"\" Return list of dimensions that are not time. \"\"\" return [ dim for dim in self . data . dims if dim != \"time\" ] @property def coords_not_time ( self ): \"\"\" Return dict with all coordinates except time. \"\"\" return { k : v . values for k , v in self . data . coords . items () if k != \"time\" } @property def start_time ( self ): \"\"\" Return starting time of the signal. \"\"\" return self . data . time . values [ 0 ] @property def end_time ( self ): \"\"\" Return ending time of the signal. \"\"\" return self . data . time . values [ - 1 ] @property def time ( self ): \"\"\" Return time vector. \"\"\" return self . data . time . values @property def preprocessing_steps ( self ): \"\"\" Return preprocessing steps done on the data. \"\"\" return \" -> \" . join ( self . process_steps ) def pad ( self , how_much , in_seconds = False , padding_type = \"constant\" , side = \"both\" , inplace = True , ** kwargs ): \"\"\" Pad signal by `how_much` on given side of given type. :param how_much: how much we should pad, can be time points, or seconds, see `in_seconds` :type how_much: float|int :param in_seconds: whether `how_much` is in seconds, if False, it is number of time points :type in_seconds: bool :param padding_type: how to pad the signal, see `np.pad` documentation :type padding_type: str :param side: which side to pad - \"before\", \"after\", or \"both\" :type side: str :param inplace: whether to do the operation in place or return :type inplace: bool :kwargs: passed to `np.pad` \"\"\" if in_seconds : how_much = int ( np . around ( how_much / self . dt )) if side == \"before\" : pad_width = ( how_much , 0 ) pad_times = np . arange ( - how_much , 0 ) * self . dt + self . data . time . values [ 0 ] new_times = np . concatenate ([ pad_times , self . data . time . values ], axis = 0 ) elif side == \"after\" : pad_width = ( 0 , how_much ) pad_times = np . arange ( 1 , how_much + 1 ) * self . dt + self . data . time . values [ - 1 ] new_times = np . concatenate ([ self . data . time . values , pad_times ], axis = 0 ) elif side == \"both\" : pad_width = ( how_much , how_much ) pad_before = np . arange ( - how_much , 0 ) * self . dt + self . data . time . values [ 0 ] pad_after = np . arange ( 1 , how_much + 1 ) * self . dt + self . data . time . values [ - 1 ] new_times = np . concatenate ([ pad_before , self . data . time . values , pad_after ], axis = 0 ) side += \" sides\" else : raise ValueError ( f \"Unknown padding side: { side } \" ) # add padding for other axes than time - zeroes pad_width = [( 0 , 0 )] * len ( self . dims_not_time ) + [ pad_width ] padded = np . pad ( self . data . values , pad_width , mode = padding_type , ** kwargs ) # to dataframe padded = xr . DataArray ( padded , dims = self . data . dims , coords = { ** self . coords_not_time , \"time\" : new_times }) add_steps = [ f \" { how_much * self . dt } s { padding_type } { side } padding\" ] if inplace : self . data = padded self . process_steps += add_steps else : return self . __constructor__ ( padded ) . __finalize__ ( self , add_steps ) def normalize ( self , std = False , inplace = True ): \"\"\" De-mean the timeseries. Optionally also standardise. :param std: normalize by std, i.e. to unit variance :type std: bool :param inplace: whether to do the operation in place or return :type inplace: bool \"\"\" def norm_func ( x , dim ): demeaned = x - x . mean ( dim = dim ) if std : return demeaned / x . std ( dim = dim ) else : return demeaned normalized = norm_func ( self . data , dim = \"time\" ) add_steps = [ \"normalize\" , \"standardize\" ] if std else [ \"normalize\" ] if inplace : self . data = normalized self . process_steps += add_steps else : return self . __constructor__ ( normalized ) . __finalize__ ( self , add_steps ) def resample ( self , to_frequency , inplace = True ): \"\"\" Resample signal to target frequency. :param to_frequency: target frequency of the signal, in Hz :type to_frequency: float :param inplace: whether to do the operation in place or return :type inplace: bool \"\"\" to_frequency = float ( to_frequency ) try : from mne.filter import resample resample_func = partial ( resample , up = to_frequency , down = self . sampling_frequency , npad = \"auto\" , axis =- 1 , pad = \"edge\" ) except ImportError : logging . warning ( \"`mne` module not found, falling back to basic scipy's function\" ) def resample_func ( x ): return scipy_resample ( x , num = int ( round (( to_frequency / self . sampling_frequency ) * self . data . shape [ - 1 ])), axis =- 1 , window = \"boxcar\" , ) resampled = resample_func ( self . data . values ) # construct new times new_times = ( np . arange ( resampled . shape [ - 1 ], dtype = np . float ) / to_frequency ) + self . data . time . values [ 0 ] # to dataframe resampled = xr . DataArray ( resampled , dims = self . data . dims , coords = { ** self . coords_not_time , \"time\" : new_times }) add_steps = [ f \"resample to { to_frequency } Hz\" ] if inplace : self . data = resampled self . sampling_frequency = to_frequency self . dt = np . around ( np . diff ( resampled . time ) . mean (), 6 ) self . process_steps += add_steps else : return self . __constructor__ ( resampled ) . __finalize__ ( self , add_steps ) def hilbert_transform ( self , return_as = \"complex\" , inplace = True ): \"\"\" Perform hilbert transform on the signal resulting in analytic signal. :param return_as: what to return `complex` will compute only analytical signal `amplitude` will compute amplitude, hence abs(H(x)) `phase_wrapped` will compute phase, hence angle(H(x)), in -pi,pi `phase_unwrapped` will compute phase in a continuous sense, hence monotonic :param inplace: whether to do the operation in place or return :type inplace: bool \"\"\" analytic = hilbert ( self . data , axis =- 1 ) if return_as == \"amplitude\" : analytic = np . abs ( analytic ) add_steps = [ \"Hilbert - amplitude\" ] elif return_as == \"phase_unwrapped\" : analytic = np . unwrap ( np . angle ( analytic )) add_steps = [ \"Hilbert - unwrapped phase\" ] elif return_as == \"phase_wrapped\" : analytic = np . angle ( analytic ) add_steps = [ \"Hilbert - wrapped phase\" ] elif return_as == \"complex\" : add_steps = [ \"Hilbert - complex\" ] else : raise ValueError ( f \"Do not know how to return: { return_as } \" ) analytic = xr . DataArray ( analytic , dims = self . data . dims , coords = self . data . coords ) if inplace : self . data = analytic self . process_steps += add_steps else : return self . __constructor__ ( analytic ) . __finalize__ ( self , add_steps ) def detrend ( self , segments = None , inplace = True ): \"\"\" Linearly detrend signal. If segments are given, detrending will be performed in each part. :param segments: segments for detrending, if None will detrend whole signal, given as indices of the time array :type segments: list|None :param inplace: whether to do the operation in place or return :type inplace: bool \"\"\" segments = segments or 0 detrended = detrend ( self . data , type = \"linear\" , bp = segments , axis =- 1 ) detrended = xr . DataArray ( detrended , dims = self . data . dims , coords = self . data . coords ) segments_text = f \" with segments: { segments } \" if segments != 0 else \"\" add_steps = [ f \"detrend { segments_text } \" ] if inplace : self . data = detrended self . process_steps += add_steps else : return self . __constructor__ ( detrended ) . __finalize__ ( self , add_steps ) def filter ( self , low_freq , high_freq , l_trans_bandwidth = \"auto\" , h_trans_bandwidth = \"auto\" , inplace = True , ** kwargs ): \"\"\" Filter data. Can be: low-pass (low_freq is None, high_freq is not None), high-pass (high_freq is None, low_freq is not None), band-pass (l_freq < h_freq), band-stop (l_freq > h_freq) filter type :param low_freq: frequency below which to filter the data :type low_freq: float|None :param high_freq: frequency above which to filter the data :type high_freq: float|None :param l_trans_bandwidth: transition band width for low frequency :type l_trans_bandwidth: float|str :param h_trans_bandwidth: transition band width for high frequency :type h_trans_bandwidth: float|str :param inplace: whether to do the operation in place or return :type inplace: bool :**kwargs: possible keywords to `mne.filter.create_filter`: `filter_length`=\"auto\", `method`=\"fir\", `iir_params`=None `phase`=\"zero\", `fir_window`=\"hamming\", `fir_design`=\"firwin\" \"\"\" try : from mne.filter import filter_data except ImportError : logging . warning ( \"`mne` module not found, falling back to basic scipy's function\" ) filter_data = scipy_iir_filter_data filtered = filter_data ( self . data . values , # times has to be the last axis sfreq = self . sampling_frequency , l_freq = low_freq , h_freq = high_freq , l_trans_bandwidth = l_trans_bandwidth , h_trans_bandwidth = h_trans_bandwidth , ** kwargs , ) add_steps = [ f \"filter: low { low_freq or 'x' } Hz - high { high_freq or 'x' } Hz\" ] # to dataframe filtered = xr . DataArray ( filtered , dims = self . data . dims , coords = self . data . coords ) if inplace : self . data = filtered self . process_steps += add_steps else : return self . __constructor__ ( filtered ) . __finalize__ ( self , add_steps ) def functional_connectivity ( self , fc_function = np . corrcoef ): \"\"\" Compute and return functional connectivity from the data. :param fc_function: function which to use for FC computation, should take 2D array as space x time and convert it to space x space with desired measure \"\"\" if len ( self . data [ \"space\" ]) <= 1 : logging . error ( \"Cannot compute functional connectivity from one timeseries.\" ) return None if self . data . ndim == 3 : assert callable ( fc_function ) fcs = [] for output in self . data [ \"output\" ]: current_slice = self . data . sel ({ \"output\" : output }) assert current_slice . ndim == 2 fcs . append ( fc_function ( current_slice . values )) return xr . DataArray ( np . array ( fcs ), dims = [ \"output\" , \"space\" , \"space\" ], coords = { \"output\" : self . data . coords [ \"output\" ], \"space\" : self . data . coords [ \"space\" ]}, ) if self . data . ndim == 2 : return xr . DataArray ( fc_function ( self . data . values ), dims = [ \"space\" , \"space\" ], coords = { \"space\" : self . data . coords [ \"space\" ]}, ) def apply ( self , func , inplace = True ): \"\"\" Apply func for each timeseries. :param func: function to be applied for each 1D timeseries :type func: callable :param inplace: whether to do the operation in place or return :type inplace: bool \"\"\" assert callable ( func ) try : # this will work for element-wise function that does not reduces dimensions processed = xr . apply_ufunc ( func , self . data , input_core_dims = [[ \"time\" ]], output_core_dims = [[ \"time\" ]]) add_steps = [ f \"apply ` { func . __name__ } ` function over time dim\" ] if inplace : self . data = processed self . process_steps += add_steps else : return self . __constructor__ ( processed ) . __finalize__ ( self , add_steps ) except ValueError : # this works for functions that reduce time dimension processed = xr . apply_ufunc ( func , self . data , input_core_dims = [[ \"time\" ]]) logging . warning ( f \"Shape changed after operation! Old shape: { self . shape } , new \" f \"shape: { processed . shape } ; Cannot cast to Signal class, \" \"returing as `xr.DataArray`\" ) return processed __constructor__ property readonly special Return constructor, so that each child class would initiate a new instance of the correct class, i.e. first in the method resolution order. coords_not_time property readonly Return dict with all coordinates except time. dims_not_time property readonly Return list of dimensions that are not time. end_time property readonly Return ending time of the signal. preprocessing_steps property readonly Return preprocessing steps done on the data. shape property readonly Return shape of the data. Time axis is the first one. start_time property readonly Return starting time of the signal. time property readonly Return time vector. __eq__ ( self , other ) special Comparison operator. Parameters: Name Type Description Default other `Signal` other Signal to compare with required Returns: Type Description bool whether two Signals are the same Source code in neurolib/utils/signal.py def __eq__ ( self , other ): \"\"\" Comparison operator. :param other: other `Signal` to compare with :type other: `Signal` :return: whether two `Signals` are the same :rtype: bool \"\"\" assert isinstance ( other , Signal ) # assert data are the same try : xr . testing . assert_allclose ( self . data , other . data ) eq = True except AssertionError : eq = False # check attributes, but if not equal, only warn the user for attr in self . _copy_attributes : if getattr ( self , attr ) != getattr ( other , attr ): logging . warning ( f \"` { attr } ` not equal between signals.\" ) return eq __finalize__ ( self , other , add_steps = None ) special Copy attributes from other to self. Used when constructing class instance with different data, but same metadata. Parameters: Name Type Description Default other `Signal` other instance of Signal required add_steps list|None add steps to preprocessing None Source code in neurolib/utils/signal.py def __finalize__ ( self , other , add_steps = None ): \"\"\" Copy attributes from other to self. Used when constructing class instance with different data, but same metadata. :param other: other instance of `Signal` :type other: `Signal` :param add_steps: add steps to preprocessing :type add_steps: list|None \"\"\" assert isinstance ( other , Signal ) for attr in self . _copy_attributes : setattr ( self , attr , deepcopy ( getattr ( other , attr ))) if add_steps is not None : self . process_steps += add_steps return self __getitem__ ( self , pos ) special Get item selects in output dimension. Source code in neurolib/utils/signal.py def __getitem__ ( self , pos ): \"\"\" Get item selects in output dimension. \"\"\" add_steps = [ f \"select ` { pos } ` output\" ] return self . __constructor__ ( self . data . sel ( output = pos )) . __finalize__ ( self , add_steps ) __init__ ( self , data , time_in_ms = False ) special Parameters: Name Type Description Default data xr.DataArray data for the signal, assumes time dimension with time in seconds required time_in_ms bool whether time dimension is in ms False Source code in neurolib/utils/signal.py def __init__ ( self , data , time_in_ms = False ): \"\"\" :param data: data for the signal, assumes time dimension with time in seconds :type data: xr.DataArray :param time_in_ms: whether time dimension is in ms :type time_in_ms: bool \"\"\" assert isinstance ( data , xr . DataArray ) data = deepcopy ( data ) assert \"time\" in data . dims , \"DataArray must have time axis\" if time_in_ms : data [ \"time\" ] = data [ \"time\" ] / 1000.0 data [ \"time\" ] = np . around ( data [ \"time\" ], 6 ) self . data = data # assert time dimension is last self . data = self . data . transpose ( * ( self . dims_not_time + [ \"time\" ])) # compute dt and sampling frequency self . dt = np . around ( np . diff ( data . time ) . mean (), 6 ) self . sampling_frequency = 1.0 / self . dt self . process_steps = [ f \"raw { self . signal_type } signal: { self . start_time } -- { self . end_time } s\" ] __repr__ ( self ) special Representation. Source code in neurolib/utils/signal.py def __repr__ ( self ): \"\"\" Representation. \"\"\" return self . __str__ () __str__ ( self ) special String representation. Source code in neurolib/utils/signal.py def __str__ ( self ): \"\"\" String representation. \"\"\" return ( f \" { self . name } representing { self . signal_type } signal with unit of \" f \" { self . unit } with user-provided description: ` { self . description } `\" f \". Shape of the signal is { self . shape } with dimensions \" f \" { self . data . dims } . Signal starts at { self . start_time } and ends at \" f \" { self . end_time } .\" ) apply ( self , func , inplace = True ) Apply func for each timeseries. Parameters: Name Type Description Default func callable function to be applied for each 1D timeseries required inplace bool whether to do the operation in place or return True Source code in neurolib/utils/signal.py def apply ( self , func , inplace = True ): \"\"\" Apply func for each timeseries. :param func: function to be applied for each 1D timeseries :type func: callable :param inplace: whether to do the operation in place or return :type inplace: bool \"\"\" assert callable ( func ) try : # this will work for element-wise function that does not reduces dimensions processed = xr . apply_ufunc ( func , self . data , input_core_dims = [[ \"time\" ]], output_core_dims = [[ \"time\" ]]) add_steps = [ f \"apply ` { func . __name__ } ` function over time dim\" ] if inplace : self . data = processed self . process_steps += add_steps else : return self . __constructor__ ( processed ) . __finalize__ ( self , add_steps ) except ValueError : # this works for functions that reduce time dimension processed = xr . apply_ufunc ( func , self . data , input_core_dims = [[ \"time\" ]]) logging . warning ( f \"Shape changed after operation! Old shape: { self . shape } , new \" f \"shape: { processed . shape } ; Cannot cast to Signal class, \" \"returing as `xr.DataArray`\" ) return processed detrend ( self , segments = None , inplace = True ) Linearly detrend signal. If segments are given, detrending will be performed in each part. Parameters: Name Type Description Default segments list|None segments for detrending, if None will detrend whole signal, given as indices of the time array None inplace bool whether to do the operation in place or return True Source code in neurolib/utils/signal.py def detrend ( self , segments = None , inplace = True ): \"\"\" Linearly detrend signal. If segments are given, detrending will be performed in each part. :param segments: segments for detrending, if None will detrend whole signal, given as indices of the time array :type segments: list|None :param inplace: whether to do the operation in place or return :type inplace: bool \"\"\" segments = segments or 0 detrended = detrend ( self . data , type = \"linear\" , bp = segments , axis =- 1 ) detrended = xr . DataArray ( detrended , dims = self . data . dims , coords = self . data . coords ) segments_text = f \" with segments: { segments } \" if segments != 0 else \"\" add_steps = [ f \"detrend { segments_text } \" ] if inplace : self . data = detrended self . process_steps += add_steps else : return self . __constructor__ ( detrended ) . __finalize__ ( self , add_steps ) filter ( self , low_freq , high_freq , l_trans_bandwidth = 'auto' , h_trans_bandwidth = 'auto' , inplace = True , ** kwargs ) Filter data. Can be: low-pass (low_freq is None, high_freq is not None), high-pass (high_freq is None, low_freq is not None), band-pass (l_freq < h_freq), band-stop (l_freq > h_freq) filter type :**kwargs: possible keywords to mne.filter.create_filter : filter_length =\"auto\", method =\"fir\", iir_params =None phase =\"zero\", fir_window =\"hamming\", fir_design =\"firwin\" Parameters: Name Type Description Default low_freq float|None frequency below which to filter the data required high_freq float|None frequency above which to filter the data required l_trans_bandwidth float|str transition band width for low frequency 'auto' h_trans_bandwidth float|str transition band width for high frequency 'auto' inplace bool whether to do the operation in place or return True Source code in neurolib/utils/signal.py def filter ( self , low_freq , high_freq , l_trans_bandwidth = \"auto\" , h_trans_bandwidth = \"auto\" , inplace = True , ** kwargs ): \"\"\" Filter data. Can be: low-pass (low_freq is None, high_freq is not None), high-pass (high_freq is None, low_freq is not None), band-pass (l_freq < h_freq), band-stop (l_freq > h_freq) filter type :param low_freq: frequency below which to filter the data :type low_freq: float|None :param high_freq: frequency above which to filter the data :type high_freq: float|None :param l_trans_bandwidth: transition band width for low frequency :type l_trans_bandwidth: float|str :param h_trans_bandwidth: transition band width for high frequency :type h_trans_bandwidth: float|str :param inplace: whether to do the operation in place or return :type inplace: bool :**kwargs: possible keywords to `mne.filter.create_filter`: `filter_length`=\"auto\", `method`=\"fir\", `iir_params`=None `phase`=\"zero\", `fir_window`=\"hamming\", `fir_design`=\"firwin\" \"\"\" try : from mne.filter import filter_data except ImportError : logging . warning ( \"`mne` module not found, falling back to basic scipy's function\" ) filter_data = scipy_iir_filter_data filtered = filter_data ( self . data . values , # times has to be the last axis sfreq = self . sampling_frequency , l_freq = low_freq , h_freq = high_freq , l_trans_bandwidth = l_trans_bandwidth , h_trans_bandwidth = h_trans_bandwidth , ** kwargs , ) add_steps = [ f \"filter: low { low_freq or 'x' } Hz - high { high_freq or 'x' } Hz\" ] # to dataframe filtered = xr . DataArray ( filtered , dims = self . data . dims , coords = self . data . coords ) if inplace : self . data = filtered self . process_steps += add_steps else : return self . __constructor__ ( filtered ) . __finalize__ ( self , add_steps ) from_file ( filename ) classmethod Load signal from saved file. Parameters: Name Type Description Default filename str filename for the Signal required Source code in neurolib/utils/signal.py @classmethod def from_file ( cls , filename ): \"\"\" Load signal from saved file. :param filename: filename for the Signal :type filename: str \"\"\" if not filename . endswith ( NC_EXT ): filename += NC_EXT # load NC file xarray = xr . load_dataarray ( filename ) # init class signal = cls ( xarray ) # if nc file has attributes, copy them to signal class if xarray . attrs : process_steps = [] for k , v in xarray . attrs . items (): if cls . PROCESS_STEPS_KEY in k : idx = int ( k [ len ( cls . PROCESS_STEPS_KEY ) + 1 :]) process_steps . insert ( idx , v ) else : setattr ( signal , k , v ) else : logging . warning ( \"No metadata found, setting empty...\" ) process_steps = [ f \"raw { signal . signal_type } signal: { signal . start_time } --\" f \" { signal . end_time } s\" ] setattr ( signal , cls . PROCESS_STEPS_KEY , process_steps ) return signal from_model_output ( model , group = '' , time_in_ms = True ) classmethod Initial Signal from modelling output. Source code in neurolib/utils/signal.py @classmethod def from_model_output ( cls , model , group = \"\" , time_in_ms = True ): \"\"\" Initial Signal from modelling output. \"\"\" assert isinstance ( model , Model ) return cls ( model . xr ( group = group ), time_in_ms = time_in_ms ) functional_connectivity ( self , fc_function =< function corrcoef at 0x7f13510dce60 > ) Compute and return functional connectivity from the data. Parameters: Name Type Description Default fc_function function which to use for FC computation, should take 2D array as space x time and convert it to space x space with desired measure <function corrcoef at 0x7f13510dce60> Source code in neurolib/utils/signal.py def functional_connectivity ( self , fc_function = np . corrcoef ): \"\"\" Compute and return functional connectivity from the data. :param fc_function: function which to use for FC computation, should take 2D array as space x time and convert it to space x space with desired measure \"\"\" if len ( self . data [ \"space\" ]) <= 1 : logging . error ( \"Cannot compute functional connectivity from one timeseries.\" ) return None if self . data . ndim == 3 : assert callable ( fc_function ) fcs = [] for output in self . data [ \"output\" ]: current_slice = self . data . sel ({ \"output\" : output }) assert current_slice . ndim == 2 fcs . append ( fc_function ( current_slice . values )) return xr . DataArray ( np . array ( fcs ), dims = [ \"output\" , \"space\" , \"space\" ], coords = { \"output\" : self . data . coords [ \"output\" ], \"space\" : self . data . coords [ \"space\" ]}, ) if self . data . ndim == 2 : return xr . DataArray ( fc_function ( self . data . values ), dims = [ \"space\" , \"space\" ], coords = { \"space\" : self . data . coords [ \"space\" ]}, ) hilbert_transform ( self , return_as = 'complex' , inplace = True ) Perform hilbert transform on the signal resulting in analytic signal. Parameters: Name Type Description Default return_as what to return complex will compute only analytical signal amplitude will compute amplitude, hence abs(H(x)) phase_wrapped will compute phase, hence angle(H(x)), in -pi,pi phase_unwrapped will compute phase in a continuous sense, hence monotonic 'complex' inplace bool whether to do the operation in place or return True Source code in neurolib/utils/signal.py def hilbert_transform ( self , return_as = \"complex\" , inplace = True ): \"\"\" Perform hilbert transform on the signal resulting in analytic signal. :param return_as: what to return `complex` will compute only analytical signal `amplitude` will compute amplitude, hence abs(H(x)) `phase_wrapped` will compute phase, hence angle(H(x)), in -pi,pi `phase_unwrapped` will compute phase in a continuous sense, hence monotonic :param inplace: whether to do the operation in place or return :type inplace: bool \"\"\" analytic = hilbert ( self . data , axis =- 1 ) if return_as == \"amplitude\" : analytic = np . abs ( analytic ) add_steps = [ \"Hilbert - amplitude\" ] elif return_as == \"phase_unwrapped\" : analytic = np . unwrap ( np . angle ( analytic )) add_steps = [ \"Hilbert - unwrapped phase\" ] elif return_as == \"phase_wrapped\" : analytic = np . angle ( analytic ) add_steps = [ \"Hilbert - wrapped phase\" ] elif return_as == \"complex\" : add_steps = [ \"Hilbert - complex\" ] else : raise ValueError ( f \"Do not know how to return: { return_as } \" ) analytic = xr . DataArray ( analytic , dims = self . data . dims , coords = self . data . coords ) if inplace : self . data = analytic self . process_steps += add_steps else : return self . __constructor__ ( analytic ) . __finalize__ ( self , add_steps ) isel ( self , isel_args , inplace = True ) Subselect part of signal using xarray's isel , i.e. selecting by index, hence integers. Parameters: Name Type Description Default loc_args tuple|list arguments you'd give to xr.isel(), i.e. slice of indices you want to select, in seconds as a len=2 list or tuple required inplace bool whether to do the operation in place or return True Source code in neurolib/utils/signal.py def isel ( self , isel_args , inplace = True ): \"\"\" Subselect part of signal using xarray's `isel`, i.e. selecting by index, hence integers. :param loc_args: arguments you'd give to xr.isel(), i.e. slice of indices you want to select, in seconds as a len=2 list or tuple :type loc_args: tuple|list :param inplace: whether to do the operation in place or return :type inplace: bool \"\"\" assert len ( isel_args ) == 2 , \"Must provide 2 arguments\" selected = self . data . isel ( time = slice ( isel_args [ 0 ], isel_args [ 1 ])) start = isel_args [ 0 ] * self . dt if isel_args [ 0 ] is not None else \"x\" end = isel_args [ 1 ] * self . dt if isel_args [ 1 ] is not None else \"x\" add_steps = [ f \"select { start } : { end } s\" ] if inplace : self . data = selected self . process_steps += add_steps else : return self . __constructor__ ( selected ) . __finalize__ ( self , add_steps ) iterate ( self , return_as = 'signal' ) Return iterator over columns, so univariate measures can be computed per column. Loops over tuples as (variable name, timeseries). Parameters: Name Type Description Default return_as str how to return columns: xr as xr.DataArray, signal as instance of NeuroSignal with the same attributes as the mother signal 'signal' Source code in neurolib/utils/signal.py def iterate ( self , return_as = \"signal\" ): \"\"\" Return iterator over columns, so univariate measures can be computed per column. Loops over tuples as (variable name, timeseries). :param return_as: how to return columns: `xr` as xr.DataArray, `signal` as instance of NeuroSignal with the same attributes as the mother signal :type return_as: str \"\"\" try : stacked = self . data . stack ({ \"all\" : self . dims_not_time }) except ValueError : logging . warning ( \"No dimensions along which to stack...\" ) stacked = self . data . expand_dims ( \"all\" ) if return_as == \"xr\" : yield from stacked . groupby ( \"all\" ) elif return_as == \"signal\" : for name_coords , column in stacked . groupby ( \"all\" ): if not isinstance ( name_coords , ( list , tuple )): name_coords = [ name_coords ] name_dict = { k : v for k , v in zip ( self . dims_not_time , name_coords )} yield name_dict , self . __constructor__ ( column ) . __finalize__ ( self , [ f \"select { column . name } \" ]) else : raise ValueError ( f \"Data type not understood: { return_as } \" ) normalize ( self , std = False , inplace = True ) De-mean the timeseries. Optionally also standardise. Parameters: Name Type Description Default std bool normalize by std, i.e. to unit variance False inplace bool whether to do the operation in place or return True Source code in neurolib/utils/signal.py def normalize ( self , std = False , inplace = True ): \"\"\" De-mean the timeseries. Optionally also standardise. :param std: normalize by std, i.e. to unit variance :type std: bool :param inplace: whether to do the operation in place or return :type inplace: bool \"\"\" def norm_func ( x , dim ): demeaned = x - x . mean ( dim = dim ) if std : return demeaned / x . std ( dim = dim ) else : return demeaned normalized = norm_func ( self . data , dim = \"time\" ) add_steps = [ \"normalize\" , \"standardize\" ] if std else [ \"normalize\" ] if inplace : self . data = normalized self . process_steps += add_steps else : return self . __constructor__ ( normalized ) . __finalize__ ( self , add_steps ) pad ( self , how_much , in_seconds = False , padding_type = 'constant' , side = 'both' , inplace = True , ** kwargs ) Pad signal by how_much on given side of given type. :kwargs: passed to np.pad Parameters: Name Type Description Default how_much float|int how much we should pad, can be time points, or seconds, see in_seconds required in_seconds bool whether how_much is in seconds, if False, it is number of time points False padding_type str how to pad the signal, see np.pad documentation 'constant' side str which side to pad - \"before\", \"after\", or \"both\" 'both' inplace bool whether to do the operation in place or return True Source code in neurolib/utils/signal.py def pad ( self , how_much , in_seconds = False , padding_type = \"constant\" , side = \"both\" , inplace = True , ** kwargs ): \"\"\" Pad signal by `how_much` on given side of given type. :param how_much: how much we should pad, can be time points, or seconds, see `in_seconds` :type how_much: float|int :param in_seconds: whether `how_much` is in seconds, if False, it is number of time points :type in_seconds: bool :param padding_type: how to pad the signal, see `np.pad` documentation :type padding_type: str :param side: which side to pad - \"before\", \"after\", or \"both\" :type side: str :param inplace: whether to do the operation in place or return :type inplace: bool :kwargs: passed to `np.pad` \"\"\" if in_seconds : how_much = int ( np . around ( how_much / self . dt )) if side == \"before\" : pad_width = ( how_much , 0 ) pad_times = np . arange ( - how_much , 0 ) * self . dt + self . data . time . values [ 0 ] new_times = np . concatenate ([ pad_times , self . data . time . values ], axis = 0 ) elif side == \"after\" : pad_width = ( 0 , how_much ) pad_times = np . arange ( 1 , how_much + 1 ) * self . dt + self . data . time . values [ - 1 ] new_times = np . concatenate ([ self . data . time . values , pad_times ], axis = 0 ) elif side == \"both\" : pad_width = ( how_much , how_much ) pad_before = np . arange ( - how_much , 0 ) * self . dt + self . data . time . values [ 0 ] pad_after = np . arange ( 1 , how_much + 1 ) * self . dt + self . data . time . values [ - 1 ] new_times = np . concatenate ([ pad_before , self . data . time . values , pad_after ], axis = 0 ) side += \" sides\" else : raise ValueError ( f \"Unknown padding side: { side } \" ) # add padding for other axes than time - zeroes pad_width = [( 0 , 0 )] * len ( self . dims_not_time ) + [ pad_width ] padded = np . pad ( self . data . values , pad_width , mode = padding_type , ** kwargs ) # to dataframe padded = xr . DataArray ( padded , dims = self . data . dims , coords = { ** self . coords_not_time , \"time\" : new_times }) add_steps = [ f \" { how_much * self . dt } s { padding_type } { side } padding\" ] if inplace : self . data = padded self . process_steps += add_steps else : return self . __constructor__ ( padded ) . __finalize__ ( self , add_steps ) resample ( self , to_frequency , inplace = True ) Resample signal to target frequency. Parameters: Name Type Description Default to_frequency float target frequency of the signal, in Hz required inplace bool whether to do the operation in place or return True Source code in neurolib/utils/signal.py def resample ( self , to_frequency , inplace = True ): \"\"\" Resample signal to target frequency. :param to_frequency: target frequency of the signal, in Hz :type to_frequency: float :param inplace: whether to do the operation in place or return :type inplace: bool \"\"\" to_frequency = float ( to_frequency ) try : from mne.filter import resample resample_func = partial ( resample , up = to_frequency , down = self . sampling_frequency , npad = \"auto\" , axis =- 1 , pad = \"edge\" ) except ImportError : logging . warning ( \"`mne` module not found, falling back to basic scipy's function\" ) def resample_func ( x ): return scipy_resample ( x , num = int ( round (( to_frequency / self . sampling_frequency ) * self . data . shape [ - 1 ])), axis =- 1 , window = \"boxcar\" , ) resampled = resample_func ( self . data . values ) # construct new times new_times = ( np . arange ( resampled . shape [ - 1 ], dtype = np . float ) / to_frequency ) + self . data . time . values [ 0 ] # to dataframe resampled = xr . DataArray ( resampled , dims = self . data . dims , coords = { ** self . coords_not_time , \"time\" : new_times }) add_steps = [ f \"resample to { to_frequency } Hz\" ] if inplace : self . data = resampled self . sampling_frequency = to_frequency self . dt = np . around ( np . diff ( resampled . time ) . mean (), 6 ) self . process_steps += add_steps else : return self . __constructor__ ( resampled ) . __finalize__ ( self , add_steps ) rolling ( self , roll_over , function =< function mean at 0x7f1351848290 > , dropnans = True , inplace = True ) Return rolling reduction over signal's time dimension. The window is centered around the midpoint. Parameters: Name Type Description Default roll_over float window to use, in seconds required function callable function to use for reduction <function mean at 0x7f1351848290> dropnans bool whether to drop NaNs - will shorten time dimension, or not True inplace bool whether to do the operation in place or return True Source code in neurolib/utils/signal.py def rolling ( self , roll_over , function = np . mean , dropnans = True , inplace = True ): \"\"\" Return rolling reduction over signal's time dimension. The window is centered around the midpoint. :param roll_over: window to use, in seconds :type roll_over: float :param function: function to use for reduction :type function: callable :param dropnans: whether to drop NaNs - will shorten time dimension, or not :type dropnans: bool :param inplace: whether to do the operation in place or return :type inplace: bool \"\"\" assert callable ( function ) rolling = self . data . rolling ( time = int ( roll_over * self . sampling_frequency ), center = True ) . reduce ( function ) add_steps = [ f \"rolling { function . __name__ } over { roll_over } s\" ] if dropnans : rolling = rolling . dropna ( \"time\" ) add_steps [ 0 ] += \"; drop NaNs\" if inplace : self . data = rolling self . process_steps += add_steps else : return self . __constructor__ ( rolling ) . __finalize__ ( self , add_steps ) save ( self , filename ) Save signal. Parameters: Name Type Description Default filename str filename to save, currently saves to netCDF file, which is natively supported by xarray required Source code in neurolib/utils/signal.py def save ( self , filename ): \"\"\" Save signal. :param filename: filename to save, currently saves to netCDF file, which is natively supported by xarray :type filename: str \"\"\" self . _write_attrs_to_xr () if not filename . endswith ( NC_EXT ): filename += NC_EXT self . data . to_netcdf ( filename ) sel ( self , sel_args , inplace = True ) Subselect part of signal using xarray's sel , i.e. selecting by actual physical index, hence time in seconds. Parameters: Name Type Description Default sel_args tuple|list arguments you'd give to xr.sel(), i.e. slice of times you want to select, in seconds as a len=2 list or tuple required inplace bool whether to do the operation in place or return True Source code in neurolib/utils/signal.py def sel ( self , sel_args , inplace = True ): \"\"\" Subselect part of signal using xarray's `sel`, i.e. selecting by actual physical index, hence time in seconds. :param sel_args: arguments you'd give to xr.sel(), i.e. slice of times you want to select, in seconds as a len=2 list or tuple :type sel_args: tuple|list :param inplace: whether to do the operation in place or return :type inplace: bool \"\"\" assert len ( sel_args ) == 2 , \"Must provide 2 arguments\" selected = self . data . sel ( time = slice ( sel_args [ 0 ], sel_args [ 1 ])) add_steps = [ f \"select { sel_args [ 0 ] or 'x' } : { sel_args [ 1 ] or 'x' } s\" ] if inplace : self . data = selected self . process_steps += add_steps else : return self . __constructor__ ( selected ) . __finalize__ ( self , add_steps ) sliding_window ( self , length , step = 1 , window_function = 'boxcar' , lengths_in_seconds = False ) Return iterator over sliding windows with windowing function applied. Each window has length length and each is translated by step steps. For no windowing function use \"boxcar\". If the last window would have the same length as other, it is omitted, i.e. last window does not have to end with the final timeseries point! :yield: generator with windowed Signals Parameters: Name Type Description Default length int|float length of the window, can be index or time in seconds, see lengths_in_seconds required step int|float how much to translate window in the temporal sense, can be index or time in seconds, see lengths_in_seconds 1 window_function str|tuple|float windowing function to use, this is passed to get_window() ; see scipy.signal.windows.get_window documentation 'boxcar' lengths_in_seconds bool if True, length and step are interpreted in seconds, if False they are indices False Source code in neurolib/utils/signal.py def sliding_window ( self , length , step = 1 , window_function = \"boxcar\" , lengths_in_seconds = False ): \"\"\" Return iterator over sliding windows with windowing function applied. Each window has length `length` and each is translated by `step` steps. For no windowing function use \"boxcar\". If the last window would have the same length as other, it is omitted, i.e. last window does not have to end with the final timeseries point! :param length: length of the window, can be index or time in seconds, see `lengths_in_seconds` :type length: int|float :param step: how much to translate window in the temporal sense, can be index or time in seconds, see `lengths_in_seconds` :type step: int|float :param window_function: windowing function to use, this is passed to `get_window()`; see `scipy.signal.windows.get_window` documentation :type window_function: str|tuple|float :param lengths_in_seconds: if True, `length` and `step` are interpreted in seconds, if False they are indices :type lengths_in_seconds: bool :yield: generator with windowed Signals \"\"\" if lengths_in_seconds : length = int ( length / self . dt ) step = int ( step / self . dt ) assert ( length < self . data . time . shape [ 0 ] ), f \"Length must be smaller than time span of the timeseries: { self . data . time . shape [ 0 ] } \" assert step <= length , \"Step cannot be larger than length, some part of timeseries would be omitted!\" current_idx = 0 add_steps = f \" { str ( window_function ) } window: \" windowing_function = get_window ( window_function , Nx = length ) while current_idx <= ( self . data . time . shape [ 0 ] - length ): yield self . __constructor__ ( self . data . isel ( time = slice ( current_idx , current_idx + length )) * windowing_function ) . __finalize__ ( self , [ add_steps + f \" { current_idx } : { current_idx + length } \" ]) current_idx += step","title":"Signal"},{"location":"utils/signal/#signal","text":"Source code in neurolib/utils/signal.py class Signal : name = \"\" label = \"\" signal_type = \"\" unit = \"\" description = \"\" _copy_attributes = [ \"name\" , \"label\" , \"signal_type\" , \"unit\" , \"description\" , \"process_steps\" , ] PROCESS_STEPS_KEY = \"process_steps\" @classmethod def from_model_output ( cls , model , group = \"\" , time_in_ms = True ): \"\"\" Initial Signal from modelling output. \"\"\" assert isinstance ( model , Model ) return cls ( model . xr ( group = group ), time_in_ms = time_in_ms ) @classmethod def from_file ( cls , filename ): \"\"\" Load signal from saved file. :param filename: filename for the Signal :type filename: str \"\"\" if not filename . endswith ( NC_EXT ): filename += NC_EXT # load NC file xarray = xr . load_dataarray ( filename ) # init class signal = cls ( xarray ) # if nc file has attributes, copy them to signal class if xarray . attrs : process_steps = [] for k , v in xarray . attrs . items (): if cls . PROCESS_STEPS_KEY in k : idx = int ( k [ len ( cls . PROCESS_STEPS_KEY ) + 1 :]) process_steps . insert ( idx , v ) else : setattr ( signal , k , v ) else : logging . warning ( \"No metadata found, setting empty...\" ) process_steps = [ f \"raw { signal . signal_type } signal: { signal . start_time } --\" f \" { signal . end_time } s\" ] setattr ( signal , cls . PROCESS_STEPS_KEY , process_steps ) return signal def __init__ ( self , data , time_in_ms = False ): \"\"\" :param data: data for the signal, assumes time dimension with time in seconds :type data: xr.DataArray :param time_in_ms: whether time dimension is in ms :type time_in_ms: bool \"\"\" assert isinstance ( data , xr . DataArray ) data = deepcopy ( data ) assert \"time\" in data . dims , \"DataArray must have time axis\" if time_in_ms : data [ \"time\" ] = data [ \"time\" ] / 1000.0 data [ \"time\" ] = np . around ( data [ \"time\" ], 6 ) self . data = data # assert time dimension is last self . data = self . data . transpose ( * ( self . dims_not_time + [ \"time\" ])) # compute dt and sampling frequency self . dt = np . around ( np . diff ( data . time ) . mean (), 6 ) self . sampling_frequency = 1.0 / self . dt self . process_steps = [ f \"raw { self . signal_type } signal: { self . start_time } -- { self . end_time } s\" ] def __str__ ( self ): \"\"\" String representation. \"\"\" return ( f \" { self . name } representing { self . signal_type } signal with unit of \" f \" { self . unit } with user-provided description: ` { self . description } `\" f \". Shape of the signal is { self . shape } with dimensions \" f \" { self . data . dims } . Signal starts at { self . start_time } and ends at \" f \" { self . end_time } .\" ) def __repr__ ( self ): \"\"\" Representation. \"\"\" return self . __str__ () def __eq__ ( self , other ): \"\"\" Comparison operator. :param other: other `Signal` to compare with :type other: `Signal` :return: whether two `Signals` are the same :rtype: bool \"\"\" assert isinstance ( other , Signal ) # assert data are the same try : xr . testing . assert_allclose ( self . data , other . data ) eq = True except AssertionError : eq = False # check attributes, but if not equal, only warn the user for attr in self . _copy_attributes : if getattr ( self , attr ) != getattr ( other , attr ): logging . warning ( f \"` { attr } ` not equal between signals.\" ) return eq def __getitem__ ( self , pos ): \"\"\" Get item selects in output dimension. \"\"\" add_steps = [ f \"select ` { pos } ` output\" ] return self . __constructor__ ( self . data . sel ( output = pos )) . __finalize__ ( self , add_steps ) def __finalize__ ( self , other , add_steps = None ): \"\"\" Copy attributes from other to self. Used when constructing class instance with different data, but same metadata. :param other: other instance of `Signal` :type other: `Signal` :param add_steps: add steps to preprocessing :type add_steps: list|None \"\"\" assert isinstance ( other , Signal ) for attr in self . _copy_attributes : setattr ( self , attr , deepcopy ( getattr ( other , attr ))) if add_steps is not None : self . process_steps += add_steps return self @property def __constructor__ ( self ): \"\"\" Return constructor, so that each child class would initiate a new instance of the correct class, i.e. first in the method resolution order. \"\"\" return self . __class__ . mro ()[ 0 ] def _write_attrs_to_xr ( self ): \"\"\" Copy attributes to xarray before saving. \"\"\" # write attributes to xarray for attr in self . _copy_attributes : value = getattr ( self , attr ) # if list need to unwrap if isinstance ( value , ( list , tuple )): for idx , val in enumerate ( value ): self . data . attrs [ f \" { attr } _ { idx } \" ] = val else : self . data . attrs [ attr ] = deepcopy ( value ) def save ( self , filename ): \"\"\" Save signal. :param filename: filename to save, currently saves to netCDF file, which is natively supported by xarray :type filename: str \"\"\" self . _write_attrs_to_xr () if not filename . endswith ( NC_EXT ): filename += NC_EXT self . data . to_netcdf ( filename ) def iterate ( self , return_as = \"signal\" ): \"\"\" Return iterator over columns, so univariate measures can be computed per column. Loops over tuples as (variable name, timeseries). :param return_as: how to return columns: `xr` as xr.DataArray, `signal` as instance of NeuroSignal with the same attributes as the mother signal :type return_as: str \"\"\" try : stacked = self . data . stack ({ \"all\" : self . dims_not_time }) except ValueError : logging . warning ( \"No dimensions along which to stack...\" ) stacked = self . data . expand_dims ( \"all\" ) if return_as == \"xr\" : yield from stacked . groupby ( \"all\" ) elif return_as == \"signal\" : for name_coords , column in stacked . groupby ( \"all\" ): if not isinstance ( name_coords , ( list , tuple )): name_coords = [ name_coords ] name_dict = { k : v for k , v in zip ( self . dims_not_time , name_coords )} yield name_dict , self . __constructor__ ( column ) . __finalize__ ( self , [ f \"select { column . name } \" ]) else : raise ValueError ( f \"Data type not understood: { return_as } \" ) def sel ( self , sel_args , inplace = True ): \"\"\" Subselect part of signal using xarray's `sel`, i.e. selecting by actual physical index, hence time in seconds. :param sel_args: arguments you'd give to xr.sel(), i.e. slice of times you want to select, in seconds as a len=2 list or tuple :type sel_args: tuple|list :param inplace: whether to do the operation in place or return :type inplace: bool \"\"\" assert len ( sel_args ) == 2 , \"Must provide 2 arguments\" selected = self . data . sel ( time = slice ( sel_args [ 0 ], sel_args [ 1 ])) add_steps = [ f \"select { sel_args [ 0 ] or 'x' } : { sel_args [ 1 ] or 'x' } s\" ] if inplace : self . data = selected self . process_steps += add_steps else : return self . __constructor__ ( selected ) . __finalize__ ( self , add_steps ) def isel ( self , isel_args , inplace = True ): \"\"\" Subselect part of signal using xarray's `isel`, i.e. selecting by index, hence integers. :param loc_args: arguments you'd give to xr.isel(), i.e. slice of indices you want to select, in seconds as a len=2 list or tuple :type loc_args: tuple|list :param inplace: whether to do the operation in place or return :type inplace: bool \"\"\" assert len ( isel_args ) == 2 , \"Must provide 2 arguments\" selected = self . data . isel ( time = slice ( isel_args [ 0 ], isel_args [ 1 ])) start = isel_args [ 0 ] * self . dt if isel_args [ 0 ] is not None else \"x\" end = isel_args [ 1 ] * self . dt if isel_args [ 1 ] is not None else \"x\" add_steps = [ f \"select { start } : { end } s\" ] if inplace : self . data = selected self . process_steps += add_steps else : return self . __constructor__ ( selected ) . __finalize__ ( self , add_steps ) def rolling ( self , roll_over , function = np . mean , dropnans = True , inplace = True ): \"\"\" Return rolling reduction over signal's time dimension. The window is centered around the midpoint. :param roll_over: window to use, in seconds :type roll_over: float :param function: function to use for reduction :type function: callable :param dropnans: whether to drop NaNs - will shorten time dimension, or not :type dropnans: bool :param inplace: whether to do the operation in place or return :type inplace: bool \"\"\" assert callable ( function ) rolling = self . data . rolling ( time = int ( roll_over * self . sampling_frequency ), center = True ) . reduce ( function ) add_steps = [ f \"rolling { function . __name__ } over { roll_over } s\" ] if dropnans : rolling = rolling . dropna ( \"time\" ) add_steps [ 0 ] += \"; drop NaNs\" if inplace : self . data = rolling self . process_steps += add_steps else : return self . __constructor__ ( rolling ) . __finalize__ ( self , add_steps ) def sliding_window ( self , length , step = 1 , window_function = \"boxcar\" , lengths_in_seconds = False ): \"\"\" Return iterator over sliding windows with windowing function applied. Each window has length `length` and each is translated by `step` steps. For no windowing function use \"boxcar\". If the last window would have the same length as other, it is omitted, i.e. last window does not have to end with the final timeseries point! :param length: length of the window, can be index or time in seconds, see `lengths_in_seconds` :type length: int|float :param step: how much to translate window in the temporal sense, can be index or time in seconds, see `lengths_in_seconds` :type step: int|float :param window_function: windowing function to use, this is passed to `get_window()`; see `scipy.signal.windows.get_window` documentation :type window_function: str|tuple|float :param lengths_in_seconds: if True, `length` and `step` are interpreted in seconds, if False they are indices :type lengths_in_seconds: bool :yield: generator with windowed Signals \"\"\" if lengths_in_seconds : length = int ( length / self . dt ) step = int ( step / self . dt ) assert ( length < self . data . time . shape [ 0 ] ), f \"Length must be smaller than time span of the timeseries: { self . data . time . shape [ 0 ] } \" assert step <= length , \"Step cannot be larger than length, some part of timeseries would be omitted!\" current_idx = 0 add_steps = f \" { str ( window_function ) } window: \" windowing_function = get_window ( window_function , Nx = length ) while current_idx <= ( self . data . time . shape [ 0 ] - length ): yield self . __constructor__ ( self . data . isel ( time = slice ( current_idx , current_idx + length )) * windowing_function ) . __finalize__ ( self , [ add_steps + f \" { current_idx } : { current_idx + length } \" ]) current_idx += step @property def shape ( self ): \"\"\" Return shape of the data. Time axis is the first one. \"\"\" return self . data . shape @property def dims_not_time ( self ): \"\"\" Return list of dimensions that are not time. \"\"\" return [ dim for dim in self . data . dims if dim != \"time\" ] @property def coords_not_time ( self ): \"\"\" Return dict with all coordinates except time. \"\"\" return { k : v . values for k , v in self . data . coords . items () if k != \"time\" } @property def start_time ( self ): \"\"\" Return starting time of the signal. \"\"\" return self . data . time . values [ 0 ] @property def end_time ( self ): \"\"\" Return ending time of the signal. \"\"\" return self . data . time . values [ - 1 ] @property def time ( self ): \"\"\" Return time vector. \"\"\" return self . data . time . values @property def preprocessing_steps ( self ): \"\"\" Return preprocessing steps done on the data. \"\"\" return \" -> \" . join ( self . process_steps ) def pad ( self , how_much , in_seconds = False , padding_type = \"constant\" , side = \"both\" , inplace = True , ** kwargs ): \"\"\" Pad signal by `how_much` on given side of given type. :param how_much: how much we should pad, can be time points, or seconds, see `in_seconds` :type how_much: float|int :param in_seconds: whether `how_much` is in seconds, if False, it is number of time points :type in_seconds: bool :param padding_type: how to pad the signal, see `np.pad` documentation :type padding_type: str :param side: which side to pad - \"before\", \"after\", or \"both\" :type side: str :param inplace: whether to do the operation in place or return :type inplace: bool :kwargs: passed to `np.pad` \"\"\" if in_seconds : how_much = int ( np . around ( how_much / self . dt )) if side == \"before\" : pad_width = ( how_much , 0 ) pad_times = np . arange ( - how_much , 0 ) * self . dt + self . data . time . values [ 0 ] new_times = np . concatenate ([ pad_times , self . data . time . values ], axis = 0 ) elif side == \"after\" : pad_width = ( 0 , how_much ) pad_times = np . arange ( 1 , how_much + 1 ) * self . dt + self . data . time . values [ - 1 ] new_times = np . concatenate ([ self . data . time . values , pad_times ], axis = 0 ) elif side == \"both\" : pad_width = ( how_much , how_much ) pad_before = np . arange ( - how_much , 0 ) * self . dt + self . data . time . values [ 0 ] pad_after = np . arange ( 1 , how_much + 1 ) * self . dt + self . data . time . values [ - 1 ] new_times = np . concatenate ([ pad_before , self . data . time . values , pad_after ], axis = 0 ) side += \" sides\" else : raise ValueError ( f \"Unknown padding side: { side } \" ) # add padding for other axes than time - zeroes pad_width = [( 0 , 0 )] * len ( self . dims_not_time ) + [ pad_width ] padded = np . pad ( self . data . values , pad_width , mode = padding_type , ** kwargs ) # to dataframe padded = xr . DataArray ( padded , dims = self . data . dims , coords = { ** self . coords_not_time , \"time\" : new_times }) add_steps = [ f \" { how_much * self . dt } s { padding_type } { side } padding\" ] if inplace : self . data = padded self . process_steps += add_steps else : return self . __constructor__ ( padded ) . __finalize__ ( self , add_steps ) def normalize ( self , std = False , inplace = True ): \"\"\" De-mean the timeseries. Optionally also standardise. :param std: normalize by std, i.e. to unit variance :type std: bool :param inplace: whether to do the operation in place or return :type inplace: bool \"\"\" def norm_func ( x , dim ): demeaned = x - x . mean ( dim = dim ) if std : return demeaned / x . std ( dim = dim ) else : return demeaned normalized = norm_func ( self . data , dim = \"time\" ) add_steps = [ \"normalize\" , \"standardize\" ] if std else [ \"normalize\" ] if inplace : self . data = normalized self . process_steps += add_steps else : return self . __constructor__ ( normalized ) . __finalize__ ( self , add_steps ) def resample ( self , to_frequency , inplace = True ): \"\"\" Resample signal to target frequency. :param to_frequency: target frequency of the signal, in Hz :type to_frequency: float :param inplace: whether to do the operation in place or return :type inplace: bool \"\"\" to_frequency = float ( to_frequency ) try : from mne.filter import resample resample_func = partial ( resample , up = to_frequency , down = self . sampling_frequency , npad = \"auto\" , axis =- 1 , pad = \"edge\" ) except ImportError : logging . warning ( \"`mne` module not found, falling back to basic scipy's function\" ) def resample_func ( x ): return scipy_resample ( x , num = int ( round (( to_frequency / self . sampling_frequency ) * self . data . shape [ - 1 ])), axis =- 1 , window = \"boxcar\" , ) resampled = resample_func ( self . data . values ) # construct new times new_times = ( np . arange ( resampled . shape [ - 1 ], dtype = np . float ) / to_frequency ) + self . data . time . values [ 0 ] # to dataframe resampled = xr . DataArray ( resampled , dims = self . data . dims , coords = { ** self . coords_not_time , \"time\" : new_times }) add_steps = [ f \"resample to { to_frequency } Hz\" ] if inplace : self . data = resampled self . sampling_frequency = to_frequency self . dt = np . around ( np . diff ( resampled . time ) . mean (), 6 ) self . process_steps += add_steps else : return self . __constructor__ ( resampled ) . __finalize__ ( self , add_steps ) def hilbert_transform ( self , return_as = \"complex\" , inplace = True ): \"\"\" Perform hilbert transform on the signal resulting in analytic signal. :param return_as: what to return `complex` will compute only analytical signal `amplitude` will compute amplitude, hence abs(H(x)) `phase_wrapped` will compute phase, hence angle(H(x)), in -pi,pi `phase_unwrapped` will compute phase in a continuous sense, hence monotonic :param inplace: whether to do the operation in place or return :type inplace: bool \"\"\" analytic = hilbert ( self . data , axis =- 1 ) if return_as == \"amplitude\" : analytic = np . abs ( analytic ) add_steps = [ \"Hilbert - amplitude\" ] elif return_as == \"phase_unwrapped\" : analytic = np . unwrap ( np . angle ( analytic )) add_steps = [ \"Hilbert - unwrapped phase\" ] elif return_as == \"phase_wrapped\" : analytic = np . angle ( analytic ) add_steps = [ \"Hilbert - wrapped phase\" ] elif return_as == \"complex\" : add_steps = [ \"Hilbert - complex\" ] else : raise ValueError ( f \"Do not know how to return: { return_as } \" ) analytic = xr . DataArray ( analytic , dims = self . data . dims , coords = self . data . coords ) if inplace : self . data = analytic self . process_steps += add_steps else : return self . __constructor__ ( analytic ) . __finalize__ ( self , add_steps ) def detrend ( self , segments = None , inplace = True ): \"\"\" Linearly detrend signal. If segments are given, detrending will be performed in each part. :param segments: segments for detrending, if None will detrend whole signal, given as indices of the time array :type segments: list|None :param inplace: whether to do the operation in place or return :type inplace: bool \"\"\" segments = segments or 0 detrended = detrend ( self . data , type = \"linear\" , bp = segments , axis =- 1 ) detrended = xr . DataArray ( detrended , dims = self . data . dims , coords = self . data . coords ) segments_text = f \" with segments: { segments } \" if segments != 0 else \"\" add_steps = [ f \"detrend { segments_text } \" ] if inplace : self . data = detrended self . process_steps += add_steps else : return self . __constructor__ ( detrended ) . __finalize__ ( self , add_steps ) def filter ( self , low_freq , high_freq , l_trans_bandwidth = \"auto\" , h_trans_bandwidth = \"auto\" , inplace = True , ** kwargs ): \"\"\" Filter data. Can be: low-pass (low_freq is None, high_freq is not None), high-pass (high_freq is None, low_freq is not None), band-pass (l_freq < h_freq), band-stop (l_freq > h_freq) filter type :param low_freq: frequency below which to filter the data :type low_freq: float|None :param high_freq: frequency above which to filter the data :type high_freq: float|None :param l_trans_bandwidth: transition band width for low frequency :type l_trans_bandwidth: float|str :param h_trans_bandwidth: transition band width for high frequency :type h_trans_bandwidth: float|str :param inplace: whether to do the operation in place or return :type inplace: bool :**kwargs: possible keywords to `mne.filter.create_filter`: `filter_length`=\"auto\", `method`=\"fir\", `iir_params`=None `phase`=\"zero\", `fir_window`=\"hamming\", `fir_design`=\"firwin\" \"\"\" try : from mne.filter import filter_data except ImportError : logging . warning ( \"`mne` module not found, falling back to basic scipy's function\" ) filter_data = scipy_iir_filter_data filtered = filter_data ( self . data . values , # times has to be the last axis sfreq = self . sampling_frequency , l_freq = low_freq , h_freq = high_freq , l_trans_bandwidth = l_trans_bandwidth , h_trans_bandwidth = h_trans_bandwidth , ** kwargs , ) add_steps = [ f \"filter: low { low_freq or 'x' } Hz - high { high_freq or 'x' } Hz\" ] # to dataframe filtered = xr . DataArray ( filtered , dims = self . data . dims , coords = self . data . coords ) if inplace : self . data = filtered self . process_steps += add_steps else : return self . __constructor__ ( filtered ) . __finalize__ ( self , add_steps ) def functional_connectivity ( self , fc_function = np . corrcoef ): \"\"\" Compute and return functional connectivity from the data. :param fc_function: function which to use for FC computation, should take 2D array as space x time and convert it to space x space with desired measure \"\"\" if len ( self . data [ \"space\" ]) <= 1 : logging . error ( \"Cannot compute functional connectivity from one timeseries.\" ) return None if self . data . ndim == 3 : assert callable ( fc_function ) fcs = [] for output in self . data [ \"output\" ]: current_slice = self . data . sel ({ \"output\" : output }) assert current_slice . ndim == 2 fcs . append ( fc_function ( current_slice . values )) return xr . DataArray ( np . array ( fcs ), dims = [ \"output\" , \"space\" , \"space\" ], coords = { \"output\" : self . data . coords [ \"output\" ], \"space\" : self . data . coords [ \"space\" ]}, ) if self . data . ndim == 2 : return xr . DataArray ( fc_function ( self . data . values ), dims = [ \"space\" , \"space\" ], coords = { \"space\" : self . data . coords [ \"space\" ]}, ) def apply ( self , func , inplace = True ): \"\"\" Apply func for each timeseries. :param func: function to be applied for each 1D timeseries :type func: callable :param inplace: whether to do the operation in place or return :type inplace: bool \"\"\" assert callable ( func ) try : # this will work for element-wise function that does not reduces dimensions processed = xr . apply_ufunc ( func , self . data , input_core_dims = [[ \"time\" ]], output_core_dims = [[ \"time\" ]]) add_steps = [ f \"apply ` { func . __name__ } ` function over time dim\" ] if inplace : self . data = processed self . process_steps += add_steps else : return self . __constructor__ ( processed ) . __finalize__ ( self , add_steps ) except ValueError : # this works for functions that reduce time dimension processed = xr . apply_ufunc ( func , self . data , input_core_dims = [[ \"time\" ]]) logging . warning ( f \"Shape changed after operation! Old shape: { self . shape } , new \" f \"shape: { processed . shape } ; Cannot cast to Signal class, \" \"returing as `xr.DataArray`\" ) return processed","title":"Signal"},{"location":"utils/signal/#neurolib.utils.signal.Signal.__constructor__","text":"Return constructor, so that each child class would initiate a new instance of the correct class, i.e. first in the method resolution order.","title":"__constructor__"},{"location":"utils/signal/#neurolib.utils.signal.Signal.coords_not_time","text":"Return dict with all coordinates except time.","title":"coords_not_time"},{"location":"utils/signal/#neurolib.utils.signal.Signal.dims_not_time","text":"Return list of dimensions that are not time.","title":"dims_not_time"},{"location":"utils/signal/#neurolib.utils.signal.Signal.end_time","text":"Return ending time of the signal.","title":"end_time"},{"location":"utils/signal/#neurolib.utils.signal.Signal.preprocessing_steps","text":"Return preprocessing steps done on the data.","title":"preprocessing_steps"},{"location":"utils/signal/#neurolib.utils.signal.Signal.shape","text":"Return shape of the data. Time axis is the first one.","title":"shape"},{"location":"utils/signal/#neurolib.utils.signal.Signal.start_time","text":"Return starting time of the signal.","title":"start_time"},{"location":"utils/signal/#neurolib.utils.signal.Signal.time","text":"Return time vector.","title":"time"},{"location":"utils/signal/#neurolib.utils.signal.Signal.__eq__","text":"Comparison operator. Parameters: Name Type Description Default other `Signal` other Signal to compare with required Returns: Type Description bool whether two Signals are the same Source code in neurolib/utils/signal.py def __eq__ ( self , other ): \"\"\" Comparison operator. :param other: other `Signal` to compare with :type other: `Signal` :return: whether two `Signals` are the same :rtype: bool \"\"\" assert isinstance ( other , Signal ) # assert data are the same try : xr . testing . assert_allclose ( self . data , other . data ) eq = True except AssertionError : eq = False # check attributes, but if not equal, only warn the user for attr in self . _copy_attributes : if getattr ( self , attr ) != getattr ( other , attr ): logging . warning ( f \"` { attr } ` not equal between signals.\" ) return eq","title":"__eq__()"},{"location":"utils/signal/#neurolib.utils.signal.Signal.__finalize__","text":"Copy attributes from other to self. Used when constructing class instance with different data, but same metadata. Parameters: Name Type Description Default other `Signal` other instance of Signal required add_steps list|None add steps to preprocessing None Source code in neurolib/utils/signal.py def __finalize__ ( self , other , add_steps = None ): \"\"\" Copy attributes from other to self. Used when constructing class instance with different data, but same metadata. :param other: other instance of `Signal` :type other: `Signal` :param add_steps: add steps to preprocessing :type add_steps: list|None \"\"\" assert isinstance ( other , Signal ) for attr in self . _copy_attributes : setattr ( self , attr , deepcopy ( getattr ( other , attr ))) if add_steps is not None : self . process_steps += add_steps return self","title":"__finalize__()"},{"location":"utils/signal/#neurolib.utils.signal.Signal.__getitem__","text":"Get item selects in output dimension. Source code in neurolib/utils/signal.py def __getitem__ ( self , pos ): \"\"\" Get item selects in output dimension. \"\"\" add_steps = [ f \"select ` { pos } ` output\" ] return self . __constructor__ ( self . data . sel ( output = pos )) . __finalize__ ( self , add_steps )","title":"__getitem__()"},{"location":"utils/signal/#neurolib.utils.signal.Signal.__init__","text":"Parameters: Name Type Description Default data xr.DataArray data for the signal, assumes time dimension with time in seconds required time_in_ms bool whether time dimension is in ms False Source code in neurolib/utils/signal.py def __init__ ( self , data , time_in_ms = False ): \"\"\" :param data: data for the signal, assumes time dimension with time in seconds :type data: xr.DataArray :param time_in_ms: whether time dimension is in ms :type time_in_ms: bool \"\"\" assert isinstance ( data , xr . DataArray ) data = deepcopy ( data ) assert \"time\" in data . dims , \"DataArray must have time axis\" if time_in_ms : data [ \"time\" ] = data [ \"time\" ] / 1000.0 data [ \"time\" ] = np . around ( data [ \"time\" ], 6 ) self . data = data # assert time dimension is last self . data = self . data . transpose ( * ( self . dims_not_time + [ \"time\" ])) # compute dt and sampling frequency self . dt = np . around ( np . diff ( data . time ) . mean (), 6 ) self . sampling_frequency = 1.0 / self . dt self . process_steps = [ f \"raw { self . signal_type } signal: { self . start_time } -- { self . end_time } s\" ]","title":"__init__()"},{"location":"utils/signal/#neurolib.utils.signal.Signal.__repr__","text":"Representation. Source code in neurolib/utils/signal.py def __repr__ ( self ): \"\"\" Representation. \"\"\" return self . __str__ ()","title":"__repr__()"},{"location":"utils/signal/#neurolib.utils.signal.Signal.__str__","text":"String representation. Source code in neurolib/utils/signal.py def __str__ ( self ): \"\"\" String representation. \"\"\" return ( f \" { self . name } representing { self . signal_type } signal with unit of \" f \" { self . unit } with user-provided description: ` { self . description } `\" f \". Shape of the signal is { self . shape } with dimensions \" f \" { self . data . dims } . Signal starts at { self . start_time } and ends at \" f \" { self . end_time } .\" )","title":"__str__()"},{"location":"utils/signal/#neurolib.utils.signal.Signal.apply","text":"Apply func for each timeseries. Parameters: Name Type Description Default func callable function to be applied for each 1D timeseries required inplace bool whether to do the operation in place or return True Source code in neurolib/utils/signal.py def apply ( self , func , inplace = True ): \"\"\" Apply func for each timeseries. :param func: function to be applied for each 1D timeseries :type func: callable :param inplace: whether to do the operation in place or return :type inplace: bool \"\"\" assert callable ( func ) try : # this will work for element-wise function that does not reduces dimensions processed = xr . apply_ufunc ( func , self . data , input_core_dims = [[ \"time\" ]], output_core_dims = [[ \"time\" ]]) add_steps = [ f \"apply ` { func . __name__ } ` function over time dim\" ] if inplace : self . data = processed self . process_steps += add_steps else : return self . __constructor__ ( processed ) . __finalize__ ( self , add_steps ) except ValueError : # this works for functions that reduce time dimension processed = xr . apply_ufunc ( func , self . data , input_core_dims = [[ \"time\" ]]) logging . warning ( f \"Shape changed after operation! Old shape: { self . shape } , new \" f \"shape: { processed . shape } ; Cannot cast to Signal class, \" \"returing as `xr.DataArray`\" ) return processed","title":"apply()"},{"location":"utils/signal/#neurolib.utils.signal.Signal.detrend","text":"Linearly detrend signal. If segments are given, detrending will be performed in each part. Parameters: Name Type Description Default segments list|None segments for detrending, if None will detrend whole signal, given as indices of the time array None inplace bool whether to do the operation in place or return True Source code in neurolib/utils/signal.py def detrend ( self , segments = None , inplace = True ): \"\"\" Linearly detrend signal. If segments are given, detrending will be performed in each part. :param segments: segments for detrending, if None will detrend whole signal, given as indices of the time array :type segments: list|None :param inplace: whether to do the operation in place or return :type inplace: bool \"\"\" segments = segments or 0 detrended = detrend ( self . data , type = \"linear\" , bp = segments , axis =- 1 ) detrended = xr . DataArray ( detrended , dims = self . data . dims , coords = self . data . coords ) segments_text = f \" with segments: { segments } \" if segments != 0 else \"\" add_steps = [ f \"detrend { segments_text } \" ] if inplace : self . data = detrended self . process_steps += add_steps else : return self . __constructor__ ( detrended ) . __finalize__ ( self , add_steps )","title":"detrend()"},{"location":"utils/signal/#neurolib.utils.signal.Signal.filter","text":"Filter data. Can be: low-pass (low_freq is None, high_freq is not None), high-pass (high_freq is None, low_freq is not None), band-pass (l_freq < h_freq), band-stop (l_freq > h_freq) filter type :**kwargs: possible keywords to mne.filter.create_filter : filter_length =\"auto\", method =\"fir\", iir_params =None phase =\"zero\", fir_window =\"hamming\", fir_design =\"firwin\" Parameters: Name Type Description Default low_freq float|None frequency below which to filter the data required high_freq float|None frequency above which to filter the data required l_trans_bandwidth float|str transition band width for low frequency 'auto' h_trans_bandwidth float|str transition band width for high frequency 'auto' inplace bool whether to do the operation in place or return True Source code in neurolib/utils/signal.py def filter ( self , low_freq , high_freq , l_trans_bandwidth = \"auto\" , h_trans_bandwidth = \"auto\" , inplace = True , ** kwargs ): \"\"\" Filter data. Can be: low-pass (low_freq is None, high_freq is not None), high-pass (high_freq is None, low_freq is not None), band-pass (l_freq < h_freq), band-stop (l_freq > h_freq) filter type :param low_freq: frequency below which to filter the data :type low_freq: float|None :param high_freq: frequency above which to filter the data :type high_freq: float|None :param l_trans_bandwidth: transition band width for low frequency :type l_trans_bandwidth: float|str :param h_trans_bandwidth: transition band width for high frequency :type h_trans_bandwidth: float|str :param inplace: whether to do the operation in place or return :type inplace: bool :**kwargs: possible keywords to `mne.filter.create_filter`: `filter_length`=\"auto\", `method`=\"fir\", `iir_params`=None `phase`=\"zero\", `fir_window`=\"hamming\", `fir_design`=\"firwin\" \"\"\" try : from mne.filter import filter_data except ImportError : logging . warning ( \"`mne` module not found, falling back to basic scipy's function\" ) filter_data = scipy_iir_filter_data filtered = filter_data ( self . data . values , # times has to be the last axis sfreq = self . sampling_frequency , l_freq = low_freq , h_freq = high_freq , l_trans_bandwidth = l_trans_bandwidth , h_trans_bandwidth = h_trans_bandwidth , ** kwargs , ) add_steps = [ f \"filter: low { low_freq or 'x' } Hz - high { high_freq or 'x' } Hz\" ] # to dataframe filtered = xr . DataArray ( filtered , dims = self . data . dims , coords = self . data . coords ) if inplace : self . data = filtered self . process_steps += add_steps else : return self . __constructor__ ( filtered ) . __finalize__ ( self , add_steps )","title":"filter()"},{"location":"utils/signal/#neurolib.utils.signal.Signal.from_file","text":"Load signal from saved file. Parameters: Name Type Description Default filename str filename for the Signal required Source code in neurolib/utils/signal.py @classmethod def from_file ( cls , filename ): \"\"\" Load signal from saved file. :param filename: filename for the Signal :type filename: str \"\"\" if not filename . endswith ( NC_EXT ): filename += NC_EXT # load NC file xarray = xr . load_dataarray ( filename ) # init class signal = cls ( xarray ) # if nc file has attributes, copy them to signal class if xarray . attrs : process_steps = [] for k , v in xarray . attrs . items (): if cls . PROCESS_STEPS_KEY in k : idx = int ( k [ len ( cls . PROCESS_STEPS_KEY ) + 1 :]) process_steps . insert ( idx , v ) else : setattr ( signal , k , v ) else : logging . warning ( \"No metadata found, setting empty...\" ) process_steps = [ f \"raw { signal . signal_type } signal: { signal . start_time } --\" f \" { signal . end_time } s\" ] setattr ( signal , cls . PROCESS_STEPS_KEY , process_steps ) return signal","title":"from_file()"},{"location":"utils/signal/#neurolib.utils.signal.Signal.from_model_output","text":"Initial Signal from modelling output. Source code in neurolib/utils/signal.py @classmethod def from_model_output ( cls , model , group = \"\" , time_in_ms = True ): \"\"\" Initial Signal from modelling output. \"\"\" assert isinstance ( model , Model ) return cls ( model . xr ( group = group ), time_in_ms = time_in_ms )","title":"from_model_output()"},{"location":"utils/signal/#neurolib.utils.signal.Signal.functional_connectivity","text":"Compute and return functional connectivity from the data. Parameters: Name Type Description Default fc_function function which to use for FC computation, should take 2D array as space x time and convert it to space x space with desired measure <function corrcoef at 0x7f13510dce60> Source code in neurolib/utils/signal.py def functional_connectivity ( self , fc_function = np . corrcoef ): \"\"\" Compute and return functional connectivity from the data. :param fc_function: function which to use for FC computation, should take 2D array as space x time and convert it to space x space with desired measure \"\"\" if len ( self . data [ \"space\" ]) <= 1 : logging . error ( \"Cannot compute functional connectivity from one timeseries.\" ) return None if self . data . ndim == 3 : assert callable ( fc_function ) fcs = [] for output in self . data [ \"output\" ]: current_slice = self . data . sel ({ \"output\" : output }) assert current_slice . ndim == 2 fcs . append ( fc_function ( current_slice . values )) return xr . DataArray ( np . array ( fcs ), dims = [ \"output\" , \"space\" , \"space\" ], coords = { \"output\" : self . data . coords [ \"output\" ], \"space\" : self . data . coords [ \"space\" ]}, ) if self . data . ndim == 2 : return xr . DataArray ( fc_function ( self . data . values ), dims = [ \"space\" , \"space\" ], coords = { \"space\" : self . data . coords [ \"space\" ]}, )","title":"functional_connectivity()"},{"location":"utils/signal/#neurolib.utils.signal.Signal.hilbert_transform","text":"Perform hilbert transform on the signal resulting in analytic signal. Parameters: Name Type Description Default return_as what to return complex will compute only analytical signal amplitude will compute amplitude, hence abs(H(x)) phase_wrapped will compute phase, hence angle(H(x)), in -pi,pi phase_unwrapped will compute phase in a continuous sense, hence monotonic 'complex' inplace bool whether to do the operation in place or return True Source code in neurolib/utils/signal.py def hilbert_transform ( self , return_as = \"complex\" , inplace = True ): \"\"\" Perform hilbert transform on the signal resulting in analytic signal. :param return_as: what to return `complex` will compute only analytical signal `amplitude` will compute amplitude, hence abs(H(x)) `phase_wrapped` will compute phase, hence angle(H(x)), in -pi,pi `phase_unwrapped` will compute phase in a continuous sense, hence monotonic :param inplace: whether to do the operation in place or return :type inplace: bool \"\"\" analytic = hilbert ( self . data , axis =- 1 ) if return_as == \"amplitude\" : analytic = np . abs ( analytic ) add_steps = [ \"Hilbert - amplitude\" ] elif return_as == \"phase_unwrapped\" : analytic = np . unwrap ( np . angle ( analytic )) add_steps = [ \"Hilbert - unwrapped phase\" ] elif return_as == \"phase_wrapped\" : analytic = np . angle ( analytic ) add_steps = [ \"Hilbert - wrapped phase\" ] elif return_as == \"complex\" : add_steps = [ \"Hilbert - complex\" ] else : raise ValueError ( f \"Do not know how to return: { return_as } \" ) analytic = xr . DataArray ( analytic , dims = self . data . dims , coords = self . data . coords ) if inplace : self . data = analytic self . process_steps += add_steps else : return self . __constructor__ ( analytic ) . __finalize__ ( self , add_steps )","title":"hilbert_transform()"},{"location":"utils/signal/#neurolib.utils.signal.Signal.isel","text":"Subselect part of signal using xarray's isel , i.e. selecting by index, hence integers. Parameters: Name Type Description Default loc_args tuple|list arguments you'd give to xr.isel(), i.e. slice of indices you want to select, in seconds as a len=2 list or tuple required inplace bool whether to do the operation in place or return True Source code in neurolib/utils/signal.py def isel ( self , isel_args , inplace = True ): \"\"\" Subselect part of signal using xarray's `isel`, i.e. selecting by index, hence integers. :param loc_args: arguments you'd give to xr.isel(), i.e. slice of indices you want to select, in seconds as a len=2 list or tuple :type loc_args: tuple|list :param inplace: whether to do the operation in place or return :type inplace: bool \"\"\" assert len ( isel_args ) == 2 , \"Must provide 2 arguments\" selected = self . data . isel ( time = slice ( isel_args [ 0 ], isel_args [ 1 ])) start = isel_args [ 0 ] * self . dt if isel_args [ 0 ] is not None else \"x\" end = isel_args [ 1 ] * self . dt if isel_args [ 1 ] is not None else \"x\" add_steps = [ f \"select { start } : { end } s\" ] if inplace : self . data = selected self . process_steps += add_steps else : return self . __constructor__ ( selected ) . __finalize__ ( self , add_steps )","title":"isel()"},{"location":"utils/signal/#neurolib.utils.signal.Signal.iterate","text":"Return iterator over columns, so univariate measures can be computed per column. Loops over tuples as (variable name, timeseries). Parameters: Name Type Description Default return_as str how to return columns: xr as xr.DataArray, signal as instance of NeuroSignal with the same attributes as the mother signal 'signal' Source code in neurolib/utils/signal.py def iterate ( self , return_as = \"signal\" ): \"\"\" Return iterator over columns, so univariate measures can be computed per column. Loops over tuples as (variable name, timeseries). :param return_as: how to return columns: `xr` as xr.DataArray, `signal` as instance of NeuroSignal with the same attributes as the mother signal :type return_as: str \"\"\" try : stacked = self . data . stack ({ \"all\" : self . dims_not_time }) except ValueError : logging . warning ( \"No dimensions along which to stack...\" ) stacked = self . data . expand_dims ( \"all\" ) if return_as == \"xr\" : yield from stacked . groupby ( \"all\" ) elif return_as == \"signal\" : for name_coords , column in stacked . groupby ( \"all\" ): if not isinstance ( name_coords , ( list , tuple )): name_coords = [ name_coords ] name_dict = { k : v for k , v in zip ( self . dims_not_time , name_coords )} yield name_dict , self . __constructor__ ( column ) . __finalize__ ( self , [ f \"select { column . name } \" ]) else : raise ValueError ( f \"Data type not understood: { return_as } \" )","title":"iterate()"},{"location":"utils/signal/#neurolib.utils.signal.Signal.normalize","text":"De-mean the timeseries. Optionally also standardise. Parameters: Name Type Description Default std bool normalize by std, i.e. to unit variance False inplace bool whether to do the operation in place or return True Source code in neurolib/utils/signal.py def normalize ( self , std = False , inplace = True ): \"\"\" De-mean the timeseries. Optionally also standardise. :param std: normalize by std, i.e. to unit variance :type std: bool :param inplace: whether to do the operation in place or return :type inplace: bool \"\"\" def norm_func ( x , dim ): demeaned = x - x . mean ( dim = dim ) if std : return demeaned / x . std ( dim = dim ) else : return demeaned normalized = norm_func ( self . data , dim = \"time\" ) add_steps = [ \"normalize\" , \"standardize\" ] if std else [ \"normalize\" ] if inplace : self . data = normalized self . process_steps += add_steps else : return self . __constructor__ ( normalized ) . __finalize__ ( self , add_steps )","title":"normalize()"},{"location":"utils/signal/#neurolib.utils.signal.Signal.pad","text":"Pad signal by how_much on given side of given type. :kwargs: passed to np.pad Parameters: Name Type Description Default how_much float|int how much we should pad, can be time points, or seconds, see in_seconds required in_seconds bool whether how_much is in seconds, if False, it is number of time points False padding_type str how to pad the signal, see np.pad documentation 'constant' side str which side to pad - \"before\", \"after\", or \"both\" 'both' inplace bool whether to do the operation in place or return True Source code in neurolib/utils/signal.py def pad ( self , how_much , in_seconds = False , padding_type = \"constant\" , side = \"both\" , inplace = True , ** kwargs ): \"\"\" Pad signal by `how_much` on given side of given type. :param how_much: how much we should pad, can be time points, or seconds, see `in_seconds` :type how_much: float|int :param in_seconds: whether `how_much` is in seconds, if False, it is number of time points :type in_seconds: bool :param padding_type: how to pad the signal, see `np.pad` documentation :type padding_type: str :param side: which side to pad - \"before\", \"after\", or \"both\" :type side: str :param inplace: whether to do the operation in place or return :type inplace: bool :kwargs: passed to `np.pad` \"\"\" if in_seconds : how_much = int ( np . around ( how_much / self . dt )) if side == \"before\" : pad_width = ( how_much , 0 ) pad_times = np . arange ( - how_much , 0 ) * self . dt + self . data . time . values [ 0 ] new_times = np . concatenate ([ pad_times , self . data . time . values ], axis = 0 ) elif side == \"after\" : pad_width = ( 0 , how_much ) pad_times = np . arange ( 1 , how_much + 1 ) * self . dt + self . data . time . values [ - 1 ] new_times = np . concatenate ([ self . data . time . values , pad_times ], axis = 0 ) elif side == \"both\" : pad_width = ( how_much , how_much ) pad_before = np . arange ( - how_much , 0 ) * self . dt + self . data . time . values [ 0 ] pad_after = np . arange ( 1 , how_much + 1 ) * self . dt + self . data . time . values [ - 1 ] new_times = np . concatenate ([ pad_before , self . data . time . values , pad_after ], axis = 0 ) side += \" sides\" else : raise ValueError ( f \"Unknown padding side: { side } \" ) # add padding for other axes than time - zeroes pad_width = [( 0 , 0 )] * len ( self . dims_not_time ) + [ pad_width ] padded = np . pad ( self . data . values , pad_width , mode = padding_type , ** kwargs ) # to dataframe padded = xr . DataArray ( padded , dims = self . data . dims , coords = { ** self . coords_not_time , \"time\" : new_times }) add_steps = [ f \" { how_much * self . dt } s { padding_type } { side } padding\" ] if inplace : self . data = padded self . process_steps += add_steps else : return self . __constructor__ ( padded ) . __finalize__ ( self , add_steps )","title":"pad()"},{"location":"utils/signal/#neurolib.utils.signal.Signal.resample","text":"Resample signal to target frequency. Parameters: Name Type Description Default to_frequency float target frequency of the signal, in Hz required inplace bool whether to do the operation in place or return True Source code in neurolib/utils/signal.py def resample ( self , to_frequency , inplace = True ): \"\"\" Resample signal to target frequency. :param to_frequency: target frequency of the signal, in Hz :type to_frequency: float :param inplace: whether to do the operation in place or return :type inplace: bool \"\"\" to_frequency = float ( to_frequency ) try : from mne.filter import resample resample_func = partial ( resample , up = to_frequency , down = self . sampling_frequency , npad = \"auto\" , axis =- 1 , pad = \"edge\" ) except ImportError : logging . warning ( \"`mne` module not found, falling back to basic scipy's function\" ) def resample_func ( x ): return scipy_resample ( x , num = int ( round (( to_frequency / self . sampling_frequency ) * self . data . shape [ - 1 ])), axis =- 1 , window = \"boxcar\" , ) resampled = resample_func ( self . data . values ) # construct new times new_times = ( np . arange ( resampled . shape [ - 1 ], dtype = np . float ) / to_frequency ) + self . data . time . values [ 0 ] # to dataframe resampled = xr . DataArray ( resampled , dims = self . data . dims , coords = { ** self . coords_not_time , \"time\" : new_times }) add_steps = [ f \"resample to { to_frequency } Hz\" ] if inplace : self . data = resampled self . sampling_frequency = to_frequency self . dt = np . around ( np . diff ( resampled . time ) . mean (), 6 ) self . process_steps += add_steps else : return self . __constructor__ ( resampled ) . __finalize__ ( self , add_steps )","title":"resample()"},{"location":"utils/signal/#neurolib.utils.signal.Signal.rolling","text":"Return rolling reduction over signal's time dimension. The window is centered around the midpoint. Parameters: Name Type Description Default roll_over float window to use, in seconds required function callable function to use for reduction <function mean at 0x7f1351848290> dropnans bool whether to drop NaNs - will shorten time dimension, or not True inplace bool whether to do the operation in place or return True Source code in neurolib/utils/signal.py def rolling ( self , roll_over , function = np . mean , dropnans = True , inplace = True ): \"\"\" Return rolling reduction over signal's time dimension. The window is centered around the midpoint. :param roll_over: window to use, in seconds :type roll_over: float :param function: function to use for reduction :type function: callable :param dropnans: whether to drop NaNs - will shorten time dimension, or not :type dropnans: bool :param inplace: whether to do the operation in place or return :type inplace: bool \"\"\" assert callable ( function ) rolling = self . data . rolling ( time = int ( roll_over * self . sampling_frequency ), center = True ) . reduce ( function ) add_steps = [ f \"rolling { function . __name__ } over { roll_over } s\" ] if dropnans : rolling = rolling . dropna ( \"time\" ) add_steps [ 0 ] += \"; drop NaNs\" if inplace : self . data = rolling self . process_steps += add_steps else : return self . __constructor__ ( rolling ) . __finalize__ ( self , add_steps )","title":"rolling()"},{"location":"utils/signal/#neurolib.utils.signal.Signal.save","text":"Save signal. Parameters: Name Type Description Default filename str filename to save, currently saves to netCDF file, which is natively supported by xarray required Source code in neurolib/utils/signal.py def save ( self , filename ): \"\"\" Save signal. :param filename: filename to save, currently saves to netCDF file, which is natively supported by xarray :type filename: str \"\"\" self . _write_attrs_to_xr () if not filename . endswith ( NC_EXT ): filename += NC_EXT self . data . to_netcdf ( filename )","title":"save()"},{"location":"utils/signal/#neurolib.utils.signal.Signal.sel","text":"Subselect part of signal using xarray's sel , i.e. selecting by actual physical index, hence time in seconds. Parameters: Name Type Description Default sel_args tuple|list arguments you'd give to xr.sel(), i.e. slice of times you want to select, in seconds as a len=2 list or tuple required inplace bool whether to do the operation in place or return True Source code in neurolib/utils/signal.py def sel ( self , sel_args , inplace = True ): \"\"\" Subselect part of signal using xarray's `sel`, i.e. selecting by actual physical index, hence time in seconds. :param sel_args: arguments you'd give to xr.sel(), i.e. slice of times you want to select, in seconds as a len=2 list or tuple :type sel_args: tuple|list :param inplace: whether to do the operation in place or return :type inplace: bool \"\"\" assert len ( sel_args ) == 2 , \"Must provide 2 arguments\" selected = self . data . sel ( time = slice ( sel_args [ 0 ], sel_args [ 1 ])) add_steps = [ f \"select { sel_args [ 0 ] or 'x' } : { sel_args [ 1 ] or 'x' } s\" ] if inplace : self . data = selected self . process_steps += add_steps else : return self . __constructor__ ( selected ) . __finalize__ ( self , add_steps )","title":"sel()"},{"location":"utils/signal/#neurolib.utils.signal.Signal.sliding_window","text":"Return iterator over sliding windows with windowing function applied. Each window has length length and each is translated by step steps. For no windowing function use \"boxcar\". If the last window would have the same length as other, it is omitted, i.e. last window does not have to end with the final timeseries point! :yield: generator with windowed Signals Parameters: Name Type Description Default length int|float length of the window, can be index or time in seconds, see lengths_in_seconds required step int|float how much to translate window in the temporal sense, can be index or time in seconds, see lengths_in_seconds 1 window_function str|tuple|float windowing function to use, this is passed to get_window() ; see scipy.signal.windows.get_window documentation 'boxcar' lengths_in_seconds bool if True, length and step are interpreted in seconds, if False they are indices False Source code in neurolib/utils/signal.py def sliding_window ( self , length , step = 1 , window_function = \"boxcar\" , lengths_in_seconds = False ): \"\"\" Return iterator over sliding windows with windowing function applied. Each window has length `length` and each is translated by `step` steps. For no windowing function use \"boxcar\". If the last window would have the same length as other, it is omitted, i.e. last window does not have to end with the final timeseries point! :param length: length of the window, can be index or time in seconds, see `lengths_in_seconds` :type length: int|float :param step: how much to translate window in the temporal sense, can be index or time in seconds, see `lengths_in_seconds` :type step: int|float :param window_function: windowing function to use, this is passed to `get_window()`; see `scipy.signal.windows.get_window` documentation :type window_function: str|tuple|float :param lengths_in_seconds: if True, `length` and `step` are interpreted in seconds, if False they are indices :type lengths_in_seconds: bool :yield: generator with windowed Signals \"\"\" if lengths_in_seconds : length = int ( length / self . dt ) step = int ( step / self . dt ) assert ( length < self . data . time . shape [ 0 ] ), f \"Length must be smaller than time span of the timeseries: { self . data . time . shape [ 0 ] } \" assert step <= length , \"Step cannot be larger than length, some part of timeseries would be omitted!\" current_idx = 0 add_steps = f \" { str ( window_function ) } window: \" windowing_function = get_window ( window_function , Nx = length ) while current_idx <= ( self . data . time . shape [ 0 ] - length ): yield self . __constructor__ ( self . data . isel ( time = slice ( current_idx , current_idx + length )) * windowing_function ) . __finalize__ ( self , [ add_steps + f \" { current_idx } : { current_idx + length } \" ]) current_idx += step","title":"sliding_window()"},{"location":"utils/stimulus/","text":"Stimulus Functions for creating stimuli and noise inputs for models. BaseMultipleInputs ( Stimulus ) Base class for stimuli consisting of multiple time series, such as summed inputs or concatenated inputs. Source code in neurolib/utils/stimulus.py class BaseMultipleInputs ( Stimulus ): \"\"\" Base class for stimuli consisting of multiple time series, such as summed inputs or concatenated inputs. \"\"\" def __init__ ( self , inputs ): \"\"\" :param inputs: List of Inputs to combine :type inputs: list[`Input`] \"\"\" assert all ( isinstance ( input , Input ) for input in inputs ) self . inputs = inputs def __len__ ( self ): \"\"\" Return number of inputs. \"\"\" return len ( self . inputs ) def __getitem__ ( self , index ): \"\"\" Return inputs by index. This also allows iteration. \"\"\" return self . inputs [ index ] @property def n ( self ): n = set ([ input . n for input in self ]) assert len ( n ) == 1 return next ( iter ( n )) @n . setter def n ( self , n ): for input in self : input . n = n def get_params ( self ): \"\"\" Get all parameters recursively for all inputs. \"\"\" return { \"type\" : self . __class__ . __name__ , ** { f \"input_ { i } \" : input . get_params () for i , input in enumerate ( self )}, } def update_params ( self , params_dict ): \"\"\" Update all parameters recursively. \"\"\" for i , input in enumerate ( self ): input . update_params ( params_dict . get ( f \"input_ { i } \" , {})) __getitem__ ( self , index ) special Return inputs by index. This also allows iteration. Source code in neurolib/utils/stimulus.py def __getitem__ ( self , index ): \"\"\" Return inputs by index. This also allows iteration. \"\"\" return self . inputs [ index ] __init__ ( self , inputs ) special Parameters: Name Type Description Default inputs list[`Input`] List of Inputs to combine required Source code in neurolib/utils/stimulus.py def __init__ ( self , inputs ): \"\"\" :param inputs: List of Inputs to combine :type inputs: list[`Input`] \"\"\" assert all ( isinstance ( input , Input ) for input in inputs ) self . inputs = inputs __len__ ( self ) special Return number of inputs. Source code in neurolib/utils/stimulus.py def __len__ ( self ): \"\"\" Return number of inputs. \"\"\" return len ( self . inputs ) get_params ( self ) Get all parameters recursively for all inputs. Source code in neurolib/utils/stimulus.py def get_params ( self ): \"\"\" Get all parameters recursively for all inputs. \"\"\" return { \"type\" : self . __class__ . __name__ , ** { f \"input_ { i } \" : input . get_params () for i , input in enumerate ( self )}, } update_params ( self , params_dict ) Update all parameters recursively. Source code in neurolib/utils/stimulus.py def update_params ( self , params_dict ): \"\"\" Update all parameters recursively. \"\"\" for i , input in enumerate ( self ): input . update_params ( params_dict . get ( f \"input_ { i } \" , {})) ConcatenatedStimulus ( BaseMultipleInputs ) Represents temporal concatenation of of arbitrary many stimuli. Example: summed_stimulus = SinusoidalInput(...) & OrnsteinUhlenbeckProcess(...) Source code in neurolib/utils/stimulus.py class ConcatenatedStimulus ( BaseMultipleInputs ): \"\"\" Represents temporal concatenation of of arbitrary many stimuli. Example: ``` summed_stimulus = SinusoidalInput(...) & OrnsteinUhlenbeckProcess(...) ``` \"\"\" def __init__ ( self , inputs , length_ratios = None ): \"\"\" :param length_ratios: Ratios of lengths of concatenated stimuli :type length_ratios: list[int|float] \"\"\" if length_ratios is None : length_ratios = [ 1 ] * len ( inputs ) assert len ( inputs ) == len ( length_ratios ) assert all ( length > 0 for length in length_ratios ) self . length_ratios = length_ratios super () . __init__ ( inputs ) def __and__ ( self , other ): assert isinstance ( other , Input ) assert self . n == other . n if isinstance ( other , ConcatenatedStimulus ): return ConcatenatedStimulus ( inputs = self . inputs + other . inputs , length_ratios = self . length_ratios + other . length_ratios , ) else : return ConcatenatedStimulus ( inputs = self . inputs + [ other ], length_ratios = self . length_ratios + [ 1 ]) def as_array ( self , duration , dt ): \"\"\" Return concatenation of all stimuli as numpy array. \"\"\" # normalize ratios to sum = 1 ratios = [ i / sum ( self . length_ratios ) for i in self . length_ratios ] concat = np . concatenate ( [ input . as_array ( duration * ratio , dt ) for input , ratio in zip ( self . inputs , ratios )], axis = 1 , ) length = int ( duration / dt ) # due to rounding errors, the overall length might be longer by a few dt return concat [:, : length ] def as_cubic_splines ( self , duration , dt , shift_start_time = 0.0 ): # normalize ratios to sum = 1 ratios = [ i / sum ( self . length_ratios ) for i in self . length_ratios ] result = self . inputs [ 0 ] . as_cubic_splines ( duration * ratios [ 0 ], dt , shift_start_time ) for input , ratio in zip ( self . inputs [ 1 :], ratios [ 1 :]): last_time = result [ - 1 ] . time temp = input . as_cubic_splines ( duration * ratio , dt , shift_start_time = last_time ) # `extend` adds an iteratable (whole `CubicHermiteSpline` is an # iterable of `Anchors`) to the current spline result . extend ( temp ) return result __init__ ( self , inputs , length_ratios = None ) special Parameters: Name Type Description Default length_ratios list[int|float] Ratios of lengths of concatenated stimuli None Source code in neurolib/utils/stimulus.py def __init__ ( self , inputs , length_ratios = None ): \"\"\" :param length_ratios: Ratios of lengths of concatenated stimuli :type length_ratios: list[int|float] \"\"\" if length_ratios is None : length_ratios = [ 1 ] * len ( inputs ) assert len ( inputs ) == len ( length_ratios ) assert all ( length > 0 for length in length_ratios ) self . length_ratios = length_ratios super () . __init__ ( inputs ) as_array ( self , duration , dt ) Return concatenation of all stimuli as numpy array. Source code in neurolib/utils/stimulus.py def as_array ( self , duration , dt ): \"\"\" Return concatenation of all stimuli as numpy array. \"\"\" # normalize ratios to sum = 1 ratios = [ i / sum ( self . length_ratios ) for i in self . length_ratios ] concat = np . concatenate ( [ input . as_array ( duration * ratio , dt ) for input , ratio in zip ( self . inputs , ratios )], axis = 1 , ) length = int ( duration / dt ) # due to rounding errors, the overall length might be longer by a few dt return concat [:, : length ] as_cubic_splines ( self , duration , dt , shift_start_time = 0.0 ) Return as cubic Hermite splines. Parameters: Name Type Description Default duration float Duration of the input, in milliseconds required dt float dt of input, in milliseconds required shift_start_time float By how much to shift the stimulus start time 0.0 Source code in neurolib/utils/stimulus.py def as_cubic_splines ( self , duration , dt , shift_start_time = 0.0 ): # normalize ratios to sum = 1 ratios = [ i / sum ( self . length_ratios ) for i in self . length_ratios ] result = self . inputs [ 0 ] . as_cubic_splines ( duration * ratios [ 0 ], dt , shift_start_time ) for input , ratio in zip ( self . inputs [ 1 :], ratios [ 1 :]): last_time = result [ - 1 ] . time temp = input . as_cubic_splines ( duration * ratio , dt , shift_start_time = last_time ) # `extend` adds an iteratable (whole `CubicHermiteSpline` is an # iterable of `Anchors`) to the current spline result . extend ( temp ) return result ExponentialInput ( Stimulus ) Exponential rise or decay input. Source code in neurolib/utils/stimulus.py class ExponentialInput ( Stimulus ): \"\"\" Exponential rise or decay input. \"\"\" def __init__ ( self , inp_max , exp_coef = 30.0 , exp_type = \"rise\" , start = None , end = None , n = 1 , seed = None , ): \"\"\" :param inp_max: Maximum of stimulus. :type inp_max: float :param exp_coeficient: Coeffiecent for the exponential (the higher the coefficient, the faster it rises or decays). :type exp_coeficient: float :param exp_type: Whether to \"rise\" or to \"decay\". :type exp_type: str \"\"\" self . inp_max = inp_max self . exp_coef = exp_coef assert exp_type in [ \"rise\" , \"decay\" ] self . exp_type = exp_type super () . __init__ ( start = start , end = end , n = n , seed = seed , ) def generate_input ( self , duration , dt ): self . _get_times ( duration = duration , dt = dt ) exponential = np . exp ( - ( self . exp_coef / self . times [ - 1 ]) * self . times ) * self . inp_max if self . exp_type == \"rise\" : exponential = - exponential + self . inp_max return self . _trim_stim ( np . vstack ([ exponential ] * self . n )) __init__ ( self , inp_max , exp_coef = 30.0 , exp_type = 'rise' , start = None , end = None , n = 1 , seed = None ) special Parameters: Name Type Description Default inp_max float Maximum of stimulus. required exp_coeficient float Coeffiecent for the exponential (the higher the coefficient, the faster it rises or decays). required exp_type str Whether to \"rise\" or to \"decay\". 'rise' Source code in neurolib/utils/stimulus.py def __init__ ( self , inp_max , exp_coef = 30.0 , exp_type = \"rise\" , start = None , end = None , n = 1 , seed = None , ): \"\"\" :param inp_max: Maximum of stimulus. :type inp_max: float :param exp_coeficient: Coeffiecent for the exponential (the higher the coefficient, the faster it rises or decays). :type exp_coeficient: float :param exp_type: Whether to \"rise\" or to \"decay\". :type exp_type: str \"\"\" self . inp_max = inp_max self . exp_coef = exp_coef assert exp_type in [ \"rise\" , \"decay\" ] self . exp_type = exp_type super () . __init__ ( start = start , end = end , n = n , seed = seed , ) generate_input ( self , duration , dt ) Function to generate input. Parameters: Name Type Description Default duration float Duration of the input, in milliseconds required dt float dt of input, in milliseconds required Source code in neurolib/utils/stimulus.py def generate_input ( self , duration , dt ): self . _get_times ( duration = duration , dt = dt ) exponential = np . exp ( - ( self . exp_coef / self . times [ - 1 ]) * self . times ) * self . inp_max if self . exp_type == \"rise\" : exponential = - exponential + self . inp_max return self . _trim_stim ( np . vstack ([ exponential ] * self . n )) Input Generates input to model. Base class for other input types. Source code in neurolib/utils/stimulus.py class Input : \"\"\" Generates input to model. Base class for other input types. \"\"\" def __init__ ( self , n = 1 , seed = None ): \"\"\" :param n: Number of spatial dimensions / independent realizations of the input. For determinstic inputs, the array is just copied, for stociastic / noisy inputs, this means independent realizations. :type n: int :param seed: Seed for the random number generator. :type seed: int|None \"\"\" self . n = n self . seed = seed # seed the generator np . random . seed ( seed ) # get parameter names self . param_names = inspect . getfullargspec ( self . __init__ ) . args self . param_names . remove ( \"self\" ) def __add__ ( self , other ): \"\"\" Sum two inputs into one SummedStimulus. \"\"\" assert isinstance ( other , Input ) assert self . n == other . n if isinstance ( other , SummedStimulus ): return SummedStimulus ( inputs = [ self ] + other . inputs ) else : return SummedStimulus ( inputs = [ self , other ]) def __and__ ( self , other ): \"\"\" Concatenate two inputs into ConcatenatedStimulus. \"\"\" assert isinstance ( other , Input ) assert self . n == other . n if isinstance ( other , ConcatenatedStimulus ): return ConcatenatedStimulus ( inputs = [ self ] + other . inputs , length_ratios = [ 1 ] + other . length_ratios ) else : return ConcatenatedStimulus ( inputs = [ self , other ]) def _reset ( self ): \"\"\" Reset is called after generating an input. Can be used to reset intrinsic properties. \"\"\" pass def get_params ( self ): \"\"\" Return the parameters of the input as dict. \"\"\" assert all ( hasattr ( self , name ) for name in self . param_names ), self . param_names params = { name : getattr ( self , name ) for name in self . param_names } return { \"type\" : self . __class__ . __name__ , ** params } def update_params ( self , params_dict ): \"\"\" Update model input parameters. :param params_dict: New parameters for this input :type params_dict: dict \"\"\" def _sanitize ( value ): \"\"\" Change string `None` to actual None - can happen with Exploration or Evolution, since `pypet` does None -> \"None\". \"\"\" if value == \"None\" : return None else : return value for param , value in params_dict . items (): if hasattr ( self , param ): setattr ( self , param , _sanitize ( value )) def _get_times ( self , duration , dt ): \"\"\" Generate time vector. :param duration: Duration of the input, in milliseconds :type duration: float :param dt: dt of input, in milliseconds :type dt: float \"\"\" self . times = np . arange ( dt , duration + dt , dt ) def generate_input ( self , duration , dt ): \"\"\" Function to generate input. :param duration: Duration of the input, in milliseconds :type duration: float :param dt: dt of input, in milliseconds :type dt: float \"\"\" raise NotImplementedError def as_array ( self , duration , dt ): \"\"\" Return input as numpy array. :param duration: Duration of the input, in milliseconds :type duration: float :param dt: dt of input, in milliseconds :type dt: float \"\"\" array = self . generate_input ( duration , dt ) self . _reset () return array def as_cubic_splines ( self , duration , dt , shift_start_time = 0.0 ): \"\"\" Return as cubic Hermite splines. :param duration: Duration of the input, in milliseconds :type duration: float :param dt: dt of input, in milliseconds :type dt: float :param shift_start_time: By how much to shift the stimulus start time :type shift_start_time: float \"\"\" self . _get_times ( duration , dt ) splines = CubicHermiteSpline . from_data ( self . times + shift_start_time , self . generate_input ( duration , dt ) . T ) self . _reset () return splines def to_model ( self , model ): \"\"\" Return numpy array of stimuli based on model parameters. Example: ``` model.params[\"ext_exc_input\"] = SinusoidalInput(...).to_model(model) ``` :param model: neurolib's model :type model: `neurolib.models.Model` \"\"\" assert isinstance ( model , Model ) # set number of spatial dimensions as the number of nodes in the brian network self . n = model . params [ \"N\" ] return self . as_array ( duration = model . params [ \"duration\" ], dt = model . params [ \"dt\" ]) __add__ ( self , other ) special Sum two inputs into one SummedStimulus. Source code in neurolib/utils/stimulus.py def __add__ ( self , other ): \"\"\" Sum two inputs into one SummedStimulus. \"\"\" assert isinstance ( other , Input ) assert self . n == other . n if isinstance ( other , SummedStimulus ): return SummedStimulus ( inputs = [ self ] + other . inputs ) else : return SummedStimulus ( inputs = [ self , other ]) __and__ ( self , other ) special Concatenate two inputs into ConcatenatedStimulus. Source code in neurolib/utils/stimulus.py def __and__ ( self , other ): \"\"\" Concatenate two inputs into ConcatenatedStimulus. \"\"\" assert isinstance ( other , Input ) assert self . n == other . n if isinstance ( other , ConcatenatedStimulus ): return ConcatenatedStimulus ( inputs = [ self ] + other . inputs , length_ratios = [ 1 ] + other . length_ratios ) else : return ConcatenatedStimulus ( inputs = [ self , other ]) __init__ ( self , n = 1 , seed = None ) special Parameters: Name Type Description Default n int Number of spatial dimensions / independent realizations of the input. For determinstic inputs, the array is just copied, for stociastic / noisy inputs, this means independent realizations. 1 seed int|None Seed for the random number generator. None Source code in neurolib/utils/stimulus.py def __init__ ( self , n = 1 , seed = None ): \"\"\" :param n: Number of spatial dimensions / independent realizations of the input. For determinstic inputs, the array is just copied, for stociastic / noisy inputs, this means independent realizations. :type n: int :param seed: Seed for the random number generator. :type seed: int|None \"\"\" self . n = n self . seed = seed # seed the generator np . random . seed ( seed ) # get parameter names self . param_names = inspect . getfullargspec ( self . __init__ ) . args self . param_names . remove ( \"self\" ) as_array ( self , duration , dt ) Return input as numpy array. Parameters: Name Type Description Default duration float Duration of the input, in milliseconds required dt float dt of input, in milliseconds required Source code in neurolib/utils/stimulus.py def as_array ( self , duration , dt ): \"\"\" Return input as numpy array. :param duration: Duration of the input, in milliseconds :type duration: float :param dt: dt of input, in milliseconds :type dt: float \"\"\" array = self . generate_input ( duration , dt ) self . _reset () return array as_cubic_splines ( self , duration , dt , shift_start_time = 0.0 ) Return as cubic Hermite splines. Parameters: Name Type Description Default duration float Duration of the input, in milliseconds required dt float dt of input, in milliseconds required shift_start_time float By how much to shift the stimulus start time 0.0 Source code in neurolib/utils/stimulus.py def as_cubic_splines ( self , duration , dt , shift_start_time = 0.0 ): \"\"\" Return as cubic Hermite splines. :param duration: Duration of the input, in milliseconds :type duration: float :param dt: dt of input, in milliseconds :type dt: float :param shift_start_time: By how much to shift the stimulus start time :type shift_start_time: float \"\"\" self . _get_times ( duration , dt ) splines = CubicHermiteSpline . from_data ( self . times + shift_start_time , self . generate_input ( duration , dt ) . T ) self . _reset () return splines generate_input ( self , duration , dt ) Function to generate input. Parameters: Name Type Description Default duration float Duration of the input, in milliseconds required dt float dt of input, in milliseconds required Source code in neurolib/utils/stimulus.py def generate_input ( self , duration , dt ): \"\"\" Function to generate input. :param duration: Duration of the input, in milliseconds :type duration: float :param dt: dt of input, in milliseconds :type dt: float \"\"\" raise NotImplementedError get_params ( self ) Return the parameters of the input as dict. Source code in neurolib/utils/stimulus.py def get_params ( self ): \"\"\" Return the parameters of the input as dict. \"\"\" assert all ( hasattr ( self , name ) for name in self . param_names ), self . param_names params = { name : getattr ( self , name ) for name in self . param_names } return { \"type\" : self . __class__ . __name__ , ** params } to_model ( self , model ) Return numpy array of stimuli based on model parameters. Example: model.params[\"ext_exc_input\"] = SinusoidalInput(...).to_model(model) Parameters: Name Type Description Default model `neurolib.models.Model` neurolib's model required Source code in neurolib/utils/stimulus.py def to_model ( self , model ): \"\"\" Return numpy array of stimuli based on model parameters. Example: ``` model.params[\"ext_exc_input\"] = SinusoidalInput(...).to_model(model) ``` :param model: neurolib's model :type model: `neurolib.models.Model` \"\"\" assert isinstance ( model , Model ) # set number of spatial dimensions as the number of nodes in the brian network self . n = model . params [ \"N\" ] return self . as_array ( duration = model . params [ \"duration\" ], dt = model . params [ \"dt\" ]) update_params ( self , params_dict ) Update model input parameters. Parameters: Name Type Description Default params_dict dict New parameters for this input required Source code in neurolib/utils/stimulus.py def update_params ( self , params_dict ): \"\"\" Update model input parameters. :param params_dict: New parameters for this input :type params_dict: dict \"\"\" def _sanitize ( value ): \"\"\" Change string `None` to actual None - can happen with Exploration or Evolution, since `pypet` does None -> \"None\". \"\"\" if value == \"None\" : return None else : return value for param , value in params_dict . items (): if hasattr ( self , param ): setattr ( self , param , _sanitize ( value )) LinearRampInput ( Stimulus ) Linear ramp input. Source code in neurolib/utils/stimulus.py class LinearRampInput ( Stimulus ): \"\"\" Linear ramp input. \"\"\" def __init__ ( self , inp_max , ramp_length , start = None , end = None , n = 1 , seed = None , ): \"\"\" :param inp_max: Maximum of stimulus. :type inp_max: float :param ramp_length: Duration of linear ramp, in milliseconds :type ramp_length: float \"\"\" self . inp_max = inp_max self . ramp_length = ramp_length super () . __init__ ( start = start , end = end , n = n , seed = seed , ) def generate_input ( self , duration , dt ): self . _get_times ( duration = duration , dt = dt ) linear_inp = ( self . inp_max / self . ramp_length ) * self . times * ( self . times < self . ramp_length ) + self . inp_max * ( self . times >= self . ramp_length ) return self . _trim_stim ( np . vstack ([ linear_inp ] * self . n )) __init__ ( self , inp_max , ramp_length , start = None , end = None , n = 1 , seed = None ) special Parameters: Name Type Description Default inp_max float Maximum of stimulus. required ramp_length float Duration of linear ramp, in milliseconds required Source code in neurolib/utils/stimulus.py def __init__ ( self , inp_max , ramp_length , start = None , end = None , n = 1 , seed = None , ): \"\"\" :param inp_max: Maximum of stimulus. :type inp_max: float :param ramp_length: Duration of linear ramp, in milliseconds :type ramp_length: float \"\"\" self . inp_max = inp_max self . ramp_length = ramp_length super () . __init__ ( start = start , end = end , n = n , seed = seed , ) generate_input ( self , duration , dt ) Function to generate input. Parameters: Name Type Description Default duration float Duration of the input, in milliseconds required dt float dt of input, in milliseconds required Source code in neurolib/utils/stimulus.py def generate_input ( self , duration , dt ): self . _get_times ( duration = duration , dt = dt ) linear_inp = ( self . inp_max / self . ramp_length ) * self . times * ( self . times < self . ramp_length ) + self . inp_max * ( self . times >= self . ramp_length ) return self . _trim_stim ( np . vstack ([ linear_inp ] * self . n )) OrnsteinUhlenbeckProcess ( Input ) Ornstein\u2013Uhlenbeck input, i.e. dX = (mu - X)/tau * dt + sigma*dW Source code in neurolib/utils/stimulus.py class OrnsteinUhlenbeckProcess ( Input ): \"\"\" Ornstein\u2013Uhlenbeck input, i.e. dX = (mu - X)/tau * dt + sigma*dW \"\"\" def __init__ ( self , mu , sigma , tau , n = 1 , seed = None , ): \"\"\" :param mu: Drift of the OU process :type mu: float :param sigma: Standard deviation of the Wiener process, i.e. strength of the noise :type sigma: float :param tau: Timescale of the OU process, in ms :type tau: float \"\"\" self . mu = mu self . sigma = sigma self . tau = tau super () . __init__ ( n = n , seed = seed , ) def generate_input ( self , duration , dt ): self . _get_times ( duration = duration , dt = dt ) x = np . random . rand ( self . n , self . times . shape [ 0 ]) * self . mu return self . numba_ou ( x , self . times , dt , self . mu , self . sigma , self . tau , self . n ) @staticmethod @numba . njit () def numba_ou ( x , times , dt , mu , sigma , tau , n ): \"\"\" Generation of Ornstein-Uhlenback input - wrapped in numba's jit for speed. \"\"\" for i in range ( times . shape [ 0 ] - 1 ): x [:, i + 1 ] = x [:, i ] + dt * (( mu - x [:, i ]) / tau ) + sigma * np . sqrt ( dt ) * np . random . randn ( n ) return x __init__ ( self , mu , sigma , tau , n = 1 , seed = None ) special Parameters: Name Type Description Default mu float Drift of the OU process required sigma float Standard deviation of the Wiener process, i.e. strength of the noise required tau float Timescale of the OU process, in ms required Source code in neurolib/utils/stimulus.py def __init__ ( self , mu , sigma , tau , n = 1 , seed = None , ): \"\"\" :param mu: Drift of the OU process :type mu: float :param sigma: Standard deviation of the Wiener process, i.e. strength of the noise :type sigma: float :param tau: Timescale of the OU process, in ms :type tau: float \"\"\" self . mu = mu self . sigma = sigma self . tau = tau super () . __init__ ( n = n , seed = seed , ) generate_input ( self , duration , dt ) Function to generate input. Parameters: Name Type Description Default duration float Duration of the input, in milliseconds required dt float dt of input, in milliseconds required Source code in neurolib/utils/stimulus.py def generate_input ( self , duration , dt ): self . _get_times ( duration = duration , dt = dt ) x = np . random . rand ( self . n , self . times . shape [ 0 ]) * self . mu return self . numba_ou ( x , self . times , dt , self . mu , self . sigma , self . tau , self . n ) numba_ou ( x , times , dt , mu , sigma , tau , n ) staticmethod Generation of Ornstein-Uhlenback input - wrapped in numba's jit for speed. Source code in neurolib/utils/stimulus.py @staticmethod @numba . njit () def numba_ou ( x , times , dt , mu , sigma , tau , n ): \"\"\" Generation of Ornstein-Uhlenback input - wrapped in numba's jit for speed. \"\"\" for i in range ( times . shape [ 0 ] - 1 ): x [:, i + 1 ] = x [:, i ] + dt * (( mu - x [:, i ]) / tau ) + sigma * np . sqrt ( dt ) * np . random . randn ( n ) return x SinusoidalInput ( Stimulus ) Sinusoidal input. Source code in neurolib/utils/stimulus.py class SinusoidalInput ( Stimulus ): \"\"\" Sinusoidal input. \"\"\" def __init__ ( self , amplitude , frequency , dc_bias = False , start = None , end = None , n = 1 , seed = None , ): \"\"\" :param amplitude: Amplitude of the sinusoid. :type amplitude: float :param frequency: Frequency of the sinus oscillation, in Hz :type frequency: float :param dc_bias: Whether the sinusoid oscillates around 0 (False), or has a positive DC bias, thus non-negative (True). :type dc_bias: bool \"\"\" self . amplitude = amplitude self . frequency = frequency self . dc_bias = dc_bias super () . __init__ ( start = start , end = end , n = n , seed = seed , ) def generate_input ( self , duration , dt ): self . _get_times ( duration = duration , dt = dt ) sinusoid = self . amplitude * np . sin ( 2 * np . pi * self . times * ( self . frequency / 1000.0 )) if self . dc_bias : sinusoid += self . amplitude return self . _trim_stim ( np . vstack ([ sinusoid ] * self . n )) __init__ ( self , amplitude , frequency , dc_bias = False , start = None , end = None , n = 1 , seed = None ) special Parameters: Name Type Description Default amplitude float Amplitude of the sinusoid. required frequency float Frequency of the sinus oscillation, in Hz required dc_bias bool Whether the sinusoid oscillates around 0 (False), or has a positive DC bias, thus non-negative (True). False Source code in neurolib/utils/stimulus.py def __init__ ( self , amplitude , frequency , dc_bias = False , start = None , end = None , n = 1 , seed = None , ): \"\"\" :param amplitude: Amplitude of the sinusoid. :type amplitude: float :param frequency: Frequency of the sinus oscillation, in Hz :type frequency: float :param dc_bias: Whether the sinusoid oscillates around 0 (False), or has a positive DC bias, thus non-negative (True). :type dc_bias: bool \"\"\" self . amplitude = amplitude self . frequency = frequency self . dc_bias = dc_bias super () . __init__ ( start = start , end = end , n = n , seed = seed , ) generate_input ( self , duration , dt ) Function to generate input. Parameters: Name Type Description Default duration float Duration of the input, in milliseconds required dt float dt of input, in milliseconds required Source code in neurolib/utils/stimulus.py def generate_input ( self , duration , dt ): self . _get_times ( duration = duration , dt = dt ) sinusoid = self . amplitude * np . sin ( 2 * np . pi * self . times * ( self . frequency / 1000.0 )) if self . dc_bias : sinusoid += self . amplitude return self . _trim_stim ( np . vstack ([ sinusoid ] * self . n )) SquareInput ( Stimulus ) Oscillatory square input. Source code in neurolib/utils/stimulus.py class SquareInput ( Stimulus ): \"\"\" Oscillatory square input. \"\"\" def __init__ ( self , amplitude , frequency , dc_bias = False , start = None , end = None , n = 1 , seed = None , ): \"\"\" :param amplitude: Amplitude of the square :type amplitude: float :param frequency: Frequency of the square oscillation, in Hz :type frequency: float :param dc_bias: Whether the square oscillates around 0 (False), or has a positive DC bias, thus non-negative (True). :type dc_bias: bool \"\"\" self . amplitude = amplitude self . frequency = frequency self . dc_bias = dc_bias super () . __init__ ( start = start , end = end , n = n , seed = seed , ) def generate_input ( self , duration , dt ): self . _get_times ( duration = duration , dt = dt ) square_inp = self . amplitude * square ( 2 * np . pi * self . times * ( self . frequency / 1000.0 )) if self . dc_bias : square_inp += self . amplitude return self . _trim_stim ( np . vstack ([ square_inp ] * self . n )) __init__ ( self , amplitude , frequency , dc_bias = False , start = None , end = None , n = 1 , seed = None ) special Parameters: Name Type Description Default amplitude float Amplitude of the square required frequency float Frequency of the square oscillation, in Hz required dc_bias bool Whether the square oscillates around 0 (False), or has a positive DC bias, thus non-negative (True). False Source code in neurolib/utils/stimulus.py def __init__ ( self , amplitude , frequency , dc_bias = False , start = None , end = None , n = 1 , seed = None , ): \"\"\" :param amplitude: Amplitude of the square :type amplitude: float :param frequency: Frequency of the square oscillation, in Hz :type frequency: float :param dc_bias: Whether the square oscillates around 0 (False), or has a positive DC bias, thus non-negative (True). :type dc_bias: bool \"\"\" self . amplitude = amplitude self . frequency = frequency self . dc_bias = dc_bias super () . __init__ ( start = start , end = end , n = n , seed = seed , ) generate_input ( self , duration , dt ) Function to generate input. Parameters: Name Type Description Default duration float Duration of the input, in milliseconds required dt float dt of input, in milliseconds required Source code in neurolib/utils/stimulus.py def generate_input ( self , duration , dt ): self . _get_times ( duration = duration , dt = dt ) square_inp = self . amplitude * square ( 2 * np . pi * self . times * ( self . frequency / 1000.0 )) if self . dc_bias : square_inp += self . amplitude return self . _trim_stim ( np . vstack ([ square_inp ] * self . n )) StepInput ( Stimulus ) Step input. Source code in neurolib/utils/stimulus.py class StepInput ( Stimulus ): \"\"\" Step input. \"\"\" def __init__ ( self , step_size , start = None , end = None , n = 1 , seed = None , ): \"\"\" :param step_size: Size of the step, i.e., the amplitude. :type step_size: float \"\"\" self . step_size = step_size super () . __init__ ( start = start , end = end , n = n , seed = seed , ) def generate_input ( self , duration , dt ): self . _get_times ( duration = duration , dt = dt ) return self . _trim_stim ( np . ones (( self . n , self . times . shape [ 0 ])) * self . step_size ) __init__ ( self , step_size , start = None , end = None , n = 1 , seed = None ) special Parameters: Name Type Description Default step_size float Size of the step, i.e., the amplitude. required Source code in neurolib/utils/stimulus.py def __init__ ( self , step_size , start = None , end = None , n = 1 , seed = None , ): \"\"\" :param step_size: Size of the step, i.e., the amplitude. :type step_size: float \"\"\" self . step_size = step_size super () . __init__ ( start = start , end = end , n = n , seed = seed , ) generate_input ( self , duration , dt ) Function to generate input. Parameters: Name Type Description Default duration float Duration of the input, in milliseconds required dt float dt of input, in milliseconds required Source code in neurolib/utils/stimulus.py def generate_input ( self , duration , dt ): self . _get_times ( duration = duration , dt = dt ) return self . _trim_stim ( np . ones (( self . n , self . times . shape [ 0 ])) * self . step_size ) Stimulus ( Input ) Generates a stimulus with optional start and end times. Source code in neurolib/utils/stimulus.py class Stimulus ( Input ): \"\"\" Generates a stimulus with optional start and end times. \"\"\" def __init__ ( self , start = None , end = None , n = 1 , seed = None , ): \"\"\" :param start: start of the stimulus, in milliseconds :type start: float :param end: end of the stimulus, in milliseconds :type end: float \"\"\" self . start = start self . end = end self . _default_start = start self . _default_end = end super () . __init__ ( n = n , seed = seed , ) def _reset ( self ): self . start = self . _default_start self . end = self . _default_end def _get_times ( self , duration , dt ): super () . _get_times ( duration = duration , dt = dt ) self . start = self . start or 0.0 self . end = self . end or duration + dt assert self . start < duration assert self . end <= duration + dt def _trim_stim ( self , stim_input ): \"\"\" Trim stimulus. Translate the start of the stimulus by padding the beginning and replace the end with zeros. \"\"\" # trim start how_much = int ( np . sum ( self . times <= self . start )) # translate start of the stim by padding the beginning with zeros stim_input = np . pad ( stim_input , (( 0 , 0 ), ( how_much , 0 )), mode = \"constant\" ) if how_much > 0 : stim_input = stim_input [:, : - how_much ] # trim end stim_input [:, self . times > self . end ] = 0.0 return stim_input __init__ ( self , start = None , end = None , n = 1 , seed = None ) special Parameters: Name Type Description Default start float start of the stimulus, in milliseconds None end float end of the stimulus, in milliseconds None Source code in neurolib/utils/stimulus.py def __init__ ( self , start = None , end = None , n = 1 , seed = None , ): \"\"\" :param start: start of the stimulus, in milliseconds :type start: float :param end: end of the stimulus, in milliseconds :type end: float \"\"\" self . start = start self . end = end self . _default_start = start self . _default_end = end super () . __init__ ( n = n , seed = seed , ) SummedStimulus ( BaseMultipleInputs ) Represents the summation of arbitrary many stimuli. Example: summed_stimulus = SinusoidalInput(...) + OrnsteinUhlenbeckProcess(...) Source code in neurolib/utils/stimulus.py class SummedStimulus ( BaseMultipleInputs ): \"\"\" Represents the summation of arbitrary many stimuli. Example: ``` summed_stimulus = SinusoidalInput(...) + OrnsteinUhlenbeckProcess(...) ``` \"\"\" def __add__ ( self , other ): assert isinstance ( other , Input ) assert self . n == other . n if isinstance ( other , SummedStimulus ): return SummedStimulus ( inputs = self . inputs + other . inputs ) else : return SummedStimulus ( inputs = self . inputs + [ other ]) def as_array ( self , duration , dt ): \"\"\" Return sum of all inputes as numpy array. \"\"\" return np . sum ( np . stack ([ input . as_array ( duration , dt ) for input in self . inputs ]), axis = 0 , ) def as_cubic_splines ( self , duration , dt , shift_start_time = 0.0 ): \"\"\" Return sum of all inputes as cubic Hermite splines. \"\"\" result = self . inputs [ 0 ] . as_cubic_splines ( duration , dt , shift_start_time ) for input in self . inputs [ 1 :]: result . plus ( input . as_cubic_splines ( duration , dt , shift_start_time )) return result as_array ( self , duration , dt ) Return sum of all inputes as numpy array. Source code in neurolib/utils/stimulus.py def as_array ( self , duration , dt ): \"\"\" Return sum of all inputes as numpy array. \"\"\" return np . sum ( np . stack ([ input . as_array ( duration , dt ) for input in self . inputs ]), axis = 0 , ) as_cubic_splines ( self , duration , dt , shift_start_time = 0.0 ) Return sum of all inputes as cubic Hermite splines. Source code in neurolib/utils/stimulus.py def as_cubic_splines ( self , duration , dt , shift_start_time = 0.0 ): \"\"\" Return sum of all inputes as cubic Hermite splines. \"\"\" result = self . inputs [ 0 ] . as_cubic_splines ( duration , dt , shift_start_time ) for input in self . inputs [ 1 :]: result . plus ( input . as_cubic_splines ( duration , dt , shift_start_time )) return result WienerProcess ( Input ) Stimulus sampled from a Wiener process, i.e. drawn from standard normal distribution N(0, sqrt(dt)). Source code in neurolib/utils/stimulus.py class WienerProcess ( Input ): \"\"\" Stimulus sampled from a Wiener process, i.e. drawn from standard normal distribution N(0, sqrt(dt)). \"\"\" def generate_input ( self , duration , dt ): self . _get_times ( duration = duration , dt = dt ) return np . random . normal ( 0.0 , np . sqrt ( dt ), ( self . n , self . times . shape [ 0 ])) generate_input ( self , duration , dt ) Function to generate input. Parameters: Name Type Description Default duration float Duration of the input, in milliseconds required dt float dt of input, in milliseconds required Source code in neurolib/utils/stimulus.py def generate_input ( self , duration , dt ): self . _get_times ( duration = duration , dt = dt ) return np . random . normal ( 0.0 , np . sqrt ( dt ), ( self . n , self . times . shape [ 0 ])) ZeroInput ( Input ) No stimulus, i.e. all zeros. Can be used to add a delay between two stimuli. Source code in neurolib/utils/stimulus.py class ZeroInput ( Input ): \"\"\" No stimulus, i.e. all zeros. Can be used to add a delay between two stimuli. \"\"\" def generate_input ( self , duration , dt ): self . _get_times ( duration = duration , dt = dt ) return np . zeros (( self . n , self . times . shape [ 0 ])) generate_input ( self , duration , dt ) Function to generate input. Parameters: Name Type Description Default duration float Duration of the input, in milliseconds required dt float dt of input, in milliseconds required Source code in neurolib/utils/stimulus.py def generate_input ( self , duration , dt ): self . _get_times ( duration = duration , dt = dt ) return np . zeros (( self . n , self . times . shape [ 0 ])) RectifiedInput ( amplitude , n = 1 ) Return rectified input with exponential decay, i.e. a negative step followed by a slow decay to zero, followed by a positive step and again a slow decay to zero. Can be used for bistablity detection. Parameters: Name Type Description Default amplitude float Amplitude (both negative and positive) for the step required n int Number of realizations (spatial dimension) 1 Returns: Type Description `ConctatenatedInput` Concatenated input which represents the rectified stimulus with exponential decay Source code in neurolib/utils/stimulus.py def RectifiedInput ( amplitude , n = 1 ): \"\"\" Return rectified input with exponential decay, i.e. a negative step followed by a slow decay to zero, followed by a positive step and again a slow decay to zero. Can be used for bistablity detection. :param amplitude: Amplitude (both negative and positive) for the step :type amplitude: float :param n: Number of realizations (spatial dimension) :type n: int :return: Concatenated input which represents the rectified stimulus with exponential decay :rtype: `ConctatenatedInput` \"\"\" return ConcatenatedStimulus ( [ StepInput ( step_size =- amplitude , n = n ), ExponentialInput ( inp_max = amplitude , exp_type = \"rise\" , exp_coef = 12.5 , n = n ) + StepInput ( step_size =- amplitude , n = n ), StepInput ( step_size = amplitude , n = n ), ExponentialInput ( amplitude , exp_type = \"decay\" , exp_coef = 7.5 , n = n ), StepInput ( step_size = 0.0 , n = n ), ], length_ratios = [ 0.5 , 2.5 , 0.5 , 1.5 , 1.0 ], )","title":"Stimulus"},{"location":"utils/stimulus/#stimulus","text":"Functions for creating stimuli and noise inputs for models.","title":"Stimulus"},{"location":"utils/stimulus/#neurolib.utils.stimulus.BaseMultipleInputs","text":"Base class for stimuli consisting of multiple time series, such as summed inputs or concatenated inputs. Source code in neurolib/utils/stimulus.py class BaseMultipleInputs ( Stimulus ): \"\"\" Base class for stimuli consisting of multiple time series, such as summed inputs or concatenated inputs. \"\"\" def __init__ ( self , inputs ): \"\"\" :param inputs: List of Inputs to combine :type inputs: list[`Input`] \"\"\" assert all ( isinstance ( input , Input ) for input in inputs ) self . inputs = inputs def __len__ ( self ): \"\"\" Return number of inputs. \"\"\" return len ( self . inputs ) def __getitem__ ( self , index ): \"\"\" Return inputs by index. This also allows iteration. \"\"\" return self . inputs [ index ] @property def n ( self ): n = set ([ input . n for input in self ]) assert len ( n ) == 1 return next ( iter ( n )) @n . setter def n ( self , n ): for input in self : input . n = n def get_params ( self ): \"\"\" Get all parameters recursively for all inputs. \"\"\" return { \"type\" : self . __class__ . __name__ , ** { f \"input_ { i } \" : input . get_params () for i , input in enumerate ( self )}, } def update_params ( self , params_dict ): \"\"\" Update all parameters recursively. \"\"\" for i , input in enumerate ( self ): input . update_params ( params_dict . get ( f \"input_ { i } \" , {}))","title":"BaseMultipleInputs"},{"location":"utils/stimulus/#neurolib.utils.stimulus.BaseMultipleInputs.__getitem__","text":"Return inputs by index. This also allows iteration. Source code in neurolib/utils/stimulus.py def __getitem__ ( self , index ): \"\"\" Return inputs by index. This also allows iteration. \"\"\" return self . inputs [ index ]","title":"__getitem__()"},{"location":"utils/stimulus/#neurolib.utils.stimulus.BaseMultipleInputs.__init__","text":"Parameters: Name Type Description Default inputs list[`Input`] List of Inputs to combine required Source code in neurolib/utils/stimulus.py def __init__ ( self , inputs ): \"\"\" :param inputs: List of Inputs to combine :type inputs: list[`Input`] \"\"\" assert all ( isinstance ( input , Input ) for input in inputs ) self . inputs = inputs","title":"__init__()"},{"location":"utils/stimulus/#neurolib.utils.stimulus.BaseMultipleInputs.__len__","text":"Return number of inputs. Source code in neurolib/utils/stimulus.py def __len__ ( self ): \"\"\" Return number of inputs. \"\"\" return len ( self . inputs )","title":"__len__()"},{"location":"utils/stimulus/#neurolib.utils.stimulus.BaseMultipleInputs.get_params","text":"Get all parameters recursively for all inputs. Source code in neurolib/utils/stimulus.py def get_params ( self ): \"\"\" Get all parameters recursively for all inputs. \"\"\" return { \"type\" : self . __class__ . __name__ , ** { f \"input_ { i } \" : input . get_params () for i , input in enumerate ( self )}, }","title":"get_params()"},{"location":"utils/stimulus/#neurolib.utils.stimulus.BaseMultipleInputs.update_params","text":"Update all parameters recursively. Source code in neurolib/utils/stimulus.py def update_params ( self , params_dict ): \"\"\" Update all parameters recursively. \"\"\" for i , input in enumerate ( self ): input . update_params ( params_dict . get ( f \"input_ { i } \" , {}))","title":"update_params()"},{"location":"utils/stimulus/#neurolib.utils.stimulus.ConcatenatedStimulus","text":"Represents temporal concatenation of of arbitrary many stimuli. Example: summed_stimulus = SinusoidalInput(...) & OrnsteinUhlenbeckProcess(...) Source code in neurolib/utils/stimulus.py class ConcatenatedStimulus ( BaseMultipleInputs ): \"\"\" Represents temporal concatenation of of arbitrary many stimuli. Example: ``` summed_stimulus = SinusoidalInput(...) & OrnsteinUhlenbeckProcess(...) ``` \"\"\" def __init__ ( self , inputs , length_ratios = None ): \"\"\" :param length_ratios: Ratios of lengths of concatenated stimuli :type length_ratios: list[int|float] \"\"\" if length_ratios is None : length_ratios = [ 1 ] * len ( inputs ) assert len ( inputs ) == len ( length_ratios ) assert all ( length > 0 for length in length_ratios ) self . length_ratios = length_ratios super () . __init__ ( inputs ) def __and__ ( self , other ): assert isinstance ( other , Input ) assert self . n == other . n if isinstance ( other , ConcatenatedStimulus ): return ConcatenatedStimulus ( inputs = self . inputs + other . inputs , length_ratios = self . length_ratios + other . length_ratios , ) else : return ConcatenatedStimulus ( inputs = self . inputs + [ other ], length_ratios = self . length_ratios + [ 1 ]) def as_array ( self , duration , dt ): \"\"\" Return concatenation of all stimuli as numpy array. \"\"\" # normalize ratios to sum = 1 ratios = [ i / sum ( self . length_ratios ) for i in self . length_ratios ] concat = np . concatenate ( [ input . as_array ( duration * ratio , dt ) for input , ratio in zip ( self . inputs , ratios )], axis = 1 , ) length = int ( duration / dt ) # due to rounding errors, the overall length might be longer by a few dt return concat [:, : length ] def as_cubic_splines ( self , duration , dt , shift_start_time = 0.0 ): # normalize ratios to sum = 1 ratios = [ i / sum ( self . length_ratios ) for i in self . length_ratios ] result = self . inputs [ 0 ] . as_cubic_splines ( duration * ratios [ 0 ], dt , shift_start_time ) for input , ratio in zip ( self . inputs [ 1 :], ratios [ 1 :]): last_time = result [ - 1 ] . time temp = input . as_cubic_splines ( duration * ratio , dt , shift_start_time = last_time ) # `extend` adds an iteratable (whole `CubicHermiteSpline` is an # iterable of `Anchors`) to the current spline result . extend ( temp ) return result","title":"ConcatenatedStimulus"},{"location":"utils/stimulus/#neurolib.utils.stimulus.ConcatenatedStimulus.__init__","text":"Parameters: Name Type Description Default length_ratios list[int|float] Ratios of lengths of concatenated stimuli None Source code in neurolib/utils/stimulus.py def __init__ ( self , inputs , length_ratios = None ): \"\"\" :param length_ratios: Ratios of lengths of concatenated stimuli :type length_ratios: list[int|float] \"\"\" if length_ratios is None : length_ratios = [ 1 ] * len ( inputs ) assert len ( inputs ) == len ( length_ratios ) assert all ( length > 0 for length in length_ratios ) self . length_ratios = length_ratios super () . __init__ ( inputs )","title":"__init__()"},{"location":"utils/stimulus/#neurolib.utils.stimulus.ConcatenatedStimulus.as_array","text":"Return concatenation of all stimuli as numpy array. Source code in neurolib/utils/stimulus.py def as_array ( self , duration , dt ): \"\"\" Return concatenation of all stimuli as numpy array. \"\"\" # normalize ratios to sum = 1 ratios = [ i / sum ( self . length_ratios ) for i in self . length_ratios ] concat = np . concatenate ( [ input . as_array ( duration * ratio , dt ) for input , ratio in zip ( self . inputs , ratios )], axis = 1 , ) length = int ( duration / dt ) # due to rounding errors, the overall length might be longer by a few dt return concat [:, : length ]","title":"as_array()"},{"location":"utils/stimulus/#neurolib.utils.stimulus.ConcatenatedStimulus.as_cubic_splines","text":"Return as cubic Hermite splines. Parameters: Name Type Description Default duration float Duration of the input, in milliseconds required dt float dt of input, in milliseconds required shift_start_time float By how much to shift the stimulus start time 0.0 Source code in neurolib/utils/stimulus.py def as_cubic_splines ( self , duration , dt , shift_start_time = 0.0 ): # normalize ratios to sum = 1 ratios = [ i / sum ( self . length_ratios ) for i in self . length_ratios ] result = self . inputs [ 0 ] . as_cubic_splines ( duration * ratios [ 0 ], dt , shift_start_time ) for input , ratio in zip ( self . inputs [ 1 :], ratios [ 1 :]): last_time = result [ - 1 ] . time temp = input . as_cubic_splines ( duration * ratio , dt , shift_start_time = last_time ) # `extend` adds an iteratable (whole `CubicHermiteSpline` is an # iterable of `Anchors`) to the current spline result . extend ( temp ) return result","title":"as_cubic_splines()"},{"location":"utils/stimulus/#neurolib.utils.stimulus.ExponentialInput","text":"Exponential rise or decay input. Source code in neurolib/utils/stimulus.py class ExponentialInput ( Stimulus ): \"\"\" Exponential rise or decay input. \"\"\" def __init__ ( self , inp_max , exp_coef = 30.0 , exp_type = \"rise\" , start = None , end = None , n = 1 , seed = None , ): \"\"\" :param inp_max: Maximum of stimulus. :type inp_max: float :param exp_coeficient: Coeffiecent for the exponential (the higher the coefficient, the faster it rises or decays). :type exp_coeficient: float :param exp_type: Whether to \"rise\" or to \"decay\". :type exp_type: str \"\"\" self . inp_max = inp_max self . exp_coef = exp_coef assert exp_type in [ \"rise\" , \"decay\" ] self . exp_type = exp_type super () . __init__ ( start = start , end = end , n = n , seed = seed , ) def generate_input ( self , duration , dt ): self . _get_times ( duration = duration , dt = dt ) exponential = np . exp ( - ( self . exp_coef / self . times [ - 1 ]) * self . times ) * self . inp_max if self . exp_type == \"rise\" : exponential = - exponential + self . inp_max return self . _trim_stim ( np . vstack ([ exponential ] * self . n ))","title":"ExponentialInput"},{"location":"utils/stimulus/#neurolib.utils.stimulus.ExponentialInput.__init__","text":"Parameters: Name Type Description Default inp_max float Maximum of stimulus. required exp_coeficient float Coeffiecent for the exponential (the higher the coefficient, the faster it rises or decays). required exp_type str Whether to \"rise\" or to \"decay\". 'rise' Source code in neurolib/utils/stimulus.py def __init__ ( self , inp_max , exp_coef = 30.0 , exp_type = \"rise\" , start = None , end = None , n = 1 , seed = None , ): \"\"\" :param inp_max: Maximum of stimulus. :type inp_max: float :param exp_coeficient: Coeffiecent for the exponential (the higher the coefficient, the faster it rises or decays). :type exp_coeficient: float :param exp_type: Whether to \"rise\" or to \"decay\". :type exp_type: str \"\"\" self . inp_max = inp_max self . exp_coef = exp_coef assert exp_type in [ \"rise\" , \"decay\" ] self . exp_type = exp_type super () . __init__ ( start = start , end = end , n = n , seed = seed , )","title":"__init__()"},{"location":"utils/stimulus/#neurolib.utils.stimulus.ExponentialInput.generate_input","text":"Function to generate input. Parameters: Name Type Description Default duration float Duration of the input, in milliseconds required dt float dt of input, in milliseconds required Source code in neurolib/utils/stimulus.py def generate_input ( self , duration , dt ): self . _get_times ( duration = duration , dt = dt ) exponential = np . exp ( - ( self . exp_coef / self . times [ - 1 ]) * self . times ) * self . inp_max if self . exp_type == \"rise\" : exponential = - exponential + self . inp_max return self . _trim_stim ( np . vstack ([ exponential ] * self . n ))","title":"generate_input()"},{"location":"utils/stimulus/#neurolib.utils.stimulus.Input","text":"Generates input to model. Base class for other input types. Source code in neurolib/utils/stimulus.py class Input : \"\"\" Generates input to model. Base class for other input types. \"\"\" def __init__ ( self , n = 1 , seed = None ): \"\"\" :param n: Number of spatial dimensions / independent realizations of the input. For determinstic inputs, the array is just copied, for stociastic / noisy inputs, this means independent realizations. :type n: int :param seed: Seed for the random number generator. :type seed: int|None \"\"\" self . n = n self . seed = seed # seed the generator np . random . seed ( seed ) # get parameter names self . param_names = inspect . getfullargspec ( self . __init__ ) . args self . param_names . remove ( \"self\" ) def __add__ ( self , other ): \"\"\" Sum two inputs into one SummedStimulus. \"\"\" assert isinstance ( other , Input ) assert self . n == other . n if isinstance ( other , SummedStimulus ): return SummedStimulus ( inputs = [ self ] + other . inputs ) else : return SummedStimulus ( inputs = [ self , other ]) def __and__ ( self , other ): \"\"\" Concatenate two inputs into ConcatenatedStimulus. \"\"\" assert isinstance ( other , Input ) assert self . n == other . n if isinstance ( other , ConcatenatedStimulus ): return ConcatenatedStimulus ( inputs = [ self ] + other . inputs , length_ratios = [ 1 ] + other . length_ratios ) else : return ConcatenatedStimulus ( inputs = [ self , other ]) def _reset ( self ): \"\"\" Reset is called after generating an input. Can be used to reset intrinsic properties. \"\"\" pass def get_params ( self ): \"\"\" Return the parameters of the input as dict. \"\"\" assert all ( hasattr ( self , name ) for name in self . param_names ), self . param_names params = { name : getattr ( self , name ) for name in self . param_names } return { \"type\" : self . __class__ . __name__ , ** params } def update_params ( self , params_dict ): \"\"\" Update model input parameters. :param params_dict: New parameters for this input :type params_dict: dict \"\"\" def _sanitize ( value ): \"\"\" Change string `None` to actual None - can happen with Exploration or Evolution, since `pypet` does None -> \"None\". \"\"\" if value == \"None\" : return None else : return value for param , value in params_dict . items (): if hasattr ( self , param ): setattr ( self , param , _sanitize ( value )) def _get_times ( self , duration , dt ): \"\"\" Generate time vector. :param duration: Duration of the input, in milliseconds :type duration: float :param dt: dt of input, in milliseconds :type dt: float \"\"\" self . times = np . arange ( dt , duration + dt , dt ) def generate_input ( self , duration , dt ): \"\"\" Function to generate input. :param duration: Duration of the input, in milliseconds :type duration: float :param dt: dt of input, in milliseconds :type dt: float \"\"\" raise NotImplementedError def as_array ( self , duration , dt ): \"\"\" Return input as numpy array. :param duration: Duration of the input, in milliseconds :type duration: float :param dt: dt of input, in milliseconds :type dt: float \"\"\" array = self . generate_input ( duration , dt ) self . _reset () return array def as_cubic_splines ( self , duration , dt , shift_start_time = 0.0 ): \"\"\" Return as cubic Hermite splines. :param duration: Duration of the input, in milliseconds :type duration: float :param dt: dt of input, in milliseconds :type dt: float :param shift_start_time: By how much to shift the stimulus start time :type shift_start_time: float \"\"\" self . _get_times ( duration , dt ) splines = CubicHermiteSpline . from_data ( self . times + shift_start_time , self . generate_input ( duration , dt ) . T ) self . _reset () return splines def to_model ( self , model ): \"\"\" Return numpy array of stimuli based on model parameters. Example: ``` model.params[\"ext_exc_input\"] = SinusoidalInput(...).to_model(model) ``` :param model: neurolib's model :type model: `neurolib.models.Model` \"\"\" assert isinstance ( model , Model ) # set number of spatial dimensions as the number of nodes in the brian network self . n = model . params [ \"N\" ] return self . as_array ( duration = model . params [ \"duration\" ], dt = model . params [ \"dt\" ])","title":"Input"},{"location":"utils/stimulus/#neurolib.utils.stimulus.Input.__add__","text":"Sum two inputs into one SummedStimulus. Source code in neurolib/utils/stimulus.py def __add__ ( self , other ): \"\"\" Sum two inputs into one SummedStimulus. \"\"\" assert isinstance ( other , Input ) assert self . n == other . n if isinstance ( other , SummedStimulus ): return SummedStimulus ( inputs = [ self ] + other . inputs ) else : return SummedStimulus ( inputs = [ self , other ])","title":"__add__()"},{"location":"utils/stimulus/#neurolib.utils.stimulus.Input.__and__","text":"Concatenate two inputs into ConcatenatedStimulus. Source code in neurolib/utils/stimulus.py def __and__ ( self , other ): \"\"\" Concatenate two inputs into ConcatenatedStimulus. \"\"\" assert isinstance ( other , Input ) assert self . n == other . n if isinstance ( other , ConcatenatedStimulus ): return ConcatenatedStimulus ( inputs = [ self ] + other . inputs , length_ratios = [ 1 ] + other . length_ratios ) else : return ConcatenatedStimulus ( inputs = [ self , other ])","title":"__and__()"},{"location":"utils/stimulus/#neurolib.utils.stimulus.Input.__init__","text":"Parameters: Name Type Description Default n int Number of spatial dimensions / independent realizations of the input. For determinstic inputs, the array is just copied, for stociastic / noisy inputs, this means independent realizations. 1 seed int|None Seed for the random number generator. None Source code in neurolib/utils/stimulus.py def __init__ ( self , n = 1 , seed = None ): \"\"\" :param n: Number of spatial dimensions / independent realizations of the input. For determinstic inputs, the array is just copied, for stociastic / noisy inputs, this means independent realizations. :type n: int :param seed: Seed for the random number generator. :type seed: int|None \"\"\" self . n = n self . seed = seed # seed the generator np . random . seed ( seed ) # get parameter names self . param_names = inspect . getfullargspec ( self . __init__ ) . args self . param_names . remove ( \"self\" )","title":"__init__()"},{"location":"utils/stimulus/#neurolib.utils.stimulus.Input.as_array","text":"Return input as numpy array. Parameters: Name Type Description Default duration float Duration of the input, in milliseconds required dt float dt of input, in milliseconds required Source code in neurolib/utils/stimulus.py def as_array ( self , duration , dt ): \"\"\" Return input as numpy array. :param duration: Duration of the input, in milliseconds :type duration: float :param dt: dt of input, in milliseconds :type dt: float \"\"\" array = self . generate_input ( duration , dt ) self . _reset () return array","title":"as_array()"},{"location":"utils/stimulus/#neurolib.utils.stimulus.Input.as_cubic_splines","text":"Return as cubic Hermite splines. Parameters: Name Type Description Default duration float Duration of the input, in milliseconds required dt float dt of input, in milliseconds required shift_start_time float By how much to shift the stimulus start time 0.0 Source code in neurolib/utils/stimulus.py def as_cubic_splines ( self , duration , dt , shift_start_time = 0.0 ): \"\"\" Return as cubic Hermite splines. :param duration: Duration of the input, in milliseconds :type duration: float :param dt: dt of input, in milliseconds :type dt: float :param shift_start_time: By how much to shift the stimulus start time :type shift_start_time: float \"\"\" self . _get_times ( duration , dt ) splines = CubicHermiteSpline . from_data ( self . times + shift_start_time , self . generate_input ( duration , dt ) . T ) self . _reset () return splines","title":"as_cubic_splines()"},{"location":"utils/stimulus/#neurolib.utils.stimulus.Input.generate_input","text":"Function to generate input. Parameters: Name Type Description Default duration float Duration of the input, in milliseconds required dt float dt of input, in milliseconds required Source code in neurolib/utils/stimulus.py def generate_input ( self , duration , dt ): \"\"\" Function to generate input. :param duration: Duration of the input, in milliseconds :type duration: float :param dt: dt of input, in milliseconds :type dt: float \"\"\" raise NotImplementedError","title":"generate_input()"},{"location":"utils/stimulus/#neurolib.utils.stimulus.Input.get_params","text":"Return the parameters of the input as dict. Source code in neurolib/utils/stimulus.py def get_params ( self ): \"\"\" Return the parameters of the input as dict. \"\"\" assert all ( hasattr ( self , name ) for name in self . param_names ), self . param_names params = { name : getattr ( self , name ) for name in self . param_names } return { \"type\" : self . __class__ . __name__ , ** params }","title":"get_params()"},{"location":"utils/stimulus/#neurolib.utils.stimulus.Input.to_model","text":"Return numpy array of stimuli based on model parameters. Example: model.params[\"ext_exc_input\"] = SinusoidalInput(...).to_model(model) Parameters: Name Type Description Default model `neurolib.models.Model` neurolib's model required Source code in neurolib/utils/stimulus.py def to_model ( self , model ): \"\"\" Return numpy array of stimuli based on model parameters. Example: ``` model.params[\"ext_exc_input\"] = SinusoidalInput(...).to_model(model) ``` :param model: neurolib's model :type model: `neurolib.models.Model` \"\"\" assert isinstance ( model , Model ) # set number of spatial dimensions as the number of nodes in the brian network self . n = model . params [ \"N\" ] return self . as_array ( duration = model . params [ \"duration\" ], dt = model . params [ \"dt\" ])","title":"to_model()"},{"location":"utils/stimulus/#neurolib.utils.stimulus.Input.update_params","text":"Update model input parameters. Parameters: Name Type Description Default params_dict dict New parameters for this input required Source code in neurolib/utils/stimulus.py def update_params ( self , params_dict ): \"\"\" Update model input parameters. :param params_dict: New parameters for this input :type params_dict: dict \"\"\" def _sanitize ( value ): \"\"\" Change string `None` to actual None - can happen with Exploration or Evolution, since `pypet` does None -> \"None\". \"\"\" if value == \"None\" : return None else : return value for param , value in params_dict . items (): if hasattr ( self , param ): setattr ( self , param , _sanitize ( value ))","title":"update_params()"},{"location":"utils/stimulus/#neurolib.utils.stimulus.LinearRampInput","text":"Linear ramp input. Source code in neurolib/utils/stimulus.py class LinearRampInput ( Stimulus ): \"\"\" Linear ramp input. \"\"\" def __init__ ( self , inp_max , ramp_length , start = None , end = None , n = 1 , seed = None , ): \"\"\" :param inp_max: Maximum of stimulus. :type inp_max: float :param ramp_length: Duration of linear ramp, in milliseconds :type ramp_length: float \"\"\" self . inp_max = inp_max self . ramp_length = ramp_length super () . __init__ ( start = start , end = end , n = n , seed = seed , ) def generate_input ( self , duration , dt ): self . _get_times ( duration = duration , dt = dt ) linear_inp = ( self . inp_max / self . ramp_length ) * self . times * ( self . times < self . ramp_length ) + self . inp_max * ( self . times >= self . ramp_length ) return self . _trim_stim ( np . vstack ([ linear_inp ] * self . n ))","title":"LinearRampInput"},{"location":"utils/stimulus/#neurolib.utils.stimulus.LinearRampInput.__init__","text":"Parameters: Name Type Description Default inp_max float Maximum of stimulus. required ramp_length float Duration of linear ramp, in milliseconds required Source code in neurolib/utils/stimulus.py def __init__ ( self , inp_max , ramp_length , start = None , end = None , n = 1 , seed = None , ): \"\"\" :param inp_max: Maximum of stimulus. :type inp_max: float :param ramp_length: Duration of linear ramp, in milliseconds :type ramp_length: float \"\"\" self . inp_max = inp_max self . ramp_length = ramp_length super () . __init__ ( start = start , end = end , n = n , seed = seed , )","title":"__init__()"},{"location":"utils/stimulus/#neurolib.utils.stimulus.LinearRampInput.generate_input","text":"Function to generate input. Parameters: Name Type Description Default duration float Duration of the input, in milliseconds required dt float dt of input, in milliseconds required Source code in neurolib/utils/stimulus.py def generate_input ( self , duration , dt ): self . _get_times ( duration = duration , dt = dt ) linear_inp = ( self . inp_max / self . ramp_length ) * self . times * ( self . times < self . ramp_length ) + self . inp_max * ( self . times >= self . ramp_length ) return self . _trim_stim ( np . vstack ([ linear_inp ] * self . n ))","title":"generate_input()"},{"location":"utils/stimulus/#neurolib.utils.stimulus.OrnsteinUhlenbeckProcess","text":"Ornstein\u2013Uhlenbeck input, i.e. dX = (mu - X)/tau * dt + sigma*dW Source code in neurolib/utils/stimulus.py class OrnsteinUhlenbeckProcess ( Input ): \"\"\" Ornstein\u2013Uhlenbeck input, i.e. dX = (mu - X)/tau * dt + sigma*dW \"\"\" def __init__ ( self , mu , sigma , tau , n = 1 , seed = None , ): \"\"\" :param mu: Drift of the OU process :type mu: float :param sigma: Standard deviation of the Wiener process, i.e. strength of the noise :type sigma: float :param tau: Timescale of the OU process, in ms :type tau: float \"\"\" self . mu = mu self . sigma = sigma self . tau = tau super () . __init__ ( n = n , seed = seed , ) def generate_input ( self , duration , dt ): self . _get_times ( duration = duration , dt = dt ) x = np . random . rand ( self . n , self . times . shape [ 0 ]) * self . mu return self . numba_ou ( x , self . times , dt , self . mu , self . sigma , self . tau , self . n ) @staticmethod @numba . njit () def numba_ou ( x , times , dt , mu , sigma , tau , n ): \"\"\" Generation of Ornstein-Uhlenback input - wrapped in numba's jit for speed. \"\"\" for i in range ( times . shape [ 0 ] - 1 ): x [:, i + 1 ] = x [:, i ] + dt * (( mu - x [:, i ]) / tau ) + sigma * np . sqrt ( dt ) * np . random . randn ( n ) return x","title":"OrnsteinUhlenbeckProcess"},{"location":"utils/stimulus/#neurolib.utils.stimulus.OrnsteinUhlenbeckProcess.__init__","text":"Parameters: Name Type Description Default mu float Drift of the OU process required sigma float Standard deviation of the Wiener process, i.e. strength of the noise required tau float Timescale of the OU process, in ms required Source code in neurolib/utils/stimulus.py def __init__ ( self , mu , sigma , tau , n = 1 , seed = None , ): \"\"\" :param mu: Drift of the OU process :type mu: float :param sigma: Standard deviation of the Wiener process, i.e. strength of the noise :type sigma: float :param tau: Timescale of the OU process, in ms :type tau: float \"\"\" self . mu = mu self . sigma = sigma self . tau = tau super () . __init__ ( n = n , seed = seed , )","title":"__init__()"},{"location":"utils/stimulus/#neurolib.utils.stimulus.OrnsteinUhlenbeckProcess.generate_input","text":"Function to generate input. Parameters: Name Type Description Default duration float Duration of the input, in milliseconds required dt float dt of input, in milliseconds required Source code in neurolib/utils/stimulus.py def generate_input ( self , duration , dt ): self . _get_times ( duration = duration , dt = dt ) x = np . random . rand ( self . n , self . times . shape [ 0 ]) * self . mu return self . numba_ou ( x , self . times , dt , self . mu , self . sigma , self . tau , self . n )","title":"generate_input()"},{"location":"utils/stimulus/#neurolib.utils.stimulus.OrnsteinUhlenbeckProcess.numba_ou","text":"Generation of Ornstein-Uhlenback input - wrapped in numba's jit for speed. Source code in neurolib/utils/stimulus.py @staticmethod @numba . njit () def numba_ou ( x , times , dt , mu , sigma , tau , n ): \"\"\" Generation of Ornstein-Uhlenback input - wrapped in numba's jit for speed. \"\"\" for i in range ( times . shape [ 0 ] - 1 ): x [:, i + 1 ] = x [:, i ] + dt * (( mu - x [:, i ]) / tau ) + sigma * np . sqrt ( dt ) * np . random . randn ( n ) return x","title":"numba_ou()"},{"location":"utils/stimulus/#neurolib.utils.stimulus.SinusoidalInput","text":"Sinusoidal input. Source code in neurolib/utils/stimulus.py class SinusoidalInput ( Stimulus ): \"\"\" Sinusoidal input. \"\"\" def __init__ ( self , amplitude , frequency , dc_bias = False , start = None , end = None , n = 1 , seed = None , ): \"\"\" :param amplitude: Amplitude of the sinusoid. :type amplitude: float :param frequency: Frequency of the sinus oscillation, in Hz :type frequency: float :param dc_bias: Whether the sinusoid oscillates around 0 (False), or has a positive DC bias, thus non-negative (True). :type dc_bias: bool \"\"\" self . amplitude = amplitude self . frequency = frequency self . dc_bias = dc_bias super () . __init__ ( start = start , end = end , n = n , seed = seed , ) def generate_input ( self , duration , dt ): self . _get_times ( duration = duration , dt = dt ) sinusoid = self . amplitude * np . sin ( 2 * np . pi * self . times * ( self . frequency / 1000.0 )) if self . dc_bias : sinusoid += self . amplitude return self . _trim_stim ( np . vstack ([ sinusoid ] * self . n ))","title":"SinusoidalInput"},{"location":"utils/stimulus/#neurolib.utils.stimulus.SinusoidalInput.__init__","text":"Parameters: Name Type Description Default amplitude float Amplitude of the sinusoid. required frequency float Frequency of the sinus oscillation, in Hz required dc_bias bool Whether the sinusoid oscillates around 0 (False), or has a positive DC bias, thus non-negative (True). False Source code in neurolib/utils/stimulus.py def __init__ ( self , amplitude , frequency , dc_bias = False , start = None , end = None , n = 1 , seed = None , ): \"\"\" :param amplitude: Amplitude of the sinusoid. :type amplitude: float :param frequency: Frequency of the sinus oscillation, in Hz :type frequency: float :param dc_bias: Whether the sinusoid oscillates around 0 (False), or has a positive DC bias, thus non-negative (True). :type dc_bias: bool \"\"\" self . amplitude = amplitude self . frequency = frequency self . dc_bias = dc_bias super () . __init__ ( start = start , end = end , n = n , seed = seed , )","title":"__init__()"},{"location":"utils/stimulus/#neurolib.utils.stimulus.SinusoidalInput.generate_input","text":"Function to generate input. Parameters: Name Type Description Default duration float Duration of the input, in milliseconds required dt float dt of input, in milliseconds required Source code in neurolib/utils/stimulus.py def generate_input ( self , duration , dt ): self . _get_times ( duration = duration , dt = dt ) sinusoid = self . amplitude * np . sin ( 2 * np . pi * self . times * ( self . frequency / 1000.0 )) if self . dc_bias : sinusoid += self . amplitude return self . _trim_stim ( np . vstack ([ sinusoid ] * self . n ))","title":"generate_input()"},{"location":"utils/stimulus/#neurolib.utils.stimulus.SquareInput","text":"Oscillatory square input. Source code in neurolib/utils/stimulus.py class SquareInput ( Stimulus ): \"\"\" Oscillatory square input. \"\"\" def __init__ ( self , amplitude , frequency , dc_bias = False , start = None , end = None , n = 1 , seed = None , ): \"\"\" :param amplitude: Amplitude of the square :type amplitude: float :param frequency: Frequency of the square oscillation, in Hz :type frequency: float :param dc_bias: Whether the square oscillates around 0 (False), or has a positive DC bias, thus non-negative (True). :type dc_bias: bool \"\"\" self . amplitude = amplitude self . frequency = frequency self . dc_bias = dc_bias super () . __init__ ( start = start , end = end , n = n , seed = seed , ) def generate_input ( self , duration , dt ): self . _get_times ( duration = duration , dt = dt ) square_inp = self . amplitude * square ( 2 * np . pi * self . times * ( self . frequency / 1000.0 )) if self . dc_bias : square_inp += self . amplitude return self . _trim_stim ( np . vstack ([ square_inp ] * self . n ))","title":"SquareInput"},{"location":"utils/stimulus/#neurolib.utils.stimulus.SquareInput.__init__","text":"Parameters: Name Type Description Default amplitude float Amplitude of the square required frequency float Frequency of the square oscillation, in Hz required dc_bias bool Whether the square oscillates around 0 (False), or has a positive DC bias, thus non-negative (True). False Source code in neurolib/utils/stimulus.py def __init__ ( self , amplitude , frequency , dc_bias = False , start = None , end = None , n = 1 , seed = None , ): \"\"\" :param amplitude: Amplitude of the square :type amplitude: float :param frequency: Frequency of the square oscillation, in Hz :type frequency: float :param dc_bias: Whether the square oscillates around 0 (False), or has a positive DC bias, thus non-negative (True). :type dc_bias: bool \"\"\" self . amplitude = amplitude self . frequency = frequency self . dc_bias = dc_bias super () . __init__ ( start = start , end = end , n = n , seed = seed , )","title":"__init__()"},{"location":"utils/stimulus/#neurolib.utils.stimulus.SquareInput.generate_input","text":"Function to generate input. Parameters: Name Type Description Default duration float Duration of the input, in milliseconds required dt float dt of input, in milliseconds required Source code in neurolib/utils/stimulus.py def generate_input ( self , duration , dt ): self . _get_times ( duration = duration , dt = dt ) square_inp = self . amplitude * square ( 2 * np . pi * self . times * ( self . frequency / 1000.0 )) if self . dc_bias : square_inp += self . amplitude return self . _trim_stim ( np . vstack ([ square_inp ] * self . n ))","title":"generate_input()"},{"location":"utils/stimulus/#neurolib.utils.stimulus.StepInput","text":"Step input. Source code in neurolib/utils/stimulus.py class StepInput ( Stimulus ): \"\"\" Step input. \"\"\" def __init__ ( self , step_size , start = None , end = None , n = 1 , seed = None , ): \"\"\" :param step_size: Size of the step, i.e., the amplitude. :type step_size: float \"\"\" self . step_size = step_size super () . __init__ ( start = start , end = end , n = n , seed = seed , ) def generate_input ( self , duration , dt ): self . _get_times ( duration = duration , dt = dt ) return self . _trim_stim ( np . ones (( self . n , self . times . shape [ 0 ])) * self . step_size )","title":"StepInput"},{"location":"utils/stimulus/#neurolib.utils.stimulus.StepInput.__init__","text":"Parameters: Name Type Description Default step_size float Size of the step, i.e., the amplitude. required Source code in neurolib/utils/stimulus.py def __init__ ( self , step_size , start = None , end = None , n = 1 , seed = None , ): \"\"\" :param step_size: Size of the step, i.e., the amplitude. :type step_size: float \"\"\" self . step_size = step_size super () . __init__ ( start = start , end = end , n = n , seed = seed , )","title":"__init__()"},{"location":"utils/stimulus/#neurolib.utils.stimulus.StepInput.generate_input","text":"Function to generate input. Parameters: Name Type Description Default duration float Duration of the input, in milliseconds required dt float dt of input, in milliseconds required Source code in neurolib/utils/stimulus.py def generate_input ( self , duration , dt ): self . _get_times ( duration = duration , dt = dt ) return self . _trim_stim ( np . ones (( self . n , self . times . shape [ 0 ])) * self . step_size )","title":"generate_input()"},{"location":"utils/stimulus/#neurolib.utils.stimulus.Stimulus","text":"Generates a stimulus with optional start and end times. Source code in neurolib/utils/stimulus.py class Stimulus ( Input ): \"\"\" Generates a stimulus with optional start and end times. \"\"\" def __init__ ( self , start = None , end = None , n = 1 , seed = None , ): \"\"\" :param start: start of the stimulus, in milliseconds :type start: float :param end: end of the stimulus, in milliseconds :type end: float \"\"\" self . start = start self . end = end self . _default_start = start self . _default_end = end super () . __init__ ( n = n , seed = seed , ) def _reset ( self ): self . start = self . _default_start self . end = self . _default_end def _get_times ( self , duration , dt ): super () . _get_times ( duration = duration , dt = dt ) self . start = self . start or 0.0 self . end = self . end or duration + dt assert self . start < duration assert self . end <= duration + dt def _trim_stim ( self , stim_input ): \"\"\" Trim stimulus. Translate the start of the stimulus by padding the beginning and replace the end with zeros. \"\"\" # trim start how_much = int ( np . sum ( self . times <= self . start )) # translate start of the stim by padding the beginning with zeros stim_input = np . pad ( stim_input , (( 0 , 0 ), ( how_much , 0 )), mode = \"constant\" ) if how_much > 0 : stim_input = stim_input [:, : - how_much ] # trim end stim_input [:, self . times > self . end ] = 0.0 return stim_input","title":"Stimulus"},{"location":"utils/stimulus/#neurolib.utils.stimulus.Stimulus.__init__","text":"Parameters: Name Type Description Default start float start of the stimulus, in milliseconds None end float end of the stimulus, in milliseconds None Source code in neurolib/utils/stimulus.py def __init__ ( self , start = None , end = None , n = 1 , seed = None , ): \"\"\" :param start: start of the stimulus, in milliseconds :type start: float :param end: end of the stimulus, in milliseconds :type end: float \"\"\" self . start = start self . end = end self . _default_start = start self . _default_end = end super () . __init__ ( n = n , seed = seed , )","title":"__init__()"},{"location":"utils/stimulus/#neurolib.utils.stimulus.SummedStimulus","text":"Represents the summation of arbitrary many stimuli. Example: summed_stimulus = SinusoidalInput(...) + OrnsteinUhlenbeckProcess(...) Source code in neurolib/utils/stimulus.py class SummedStimulus ( BaseMultipleInputs ): \"\"\" Represents the summation of arbitrary many stimuli. Example: ``` summed_stimulus = SinusoidalInput(...) + OrnsteinUhlenbeckProcess(...) ``` \"\"\" def __add__ ( self , other ): assert isinstance ( other , Input ) assert self . n == other . n if isinstance ( other , SummedStimulus ): return SummedStimulus ( inputs = self . inputs + other . inputs ) else : return SummedStimulus ( inputs = self . inputs + [ other ]) def as_array ( self , duration , dt ): \"\"\" Return sum of all inputes as numpy array. \"\"\" return np . sum ( np . stack ([ input . as_array ( duration , dt ) for input in self . inputs ]), axis = 0 , ) def as_cubic_splines ( self , duration , dt , shift_start_time = 0.0 ): \"\"\" Return sum of all inputes as cubic Hermite splines. \"\"\" result = self . inputs [ 0 ] . as_cubic_splines ( duration , dt , shift_start_time ) for input in self . inputs [ 1 :]: result . plus ( input . as_cubic_splines ( duration , dt , shift_start_time )) return result","title":"SummedStimulus"},{"location":"utils/stimulus/#neurolib.utils.stimulus.SummedStimulus.as_array","text":"Return sum of all inputes as numpy array. Source code in neurolib/utils/stimulus.py def as_array ( self , duration , dt ): \"\"\" Return sum of all inputes as numpy array. \"\"\" return np . sum ( np . stack ([ input . as_array ( duration , dt ) for input in self . inputs ]), axis = 0 , )","title":"as_array()"},{"location":"utils/stimulus/#neurolib.utils.stimulus.SummedStimulus.as_cubic_splines","text":"Return sum of all inputes as cubic Hermite splines. Source code in neurolib/utils/stimulus.py def as_cubic_splines ( self , duration , dt , shift_start_time = 0.0 ): \"\"\" Return sum of all inputes as cubic Hermite splines. \"\"\" result = self . inputs [ 0 ] . as_cubic_splines ( duration , dt , shift_start_time ) for input in self . inputs [ 1 :]: result . plus ( input . as_cubic_splines ( duration , dt , shift_start_time )) return result","title":"as_cubic_splines()"},{"location":"utils/stimulus/#neurolib.utils.stimulus.WienerProcess","text":"Stimulus sampled from a Wiener process, i.e. drawn from standard normal distribution N(0, sqrt(dt)). Source code in neurolib/utils/stimulus.py class WienerProcess ( Input ): \"\"\" Stimulus sampled from a Wiener process, i.e. drawn from standard normal distribution N(0, sqrt(dt)). \"\"\" def generate_input ( self , duration , dt ): self . _get_times ( duration = duration , dt = dt ) return np . random . normal ( 0.0 , np . sqrt ( dt ), ( self . n , self . times . shape [ 0 ]))","title":"WienerProcess"},{"location":"utils/stimulus/#neurolib.utils.stimulus.WienerProcess.generate_input","text":"Function to generate input. Parameters: Name Type Description Default duration float Duration of the input, in milliseconds required dt float dt of input, in milliseconds required Source code in neurolib/utils/stimulus.py def generate_input ( self , duration , dt ): self . _get_times ( duration = duration , dt = dt ) return np . random . normal ( 0.0 , np . sqrt ( dt ), ( self . n , self . times . shape [ 0 ]))","title":"generate_input()"},{"location":"utils/stimulus/#neurolib.utils.stimulus.ZeroInput","text":"No stimulus, i.e. all zeros. Can be used to add a delay between two stimuli. Source code in neurolib/utils/stimulus.py class ZeroInput ( Input ): \"\"\" No stimulus, i.e. all zeros. Can be used to add a delay between two stimuli. \"\"\" def generate_input ( self , duration , dt ): self . _get_times ( duration = duration , dt = dt ) return np . zeros (( self . n , self . times . shape [ 0 ]))","title":"ZeroInput"},{"location":"utils/stimulus/#neurolib.utils.stimulus.ZeroInput.generate_input","text":"Function to generate input. Parameters: Name Type Description Default duration float Duration of the input, in milliseconds required dt float dt of input, in milliseconds required Source code in neurolib/utils/stimulus.py def generate_input ( self , duration , dt ): self . _get_times ( duration = duration , dt = dt ) return np . zeros (( self . n , self . times . shape [ 0 ]))","title":"generate_input()"},{"location":"utils/stimulus/#neurolib.utils.stimulus.RectifiedInput","text":"Return rectified input with exponential decay, i.e. a negative step followed by a slow decay to zero, followed by a positive step and again a slow decay to zero. Can be used for bistablity detection. Parameters: Name Type Description Default amplitude float Amplitude (both negative and positive) for the step required n int Number of realizations (spatial dimension) 1 Returns: Type Description `ConctatenatedInput` Concatenated input which represents the rectified stimulus with exponential decay Source code in neurolib/utils/stimulus.py def RectifiedInput ( amplitude , n = 1 ): \"\"\" Return rectified input with exponential decay, i.e. a negative step followed by a slow decay to zero, followed by a positive step and again a slow decay to zero. Can be used for bistablity detection. :param amplitude: Amplitude (both negative and positive) for the step :type amplitude: float :param n: Number of realizations (spatial dimension) :type n: int :return: Concatenated input which represents the rectified stimulus with exponential decay :rtype: `ConctatenatedInput` \"\"\" return ConcatenatedStimulus ( [ StepInput ( step_size =- amplitude , n = n ), ExponentialInput ( inp_max = amplitude , exp_type = \"rise\" , exp_coef = 12.5 , n = n ) + StepInput ( step_size =- amplitude , n = n ), StepInput ( step_size = amplitude , n = n ), ExponentialInput ( amplitude , exp_type = \"decay\" , exp_coef = 7.5 , n = n ), StepInput ( step_size = 0.0 , n = n ), ], length_ratios = [ 0.5 , 2.5 , 0.5 , 1.5 , 1.0 ], )","title":"RectifiedInput()"}]}